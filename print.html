<!DOCTYPE HTML>
<html lang="en" class="light" dir="ltr">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>MongoDB Driver Specifications</title>
        <meta name="robots" content="noindex">


        <!-- Custom HTML head -->
        
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff">

        <link rel="icon" href="favicon.svg">
        <link rel="shortcut icon" href="favicon.png">
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        <link rel="stylesheet" href="css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="highlight.css">
        <link rel="stylesheet" href="tomorrow-night.css">
        <link rel="stylesheet" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->

    </head>
    <body class="sidebar-visible no-js">
    <div id="body-container">
        <!-- Provide site root to javascript -->
        <script>
            var path_to_root = "";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('light')
            html.classList.add(theme);
            var body = document.querySelector('body');
            body.classList.remove('no-js')
            body.classList.add('js');
        </script>

        <input type="checkbox" id="sidebar-toggle-anchor" class="hidden">

        <!-- Hide / unhide sidebar before it is displayed -->
        <script>
            var body = document.querySelector('body');
            var sidebar = null;
            var sidebar_toggle = document.getElementById("sidebar-toggle-anchor");
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            } else {
                sidebar = 'hidden';
            }
            sidebar_toggle.checked = sidebar === 'visible';
            body.classList.remove('sidebar-visible');
            body.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item expanded affix "><a href="index.html">Introduction</a></li><li class="chapter-item expanded affix "><a href="driver-mantras.html">Mantras</a></li><li class="chapter-item expanded affix "><a href="wireversion-featurelist/wireversion-featurelist.html">Wire Version Feature List</a></li><li class="chapter-item expanded affix "><li class="part-title">Specifications</li><li class="chapter-item expanded "><div><strong aria-hidden="true">1.</strong> Serialization</div></li><li><ol class="section"><li class="chapter-item expanded "><a href="BSON.html"><strong aria-hidden="true">1.1.</strong> BSON</a></li><li class="chapter-item expanded "><a href="bson-objectid/objectid.html"><strong aria-hidden="true">1.2.</strong> ObjectId</a></li><li class="chapter-item expanded "><a href="bson-decimal128/decimal128.html"><strong aria-hidden="true">1.3.</strong> Decimal128</a></li><li class="chapter-item expanded "><a href="bson-binary-uuid/uuid.html"><strong aria-hidden="true">1.4.</strong> UUID</a></li><li class="chapter-item expanded "><a href="dbref/dbref.html"><strong aria-hidden="true">1.5.</strong> DBRef</a></li><li class="chapter-item expanded "><a href="extended-json/extended-json.html"><strong aria-hidden="true">1.6.</strong> Extended JSON</a></li></ol></li><li class="chapter-item expanded "><li class="spacer"></li><li class="chapter-item expanded "><div><strong aria-hidden="true">2.</strong> Communication</div></li><li><ol class="section"><li class="chapter-item expanded "><a href="message/OP_MSG.html"><strong aria-hidden="true">2.1.</strong> OP_MSG</a></li><li class="chapter-item expanded "><a href="run-command/run-command.html"><strong aria-hidden="true">2.2.</strong> Command Execution</a></li><li class="chapter-item expanded "><a href="connection-string/connection-string-spec.html"><strong aria-hidden="true">2.3.</strong> Connection String</a></li><li class="chapter-item expanded "><a href="uri-options/uri-options.html"><strong aria-hidden="true">2.4.</strong> URI Options</a></li><li class="chapter-item expanded "><a href="ocsp-support/ocsp-support.html"><strong aria-hidden="true">2.5.</strong> OCSP</a></li><li class="chapter-item expanded "><a href="mongodb-handshake/handshake.html"><strong aria-hidden="true">2.6.</strong> Initial Handshake</a></li><li class="chapter-item expanded "><a href="compression/OP_COMPRESSED.html"><strong aria-hidden="true">2.7.</strong> Wire Compression</a></li><li class="chapter-item expanded "><a href="socks5-support/socks5.html"><strong aria-hidden="true">2.8.</strong> SOCKS5</a></li><li class="chapter-item expanded "><a href="initial-dns-seedlist-discovery/initial-dns-seedlist-discovery.html"><strong aria-hidden="true">2.9.</strong> Initial DNS Seedlist Discovery</a></li></ol></li><li class="chapter-item expanded "><li class="spacer"></li><li class="chapter-item expanded "><div><strong aria-hidden="true">3.</strong> Connectivity</div></li><li><ol class="section"><li class="chapter-item expanded "><a href="server-discovery-and-monitoring/server-discovery-and-monitoring.html"><strong aria-hidden="true">3.1.</strong> Server Discovery and Monitoring</a></li><li class="chapter-item expanded "><a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html"><strong aria-hidden="true">3.2.</strong> Connection Monitoring and Pooling</a></li><li class="chapter-item expanded "><a href="load-balancers/load-balancers.html"><strong aria-hidden="true">3.3.</strong> Load Balancer Support</a></li></ol></li><li class="chapter-item expanded "><li class="spacer"></li><li class="chapter-item expanded "><div><strong aria-hidden="true">4.</strong> Availability</div></li><li><ol class="section"><li class="chapter-item expanded "><a href="server-discovery-and-monitoring/server-monitoring.html"><strong aria-hidden="true">4.1.</strong> Server Monitoring</a></li><li class="chapter-item expanded "><a href="polling-srv-records-for-mongos-discovery/polling-srv-records-for-mongos-discovery.html"><strong aria-hidden="true">4.2.</strong> SRV Polling for mongos Discovery</a></li><li class="chapter-item expanded "><a href="server-selection/server-selection.html"><strong aria-hidden="true">4.3.</strong> Server Selection</a></li><li class="chapter-item expanded "><a href="max-staleness/max-staleness.html"><strong aria-hidden="true">4.4.</strong> Max Staleness</a></li></ol></li><li class="chapter-item expanded "><li class="spacer"></li><li class="chapter-item expanded "><div><strong aria-hidden="true">5.</strong> Resilience</div></li><li><ol class="section"><li class="chapter-item expanded "><div><strong aria-hidden="true">5.1.</strong> Retryability</div></li><li><ol class="section"><li class="chapter-item expanded "><a href="retryable-reads/retryable-reads.html"><strong aria-hidden="true">5.1.1.</strong> Reads</a></li><li class="chapter-item expanded "><a href="retryable-writes/retryable-writes.html"><strong aria-hidden="true">5.1.2.</strong> Writes</a></li></ol></li><li class="chapter-item expanded "><a href="client-side-operations-timeout/client-side-operations-timeout.html"><strong aria-hidden="true">5.2.</strong> CSOT</a></li><li class="chapter-item expanded "><div><strong aria-hidden="true">5.3.</strong> Consistency</div></li><li><ol class="section"><li class="chapter-item expanded "><a href="sessions/driver-sessions.html"><strong aria-hidden="true">5.3.1.</strong> Sessions</a></li><li class="chapter-item expanded "><a href="causal-consistency/causal-consistency.html"><strong aria-hidden="true">5.3.2.</strong> Causal Consistency</a></li><li class="chapter-item expanded "><a href="sessions/snapshot-sessions.html"><strong aria-hidden="true">5.3.3.</strong> Snapshot Reads</a></li><li class="chapter-item expanded "><a href="transactions/transactions.html"><strong aria-hidden="true">5.3.4.</strong> Transactions</a></li><li class="chapter-item expanded "><a href="transactions-convenient-api/transactions-convenient-api.html"><strong aria-hidden="true">5.3.5.</strong> Convenient Transactions API</a></li></ol></li></ol></li><li class="chapter-item expanded "><li class="spacer"></li><li class="chapter-item expanded "><div><strong aria-hidden="true">6.</strong> Programmability</div></li><li><ol class="section"><li class="chapter-item expanded "><div><strong aria-hidden="true">6.1.</strong> Resource Management</div></li><li><ol class="section"><li class="chapter-item expanded "><a href="enumerate-databases/enumerate-databases.html"><strong aria-hidden="true">6.1.1.</strong> Databases</a></li><li class="chapter-item expanded "><a href="enumerate-collections/enumerate-collections.html"><strong aria-hidden="true">6.1.2.</strong> Collections</a></li><li class="chapter-item expanded "><a href="index-management/index-management.html"><strong aria-hidden="true">6.1.3.</strong> Indexes</a></li></ol></li><li class="chapter-item expanded "><div><strong aria-hidden="true">6.2.</strong> Data Management</div></li><li><ol class="section"><li class="chapter-item expanded "><a href="crud/crud.html"><strong aria-hidden="true">6.2.1.</strong> CRUD</a></li><li class="chapter-item expanded "><a href="collation/collation.html"><strong aria-hidden="true">6.2.2.</strong> Collation</a></li><li class="chapter-item expanded "><a href="server_write_commands/server_write_commands.html"><strong aria-hidden="true">6.2.3.</strong> Write Commands</a></li><li class="chapter-item expanded "><a href="driver-bulk-update.html"><strong aria-hidden="true">6.2.4.</strong> Bulk API</a></li><li class="chapter-item expanded "><a href="crud/bulk-write.html"><strong aria-hidden="true">6.2.5.</strong> Bulk Write</a></li><li class="chapter-item expanded "><a href="read-write-concern/read-write-concern.html"><strong aria-hidden="true">6.2.6.</strong> R/W Concern</a></li></ol></li><li class="chapter-item expanded "><div><strong aria-hidden="true">6.3.</strong> Cursors</div></li><li><ol class="section"><li class="chapter-item expanded "><a href="change-streams/change-streams.html"><strong aria-hidden="true">6.3.1.</strong> Change Streams</a></li><li class="chapter-item expanded "><a href="find_getmore_killcursors_commands/find_getmore_killcursors_commands.html"><strong aria-hidden="true">6.3.2.</strong> find/getMore/killCursors</a></li></ol></li><li class="chapter-item expanded "><a href="gridfs/gridfs-spec.html"><strong aria-hidden="true">6.4.</strong> GridFS</a></li><li class="chapter-item expanded "><a href="versioned-api/versioned-api.html"><strong aria-hidden="true">6.5.</strong> Stable API</a></li><li class="chapter-item expanded "><div><strong aria-hidden="true">6.6.</strong> Security</div></li><li><ol class="section"><li class="chapter-item expanded "><a href="client-side-encryption/client-side-encryption.html"><strong aria-hidden="true">6.6.1.</strong> Client Side Encryption</a></li><li class="chapter-item expanded "><a href="bson-binary-encrypted/binary-encrypted.html"><strong aria-hidden="true">6.6.2.</strong> BSON Binary Subtype 6</a></li></ol></li></ol></li><li class="chapter-item expanded "><li class="spacer"></li><li class="chapter-item expanded "><div><strong aria-hidden="true">7.</strong> Observability</div></li><li><ol class="section"><li class="chapter-item expanded "><a href="command-logging-and-monitoring/command-logging-and-monitoring.html"><strong aria-hidden="true">7.1.</strong> Command Logging and Monitoring</a></li><li class="chapter-item expanded "><a href="server-discovery-and-monitoring/server-discovery-and-monitoring-logging-and-monitoring.html"><strong aria-hidden="true">7.2.</strong> SDAM Logging and Monitoring</a></li><li class="chapter-item expanded "><a href="logging/logging.html"><strong aria-hidden="true">7.3.</strong> Standardized Logging</a></li><li class="chapter-item expanded "><a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html"><strong aria-hidden="true">7.4.</strong> Connection Pool Logging</a></li></ol></li><li class="chapter-item expanded "><li class="spacer"></li><li class="chapter-item expanded "><div><strong aria-hidden="true">8.</strong> Testability</div></li><li><ol class="section"><li class="chapter-item expanded "><a href="unified-test-format/unified-test-format.html"><strong aria-hidden="true">8.1.</strong> Unified Test Format</a></li><li class="chapter-item expanded "><a href="atlas-data-lake-testing/tests/index.html"><strong aria-hidden="true">8.2.</strong> Atlas Data Federation Testing</a></li><li class="chapter-item expanded "><a href="benchmarking/benchmarking.html"><strong aria-hidden="true">8.3.</strong> Performance Benchmarking</a></li><li class="chapter-item expanded "><a href="bson-corpus/bson-corpus.html"><strong aria-hidden="true">8.4.</strong> BSON Corpus</a></li><li class="chapter-item expanded "><a href="connections-survive-step-down/tests/index.html"><strong aria-hidden="true">8.5.</strong> Replication Event Resilience</a></li><li class="chapter-item expanded "><a href="faas-automated-testing/faas-automated-testing.html"><strong aria-hidden="true">8.6.</strong> FAAS Automated Testing</a></li><li class="chapter-item expanded "><a href="serverless-testing/index.html"><strong aria-hidden="true">8.7.</strong> Atlas Serverless Testing</a></li></ol></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle">
                <div class="sidebar-resize-indicator"></div>
            </div>
        </nav>

        <!-- Track and set sidebar scroll position -->
        <script>
            var sidebarScrollbox = document.querySelector('#sidebar .sidebar-scrollbox');
            sidebarScrollbox.addEventListener('click', function(e) {
                if (e.target.tagName === 'A') {
                    sessionStorage.setItem('sidebar-scroll', sidebarScrollbox.scrollTop);
                }
            }, { passive: true });
            var sidebarScrollTop = sessionStorage.getItem('sidebar-scroll');
            sessionStorage.removeItem('sidebar-scroll');
            if (sidebarScrollTop) {
                // preserve sidebar scroll position when navigating via links within sidebar
                sidebarScrollbox.scrollTop = sidebarScrollTop;
            } else {
                // scroll sidebar to current active section when navigating via "next/previous chapter" buttons
                var activeSection = document.querySelector('#sidebar .active');
                if (activeSection) {
                    activeSection.scrollIntoView({ block: 'center' });
                }
            }
        </script>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky">
                    <div class="left-buttons">
                        <label id="sidebar-toggle" class="icon-button" for="sidebar-toggle-anchor" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </label>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">MongoDB Driver Specifications</h1>

                    <div class="right-buttons">
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>

                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script>
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1 id="mongodb-driver-specifications"><a class="header" href="#mongodb-driver-specifications">MongoDB Driver Specifications</a></h1>
<p>The modern MongoDB driver consists of a number of components, each of which are thoroughly documented in <a href="https://github.com/mongodb/specifications">this repository</a>. Though this information is readily available and extremely helpful, what it lacks is a high level overview to tie the specs together into a cohesive picture of what a MongoDB driver is.</p>
<p>Architecturally an implicit hierarchy exists within the drivers, so expressing drivers in terms of an <a href="https://en.wikipedia.org/wiki/Onion_model">onion model</a> feels appropriate.</p>
<h2 id="layers-of-the-onion"><a class="header" href="#layers-of-the-onion">Layers of the Onion</a></h2>
<p><img src="drivers-onion.png" alt="" /></p>
<p>The <em>"drivers onion"</em> is meant to represent how various concepts, components and APIs can be layered atop each other to build a MongoDB driver from the ground up, or to help understand how existing drivers have been structured. Hopefully this representation of MongoDB’s drivers helps provide some clarity, as the complexity of these libraries - like the onion above - could otherwise bring you to tears.</p>
<h3 id="serialization"><a class="header" href="#serialization">Serialization</a></h3>
<p>At their lowest level all MongoDB drivers will need to know how to work with <a href="https://bsonspec.org/">BSON</a>. BSON (short for "Binary JSON") is a bin­ary-en­coded serialization of <a href="https://www.json.org/json-en.html">JSON</a>-like documents, and like JSON, it sup­ports the nesting of arrays and documents. BSON also contains extensions that al­low representation of data types that are not part of the <a href="https://datatracker.ietf.org/doc/html/rfc7159">JSON spec</a>.</p>
<blockquote>
<p><strong>Specifications:</strong> <a href="https://bsonspec.org/spec.html">BSON</a>, <a href="bson-objectid/objectid.html">ObjectId</a>, <a href="bson-decimal128/decimal128.html">Decimal128</a>, <a href="bson-binary-uuid/uuid.html">UUID</a>, <a href="dbref/dbref.html">DBRef</a>, <a href="extended-json/extended-json.html">Extended JSON</a></p>
</blockquote>
<h3 id="communication"><a class="header" href="#communication">Communication</a></h3>
<p>Once BSON documents can be created and manipulated, the foundation for interacting with a MongoDB host process has been laid. Drivers communicate by sending <a href="https://www.mongodb.com/docs/manual/reference/command/">database commands</a> as serialized BSON documents using MongoDB’s <a href="https://www.mongodb.com/docs/manual/reference/mongodb-wire-protocol/">wire protocol</a>.</p>
<p>From the provided connection string and options a socket connection is established to a host, which an initial handshake verifies is in fact a valid MongoDB connection by sending a simple <a href="https://www.mongodb.com/docs/manual/reference/command/hello/"><code>hello</code></a>. Based on the response to this first command a driver can continue to establish and authenticate connections.</p>
<blockquote>
<p><strong>Specifications:</strong> <a href="message/OP_MSG.html"><code>OP_MSG</code></a>, <a href="run-command/run-command.html">Command Execution</a>, <a href="connection-string/connection-string-spec.html">Connection String</a>, <a href="uri-options/uri-options.html">URI Options</a>, <a href="ocsp-support/ocsp-support.html">OCSP</a>, <a href="mongodb-handshake/handshake.html">Initial Handshake</a>, <a href="compression/OP_COMPRESSED.html">Wire Compression</a>, <a href="socks5-support/socks5.html">SOCKS5</a>, <a href="initial-dns-seedlist-discovery/initial-dns-seedlist-discovery.html">Initial DNS Seedlist Discovery</a></p>
</blockquote>
<h3 id="connectivity"><a class="header" href="#connectivity">Connectivity</a></h3>
<p>Now that a valid host has been found, the cluster’s topology can be discovered and monitoring connections can be established. Connection pools can then be created and populated with connections. The monitoring connections will subsequently be used for ensuring operations are routed to available hosts, or hosts that meet certain criteria (such as a configured <a href="https://www.mongodb.com/docs/upcoming/core/read-preference/">read preference</a> or acceptable latency window).</p>
<blockquote>
<p><strong>Specifications:</strong> <a href="server-discovery-and-monitoring/server-discovery-and-monitoring.html">SDAM</a>, <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html">CMAP</a>, <a href="load-balancers/load-balancers.html">Load Balancer Support</a></p>
</blockquote>
<h3 id="authentication"><a class="header" href="#authentication">Authentication</a></h3>
<p>Establishing and monitoring connections to MongoDB ensures they’re available, but MongoDB server processes typically will require the connection to be <a href="https://www.mongodb.com/docs/manual/core/authentication/">authenticated</a> before commands will be accepted. MongoDB offers many authentication mechanisms such as <a href="https://www.mongodb.com/docs/manual/core/security-scram">SCRAM</a>, <a href="https://www.mongodb.com/docs/manual/core/security-x.509/">x.509</a>, <a href="https://www.mongodb.com/docs/manual/core/kerberos/">Kerberos</a>, <a href="https://www.mongodb.com/docs/manual/core/security-ldap/">LDAP</a>, <a href="https://www.mongodb.com/docs/manual/core/security-oidc/">OpenID Connect</a> and <a href="https://www.mongodb.com/docs/atlas/security/passwordless-authentication/">AWS IAM</a>, which MongoDB drivers support using the <em><a href="https://www.ietf.org/rfc/rfc4422.txt">Simple Authentication and Security Layer</a></em> (SASL) framework.</p>
<blockquote>
<p><strong>Specifications:</strong> <a href="auth/auth.html">Authentication</a></p>
</blockquote>
<h3 id="availability"><a class="header" href="#availability">Availability</a></h3>
<p>All client operations will be serialized as BSON and sent to MongoDB over a connection that will first be checked out of a connection pool. Various monitoring processes exist to ensure a driver’s internal state machine contains an accurate view of the cluster’s topology so that read and write requests can always be appropriately routed according to MongoDB’s <a href="https://www.mongodb.com/docs/manual/core/read-preference-mechanics/">server selection algorithm</a>.</p>
<blockquote>
<p><strong>Specifications:</strong> <a href="server-discovery-and-monitoring/server-monitoring.html">Server Monitoring</a>, <a href="polling-srv-records-for-mongos-discovery/polling-srv-records-for-mongos-discovery.html"><code>SRV</code> Polling for mongos Discovery</a>, <a href="server-selection/server-selection.html">Server Selection</a>, <a href="max-staleness/max-staleness.html">Max Staleness</a></p>
</blockquote>
<h3 id="resilience"><a class="header" href="#resilience">Resilience</a></h3>
<p>At their core, database drivers are client libraries meant to facilitate interactions between an application and the database. MongoDB’s drivers are no different in that regard, as they abstract away the underlying serialization, communication, connectivity, and availability functions required to programmatically interact with your data.</p>
<p>To further enhance the developer experience while working with MongoDB, various resilience features can be added based on <a href="https://www.mongodb.com/docs/manual/reference/server-sessions/">logical sessions</a> such as <a href="https://www.mongodb.com/docs/manual/core/retryable-writes">retryable writes</a>, <a href="https://www.mongodb.com/docs/manual/core/read-isolation-consistency-recency/#std-label-causal-consistency">causal consistency</a>, and <a href="https://www.mongodb.com/docs/manual/core/transactions/">transactions</a>.</p>
<blockquote>
<p><strong>Specifications:</strong> Retryability (<a href="retryable-reads/retryable-reads.html">Reads</a>, <a href="retryable-writes/retryable-writes.html">Writes</a>), <a href="client-side-operations-timeout/client-side-operations-timeout.html">CSOT</a>, Consistency (<a href="sessions/driver-sessions.html">Sessions</a>, <a href="causal-consistency/causal-consistency.html">Causal Consistency</a>, <a href="sessions/snapshot-sessions.html">Snapshot Reads</a>, <a href="transactions/transactions.html">Transactions</a>, <a href="transactions-convenient-api/transactions-convenient-api.html">Convenient Transactions API</a>)</p>
</blockquote>
<h3 id="programmability"><a class="header" href="#programmability">Programmability</a></h3>
<p>Now that we can serialize commands and send them over the wire through an authenticated connection we can begin actually manipulating data. Since all database interactions are in the form of commands, if we wanted to remove a single document we might issue a <a href="https://www.mongodb.com/docs/manual/reference/command/delete"><code>delete</code> command</a> such as the following:</p>
<pre><code class="language-js">db.runCommand(
  {
     delete: "orders",
     deletes: [ { q: { status: "D" }, limit: 0 } ]
  }
)
</code></pre>
<p>Though not exceedingly complex, a better developer experience can be achieved through more single-purpose APIs. This would allow the above example to be expressed as:</p>
<pre><code class="language-js">db.orders.deleteMany({ status: "D" })
</code></pre>
<p>To provide a cleaner and clearer developer experience, many specifications exist to describe how these APIs should be consistently presented across driver implementations, while still providing the flexibility to make APIs more idiomatic for each language.</p>
<p>Advanced security features such as <a href="https://www.mongodb.com/docs/manual/core/csfle/">client-side field level encryption</a> are also defined at this layer.</p>
<blockquote>
<p><strong>Specifications:</strong> Resource Management (<a href="enumerate-databases/enumerate-databases.html">Databases</a>, <a href="enumerate-collections/enumerate-collections.html">Collections</a>, <a href="index-management/index-management.html">Indexes</a>), Data Management (<a href="crud/crud.html">CRUD</a>, <a href="collation/collation.html">Collation</a>, <a href="server_write_commands/server_write_commands.html">Write Commands</a>, <a href="driver-bulk-update.html">Bulk API</a>, <a href="crud/bulk-write.html">Bulk Write</a>, <a href="read-write-concern/read-write-concern.html">R/W Concern</a>), Cursors (<a href="change-streams/change-streams.html">Change Streams</a>, <a href="find_getmore_killcursors_commands/find_getmore_killcursors_commands.html"><code>find</code>/<code>getMore</code>/<code>killCursors</code></a>), <a href="gridfs/gridfs-spec.html">GridFS</a>, <a href="versioned-api/versioned-api.html">Stable API</a>, Security (<a href="client-side-encryption/client-side-encryption.html">Client Side Encryption</a>, <a href="bson-binary-encrypted/binary-encrypted.html">BSON Binary Subtype 6</a>)</p>
</blockquote>
<h3 id="observability"><a class="header" href="#observability">Observability</a></h3>
<p>With database commands being serialized and sent to MongoDB servers and responses being received and deserialized, our driver can be considered fully functional for most read and write operations. As MongoDB drivers abstract away most of the complexity involved with creating and maintaining the connections these commands will be sent over, providing mechanisms for introspection into a driver’s functionality can provide developers with added confidence that things are working as expected.</p>
<p>The inner workings of connection pools, connection lifecycle, server monitoring, topology changes, command execution and other driver components are exposed by means of events developers can register listeners to capture. This can be an invaluable troubleshooting tool and can help facilitate monitoring the health of an application.</p>
<pre><code class="language-js">const { MongoClient, BSON: { EJSON } } = require('mongodb');

function debugPrint(label, event) {
 console.log(`${label}: ${EJSON.stringify(event)}`);
}

async function main() {
 const client = new MongoClient("mongodb://localhost:27017", { monitorCommands: true });
 client.on('commandStarted', (event) =&gt; debugPrint('commandStarted', event));
 client.on('connectionCheckedOut', (event) =&gt; debugPrint('connectionCheckedOut', event));
 await client.connect();
 const coll = client.db("test").collection("foo");
 const result = await coll.findOne();
 client.close();
}
main();
</code></pre>
<p>Given the example above (using the <a href="https://www.mongodb.com/docs/drivers/node/current/">Node.js driver</a>) the specified connection events and command events would be logged as they’re emitted by the driver:</p>
<p><code>connectionCheckedOut: {"time":{"$date":"2024-05-17T15:18:18.589Z"},"address":"localhost:27018","name":"connectionCheckedOut","connectionId":1}</code><br/>
<code>commandStarted: {"name":"commandStarted","address":"127.0.0.1:27018","connectionId":1,"serviceId":null,"requestId":5,"databaseName":"test","commandName":"find","command":{"find":"foo","filter":{},"limit":1,"singleBatch":true,"batchSize":1,"lsid":{"id":{"$binary":{"base64":"4B1kOPCGRUe/641MKhGT4Q==","subType":"04"}}},"$clusterTime":{"clusterTime":{"$timestamp":{"t":1715959097,"i":1}},"signature":{"hash":{"$binary":"base64":"AAAAAAAAAAAAAAAAAAAAAAAAAAA=","subType":"00"}},"keyId":0}},"$db":"test"},"serverConnectionId":140}</code></p>
<p>The preferred method of observing internal behavior would be through <a href="logging/logging.html">standardized logging</a> once it is available in all drivers (<a href="https://jira.mongodb.org/browse/DRIVERS-1204">DRIVERS-1204</a>), however until that time only event logging is consistently available. In the future additional observability tooling such as <a href="https://opentelemetry.io/">Open Telemetry</a> support may also be introduced.</p>
<blockquote>
<p><strong>Specifications:</strong> <a href="command-logging-and-monitoring/command-logging-and-monitoring.html">Command Logging and Monitoring</a>, <a href="server-discovery-and-monitoring/server-discovery-and-monitoring-logging-and-monitoring.html">SDAM Logging and Monitoring</a>, <a href="logging/logging.html">Standardized Logging</a>, <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection-pool-logging">Connection Pool Logging</a></p>
</blockquote>
<h3 id="testability"><a class="header" href="#testability">Testability</a></h3>
<p>Ensuring existing as well as net-new drivers can be effectively tested for correctness and performance, most specifications define a standard set of tests using <a href="https://web.archive.org/web/20230930061614/https://www.mongodb.com/blog/post/cat-herds-crook-yaml-test-specs-improve-driver-conformance">YAML tests to improve driver conformance</a>. This allows specification authors and maintainers to describe functionality once with the confidence that the tests can be executed alike by language-specific test runners across all drivers.</p>
<p>Though the unified test format greatly simplifies language-specific implementations, not all tests can be represented in this fashion. In those cases the specifications may describe tests to be manually implemented as prose. By limiting the number of prose tests that each driver must implement, engineers can deliver functionality with greater confidence while also minimizing the burden of upstream verification.</p>
<blockquote>
<p><strong>Specifications:</strong> <a href="unified-test-format/unified-test-format.html">Unified Test Format</a>, <a href="https://github.com/mongodb/specifications/tree/master/atlas-data-lake-testing/tests">Atlas Data Federation Testing</a>, <a href="benchmarking/benchmarking.html">Performance Benchmarking</a>, <a href="bson-corpus/bson-corpus.html">BSON Corpus</a>, <a href="https://github.com/mongodb/specifications/tree/master/connections-survive-step-down/tests">Replication Event Resilience</a>, <a href="faas-automated-testing/faas-automated-testing.html">FAAS Automated Testing</a>, <a href="serverless-testing/README.html">Atlas Serverless Testing</a></p>
</blockquote>
<h2 id="conclusion"><a class="header" href="#conclusion">Conclusion</a></h2>
<p>Most (if not all) the information required to build a new driver or maintain existing drivers technically exists within the specifications, however without a mental mode of their composition and architecture it can be extremely challenging to know where to look.</p>
<p>Peeling the <em>"drivers onion"</em> should hopefully make reasoning about them a little easier, especially with the understanding that everything can be tested to validate individual implementations are "up to spec".</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="driver-mantras"><a class="header" href="#driver-mantras">Driver Mantras</a></h1>
<p>When developing specifications -- and the drivers themselves -- we follow the following principles:</p>
<h3 id="strive-to-be-idiomatic-but-favor-consistency"><a class="header" href="#strive-to-be-idiomatic-but-favor-consistency">Strive to be idiomatic, but favor consistency</a></h3>
<p>Drivers attempt to provide the easiest way to work with MongoDB in a given language ecosystem, while specifications
attempt to provide a consistent behavior and experience across all languages. Drivers should strive to be as idiomatic
as possible while meeting the specification and staying true to the original intent.</p>
<h3 id="no-knobs"><a class="header" href="#no-knobs">No Knobs</a></h3>
<p>Too many choices stress out users. Whenever possible, we aim to minimize the number of configuration options exposed to
users. In particular, if a typical user would have no idea how to choose a correct value, we pick a good default instead
of adding a knob.</p>
<h3 id="topology-agnostic"><a class="header" href="#topology-agnostic">Topology agnostic</a></h3>
<p>Users test and deploy against different topologies or might scale up from replica sets to sharded clusters. Applications
should never need to use the driver differently based on topology type.</p>
<h3 id="where-possible-depend-on-server-to-return-errors"><a class="header" href="#where-possible-depend-on-server-to-return-errors">Where possible, depend on server to return errors</a></h3>
<p>The features available to users depend on a server's version, topology, storage engine and configuration. So that
drivers don't need to code and test all possible variations, and to maximize forward compatibility, always let users
attempt operations and let the server error when it can't comply. Exceptions should be rare: for cases where the server
might not error and correctness is at stake.</p>
<h3 id="minimize-administrative-helpers"><a class="header" href="#minimize-administrative-helpers">Minimize administrative helpers</a></h3>
<p>Administrative helpers are methods for admin tasks, like user creation. These are rarely used and have maintenance costs
as the server changes the administrative API. Don't create administrative helpers; let users rely on "RunCommand" for
administrative commands.</p>
<h3 id="check-wire-version-not-server-version"><a class="header" href="#check-wire-version-not-server-version">Check wire version, not server version</a></h3>
<p>When determining server capabilities within the driver, rely only on the maxWireVersion in the hello response, not on
the X.Y.Z server version. An exception is testing server development releases, as the server bumps wire version early
and then continues to add features until the GA.</p>
<h3 id="when-in-doubt-use-must-not-should-in-specs"><a class="header" href="#when-in-doubt-use-must-not-should-in-specs">When in doubt, use "MUST" not "SHOULD" in specs</a></h3>
<p>Specs guide our work. While there are occasionally valid technical reasons for drivers to differ in their behavior,
avoid encouraging it with a wishy-washy "SHOULD" instead of a more assertive "MUST".</p>
<h3 id="defy-augury"><a class="header" href="#defy-augury">Defy augury</a></h3>
<p>While we have some idea of what the server will do in the future, don't design features with those expectations in mind.
Design and implement based on what is expected in the next release.</p>
<p>Case Study: In designing OP_MSG, we held off on designing support for Document Sequences in Replies in drivers until the
server would support it. We subsequently decided not to implement that feature in the server.</p>
<h3 id="the-best-way-to-see-what-the-server-does-is-to-test-it"><a class="header" href="#the-best-way-to-see-what-the-server-does-is-to-test-it">The best way to see what the server does is to test it</a></h3>
<p>For any unusual case, relying on documentation or anecdote to anticipate the server's behavior in different
versions/topologies/etc. is error-prone. The best way to check the server's behavior is to use a driver or the shell and
test it directly.</p>
<h3 id="drivers-follow-semantic-versioning"><a class="header" href="#drivers-follow-semantic-versioning">Drivers follow semantic versioning</a></h3>
<p>Drivers should follow X.Y.Z versioning, where breaking API changes require a bump to X. See
<a href="https://semver.org/">semver.org</a> for more.</p>
<h3 id="backward-breaking-behavior-changes-and-semver"><a class="header" href="#backward-breaking-behavior-changes-and-semver">Backward breaking behavior changes and semver</a></h3>
<p>Backward breaking behavior changes can be more dangerous and disruptive than backward breaking API changes. When
thinking about the implications of a behavior change, ask yourself what could happen if a user upgraded your library
without carefully reading the changelog and/or adequately testing the change.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="server-wire-version-and-feature-list"><a class="header" href="#server-wire-version-and-feature-list">Server Wire version and Feature List</a></h1>
<div class="table-wrapper"><table><thead><tr><th>Server version</th><th>Wire version</th><th>Feature List</th></tr></thead><tbody>
<tr><td>2.6</td><td>1</td><td><p>Aggregation cursor</p> <p>Auth commands</p></td></tr>
<tr><td>2.6</td><td>2</td><td><p>Write commands (insert/update/delete)</p> <p>Aggregation $out pipeline operator</p></td></tr>
<tr><td>3.0</td><td>3</td><td><p>listCollections</p> <p>listIndexes</p> <p>SCRAM-SHA-1</p> <p>explain command</p></td></tr>
<tr><td>3.2</td><td>4</td><td><p>(find/getMore/killCursors) commands</p> <p>currentOp command</p> <p>fsyncUnlock command</p> <p>findAndModify take write concern</p> <p>Commands take read concern</p> <p>Document-level validation</p> <p>explain command supports distinct and findAndModify</p></td></tr>
<tr><td>3.4</td><td>5</td><td><p>Commands take write concern</p> <p>Commands take collation</p></td></tr>
<tr><td>3.6</td><td>6</td><td><p>Supports OP_MSG</p> <p>Collection-level ChangeStream support</p> <p>Retryable Writes</p> <p>Causally Consistent Reads</p> <p>Logical Sessions</p> <p>update "arrayFilters" option</p></td></tr>
<tr><td>4.0</td><td>7</td><td><p>ReplicaSet transactions</p> <p>Database and cluster-level change streams and startAtOperationTime option</p></td></tr>
<tr><td>4.2</td><td>8</td><td><p>Sharded transactions</p> <p>Aggregation $merge pipeline operator</p> <p>update "hint" option</p></td></tr>
<tr><td>4.4</td><td>9</td><td><p>Streaming protocol for SDAM</p> <p>ResumableChangeStreamError error label</p> <p>delete "hint" option</p> <p>findAndModify "hint" option</p> <p>createIndexes "commitQuorum" option</p></td></tr>
<tr><td>5.0</td><td>13</td><td>$out and $merge on secondaries (technically FCV 4.4+)</td></tr>
<tr><td>5.1</td><td>14</td><td></td></tr>
<tr><td>5.2</td><td>15</td><td></td></tr>
<tr><td>5.3</td><td>16</td><td></td></tr>
<tr><td>6.0</td><td>17</td><td><p>Support for Partial Indexes</p><p>Sharded Time Series Collections</p><p>FCV set to 5.0</p></td></tr>
<tr><td>6.1</td><td>18</td><td><p>Update Perl Compatible Regular Expressions version to PCRE2</p><p>Add <code>*UCP</code> option for regex queries</p></td></tr>
<tr><td>6.2</td><td>19</td><td><p>Collection validation ensures BSON documents conform to BSON spec</p><p>Collection validation checks time series collections for internal consistency</p></td></tr>
<tr><td>7.0</td><td>21</td><td><p>Atlas Search Index Management</p><p><code>$currentOp</code> aggregation Metrics</p><p>Compound Wildcard Indexes</p><p>Support large change stream events via <code>$changeStreamSplitLargeEvent</code> stage</p><p><code>serverStatus</code> output gets new fields</p> <p>Slot Based Query Execution</p></td></tr>
<tr><td>7.1</td><td>22</td><td><p>Improved Index Builds</p><p>Exhaust Cursors Enabled for Sharded Clusters</p><p>New Sharding Statistics for Chunk Migrations</p><p>Self-Managed Backups of Sharded Clusters</td></tr>
<tr><td>7.2</td><td>23</td><td><p>Database Validation on <code>mongos</code> Aggregation Queries</p><p><code>serverStatus</code> Metrics</p><p>Default Chunks Per Shard</p></td></tr>
<tr><td>7.3</td><td>24</td><td><p>Compaction Improvements</p><p>New <code>serverStatus</code> metrics</p></td></tr>
<tr><td>8.0</td><td>25</td><td><p>Range Encryption GA</p><p>OIDC authentication mechanism</p><p>New <code>bulkWrite</code> command</p><p><code>snapshot</code> read concern on capped collections</p></td></tr>
</tbody></table>
</div>
<p>In server versions 5.0 and earlier, the wire version was defined as a numeric literal in
<a href="https://github.com/mongodb/mongo/blob/master/src/mongo/db/wire_version.h">src/mongo/db/wire_version.h</a>. Since server
version 5.1 (<a href="https://jira.mongodb.org/browse/SERVER-58346">SERVER-58346</a>), the wire version is derived from the number
of releases since 4.0 (using
<a href="https://github.com/mongodb/mongo/blob/master/src/mongo/util/version/releases.h.tpl">src/mongo/util/version/releases.h.tpl</a>
and
<a href="https://github.com/mongodb/mongo/blob/master/src/mongo/util/version/releases.yml">src/mongo/util/version/releases.yml</a>).</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="bson"><a class="header" href="#bson">BSON</a></h1>
<p>Latest version of the specification can be found at <a href="https://bsonspec.org/spec.html">https://bsonspec.org/spec.html</a>.</p>
<hr />
<h2 id="specification-version-11"><a class="header" href="#specification-version-11">Specification Version 1.1</a></h2>
<p>BSON is a binary format in which zero or more ordered key/value pairs are stored as a single entity. We call this entity a document.</p>
<p>The following grammar specifies version 1.1 of the BSON standard. We've written the grammar using a pseudo-BNF syntax. Valid BSON data is represented by the document non-terminal.</p>
<h3 id="basic-types"><a class="header" href="#basic-types">Basic Types</a></h3>
<p>The following basic types are used as terminals in the rest of the grammar. Each type must be serialized in little-endian format.</p>
<pre><code>byte	1 byte (8-bits)
signed_byte(n)	8-bit, two's complement signed integer for which the value is n
unsigned_byte(n)	8-bit unsigned integer for which the value is n
int32	4 bytes (32-bit signed integer, two's complement)
int64	8 bytes (64-bit signed integer, two's complement)
uint64	8 bytes (64-bit unsigned integer)
double	8 bytes (64-bit IEEE 754-2008 binary floating point)
decimal128	16 bytes (128-bit IEEE 754-2008 decimal floating point)
</code></pre>
<h3 id="non-terminals"><a class="header" href="#non-terminals">Non-terminals</a></h3>
<p>The following specifies the rest of the BSON grammar. Note that we use the * operator as shorthand for repetition (e.g. (byte*2) is byte byte). When used as a unary operator, * means that the repetition can occur 0 or more times.</p>
<pre><code>document	::=	int32 e_list unsigned_byte(0)	BSON Document. int32 is the total number of bytes comprising the document.
e_list	::=	element e_list
|	""
element	::=	signed_byte(1) e_name double	64-bit binary floating point
|	signed_byte(2) e_name string	UTF-8 string
|	signed_byte(3) e_name document	Embedded document
|	signed_byte(4) e_name document	Array
|	signed_byte(5) e_name binary	Binary data
|	signed_byte(6) e_name	Undefined (value) — Deprecated
|	signed_byte(7) e_name (byte*12)	ObjectId
|	signed_byte(8) e_name unsigned_byte(0)	Boolean - false
|	signed_byte(8) e_name unsigned_byte(1)	Boolean - true
|	signed_byte(9) e_name int64	UTC datetime
|	signed_byte(10) e_name	Null value
|	signed_byte(11) e_name cstring cstring	Regular expression - The first cstring is the regex pattern, the second is the regex options string. Options are identified by characters, which must be stored in alphabetical order. Valid option characters are i for case insensitive matching, m for multiline matching, s for dotall mode ("." matches everything), x for verbose mode, and u to make "\w", "\W", etc. match Unicode.
|	signed_byte(12) e_name string (byte*12)	DBPointer — Deprecated
|	signed_byte(13) e_name string	JavaScript code
|	signed_byte(14) e_name string	Symbol — Deprecated
|	signed_byte(15) e_name code_w_s	JavaScript code with scope — Deprecated
|	signed_byte(16) e_name int32	32-bit integer
|	signed_byte(17) e_name uint64	Timestamp
|	signed_byte(18) e_name int64	64-bit integer
|	signed_byte(19) e_name decimal128	128-bit decimal floating point
|	signed_byte(-1) e_name	Min key
|	signed_byte(127) e_name	Max key
e_name	::=	cstring	Key name
string	::=	int32 (byte*) unsigned_byte(0)	String - The int32 is the number of bytes in the (byte*) plus one for the trailing null byte. The (byte*) is zero or more UTF-8 encoded characters.
cstring	::=	(byte*) unsigned_byte(0)	Zero or more modified UTF-8 encoded characters followed by the null byte. The (byte*) MUST NOT contain unsigned_byte(0), hence it is not full UTF-8.
binary	::=	int32 subtype (byte*)	Binary - The int32 is the number of bytes in the (byte*).
subtype	::=	unsigned_byte(0)	Generic binary subtype
|	unsigned_byte(1)	Function
|	unsigned_byte(2)	Binary (Old)
|	unsigned_byte(3)	UUID (Old)
|	unsigned_byte(4)	UUID
|	unsigned_byte(5)	MD5
|	unsigned_byte(6)	Encrypted BSON value
|	unsigned_byte(7)	Compressed BSON column
|	unsigned_byte(8)	Sensitive
|	unsigned_byte(128)—unsigned_byte(255)	User defined
code_w_s	::=	int32 string document	Code with scope — Deprecated
</code></pre>
<h3 id="notes"><a class="header" href="#notes">Notes</a></h3>
<ul>
<li>Array - The document for an array is a normal BSON document with integer values for the keys, starting with 0 and continuing sequentially. For example, the array ['red', 'blue'] would be encoded as the document {'0': 'red', '1': 'blue'}. The keys must be in ascending numerical order.</li>
<li>UTC datetime - The int64 is UTC milliseconds since the Unix epoch.</li>
<li>Timestamp - Special internal type used by MongoDB replication and sharding. First 4 bytes are an increment, second 4 are a timestamp.</li>
<li>Min key - Special type which compares lower than all other possible BSON element values.</li>
<li>Max key - Special type which compares higher than all other possible BSON element values.</li>
<li>Generic binary subtype - This is the most commonly used binary subtype and should be the 'default' for drivers and tools.</li>
<li>Compressed BSON Column - Compact storage of BSON data. This data type uses delta and delta-of-delta compression and run-length-encoding for efficient element storage. Also has an encoding for sparse arrays containing missing values.</li>
<li>The BSON "binary" or "BinData" datatype is used to represent arrays of bytes. It is somewhat analogous to the Java notion of a ByteArray. BSON binary values have a subtype. This is used to indicate what kind of data is in the byte array. Subtypes from 0 to 127 are predefined or reserved. Subtypes from 128 to 255 are user-defined.
<ul>
<li>unsigned_byte(2) Binary (Old) - This used to be the default subtype, but was deprecated in favor of subtype 0. Drivers and tools should be sure to handle subtype 2 appropriately. The structure of the binary data (the byte* array in the binary non-terminal) must be an int32 followed by a (byte*). The int32 is the number of bytes in the repetition.</li>
<li>unsigned_byte(3) UUID (Old) - This used to be the UUID subtype, but was deprecated in favor of subtype 4. Drivers and tools for languages with a native UUID type should handle subtype 3 appropriately.</li>
<li>unsigned_byte(128)—unsigned_byte(255) User defined subtypes. The binary data can be anything.</li>
</ul>
</li>
<li>Code with scope - Deprecated. The int32 is the length in bytes of the entire code_w_s value. The string is JavaScript code. The document is a mapping from identifiers to values, representing the scope in which the string should be evaluated.</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="bson-objectid"><a class="header" href="#bson-objectid">BSON ObjectID</a></h1>
<ul>
<li>Status: Accepted</li>
<li>Minimum Server Version: N/A</li>
</ul>
<hr />
<h2 id="abstract"><a class="header" href="#abstract">Abstract</a></h2>
<p>This specification documents the format and data contents of ObjectID BSON values that the drivers and the server
generate when no field values have been specified (e.g. creating an ObjectID BSON value when no <code>_id</code> field is present
in a document). It is primarily aimed to provide an alternative to the historical use of the MD5 hashing algorithm for
the machine information field of the ObjectID, which is problematic when providing a FIPS compliant implementation. It
also documents existing best practices for the timestamp and counter fields.</p>
<h2 id="meta"><a class="header" href="#meta">META</a></h2>
<p>The keywords "MUST", "MUST NOT", "REQUIRED", "SHALL", "SHALL NOT", "SHOULD", "SHOULD NOT", "RECOMMENDED", "MAY", and
"OPTIONAL" in this document are to be interpreted as described in <a href="https://www.ietf.org/rfc/rfc2119.txt">RFC 2119</a>.</p>
<h2 id="specification"><a class="header" href="#specification">Specification</a></h2>
<p>The <a href="https://www.mongodb.com/docs/manual/reference/method/ObjectId/">ObjectID</a> BSON type is a 12-byte value consisting
of three different portions (fields):</p>
<ul>
<li>a 4-byte value representing the seconds since the Unix epoch in the highest order bytes,</li>
<li>a 5-byte random number unique to a machine and process,</li>
<li>a 3-byte counter, starting with a random value.</li>
</ul>
<pre><code>4 byte timestamp    5 byte process unique   3 byte counter
|&lt;-----------------&gt;|&lt;----------------------&gt;|&lt;------------&gt;|
[----|----|----|----|----|----|----|----|----|----|----|----]
0                   4                   8                   12
</code></pre>
<h3 id="timestamp-field"><a class="header" href="#timestamp-field">Timestamp Field</a></h3>
<p>This 4-byte big endian field represents the seconds since the Unix epoch (Jan 1st, 1970, midnight UTC). It is an ever
increasing value that will have a range until about Jan 7th, 2106.</p>
<p>Drivers MUST create ObjectIDs with this value representing the number of seconds since the Unix epoch.</p>
<p>Drivers MUST interpret this value as an <strong>unsigned 32-bit integer</strong> when conversions to language specific date/time
values are created, and when converting this to a timestamp.</p>
<p>Drivers SHOULD have an accessor method on an ObjectID class for obtaining the timestamp value.</p>
<h3 id="random-value"><a class="header" href="#random-value">Random Value</a></h3>
<p>A 5-byte field consisting of a random value generated once per process. This random value is unique to the machine and
process.</p>
<p>Drivers MUST NOT have an accessor method on an ObjectID class for obtaining this value.</p>
<p>The random number does not have to be cryptographic. If possible, use a PRNG with OS supplied entropy that SHOULD NOT
block to wait for more entropy to become available. Otherwise, seed a deterministic PRNG to ensure uniqueness of process
and machine by combining time, process ID, and hostname.</p>
<h3 id="counter"><a class="header" href="#counter">Counter</a></h3>
<p>A 3-byte big endian counter.</p>
<p>This counter MUST be initialised to a random value when the driver is first activated. After initialisation, the counter
MUST be increased by 1 for every ObjectID creation.</p>
<p>When the counter overflows (i.e., hits 16777215+1), the counter MUST be reset to 0.</p>
<p>Drivers MUST NOT have an accessor method on an ObjectID class for obtaining this value.</p>
<p>The random number does not have to be cryptographic. If possible, use a PRNG with OS supplied entropy that SHOULD NOT
block to wait for more entropy to become available. Otherwise, seed a deterministic PRNG to ensure uniqueness of process
and machine by combining time, process ID, and hostname.</p>
<h2 id="test-plan"><a class="header" href="#test-plan">Test Plan</a></h2>
<p>Drivers MUST:</p>
<ul>
<li>Ensure that the Timestamp field is represented as an unsigned 32-bit representing the number of seconds since the
Epoch for the Timestamp values:
<ul>
<li><code>0x00000000</code>: To match <code>"Jan 1st, 1970 00:00:00 UTC"</code></li>
<li><code>0x7FFFFFFF</code>: To match <code>"Jan 19th, 2038 03:14:07 UTC"</code></li>
<li><code>0x80000000</code>: To match <code>"Jan 19th, 2038 03:14:08 UTC"</code></li>
<li><code>0xFFFFFFFF</code>: To match <code>"Feb 7th, 2106 06:28:15 UTC"</code></li>
</ul>
</li>
<li>Ensure that the Counter field successfully overflows its sequence from <code>0xFFFFFF</code> to <code>0x000000</code>.</li>
<li>Ensure that after a new process is created through a fork() or similar process creation operation, the "random number
unique to a machine and process" is no longer the same as the parent process that created the new process.</li>
</ul>
<h2 id="motivation-for-change"><a class="header" href="#motivation-for-change">Motivation for Change</a></h2>
<p>Besides the specific exclusion of MD5 as an allowed hashing algorithm, the information in this specification is meant to
align the ObjectID generation algorithm of both drivers and the server.</p>
<h2 id="design-rationale"><a class="header" href="#design-rationale">Design Rationale</a></h2>
<p><strong>Timestamp:</strong> The timestamp is a 32-bit <strong>unsigned</strong> integer, as it allows us to extend the furthest date that the
timestamp can represent from the year 2038 to 2106. There is no reason why MongoDB would generate a timestamp to mean a
date before 1970, as MongoDB did not exist back then.</p>
<p><strong>Random Value:</strong> Originally, this field consisted of the Machine ID and Process ID fields. There were numerous
divergences between drivers due to implementation choices, and the Machine ID field traditionally used the MD5 hashing
algorithm which can't be used on FIPS compliant machines. In order to allow for a similar behaviour among all drivers
<strong>and</strong> the MongoDB Server, these two fields have been collated together into a single 5-byte random value, unique to a
machine and process.</p>
<p><strong>Counter:</strong> The counter makes it possible to have multiple ObjectIDs per second, per server, and per process. As the
counter can overflow, there is a possibility of having duplicate ObjectIDs if you create more than 16 million ObjectIDs
per second in the same process on a single machine.</p>
<p><strong>Endianness:</strong> The <em>Timestamp</em> and <em>Counter</em> are big endian because we can then use <code>memcmp</code> to order ObjectIDs, and we
want to ensure an increasing order.</p>
<h2 id="backwards-compatibility"><a class="header" href="#backwards-compatibility">Backwards Compatibility</a></h2>
<p>This specification requires that the existing <em>Machine ID</em> and <em>Process ID</em> fields are merged into a single 5-byte
value. This will change the behaviour of ObjectID generation, as well as the behaviour of drivers that currently have
getters and setters for the original <em>Machine ID</em> and <em>Process ID</em> fields.</p>
<h2 id="reference-implementation"><a class="header" href="#reference-implementation">Reference Implementation</a></h2>
<p>Currently there is no full reference implementation yet.</p>
<h2 id="changelog"><a class="header" href="#changelog">Changelog</a></h2>
<ul>
<li>
<p>2024-07-30: Migrated from reStructuredText to Markdown.</p>
</li>
<li>
<p>2022-10-05: Remove spec front matter and reformat changelog.</p>
</li>
<li>
<p>2019-01-14: Clarify that the random numbers don't need to be cryptographically secure. Add a test to test that the
unique value is different in forked processes.</p>
</li>
<li>
<p>2018-10-11: Clarify that the <em>Timestamp</em> and <em>Counter</em> fields are big endian, and add the reason why.</p>
</li>
<li>
<p>2018-07-02: Replaced Machine ID and Process ID fields with a single 5-byte unique value</p>
</li>
<li>
<p>2018-05-22: Initial Release</p>
</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="bson-decimal128"><a class="header" href="#bson-decimal128">BSON Decimal128</a></h1>
<ul>
<li>Status: Accepted</li>
<li>Minimum Server Version: 3.4</li>
</ul>
<hr />
<h2 id="abstract-1"><a class="header" href="#abstract-1">Abstract</a></h2>
<p>MongoDB 3.4 introduces a new BSON type representing high precision decimal (<code>"\x13"</code>), known as Decimal128. 3.4
compatible drivers must support this type by creating a Value Object for it, possibly with accessor functions for
retrieving its value in data types supported by the respective languages.</p>
<p>Round-tripping Decimal128 types between driver and server MUST not change its value or representation in any way.
Conversion to and from native language types is complicated and there are many pitfalls to represent Decimal128
precisely in all languages</p>
<p>While many languages offer a native decimal type, the precision of these types often does not exactly match that of the
MongoDB implementation. To ensure error-free conversion and consistency between official MongoDB drivers, this
specification does not allow automatically converting the <code>BSON Decimal128</code> type into a language-defined decimal type.</p>
<p>Language drivers will wrap their native type in value objects by default and SHOULD offer accessor functions for
retrieving its value represented by language-defined types if appropriate. A driver that offers the ability to configure
mappings to/from BSON types to native types MAY allow the option to automatically convert the <code>BSON Decimal128</code> type to
a native type. It should however be made abundantly clear to the user that converting to native data types risks
incurring data loss.</p>
<h2 id="meta-1"><a class="header" href="#meta-1">META</a></h2>
<p>The keywords "MUST", "MUST NOT", "REQUIRED", "SHALL", "SHALL NOT", "SHOULD", "SHOULD NOT", "RECOMMENDED", "MAY", and
"OPTIONAL" in this document are to be interpreted as described in <a href="https://www.ietf.org/rfc/rfc2119.txt">RFC 2119</a>.</p>
<h2 id="terminology"><a class="header" href="#terminology">Terminology</a></h2>
<p><strong>IEEE 754-2008 128-bit decimal floating point (Decimal128)</strong></p>
<p>The Decimal128 specification supports 34 decimal digits of precision, a max value of approximately <code>10^6145</code>, and min
value of approximately <code>-10^6145</code>. This is the new <code>BSON Decimal128</code> type (<code>"\x13"</code>).</p>
<p><strong>Clamping</strong></p>
<p>Clamping happens when a value's exponent is too large for the destination format. This works by adding zeros to the
coefficient to reduce the exponent to the largest usable value. An overflow occurs if the number of digits required is
more than allowed in the destination format.</p>
<p><strong>Binary Integer Decimal (BID)</strong></p>
<p>MongoDB uses this binary encoding for the coefficient as specified in <code>IEEE 754-2008</code> section 3.5.2 using method 2
"binary encoding" rather than method 1 "decimal encoding". The byte order is little-endian, like the rest of the BSON
types.</p>
<p><strong>Value Object</strong></p>
<p>An immutable container type representing a value (e.g. Decimal128). This Value Object MAY provide accessors that
retrieve the abstracted value as a different type (e.g. casting it). <code>double x = valueObject.getAsDouble();</code></p>
<h2 id="specification-1"><a class="header" href="#specification-1">Specification</a></h2>
<h3 id="bson-decimal128-implementation-details"><a class="header" href="#bson-decimal128-implementation-details">BSON Decimal128 implementation details</a></h3>
<p>The <code>BSON Decimal128</code> data type implements the
<a href="http://speleotrove.com/decimal/decbits.html">Decimal Arithmetic Encodings</a> specification, with certain exceptions
around value integrity and the coefficient encoding. When a value cannot be represented exactly, the value will be
rejected.</p>
<p>The coefficient MUST be stored as an unsigned binary integer (BID) rather than the densely-packed decimal (DPD) shown in
the specification. See either the <code>IEEE Std 754-2008</code> spec or the driver examples for further detail.</p>
<p>The specification defines several statuses which are meant to signal exceptional
<a href="http://speleotrove.com/decimal/daexcep.html">circumstances</a>, such as when overflowing occurs, and how to handle them.</p>
<p><code>BSON Decimal128</code> Value Objects MUST implement these actions for these exceptions:</p>
<ul>
<li>
<p>Overflow</p>
<ul>
<li>When overflow occurs, the operation MUST emit an error and result in a failure</li>
</ul>
</li>
<li>
<p>Underflow</p>
<ul>
<li>When underflow occurs, the operation MUST emit an error and result in a failure</li>
</ul>
</li>
<li>
<p>Clamping</p>
<ul>
<li>Since clamping does not change the actual value, only the representation of it, clamping MUST occur without emitting
an error.</li>
</ul>
</li>
<li>
<p>Rounding</p>
<ul>
<li>When the coefficient requires more digits then Decimal128 provides, rounding MUST be done without emitting an error,
unless it would result in inexact rounding, in which case the operation MUST emit an error and result in a failure.</li>
</ul>
</li>
<li>
<p>Conversion Syntax</p>
<ul>
<li>Invalid strings MUST emit an error and result in a failure.</li>
</ul>
</li>
</ul>
<p>It should be noted that the given exponent is a preferred representation. If the value cannot be stored due to the value
of the exponent being too large or too small, but can be stored using an alternative representation by clamping and or
rounding, a <code>BSON Decimal128</code> compatible Value Object MUST do so, unless such operation results in an inexact rounding
or other underflow or overflow.</p>
<h3 id="reading-from-bson"><a class="header" href="#reading-from-bson">Reading from BSON</a></h3>
<p>A BSON type <code>"\x13"</code> MUST be represented by an immutable Value Object by default and MUST NOT be automatically converted
into language native numeric type by default. A driver that offers users a way to configure the exact type mapping to
and from BSON types MAY allow the <code>BSON Decimal128</code> type to be converted to the user configured type.</p>
<p>A driver SHOULD provide accessors for this immutable Value Object, which can return a language-specific representation
of the Decimal128 value, after converting it into the respective type. For example, Java may choose to provide
<code>Decimal128.getBigDecimal()</code>.</p>
<p>All drivers MUST provide an accessor for retrieving the value as a string. Drivers MAY provide other accessors,
retrieving the value as other types.</p>
<h3 id="serializing-and-writing-bson"><a class="header" href="#serializing-and-writing-bson">Serializing and writing BSON</a></h3>
<p>Drivers MUST provide a way of constructing the Value Object, as the driver representation of the <code>BSON Decimal128</code> is an
immutable Value Object by default.</p>
<p>A driver MUST have a way to construct this Value Object from a string. For example, Java MUST provide a method similar
to <code>Decimal128.valueOf("2.000")</code>.</p>
<p>A driver that has accessors for different types SHOULD provide a way to construct the Value Object from those types.</p>
<h3 id="reading-from-extended-json"><a class="header" href="#reading-from-extended-json">Reading from Extended JSON</a></h3>
<p>The Extended JSON representation of Decimal128 is a document with the key <code>$numberDecimal</code> and a value of the Decimal128
as a string. Drivers that support Extended JSON formatting MUST support the <code>$numberDecimal</code> type specifier.</p>
<p>When an Extended JSON <code>$numberDecimal</code> is parsed, its type should be the same as that of a deserialized
<code>BSON Decimal128</code>, as described in <a href="bson-decimal128/decimal128.html#reading-from-bson">Reading from BSON</a>.</p>
<p>The Extended JSON <code>$numberDecimal</code> value follows the same stringification rules as defined in
<a href="bson-decimal128/decimal128.html#from-string-representation">From String Representation</a>.</p>
<h3 id="writing-to-extended-json"><a class="header" href="#writing-to-extended-json">Writing to Extended JSON</a></h3>
<p>The Extended JSON type identifier is <code>$numberDecimal</code>, while the value itself is a string. Drivers that support
converting values to Extended JSON MUST be able to convert its Decimal128 value object to Extended JSON.</p>
<p>Converting a Decimal128 Value Object to Extended JSON MUST follow the conversion rules in
<a href="bson-decimal128/decimal128.html#to-string-representation">To String Representation</a>, and other stringification rules as when converting Decimal128
Value Object to a String.</p>
<h3 id="operator-overloading-and-math-on-decimal128-value-objects"><a class="header" href="#operator-overloading-and-math-on-decimal128-value-objects">Operator overloading and math on Decimal128 Value Objects</a></h3>
<p>Drivers MUST NOT allow any mathematical operator overloading for the Decimal128 Value Objects. This includes adding two
Decimal128 Value Objects and assigning the result to a new object.</p>
<p>If a user wants to perform mathematical operations on Decimal128 Value Objects, the user must explicitly retrieve the
native language value representations of the objects and perform the operations on those native representations. The
user will then create a new Decimal128 Value Object and optionally overwrite the original Decimal128 Value Object.</p>
<h3 id="from-string-representation"><a class="header" href="#from-string-representation">From String Representation</a></h3>
<p>For finite numbers, we will use the definition at <a href="http://speleotrove.com/decimal/daconvs.html">http://speleotrove.com/decimal/daconvs.html</a>. It has been modified to
account for a different NaN representation and whitespace rules and copied here:</p>
<pre><code>Strings which are acceptable for conversion to the abstract representation of
numbers, or which might result from conversion from the abstract representation
to a string, are called numeric strings.


A numeric string is a character string that describes either a finite
number or a special value.
* If it describes a finite number, it includes one or more decimal digits,
  with an optional decimal point. The decimal point may be embedded in the
  digits, or may be prefixed or suffixed to them. The group of digits (and
  optional point) thus constructed may have an optional sign ('+' or '-')
  which must come before any digits or decimal point. 
* The string thus described may optionally be followed by an 'E'
  (indicating an exponential part), an optional sign, and an integer
  following the sign that represents a power of ten that is to be applied.
  The 'E' may be in uppercase or lowercase.
* If it describes a special value, it is one of the case-independent names
  'Infinity', 'Inf', or 'NaN' (where the first two represent infinity and
  the second represent NaN). The name may be preceded by an optional sign,
  as for finite numbers. 
* No blanks or other whitespace characters are permitted in a numeric string.

Formally

          sign           ::=  '+' | '-'
          digit          ::=  '0' | '1' | '2' | '3' | '4' | '5' | '6' | '7' |
                              '8' | '9'
          indicator      ::=  'e' | 'E'
          digits         ::=  digit [digit]...
          decimal-part   ::=  digits '.' [digits] | ['.'] digits
          exponent-part  ::=  indicator [sign] digits
          infinity       ::=  'Infinity' | 'Inf'
          nan            ::=  'NaN'
          numeric-value  ::=  decimal-part [exponent-part] | infinity
          numeric-string ::=  [sign] numeric-value | [sign] nan

where the characters in the strings accepted for 'infinity' and 'nan' may be in
any case.  If an implementation supports the concept of diagnostic information
on NaNs, the numeric strings for NaNs MAY include one or more digits, as shown
above.[3]  These digits encode the diagnostic information in an
implementation-defined manner; however, conversions to and from string for
diagnostic NaNs should be reversible if possible. If an implementation does not
support diagnostic information on NaNs, these digits should be ignored where
necessary. A plain 'NaN' is usually the same as 'NaN0'.


Drivers MAY choose to support signed NaN (sNaN), along with sNaN with
diagnostic information. 



Examples::
Some numeric strings are:
            "0"         -- zero
           "12"         -- a whole number
          "-76"         -- a signed whole number
           "12.70"      -- some decimal places
           "+0.003"     -- a plus sign is allowed, too
          "017."        -- the same as 17
             ".5"       -- the same as 0.5
           "4E+9"       -- exponential notation
            "0.73e-7"   -- exponential notation, negative power
           "Inf"        -- the same as Infinity
           "-infinity"  -- the same as -Infinity
           "NaN"        -- not-a-Number

Notes:
1. A single period alone or with a sign is not a valid numeric string.
2. A sign alone is not a valid numeric string.
3. Significant (after the decimal point) and insignificant leading zeros
       are permitted.
</code></pre>
<h3 id="to-string-representation"><a class="header" href="#to-string-representation">To String Representation</a></h3>
<p>For finite numbers, we will use the definition at <a href="http://speleotrove.com/decimal/daconvs.html">http://speleotrove.com/decimal/daconvs.html</a>. It has been copied
here:</p>
<pre><code>The coefficient is first converted to a string in base ten using the characters
0 through 9 with no leading zeros (except if its value is zero, in which case a
single 0 character is used).


Next, the adjusted exponent is calculated; this is the exponent, plus the
number of characters in the converted coefficient, less one. That is,
exponent+(clength-1), where clength is the length of the coefficient in decimal
digits.


If the exponent is less than or equal to zero and the adjusted exponent is
greater than or equal to -6, the number will be converted to a character form
without using exponential notation. In this case, if the exponent is zero then
no decimal point is added. Otherwise (the exponent will be negative), a decimal
point will be inserted with the absolute value of the exponent specifying the
number of characters to the right of the decimal point. '0' characters are
added to the left of the converted coefficient as necessary. If no character
precedes the decimal point after this insertion then a conventional '0'
character is prefixed.


Otherwise (that is, if the exponent is positive, or the adjusted exponent is
less than -6), the number will be converted to a character form using
exponential notation. In this case, if the converted coefficient has more than
one digit a decimal point is inserted after the first digit. An exponent in
character form is then suffixed to the converted coefficient (perhaps with
inserted decimal point); this comprises the letter 'E' followed immediately by
the adjusted exponent converted to a character form. The latter is in base ten,
using the characters 0 through 9 with no leading zeros, always prefixed by a
sign character ('-' if the calculated exponent is negative, '+' otherwise).
</code></pre>
<p>This corresponds to the following code snippet:</p>
<blockquote>
<pre><code class="language-c">var adjusted_exponent = _exponent + (clength - 1);
if (_exponent &gt; 0 || adjusted_exponent &lt; -6) {
    // exponential notation
} else {
    // character form without using exponential notation
}
</code></pre>
</blockquote>
<p>For special numbers such as infinity or the not a number (NaN) variants, the below table is used:</p>
<div class="table-wrapper"><table><thead><tr><th>Value</th><th>String</th></tr></thead><tbody>
<tr><td>Positive Infinite</td><td>Infinity</td></tr>
<tr><td>Negative Infinite</td><td>-Infinity</td></tr>
<tr><td>Positive NaN</td><td>NaN</td></tr>
<tr><td>Negative NaN</td><td>NaN</td></tr>
<tr><td>Signaled NaN</td><td>NaN</td></tr>
<tr><td>Negative Signaled NaN</td><td>NaN</td></tr>
<tr><td>NaN with a payload</td><td>NaN</td></tr>
</tbody></table>
</div>
<p>Finally, there are certain other invalid representations that must be treated as zeros, as per <code>IEEE 754-2008</code>. The
tests will verify that each special value has been accounted for.</p>
<p>The server log files as well as the Extended JSON Format for Decimal128 use this format.</p>
<h2 id="motivation-for-change-1"><a class="header" href="#motivation-for-change-1">Motivation for Change</a></h2>
<p>BSON already contains support for <code>double</code> (<code>"\x01"</code>), but this type is insufficient for certain values that require
strict precision and representation, such as money, where it is necessary to perform exact decimal rounding.</p>
<p>The new BSON type is the 128-bit <code>IEEE 754-2008</code> decimal floating point number, which is specifically designed to cope
with these issues.</p>
<h2 id="design-rationale-1"><a class="header" href="#design-rationale-1">Design Rationale</a></h2>
<p>For simplicity and consistency between drivers, drivers must not automatically convert this type into a native type by
default. This also ensures original data preservation, which is crucial to Decimal128. It is however recommended that
drivers offer a way to convert the Value Object to a native type through accessors, and to create a new BSON type from
native types. This forces the user to explicitly do the conversion and thus understand the difference between the
MongoDB type and possible language precision and representation. Representations via conversions done outside MongoDB
are not guaranteed to be identical.</p>
<h2 id="backwards-compatibility-1"><a class="header" href="#backwards-compatibility-1">Backwards Compatibility</a></h2>
<p>There should be no backwards compatibility concerns. This specification merely deals with how to encode and decode
BSON/Extended JSON Decimal128.</p>
<h2 id="reference-implementations"><a class="header" href="#reference-implementations">Reference Implementations</a></h2>
<ul>
<li><a href="https://github.com/mongodb/libbson/blob/master/src/bson/bson-decimal128.c">Libbson</a></li>
<li><a href="https://github.com/estolfo/bson-ruby/blob/RUBY-1098-decimal128/lib/bson/decimal128.rb">Ruby</a></li>
<li><a href="https://github.com/craiggwilson/mongo-csharp-driver/tree/decimal">.NET</a></li>
<li><a href="https://github.com/mongodb/mongo-python-driver/blob/master/bson/decimal128.py">PyMongo</a></li>
<li><a href="https://github.com/mongodb/js-bson/blob/0.5/lib/bson/decimal128.js">Node</a></li>
<li><a href="https://github.com/mongodb/mongo-java-driver/blob/master/bson/src/main/org/bson/BsonDecimal128.java">Java</a></li>
</ul>
<h2 id="tests"><a class="header" href="#tests">Tests</a></h2>
<p>See the <a href="bson-decimal128/../bson-corpus/bson-corpus.html">BSON Corpus</a> for tests.</p>
<p>Most of the tests are converted from the
<a href="http://speleotrove.com/decimal/dectest.html">General Decimal Arithmetic Testcases</a>.</p>
<h2 id="qa"><a class="header" href="#qa">Q&amp;A</a></h2>
<ul>
<li>
<p>Is it true Decimal128 doesn't normalize the value?</p>
<ul>
<li>Yes. As a result of non-normalization rules of the Decimal128 data type, precision is represented exactly. For
example, '2.00' always remains stored as 200E-2 in Decimal128, and it differs from the representation of '2.0'
(20E-1). These two values compare equally, but represent different ideas.</li>
</ul>
</li>
<li>
<p>How does Decimal128 "2.000" look in the shell?</p>
<ul>
<li>NumberDecimal("2.000")</li>
</ul>
</li>
<li>
<p>Should a driver avoid sending Decimal128 values to pre-3.4 servers?</p>
<ul>
<li>No</li>
</ul>
</li>
<li>
<p>Is there a wire version bump or something for Decimal128?</p>
<ul>
<li>No</li>
</ul>
</li>
</ul>
<h2 id="changelog-1"><a class="header" href="#changelog-1">Changelog</a></h2>
<ul>
<li>2024-02-08: Migrated from reStructuredText to Markdown.</li>
<li>2022-10-05: Remove spec front matter.</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="bson-binary-uuid"><a class="header" href="#bson-binary-uuid">BSON Binary UUID</a></h1>
<ul>
<li>Status: Accepted</li>
<li>Minimum Server Version: N/A</li>
</ul>
<hr />
<h2 id="abstract-2"><a class="header" href="#abstract-2">Abstract</a></h2>
<p>The Java, C#, and Python drivers natively support platform types for UUID, all of which by default encode them to and
decode them from BSON binary subtype 3. However, each encode the bytes in a different order from the others. To improve
interoperability, BSON binary subtype 4 was introduced and defined the byte order according to
<a href="https://tools.ietf.org/html/rfc4122#section-4.1.2">RFC 4122</a>, and a mechanism to configure each driver to encode UUIDs
this way was added to each driver. The legacy representation remained as the default for each driver.</p>
<p>This specification moves MongoDB drivers further towards the standard UUID representation by requiring an application
relying on native UUID support to explicitly specify the representation it requires.</p>
<p>Drivers that support native UUID types will additionally create helpers on their BsonBinary class that will aid in
conversion to and from the platform native UUID type.</p>
<h2 id="meta-2"><a class="header" href="#meta-2">META</a></h2>
<p>The keywords "MUST", "MUST NOT", "REQUIRED", "SHALL", "SHALL NOT", "SHOULD", "SHOULD NOT", "RECOMMENDED", "MAY", and
"OPTIONAL" in this document are to be interpreted as described in <a href="https://www.ietf.org/rfc/rfc2119.txt">RFC 2119</a>.</p>
<h2 id="specification-2"><a class="header" href="#specification-2">Specification</a></h2>
<h3 id="terms"><a class="header" href="#terms">Terms</a></h3>
<p><strong>UUID</strong></p>
<p>A Universally Unique IDentifier</p>
<p><strong>BsonBinary</strong></p>
<p>An object that wraps an instance of a BSON binary value</p>
<h3 id="naming-deviations"><a class="header" href="#naming-deviations">Naming Deviations</a></h3>
<p>All drivers MUST name operations, objects, and parameters as defined in the following sections.</p>
<p>The following deviations are permitted:</p>
<ul>
<li>Drivers can use the platform's name for a UUID. For instance, in C# the platform class is Guid, whereas in Java it is
UUID.</li>
<li>Drivers can use a "to" prefix instead of an "as" prefix for the BsonBinary method names.</li>
</ul>
<h3 id="explicit-encoding-and-decoding"><a class="header" href="#explicit-encoding-and-decoding">Explicit encoding and decoding</a></h3>
<p>Any driver with a native UUID type MUST add the following UuidRepresentation enumeration, and associated methods to its
BsonBinary (or equivalent) class:</p>
<pre><code class="language-typescript">/**

enum UuidRepresentation {

   /**
    * An unspecified representation of UUID.  Essentially, this is the null 
    * representation value. This value is not required for languages that      
    * have better ways of indicating, or preventing use of, a null value.
    */
   UNSPECIFIED("unspecified"),

   /**
    * The canonical representation of UUID according to RFC 4122, 
    * section 4.1.2 
    * 
    * It encodes as BSON binary subtype 4
   */
   STANDARD("standard"),

   /**
    * The legacy representation of UUID used by the C# driver.
    *
    * In this representation the order of bytes 0-3 are reversed, the 
    * order of bytes 4-5 are reversed, and the order of bytes 6-7 are 
    * reversed.
    *
    * It encodes as BSON binary subtype 3
    */
   C_SHARP_LEGACY("csharpLegacy"),

   /**
    * The legacy representation of UUID used by the Java driver.
    *
    * In this representation the order of bytes 0-7 are reversed, and the 
    * order of bytes 8-15 are reversed.
    *
    * It encodes as BSON binary subtype 3
    */
   JAVA_LEGACY("javaLegacy"),

  /**
   * The legacy representation of UUID used by the Python driver.
   *
   * As with STANDARD, this representation conforms with RFC 4122, section
   * 4.1.2 
   *
   * It encodes as BSON binary subtype 3
   */
   PYTHON_LEGACY("pythonLegacy")
}

class BsonBinary {
   /* 
    * Construct from a UUID using the standard UUID representation
    * [Specification] This constructor SHOULD be included but MAY be 
    *                 omitted if it creates backwards compatibility issues
    */
   constructor(Uuid uuid) 

   /*
    * Construct from a UUID using the given UUID representation.
    *
    * The representation must not be equal to UNSPECIFIED
    */
   constructor(Uuid uuid, UuidRepresentation representation)

   /*
    * Decode a subtype 4 binary to a UUID, erroring when the subtype is not 4.
    */
   Uuid asUuid()  

   /*
    * Decode a subtype 3 or 4 to a UUID, according to the UUID    
    * representation, erroring when subtype does not match the
    * representation.
    */
   Uuid asUuid(UuidRepresentation representation)
}
</code></pre>
<h3 id="implicit-decoding-and-encoding"><a class="header" href="#implicit-decoding-and-encoding">Implicit decoding and encoding</a></h3>
<p>A new driver for a language with a native UUID type MUST NOT implicitly encode from or decode to the native UUID type.
Rather, explicit conversion MUST be used as described in the previous section.</p>
<p>Drivers that already do such implicit encoding and decoding SHOULD support a URI option, uuidRepresentation, which
controls the default behavior of the UUID codec. Alternatively, a driver MAY specify the UUID representation via global
state.</p>
<div class="table-wrapper"><table><thead><tr><th>Value</th><th>Default?</th><th>Encode to</th><th>Decode subtype 4 to</th><th>Decode subtype 3 to</th></tr></thead><tbody>
<tr><td>unspecified</td><td>yes</td><td>raise error</td><td>BsonBinary</td><td>BsonBinary</td></tr>
<tr><td>standard</td><td>no</td><td>BSON binary subtype 4</td><td>native UUID</td><td>BsonBinary</td></tr>
<tr><td>csharpLegacy</td><td>no</td><td>BSON binary subtype 3 with C# legacy byte order</td><td>BsonBinary</td><td>native UUID</td></tr>
<tr><td>javaLegacy</td><td>no</td><td>BSON binary subtype 3 with Java legacy byte order</td><td>BsonBinary</td><td>native UUID</td></tr>
<tr><td>pythonLegacy</td><td>no</td><td>BSON binary subtype 3 with standard byte order</td><td>BsonBinary</td><td>native UUID</td></tr>
</tbody></table>
</div>
<p>For scenarios where the application makes the choice (e.g. a POJO with a field of type UUID), or when serializers are
strongly typed and are constrained to always return values of a certain type, the driver will raise an exception in
cases where otherwise it would be required to decode to a different type (e.g. BsonBinary instead of UUID or vice
versa).</p>
<p>Note also that none of the above applies when decoding to strictly typed maps, e.g. a <code>Map&lt;String, BsonValue&gt;</code> like Java
or .NET's BsonDocument class. In those cases the driver is always decoding to BsonBinary, and applications would use the
asUuid methods to explicitly convert from BsonBinary to UUID.</p>
<h3 id="implementation-notes"><a class="header" href="#implementation-notes">Implementation Notes</a></h3>
<p>Since changing the default UUID representation can reasonably be considered a backwards-breaking change, drivers that
implement the full specification should stage implementation according to semantic versioning guidelines. Specifically,
support for this specification can be added to a minor release, but with several exceptions:</p>
<p>The default UUID representation should be left as is (e.g. JAVA_LEGACY for the Java driver) rather than be changed to
UNSPECIFIED. In a subsequent major release, the default UUID representation can be changed to UNSPECIFIED (along with
appropriate documentation indicating the backwards-breaking change). Drivers MUST document this in a prior minor
release.</p>
<h2 id="test-plan-1"><a class="header" href="#test-plan-1">Test Plan</a></h2>
<p>The test plan consists of a series of prose tests. They all operate on the same UUID, with the String representation of
"00112233-4455-6677-8899-aabbccddeeff".</p>
<h3 id="explicit-encoding"><a class="header" href="#explicit-encoding">Explicit encoding</a></h3>
<ol>
<li>Create a BsonBinary instance with the given UUID
<ul>
<li>Assert that the BsonBinary instance's subtype is equal to 4 and data equal to the hex-encoded string
"00112233445566778899AABBCCDDEEFF"</li>
</ul>
</li>
<li>Create a BsonBinary instance with the given UUID and UuidRepresentation equal to STANDARD
<ul>
<li>Assert that the BsonBinary instance's subtype is equal to 4 and data equal to the hex-encoded string
"00112233445566778899AABBCCDDEEFF"</li>
</ul>
</li>
<li>Create a BsonBinary instance with the given UUID and UuidRepresentation equal to JAVA_LEGACY
<ul>
<li>Assert that the BsonBinary instance's subtype is equal to 3 and data equal to the hex-encoded string
"7766554433221100FFEEDDCCBBAA9988"</li>
</ul>
</li>
<li>Create a BsonBinary instance with the given UUID and UuidRepresentation equal to CSHARP_LEGACY
<ul>
<li>Assert that the BsonBinary instance's subtype is equal to 3 and data equal to the hex-encoded string
"33221100554477668899AABBCCDDEEFF"</li>
</ul>
</li>
<li>Create a BsonBinary instance with the given UUID and UuidRepresentation equal to PYTHON_LEGACY
<ul>
<li>Assert that the BsonBinary instance's subtype is equal to 3 and data equal to the hex-encoded string
"00112233445566778899AABBCCDDEEFF"</li>
</ul>
</li>
<li>Create a BsonBinary instance with the given UUID and UuidRepresentation equal to UNSPECIFIED
<ul>
<li>Assert that an error is raised</li>
</ul>
</li>
</ol>
<h3 id="explicit-decoding"><a class="header" href="#explicit-decoding">Explicit Decoding</a></h3>
<ol>
<li>Create a BsonBinary instance with subtype equal to 4 and data equal to the hex-encoded string
"00112233445566778899AABBCCDDEEFF"
<ol>
<li>Assert that a call to BsonBinary.asUuid() returns the given UUID</li>
<li>Assert that a call to BsonBinary.asUuid(STANDARD) returns the given UUID</li>
<li>Assert that a call to BsonBinary.asUuid(UNSPECIFIED) raises an error</li>
<li>Assert that a call to BsonBinary.asUuid(JAVA_LEGACY) raises an error</li>
<li>Assert that a call to BsonBinary.asUuid(CSHARP_LEGACY) raises an error</li>
<li>Assert that a call to BsonBinary.asUuid(PYTHON_LEGACY) raises an error</li>
</ol>
</li>
<li>Create a BsonBinary instance with subtype equal to 3 and data equal to the hex-encoded string
"7766554433221100FFEEDDCCBBAA9988"
<ol>
<li>Assert that a call to BsonBinary.asUuid() raises an error</li>
<li>Assert that a call to BsonBinary.asUuid(STANDARD) raised an error</li>
<li>Assert that a call to BsonBinary.asUuid(UNSPECIFIED) raises an error</li>
<li>Assert that a call to BsonBinary.asUuid(JAVA_LEGACY) returns the given UUID</li>
</ol>
</li>
<li>Create a BsonBinary instance with subtype equal to 3 and data equal to the hex-encoded string
"33221100554477668899AABBCCDDEEFF"
<ol>
<li>Assert that a call to BsonBinary.asUuid() raises an error</li>
<li>Assert that a call to BsonBinary.asUuid(STANDARD) raised an error</li>
<li>Assert that a call to BsonBinary.asUuid(UNSPECIFIED) raises an error</li>
<li>Assert that a call to BsonBinary.asUuid(CSHARP_LEGACY) returns the given UUID</li>
</ol>
</li>
<li>Create a BsonBinary instance with subtype equal to 3 and data equal to the hex-encoded string
"00112233445566778899AABBCCDDEEFF"
<ol>
<li>Assert that a call to BsonBinary.asUuid() raises an error</li>
<li>Assert that a call to BsonBinary.asUuid(STANDARD) raised an error</li>
<li>Assert that a call to BsonBinary.asUuid(UNSPECIFIED) raises an error</li>
<li>Assert that a call to BsonBinary.asUuid(PYTHON_LEGACY) returns the given UUID</li>
</ol>
</li>
</ol>
<h3 id="implicit-encoding"><a class="header" href="#implicit-encoding">Implicit encoding</a></h3>
<ol>
<li>Set the uuidRepresentation of the client to "javaLegacy". Insert a document with an "_id" key set to the given
native UUID value.
<ul>
<li>Assert that the actual value inserted is a BSON binary with subtype 3 and data equal to the hex-encoded string
"7766554433221100FFEEDDCCBBAA9988"</li>
</ul>
</li>
<li>Set the uuidRepresentation of the client to "charpLegacy". Insert a document with an "_id" key set to the given
native UUID value.
<ul>
<li>Assert that the actual value inserted is a BSON binary with subtype 3 and data equal to the hex-encoded string
"33221100554477668899AABBCCDDEEFF"</li>
</ul>
</li>
<li>Set the uuidRepresentation of the client to "pythonLegacy". Insert a document with an "_id" key set to the given
native UUID value.
<ul>
<li>Assert that the actual value inserted is a BSON binary with subtype 3 and data equal to the hex-encoded string
"00112233445566778899AABBCCDDEEFF"</li>
</ul>
</li>
<li>Set the uuidRepresentation of the client to "standard". Insert a document with an "_id" key set to the given native
UUID value.
<ul>
<li>Assert that the actual value inserted is a BSON binary with subtype 4 and data equal to the hex-encoded string
"00112233445566778899AABBCCDDEEFF"</li>
</ul>
</li>
<li>Set the uuidRepresentation of the client to "unspecified". Insert a document with an "_id" key set to the given
native UUID value.
<ul>
<li>Assert that a BSON serialization exception is thrown</li>
</ul>
</li>
</ol>
<h3 id="implicit-decoding"><a class="header" href="#implicit-decoding">Implicit Decoding</a></h3>
<ol>
<li>
<p>Set the uuidRepresentation of the client to "javaLegacy". Insert a document containing two fields. The "standard"
field should contain a BSON Binary created by creating a BsonBinary instance with the given UUID and the STANDARD
UuidRepresentation. The "legacy" field should contain a BSON Binary created by creating a BsonBinary instance with
the given UUID and the JAVA_LEGACY UuidRepresentation. Find the document.</p>
<ol>
<li>Assert that the value of the "standard" field is of type BsonBinary and is equal to the inserted value.</li>
<li>Assert that the value of the "legacy" field is of the native UUID type and is equal to the given UUID</li>
</ol>
<p>Repeat this test with the uuidRepresentation of the client set to "csharpLegacy" and "pythonLegacy".</p>
</li>
<li>
<p>Set the uuidRepresentation of the client to "standard". Insert a document containing two fields. The "standard" field
should contain a BSON Binary created by creating a BsonBinary instance with the given UUID and the STANDARD
UuidRepresentation. The "legacy" field should contain a BSON Binary created by creating a BsonBinary instance with
the given UUID and the PYTHON_LEGACY UuidRepresentation. Find the document.</p>
<ol>
<li>Assert that the value of the "standard" field is of the native UUID type and is equal to the given UUID</li>
<li>Assert that the value of the "legacy" field is of type BsonBinary and is equal to the inserted value.</li>
</ol>
</li>
<li>
<p>Set the uuidRepresentation of the client to "unspecified". Insert a document containing two fields. The "standard"
field should contain a BSON Binary created by creating a BsonBinary instance with the given UUID and the STANDARD
UuidRepresentation. The "legacy" field should contain a BSON Binary created by creating a BsonBinary instance with
the given UUID and the PYTHON_LEGACY UuidRepresentation. Find the document.</p>
<ol>
<li>Assert that the value of the "standard" field is of type BsonBinary and is equal to the inserted value</li>
<li>Assert that the value of the "legacy" field is of type BsonBinary and is equal to the inserted value.</li>
</ol>
<p>Repeat this test with the uuidRepresentation of the client set to "csharpLegacy" and "pythonLegacy".</p>
</li>
</ol>
<p>Note: the assertions will be different in the release prior to the major release, to avoid breaking changes. Adjust
accordingly!</p>
<h2 id="q--a"><a class="header" href="#q--a">Q &amp; A</a></h2>
<h3 id="whats-the-rationale-for-the-deviations-allowed-by-the-specification"><a class="header" href="#whats-the-rationale-for-the-deviations-allowed-by-the-specification">What's the rationale for the deviations allowed by the specification?</a></h3>
<p>In short, the C# driver has existing behavior that make it infeasible to work the same as other drivers.</p>
<p>The C# driver has a global serialization registry. Since it's global and not per-MongoClient, it's not feasible to
override the UUID representation on a per-MongoClient basis, since doing so would require a per-MongoClient registry.
Instead, the specification allows for a global override so that the C# driver can implement the specification.</p>
<p>Additionally, the C# driver has an existing configuration parameter that controls the behavior of BSON readers and
writers at a level below the serializers. This configuration affects the semantics of the existing BsonBinary class in a
way that doesn't allow for the constructor(UUID) mentioned in the specification. For this reason, that constructor is
specified as optional.</p>
<h2 id="changelog-2"><a class="header" href="#changelog-2">Changelog</a></h2>
<ul>
<li>2024-08-01: Migrated from reStructuredText to Markdown.</li>
<li>2022-10-05: Remove spec front matter.</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="dbref"><a class="header" href="#dbref">DBRef</a></h1>
<ul>
<li>Status: Accepted</li>
<li>Minimum Server Version: N/A</li>
</ul>
<hr />
<h2 id="abstract-3"><a class="header" href="#abstract-3">Abstract</a></h2>
<p>DBRefs are a convention for expressing a reference to another document as an embedded document (i.e. BSON type 0x03).
Several drivers provide a model class for encoding and/or decoding DBRef documents. This specification will both define
the structure of a DBRef and provide guidance for implementing model classes in drivers that choose to do so.</p>
<h2 id="meta-3"><a class="header" href="#meta-3">META</a></h2>
<p>The keywords "MUST", "MUST NOT", "REQUIRED", "SHALL", "SHALL NOT", "SHOULD", "SHOULD NOT", "RECOMMENDED", "MAY", and
"OPTIONAL" in this document are to be interpreted as described in <a href="https://www.ietf.org/rfc/rfc2119.txt">RFC 2119</a>.</p>
<p>This specification presents documents as Extended JSON for readability and expressing special types (e.g. ObjectId).
Although JSON fields are unordered, the order of fields presented herein should be considered pertinent. This is
especially relevant for the <a href="dbref/dbref.html#test-plan">Test Plan</a>.</p>
<h2 id="specification-3"><a class="header" href="#specification-3">Specification</a></h2>
<h3 id="dbref-structure"><a class="header" href="#dbref-structure">DBRef Structure</a></h3>
<p>A DBRef is an embedded document with the following fields:</p>
<ul>
<li><code>$ref</code>: required string field. Contains the name of the collection where the referenced document resides. This MUST be
the first field in the DBRef.</li>
<li><code>$id</code>: required field. Contains the value of the <code>_id</code> field of the referenced document. This MUST be the second field
in the DBRef.</li>
<li><code>$db</code>: optional string field. Contains the name of the database where the referenced document resides. If specified,
this MUST be the third field in the DBRef. If omitted, the referenced document is assumed to reside in the same
database as the DBRef.</li>
<li>Extra, optional fields may follow after <code>$id</code> or <code>$db</code> (if specified). There are no inherent restrictions on extra
field names; however, older server versions may impose their own restrictions (e.g. no dots or dollars).</li>
</ul>
<p>DBRefs have no relation to the deprecated DBPointer BSON type (i.e. type 0x0C).</p>
<h4 id="examples-of-valid-dbrefs"><a class="header" href="#examples-of-valid-dbrefs">Examples of Valid DBRefs</a></h4>
<p>The following examples are all valid DBRefs:</p>
<pre><code class="language-typescript">// Basic DBRef with only $ref and $id fields
{ "$ref": "coll0", "$id": { "$oid": "60a6fe9a54f4180c86309efa" } }

// DBRef $id is not necessarily an ObjectId
{ "$ref": "coll0", "$id": 1 }

// DBRef with optional $db field
{ "$ref": "coll0", "$id": 1, "$db": "db0" }

// DBRef with extra, optional fields (with or without $db)
{ "$ref": "coll0", "$id": 1, "$db": "db0", "foo": "bar" }
{ "$ref": "coll0", "$id": 1, "foo": true }

// Extra field names have no inherent restrictions
{ "$ref": "coll0", "$id": 1, "$foo": "bar" }
{ "$ref": "coll0", "$id": 1, "foo.bar": 0 }
</code></pre>
<h4 id="examples-of-invalid-dbrefs"><a class="header" href="#examples-of-invalid-dbrefs">Examples of Invalid DBRefs</a></h4>
<p>The following examples are all invalid DBRefs:</p>
<pre><code class="language-typescript">// Required fields are omitted
{ "$ref": "coll0" }
{ "$id": { "$oid": "60a6fe9a54f4180c86309efa" } }

// Invalid types for $ref or $db
{ "$ref": true, "$id": 1 }
{ "$ref": "coll0", "$id": 1, "$db": 1 }

// Fields are out of order
{ "$id": 1, "$ref": "coll0" }
</code></pre>
<h3 id="implementing-a-dbref-model"><a class="header" href="#implementing-a-dbref-model">Implementing a DBRef Model</a></h3>
<p>Drivers MAY provide a model class for encoding and/or decoding DBRef documents. For those drivers that do, this section
defines expected behavior of that class. This section does not prohibit drivers from implementing additional
functionality, provided it does not conflict with any of these guidelines.</p>
<h4 id="constructing-a-dbref-model"><a class="header" href="#constructing-a-dbref-model">Constructing a DBRef model</a></h4>
<p>Drivers MAY provide an API for constructing a DBRef model directly from its constituent parts. If so:</p>
<ul>
<li>Drivers MUST solicit a string value for <code>$ref</code>.</li>
<li>Drivers MUST solicit an arbitrary value for <code>$id</code>. Drivers SHOULD NOT enforce any restrictions on this value; however,
this may be necessary if the driver is unable to differentiate between certain BSON types (e.g. <code>null</code>, <code>undefined</code>)
and the parameter being unspecified.</li>
<li>Drivers SHOULD solicit an optional string value for <code>$db</code>.</li>
<li>Drivers MUST require <code>$ref</code> and <code>$db</code> (if specified) to be strings but MUST NOT enforce any
<a href="https://www.mongodb.com/docs/manual/reference/limits/#naming-restrictions">naming restrictions</a> on the string values.</li>
<li>Drivers MAY solicit extra, optional fields.</li>
</ul>
<h4 id="decoding-a-bson-document-to-a-dbref-model"><a class="header" href="#decoding-a-bson-document-to-a-dbref-model">Decoding a BSON document to a DBRef model</a></h4>
<p>Drivers MAY support explicit and/or implicit decoding. An example of explicit decoding might be a DBRef model
constructor that takes a BSON document. An example of implicit decoding might be configuring the driver's BSON codec to
automatically convert embedded documents that comply with the <a href="dbref/dbref.html#dbref-structure">DBRef Structure</a> into a DBRef model.</p>
<p>Drivers that provide implicit decoding SHOULD provide some way for applications to opt out and allow DBRefs to be
decoded like any other embedded document.</p>
<p>When decoding a BSON document to a DBRef model:</p>
<ul>
<li>Drivers MUST require <code>$ref</code> and <code>$id</code> to be present.</li>
<li>Drivers MUST require <code>$ref</code> and <code>$db</code> (if present) to be strings but MUST NOT enforce any
<a href="https://www.mongodb.com/docs/manual/reference/limits/#naming-restrictions">naming restrictions</a> on the string values.</li>
<li>Drivers MUST accept any BSON type for <code>$id</code> and MUST NOT enforce any restrictions on its value.</li>
<li>Drivers MUST preserve extra, optional fields (beyond <code>$ref</code>, <code>$id</code>, and <code>$db</code>) and MUST provide some way to access
those fields via the DBRef model. For example, an accessor method that returns the original BSON document (including
<code>$ref</code>, etc.) would fulfill this requirement.</li>
</ul>
<p>If a BSON document cannot be implicitly decoded to a DBRef model, it MUST be left as-is (like any other embedded
document). If a BSON document cannot be explicitly decoded to a DBRef model, the driver MUST raise an error.</p>
<p>Since DBRefs are a special type of embedded document, a DBRef model class used for decoding SHOULD inherit the class
used to represent an embedded document (e.g. Hash in Ruby). This will allow applications to always expect an instance of
a common class when decoding an embedded document (if desired) and should also support the requirement for DBRef models
to provide access to any extra, optional fields.</p>
<h4 id="encoding-a-dbref-model-to-a-bson-document"><a class="header" href="#encoding-a-dbref-model-to-a-bson-document">Encoding a DBRef model to a BSON document</a></h4>
<p>Drivers MAY support explicit and/or implicit encoding. An example of explicit encoding might be a DBRef method that
returns its corresponding representation as a BSON document. An example of implicit encoding might be configuring the
driver's BSON codec to automatically convert DBRef models to the corresponding BSON document representation as needed.</p>
<p>If a driver supports implicit decoding of BSON to a DBRef model, it SHOULD also support implicit encoding. Doing so will
allow applications to more easily round-trip DBRefs through the driver.</p>
<p>When encoding a DBRef model to BSON document:</p>
<ul>
<li>Drivers MUST encode all fields in the order defined in <a href="dbref/dbref.html#dbref-structure">DBRef Structure</a>.</li>
<li>Drivers MUST encode <code>$ref</code> and <code>$id</code>. If <code>$db</code> was specified, it MUST be encoded after <code>$id</code>. If any extra, optional
fields were specified, they MUST be encoded after <code>$id</code> or <code>$db</code>.</li>
<li>If the DBRef includes any extra, optional fields after <code>$id</code> or <code>$db</code>, drivers SHOULD attempt to preserve the original
order of those fields relative to one another.</li>
</ul>
<h2 id="test-plan-2"><a class="header" href="#test-plan-2">Test Plan</a></h2>
<p>The test plan consists of a series of prose tests. These tests are only relevant to drivers that provide a DBRef model
class.</p>
<p>The documents in these tests are presented as Extended JSON for readability; however, readers should consider the field
order pertinent when translating to BSON (or their language equivalent). These tests are not intended to exercise a
driver's Extended JSON parser. Implementations SHOULD construct the documents directly using native BSON types (e.g.
Document, ObjectId).</p>
<h3 id="decoding"><a class="header" href="#decoding">Decoding</a></h3>
<p>These tests are only relevant to drivers that allow decoding into a DBRef model. Drivers SHOULD implement these tests
for both explicit and implicit decoding code paths as needed.</p>
<ol>
<li>
<p>Valid documents MUST be decoded to a DBRef model. For each of the following:</p>
<ol>
<li><code>{ "$ref": "coll0", "$id": { "$oid": "60a6fe9a54f4180c86309efa" } }</code></li>
<li><code>{ "$ref": "coll0", "$id": 1 }</code></li>
<li><code>{ "$ref": "coll0", "$id": null }</code></li>
<li><code>{ "$ref": "coll0", "$id": 1, "$db": "db0" }</code></li>
</ol>
<p>Assert that each document is successfully decoded to a DBRef model. Assert that the <code>$ref</code>, <code>$id</code>, and <code>$db</code> (if
applicable) fields have their expected value.</p>
</li>
<li>
<p>Valid documents with extra fields MUST be decoded to a DBRef model and the model MUST provide some way to access
those extra fields. For each of the following:</p>
<ol>
<li><code>{ "$ref": "coll0", "$id": 1, "$db": "db0", "foo": "bar" }</code></li>
<li><code>{ "$ref": "coll0", "$id": 1, "foo": true, "bar": false }</code></li>
<li><code>{ "$ref": "coll0", "$id": 1, "meta": { "foo": 1, "bar": 2 } }</code></li>
<li><code>{ "$ref": "coll0", "$id": 1, "$foo": "bar" }</code></li>
<li><code>{ "$ref": "coll0", "$id": 1, "foo.bar": 0 }</code></li>
</ol>
<p>Assert that each document is successfully decoded to a DBRef model. Assert that the <code>$ref</code>, <code>$id</code>, and <code>$db</code> (if
applicable) fields have their expected value. Assert that it is possible to access all extra fields and that those
fields have their expected value.</p>
</li>
<li>
<p>Documents with out of order fields that are otherwise valid MUST be decoded to a DBRef model. For each of the
following:</p>
<ol>
<li><code>{ "$id": 1, "$ref": "coll0" }</code></li>
<li><code>{ "$db": "db0", "$ref": "coll0", "$id": 1 }</code></li>
<li><code>{ "foo": 1, "$id": 1, "$ref": "coll0" }</code></li>
<li><code>{ "foo": 1, "$ref": "coll0", "$id": 1, "$db": "db0" }</code></li>
<li><code>{ "foo": 1, "$ref": "coll0", "$id": 1, "$db": "db0", "bar": 1 }</code></li>
</ol>
<p>Assert that each document is successfully decoded to a DBRef model. Assert that the <code>$ref</code>, <code>$id</code>, <code>$db</code> (if
applicable), and any extra fields (if applicable) have their expected value.</p>
</li>
<li>
<p>Documents missing required fields MUST NOT be decoded to a DBRef model. For each of the following:</p>
<ol>
<li><code>{ "$ref": "coll0" }</code></li>
<li><code>{ "$id": { "$oid": "60a6fe9a54f4180c86309efa" } }</code></li>
<li><code>{ "$db": "db0" }</code></li>
</ol>
<p>Assert that each document is not decoded to a DBRef model. In the context of implicit decoding, the document MUST be
decoded like any other embedded document. In the context of explicit decoding, the DBRef decoding method MUST raise
an error.</p>
</li>
<li>
<p>Documents with invalid types for <code>$ref</code> or <code>$db</code> MUST NOT be decoded to a DBRef model. For each of the following:</p>
<ol>
<li><code>{ "$ref": true, "$id": 1 }</code></li>
<li><code>{ "$ref": "coll0", "$id": 1, "$db": 1 }</code></li>
</ol>
<p>Assert that each document is not decoded to a DBRef model. In the context of implicit decoding, the document MUST be
decoded like any other embedded document. In the context of explicit decoding, the DBRef decoding method MUST raise
an error.</p>
</li>
</ol>
<h3 id="encoding"><a class="header" href="#encoding">Encoding</a></h3>
<p>These tests are only relevant to drivers that allow encoding a DBRef model. Drivers SHOULD implement these tests for
both explicit and implicit encoding code paths as needed.</p>
<p>Drivers MAY use any method to create the DBRef model for each test (e.g. constructor, explicit decoding method).</p>
<p>Drivers MAY skip tests that cannot be implemented as written (e.g. DBRef model constructor does not support extra,
optional fields and the driver also does not support explicit/implicit decoding).</p>
<ol>
<li>
<p>Encoding DBRefs with basic fields. For each of the following:</p>
<ol>
<li><code>{ "$ref": "coll0", "$id": { "$oid": "60a6fe9a54f4180c86309efa" } }</code></li>
<li><code>{ "$ref": "coll0", "$id": 1 }</code></li>
<li><code>{ "$ref": "coll0", "$id": null }</code></li>
<li><code>{ "$ref": "coll0", "$id": 1, "$db": "db0" }</code></li>
</ol>
<p>Assert that each DBRef model is successfully encoded to a BSON document. Assert that the <code>$ref</code>, <code>$id</code>, and <code>$db</code> (if
applicable) fields appear in the correct order and have their expected values.</p>
</li>
<li>
<p>Encoding DBRefs with extra, optional fields. For each of the following:</p>
<ol>
<li><code>{ "$ref": "coll0", "$id": 1, "$db": "db0", "foo": "bar" }</code></li>
<li><code>{ "$ref": "coll0", "$id": 1, "foo": true, "bar": false }</code></li>
<li><code>{ "$ref": "coll0", "$id": 1, "meta": { "foo": 1, "bar": 2 } }</code></li>
<li><code>{ "$ref": "coll0", "$id": 1, "$foo": "bar" }</code></li>
<li><code>{ "$ref": "coll0", "$id": 1, "foo.bar": 0 }</code></li>
</ol>
<p>Assert that each DBRef model is successfully encoded to a BSON document. Assert that the <code>$ref</code>, <code>$id</code>, <code>$db</code> (if
applicable), and any extra fields appear in the correct order and have their expected values.</p>
</li>
<li>
<p>Encoding DBRefs re-orders any out of order fields during decoding. This test MUST NOT use a constructor that solicits
fields individually. For each of the following:</p>
<ol>
<li><code>{ "$id": 1, "$ref": "coll0" }</code></li>
<li><code>{ "$db": "db0", "$ref": "coll0", "$id": 1 }</code></li>
<li><code>{ "foo": 1, "$id": 1, "$ref": "coll0" }</code></li>
<li><code>{ "foo": 1, "$ref": "coll0", "$id": 1, "$db": "db0" }</code></li>
<li><code>{ "foo": 1, "$ref": "coll0", "$id": 1, "$db": "db0", "bar": 1 }</code></li>
</ol>
<p>Assert that each document is successfully decoded to a DBRef model and then successfully encoded back to a BSON
document. Assert that the order of fields in each encoded BSON document matches the following, respectively:</p>
<ol>
<li><code>{ "$ref": "coll0", "$id": 1 }</code></li>
<li><code>{ "$ref": "coll0", "$id": 1, "$db": "db0" }</code></li>
<li><code>{ "$ref": "coll0", "$id": 1, "foo": 1 }</code></li>
<li><code>{ "$ref": "coll0", "$id": 1, "$db": "db0", "foo": 1}</code></li>
<li><code>{ "$ref": "coll0", "$id": 1, "$db": "db0", "foo": 1, "bar": 1 }</code></li>
</ol>
</li>
</ol>
<h2 id="design-rationale-2"><a class="header" href="#design-rationale-2">Design Rationale</a></h2>
<p>In contrast to always encoding DBRefs with the correct field order, decoding permits fields to be out of order (provided
the document is otherwise valid). This follows the
<a href="https://en.wikipedia.org/wiki/Robustness_principle">robustness principle</a> in having the driver be liberal in what it
accepts and conservative in what it emits. This does mean that round-tripping an out of order DBRef through a driver
could result in its field order being changed; however, this behavior is consistent with existing behavior in drivers
that model DBRefs (e.g. C#, Java, Node, Python, Ruby) and applications can opt out of implicit decoding if desired.</p>
<h2 id="changelog-3"><a class="header" href="#changelog-3">Changelog</a></h2>
<ul>
<li>2024-02-26: Migrated from reStructuredText to Markdown.</li>
<li>2022-10-05: Remove spec front matter.</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="extended-json"><a class="header" href="#extended-json">Extended JSON</a></h1>
<ul>
<li>Status: Accepted</li>
<li>Minimum Server Version: N/A</li>
</ul>
<hr />
<h2 id="abstract-4"><a class="header" href="#abstract-4">Abstract</a></h2>
<p>MongoDB Extended JSON is a string format for representing BSON documents. This specification defines the canonical
format for representing each BSON type in the Extended JSON format. Thus, a tool that implements Extended JSON will be
able to parse the output of any tool that emits Canonical Extended JSON. It also defines a Relaxed Extended JSON format
that improves readability at the expense of type information preservation.</p>
<h2 id="meta-4"><a class="header" href="#meta-4">META</a></h2>
<p>The keywords "MUST", "MUST NOT", "REQUIRED", "SHALL", "SHALL NOT", "SHOULD", "SHOULD NOT", "RECOMMENDED", "MAY", and
"OPTIONAL" in this document are to be interpreted as described in <a href="https://www.ietf.org/rfc/rfc2119.txt">RFC 2119</a>.</p>
<h3 id="naming"><a class="header" href="#naming">Naming</a></h3>
<p>Acceptable naming deviations should fall within the basic style of the language. For example, <code>CanonicalExtendedJSON</code>
would be a name in Java, where camel-case method names are used, but in Ruby <code>canonical_extended_json</code> would be
acceptable.</p>
<h2 id="terms-1"><a class="header" href="#terms-1">Terms</a></h2>
<p><em>Type wrapper object</em> - a JSON value consisting of an object with one or more <code>$</code>-prefixed keys that collectively encode
a BSON type and its corresponding value using only JSON value primitives.</p>
<p><em>Extended JSON</em> - A general term for one of many string formats based on the JSON standard that describes how to
represent BSON documents in JSON using standard JSON types and/or type wrapper objects. This specification gives a
formal definition to variations of such a format.</p>
<p><em>Relaxed Extended JSON</em> - A string format based on the JSON standard that describes BSON documents. Relaxed Extended
JSON emphasizes readability and interoperability at the expense of type preservation.</p>
<p><em>Canonical Extended JSON</em> - A string format based on the JSON standard that describes BSON documents. Canonical Extended
JSON emphasizes type preservation at the expense of readability and interoperability.</p>
<p><em>Legacy Extended JSON</em> - A string format based on the JSON standard that describes a BSON document. The Legacy Extended
JSON format does not describe a specific, standardized format, and many tools, drivers, and libraries implement Extended
JSON in conflicting ways.</p>
<h2 id="specification-4"><a class="header" href="#specification-4">Specification</a></h2>
<h3 id="extended-json-format"><a class="header" href="#extended-json-format">Extended JSON Format</a></h3>
<p>The Extended JSON grammar extends the JSON grammar as defined in
<a href="https://tools.ietf.org/html/rfc7159#section-2">section 2</a> of the
<a href="https://tools.ietf.org/html/rfc7159">JSON specification</a> by augmenting the possible JSON values as defined in
<a href="https://tools.ietf.org/html/rfc7159#section-3">Section 3</a>. This specification defines two formats for Extended JSON:</p>
<ul>
<li>Canonical Extended JSON</li>
<li>Relaxed Extended JSON</li>
</ul>
<p>An Extended JSON value MUST conform to one of these two formats as described in the table below.</p>
<h4 id="notes-on-grammar"><a class="header" href="#notes-on-grammar">Notes on grammar</a></h4>
<ul>
<li>Key order:
<ul>
<li>Keys within Canonical Extended JSON type wrapper objects SHOULD be emitted in the order described.</li>
<li>Keys within Relaxed Extended JSON type wrapper objects are unordered.</li>
</ul>
</li>
<li>Terms in <em>italics</em> represent types defined elsewhere in the table or in the
<a href="https://tools.ietf.org/html/rfc7159">JSON specification</a>.</li>
<li>JSON <em>numbers</em> (as defined in <a href="https://tools.ietf.org/html/rfc7159#section-6">Section 6</a> of the JSON specification)
include both integer and floating point types. For the purpose of this document, we define the following subtypes:
<ul>
<li>Type <em>integer</em> means a JSON <em>number</em> without <em>frac</em> or <em>exp</em> components; this is expressed in the JSON spec grammar
as <code>[minus] int</code>.</li>
<li>Type <em>non-integer</em> means a JSON <em>number</em> that is not an <em>integer</em>; it must include either a <em>frac</em> or <em>exp</em>
component or both.</li>
<li>Type <em>pos-integer</em> means a non-negative JSON <em>number</em> without <em>frac</em> or <em>exp</em> components; this is expressed in the
JSON spec grammar as <code>int</code>.</li>
</ul>
</li>
<li>A <em>hex string</em> is a JSON <em>string</em> that contains only hexadecimal digits <code>[0-9a-f]</code>. It SHOULD be emitted lower-case,
but MUST be read in a case-insensitive fashion.</li>
<li><code>&lt;Angle brackets&gt;</code> detail the contents of a value, including type information.</li>
<li><code>[Square brackets]</code> specify a type constraint that restricts the specification to a particular range or set of values.</li>
</ul>
<h4 id="conversion-table"><a class="header" href="#conversion-table">Conversion table</a></h4>
<div class="table-wrapper"><table><thead><tr><th><strong>BSON 1.1 Type or Convention</strong></th><th><strong>Canonical Extended JSON Format</strong></th><th><strong>Relaxed Extended JSON Format</strong></th></tr></thead><tbody>
<tr><td>ObjectId</td><td>{"$oid": &lt;ObjectId bytes as 24-character, big-endian <em>hex string</em>&gt;}</td><td><Same as Canonical Extended JSON></td></tr>
<tr><td>Symbol</td><td>{"$symbol": <em>string</em>}</td><td><Same as Canonical Extended JSON></td></tr>
<tr><td>String</td><td><em>string</em></td><td><Same as Canonical Extended JSON></td></tr>
<tr><td>Int32</td><td>{"$numberInt": &lt;32-bit signed integer as a <em>string</em>&gt;}</td><td><em>integer</em></td></tr>
<tr><td>Int64</td><td>{"$numberLong": &lt;64-bit signed integer as a <em>string</em>&gt;}</td><td><em>integer</em></td></tr>
<tr><td>Double [finite]</td><td>{"$numberDouble": &lt;64-bit signed floating point as a decimal <em>string</em>&gt;}</td><td><em>non-integer</em></td></tr>
<tr><td>Double [non-finite]</td><td>{"$numberDouble": &lt;One of the <em>strings</em>: "Infinity", "-Infinity", or "NaN"&gt;}</td><td><Same as Canonical Extended JSON></td></tr>
<tr><td>Decimal128</td><td>{"$numberDecimal": <decimal as a _string_>}<sup class="footnote-reference"><a href="#1">1</a></sup></td><td><Same as Canonical Extended JSON></td></tr>
<tr><td>Binary</td><td>{"$binary": {"base64": &lt;base64-encoded (with padding as <code>=</code>) payload as a <em>string</em>&gt;, "subType": <BSON binary type as a one- or two-character _hex string_>}}</td><td><Same as Canonical Extended JSON></td></tr>
<tr><td>Code</td><td>{"$code": <em>string</em>}</td><td><Same as Canonical Extended JSON></td></tr>
<tr><td>CodeWScope</td><td>{"$code": <em>string</em>, "$scope": <em>Document</em>}</td><td><Same as Canonical Extended JSON></td></tr>
<tr><td>Document</td><td><em>object</em> (with Extended JSON extensions)</td><td><Same as Canonical Extended JSON></td></tr>
<tr><td>Timestamp</td><td>{"$timestamp": {"t": <em>pos-integer</em>, "i": <em>pos-integer</em>}}</td><td><Same as Canonical Extended JSON></td></tr>
<tr><td>Regular Expression</td><td>{"$regularExpression": {pattern: <em>string</em>, "options": &lt;BSON regular expression options as a <em>string</em> or ""<sup class="footnote-reference"><a href="#2">2</a></sup>&gt;}}</td><td><Same as Canonical Extended JSON></td></tr>
<tr><td>DBPointer</td><td>{"$dbPointer": {"$ref": &lt;namespace<sup class="footnote-reference"><a href="#3">3</a></sup> as a <em>string</em>&gt;, "$id": <em>ObjectId</em>}}</td><td><Same as Canonical Extended JSON></td></tr>
<tr><td>Datetime [year from 1970 to 9999 inclusive]</td><td>{"$date": {"$numberLong": &lt;64-bit signed integer giving millisecs relative to the epoch, as a <em>string</em>&gt;}}</td><td>{"$date": &lt;ISO-8601 Internet Date/Time Format as described in RFC-3339<sup class="footnote-reference"><a href="#4">4</a></sup> with maximum time precision of milliseconds<sup class="footnote-reference"><a href="#5">5</a></sup> as a <em>string</em>&gt;}</td></tr>
<tr><td>Datetime [year before 1970 or after 9999]</td><td>{"$date": {"$numberLong": &lt;64-bit signed integer giving millisecs relative to the epoch, as a <em>string</em>&gt;}}</td><td><Same as Canonical Extended JSON></td></tr>
<tr><td>DBRef<sup class="footnote-reference"><a href="#6">6</a></sup><br><br>Note: this is not technically a BSON type, but it is a common convention.</td><td>{"$ref": <collection name as a _string_>, "$id": <Extended JSON for the id>}<br><br>If the generator supports DBRefs with a database component, and the database component is nonempty:<br><br>{"$ref": <collection name as a _string_>,<br><br>"$id": <Extended JSON for the id>, "$db": <database name as a _string_>}<br><br>DBRefs may also have other fields, which MUST appear after <code>$id</code> and <code>$db</code> (if supported).</td><td><Same as Canonical Extended JSON></td></tr>
<tr><td>MinKey</td><td>{"$minKey": 1}</td><td><Same as Canonical Extended JSON></td></tr>
<tr><td>MaxKey</td><td>{"$maxKey": 1}</td><td><Same as Canonical Extended JSON></td></tr>
<tr><td>Undefined</td><td>{"$undefined": <em>true</em>}</td><td><Same as Canonical Extended JSON></td></tr>
<tr><td>Array</td><td><em>array</em></td><td><Same as Canonical Extended JSON></td></tr>
<tr><td>Boolean</td><td><em>true</em> or <em>false</em></td><td><Same as Canonical Extended JSON></td></tr>
<tr><td>Null</td><td><em>null</em></td><td><Same as Canonical Extended JSON></td></tr>
</tbody></table>
</div>
<hr />
<h4 id="representation-of-non-finite-numeric-values"><a class="header" href="#representation-of-non-finite-numeric-values">Representation of Non-finite Numeric Values</a></h4>
<p>Following the <a href="extended-json/../bson-decimal128/decimal128.html#to-string-representation">Extended JSON format for the Decimal128 type</a>,
non-finite numeric values are encoded as follows:</p>
<div class="table-wrapper"><table><thead><tr><th><strong>Value</strong></th><th><strong>String</strong></th></tr></thead><tbody>
<tr><td>Positive Infinity</td><td><code>Infinity</code></td></tr>
<tr><td>Negative Infinity</td><td><code>-Infinity</code></td></tr>
<tr><td>NaN (all variants)</td><td><code>NaN</code></td></tr>
</tbody></table>
</div>
<p>For example, a BSON floating-point number with a value of negative infinity would be encoded as Extended JSON as
follows:</p>
<pre><code>{"$numberDouble": "-Infinity"}
</code></pre>
<h3 id="parsers"><a class="header" href="#parsers">Parsers</a></h3>
<p>An Extended JSON parser (hereafter just "parser") is a tool that transforms an Extended JSON string into another
representation, such as BSON or a language-native data structure.</p>
<p>By default, a parser MUST accept values in either Canonical Extended JSON format or Relaxed Extended JSON format as
described in this specification. A parser MAY allow users to restrict parsing to only Canonical Extended JSON format or
only Relaxed Extended JSON format.</p>
<p>A parser MAY also accept strings that adhere to other formats, such as Legacy Extended JSON formats emitted by old
versions of mongoexport or other tools, but only if explicitly configured to do so.</p>
<p>A parser that accepts Legacy Extended JSON MUST be configurable such that a JSON text of a MongoDB query filter
containing the <a href="https://www.mongodb.com/docs/manual/reference/operator/query/regex/">regex</a> query operator can be
parsed, e.g.:</p>
<pre><code class="language-javascript">{ "$regex": {
    "$regularExpression" : { "pattern": "foo*", "options": "" }
    },
    "$options" : "ix"
}
</code></pre>
<p>or:</p>
<pre><code class="language-javascript">{ "$regex": {
    "$regularExpression" : { "pattern": "foo*", "options": "" }
    }
}
</code></pre>
<p>A parser that accepts Legacy Extended JSON MUST be configurable such that a JSON text of a MongoDB query filter
containing the <a href="https://www.mongodb.com/docs/manual/reference/operator/query/type/">type</a> query operator can be parsed,
e.g.:</p>
<pre><code class="language-javascript">{ "zipCode" : { $type : 2 } }
</code></pre>
<p>or:</p>
<pre><code class="language-javascript">{ "zipCode" : { $type : "string" } }
</code></pre>
<p>A parser SHOULD support at least 200 levels of nesting in an Extended JSON document but MAY set other limits on strings
it can accept as defined in <a href="https://tools.ietf.org/html/rfc7159#section-9">section 9</a> of the
<a href="https://tools.ietf.org/html/rfc7159">JSON specification</a>.</p>
<p>When parsing a JSON object other than the top-level object, the presence of a <code>$</code>-prefixed key indicates the object
could be a type wrapper object as described in the Extended JSON <a href="extended-json/extended-json.html#conversion-table">Conversion table</a>. In such a case,
the parser MUST follow these rules, unless configured to allow Legacy Extended JSON, in which case it SHOULD follow
these rules:</p>
<ul>
<li>
<p>Parsers MUST NOT consider key order as having significance. For example, the document
<code>{"$code": "function(){}", "$scope": {}}</code> must be considered identical to <code>{"$scope": {}, "$code": "function(){}"}</code>.</p>
</li>
<li>
<p>If the parsed object contains any of the special <strong>keys</strong> for a type in the <a href="extended-json/extended-json.html#conversion-table">Conversion table</a>
(e.g. <code>"$binary"</code>, <code>"$timestamp"</code>) then it must contain exactly the keys of the type wrapper. Any missing or extra
keys constitute an error.</p>
<p>DBRef is the lone exception to this rule, as it is only a common convention and not a proper type. An object that
resembles a DBRef but fails to fully comply with its structure (e.g. has <code>$ref</code> but missing <code>$id</code>) MUST be left as-is
and MUST NOT constitute an error.</p>
</li>
<li>
<p>If the <strong>keys</strong> of the parsed object exactly match the <strong>keys</strong> of a type wrapper in the Conversion table, and the
<strong>values</strong> of the parsed object have the correct type for the type wrapper as described in the Conversion table, then
the parser MUST interpret the parsed object as a type wrapper object of the corresponding type.</p>
</li>
<li>
<p>If the <strong>keys</strong> of the parsed object exactly match the <strong>keys</strong> of a type wrapper in the Conversion table, but any of
the <strong>values</strong> are of an incorrect type, then the parser MUST report an error.</p>
</li>
<li>
<p>If the <code>$</code>-prefixed key does not match a known type wrapper in the Conversion table, the parser MUST NOT raise an
error and MUST leave the value as-is. See <a href="extended-json/extended-json.html#restrictions-and-limitations">Restrictions and limitations</a> for additional
information.</p>
</li>
</ul>
<h4 id="special-rules-for-parsing-json-numbers"><a class="header" href="#special-rules-for-parsing-json-numbers">Special rules for parsing JSON numbers</a></h4>
<p>The Relaxed Extended JSON format uses JSON numbers for several different BSON types. In order to allow parsers to use
language-native JSON decoders (which may not distinguish numeric type when parsing), the following rules apply to
parsing JSON numbers:</p>
<ul>
<li>If the number is a <em>non-integer</em>, parsers SHOULD interpret it as BSON Double.</li>
<li>If the number is an <em>integer</em>, parsers SHOULD interpret it as being of the smallest BSON integer type that can
represent the number exactly. If a parser is unable to represent the number exactly as an integer (e.g. a large 64-bit
number on a 32-bit platform), it MUST interpret it as a BSON Double even if this results in a loss of precision. The
parser MUST NOT interpret it as a BSON String containing a decimal representation of the number.</li>
</ul>
<h4 id="special-rules-for-parsing-uuid-fields"><a class="header" href="#special-rules-for-parsing-uuid-fields">Special rules for parsing <code>$uuid</code> fields</a></h4>
<p>As per the <a href="extended-json/../bson-binary-uuid/uuid.html">UUID specification</a>, Binary subtype 3 or 4 are used to represent UUIDs in BSON.
Consequently, UUIDs are handled as per the convention described for the <code>Binary</code> type in the
<a href="extended-json/extended-json.html#conversion-table">Conversion table</a>, e.g. the following document written with the MongoDB Python Driver:</p>
<pre><code class="language-javascript">{"Binary": uuid.UUID("c8edabc3-f738-4ca3-b68d-ab92a91478a3")}
</code></pre>
<p>is transformed into the following (newlines and spaces added for readability):</p>
<pre><code class="language-javascript">{"Binary": {
    "$binary": {
        "base64": "yO2rw/c4TKO2jauSqRR4ow==",
        "subType": "04"}
    }
}
</code></pre>
<blockquote>
<p>[!NOTE]
The above described type conversion assumes that UUID representation is set to <code>STANDARD</code>. See the
<a href="extended-json/../bson-binary-uuid/uuid.html">UUID specification</a> for more information about UUID representations.</p>
</blockquote>
<p>While this transformation preserves BSON subtype information (since UUIDs can be represented as BSON subtype 3 <em>or</em> 4),
base64-encoding is not the standard way of representing UUIDs and using it makes comparing these values against textual
representations coming from platform libraries difficult. Consequently, we also allow UUIDs to be represented in
extended JSON as:</p>
<pre><code class="language-javascript">{"$uuid": &lt;canonical textual representation of a UUID&gt;}
</code></pre>
<p>The rules for generating the canonical string representation of a UUID are defined in
<a href="https://tools.ietf.org/html/rfc4122#section-3">RFC 4122 Section 3</a>. Use of this format result in a more readable
extended JSON representation of the UUID from the previous example:</p>
<pre><code class="language-javascript">{"Binary": {
    "$uuid": "c8edabc3-f738-4ca3-b68d-ab92a91478a3"
    }
}
</code></pre>
<p>Parsers MUST interpret the <code>$uuid</code> key as BSON Binary subtype 4. Parsers MUST accept textual representations of UUIDs
that omit the URN prefix (usually <code>urn:uuid:</code>). Parsers MAY also accept textual representations of UUIDs that omit the
hyphens between hex character groups (e.g. <code>c8edabc3f7384ca3b68dab92a91478a3</code>).</p>
<h3 id="generators"><a class="header" href="#generators">Generators</a></h3>
<p>An Extended JSON generator (hereafter just "generator") produces strings in an Extended JSON format.</p>
<p>A generator MUST allow users to produce strings in either the Canonical Extended JSON format or the Relaxed Extended
JSON format. If generators provide a default format, the default SHOULD be the Relaxed Extended JSON format.</p>
<p>A generator MAY be capable of exporting strings that adhere to other formats, such as Legacy Extended JSON formats.</p>
<p>A generator SHOULD support at least 100 levels of nesting in a BSON document.</p>
<h4 id="transforming-bson"><a class="header" href="#transforming-bson">Transforming BSON</a></h4>
<p>Given a BSON document (e.g. a buffer of bytes meeting the requirements of the BSON specification), a generator MUST use
the corresponding JSON values or Extended JSON type wrapper objects for the BSON type given in the Extended JSON
<a href="extended-json/extended-json.html#conversion-table">Conversion table</a> for the desired format. When transforming a BSON document into Extended JSON text,
a generator SHOULD emit the JSON keys and values in the same order as given in the BSON document.</p>
<h4 id="transforming-language-native-data"><a class="header" href="#transforming-language-native-data">Transforming Language-Native data</a></h4>
<p>Given language-native data (e.g. type primitives, container types, classes, etc.), if there is a semantically-equivalent
BSON type for a given language-native type, a generator MUST use the corresponding JSON values or Extended JSON type
wrapper objects for the BSON type given in the Extended JSON <a href="extended-json/extended-json.html#conversion-table">Conversion table</a> for the desired
format. For example, a Python <code>datetime</code> object must be represented the same as a BSON datetime type. A generator SHOULD
error if a language-native type has no semantically-equivalent BSON type.</p>
<h4 id="format-and-method-names"><a class="header" href="#format-and-method-names">Format and Method Names</a></h4>
<p>The following format names SHOULD be used for selecting formats for generator output:</p>
<ul>
<li><code>canonicalExtendedJSON</code> (references Canonical Extended JSON as described in this specification)</li>
<li><code>relaxedExtendedJSON</code> (references Relaxed Extended JSON as described in this specification)</li>
<li><code>legacyExtendedJSON</code> (if supported: references Legacy Extended JSON, with implementation-defined behavior)</li>
</ul>
<p>Generators MAY use these format names as part of function/method names or MAY use them as arguments or constants, as
needed.</p>
<p>If a generator provides a generic <code>to_json</code> or <code>to_extended_json</code> method, it MUST default to producing Relaxed Extended
JSON or MUST be deprecated in favor of a spec-compliant method.</p>
<h3 id="restrictions-and-limitations"><a class="header" href="#restrictions-and-limitations">Restrictions and limitations</a></h3>
<p>Extended JSON is designed primarily for testing and human inspection of BSON documents. It is not designed to reliably
round-trip BSON documents. One fundamental limitation is that JSON objects are inherently unordered and BSON objects are
ordered.</p>
<p>Further, Extended JSON uses <code>$</code>-prefixed keys in type wrappers and has no provision for escaping a leading <code>$</code> used
elsewhere in a document. This means that the Extended JSON representation of a document with <code>$</code>-prefixed keys could be
indistinguishable from another document with a type wrapper with the same keys.</p>
<p>Extended JSON formats SHOULD NOT be used in contexts where <code>$</code>-prefixed keys could exist in BSON documents (with the
exception of the DBRef convention, which is accounted for in this spec).</p>
<h2 id="test-plan-3"><a class="header" href="#test-plan-3">Test Plan</a></h2>
<p>Drivers, tools, and libraries can test their compliance to this specification by running the tests in version 2.0 and
above of the <a href="extended-json/../bson-corpus/bson-corpus.html">BSON Corpus Test Suite</a>.</p>
<h2 id="examples"><a class="header" href="#examples">Examples</a></h2>
<h3 id="canonical-extended-json-example"><a class="header" href="#canonical-extended-json-example">Canonical Extended JSON Example</a></h3>
<p>Consider the following document, written with the MongoDB Python Driver:</p>
<pre><code class="language-javascript">{
    "_id": bson.ObjectId("57e193d7a9cc81b4027498b5"),
    "String": "string",
    "Int32": 42,
    "Int64": bson.Int64(42),
    "Double": 42.42,
    "Decimal": bson.Decimal128("1234.5"),
    "Binary": uuid.UUID("c8edabc3-f738-4ca3-b68d-ab92a91478a3"),
    "BinaryUserDefined": bson.Binary(b'123', 80),
    "Code": bson.Code("function() {}"),
    "CodeWithScope": bson.Code("function() {}", scope={}),
    "Subdocument": {"foo": "bar"},
    "Array": [1, 2, 3, 4, 5],
    "Timestamp": bson.Timestamp(42, 1),
    "RegularExpression": bson.Regex("foo*", "xi"),
    "DatetimeEpoch": datetime.datetime.utcfromtimestamp(0),
    "DatetimePositive": datetime.datetime.max,
    "DatetimeNegative": datetime.datetime.min,
    "True": True,
    "False": False,
    "DBRef": bson.DBRef(
        "collection", bson.ObjectId("57e193d7a9cc81b4027498b1"), database="database"),
    "DBRefNoDB": bson.DBRef(
        "collection", bson.ObjectId("57fd71e96e32ab4225b723fb")),
    "Minkey": bson.MinKey(),
    "Maxkey": bson.MaxKey(),
    "Null": None
}
</code></pre>
<p>The above document is transformed into the following (newlines and spaces added for readability):</p>
<pre><code class="language-javascript">{
    "_id": {
        "$oid": "57e193d7a9cc81b4027498b5"
    },
    "String": "string",
    "Int32": {
        "$numberInt": "42"
    },
    "Int64": {
        "$numberLong": "42"
    },
    "Double": {
        "$numberDouble": "42.42"
    },
    "Decimal": {
        "$numberDecimal": "1234.5"
    },
    "Binary": {
        "$binary": {
            "base64": "yO2rw/c4TKO2jauSqRR4ow==",
            "subType": "04"
        }
    },
    "BinaryUserDefined": {
        "$binary": {
            "base64": "MTIz",
            "subType": "80"
        }
    },
    "Code": {
        "$code": "function() {}"
    },
    "CodeWithScope": {
        "$code": "function() {}",
        "$scope": {}
    },
    "Subdocument": {
        "foo": "bar"
    },
    "Array": [
        {"$numberInt": "1"},
        {"$numberInt": "2"},
        {"$numberInt": "3"},
        {"$numberInt": "4"},
        {"$numberInt": "5"}
    ],
    "Timestamp": {
        "$timestamp": { "t": 42, "i": 1 }
    },
    "RegularExpression": {
        "$regularExpression": {
            "pattern": "foo*",
            "options": "ix"
        }
    },
    "DatetimeEpoch": {
        "$date": {
            "$numberLong": "0"
        }
    },
    "DatetimePositive": {
        "$date": {
            "$numberLong": "253402300799999"
        }
    },
    "DatetimeNegative": {
        "$date": {
            "$numberLong": "-62135596800000"
        }
    },
    "True": true,
    "False": false,
    "DBRef": {
        "$ref": "collection",
        "$id": {
            "$oid": "57e193d7a9cc81b4027498b1"
        },
        "$db": "database"
    },
    "DBRefNoDB": {
        "$ref": "collection",
        "$id": {
            "$oid": "57fd71e96e32ab4225b723fb"
        }
    },
    "Minkey": {
        "$minKey": 1
    },
    "Maxkey": {
        "$maxKey": 1
    },
    "Null": null
}
</code></pre>
<h3 id="relaxed-extended-json-example"><a class="header" href="#relaxed-extended-json-example">Relaxed Extended JSON Example</a></h3>
<p>In Relaxed Extended JSON, the example document is transformed similarly to Canonical Extended JSON, with the exception
of the following keys (newlines and spaces added for readability):</p>
<pre><code class="language-javascript">{
    ...
    "Int32": 42,
    "Int64": 42,
    "Double": 42.42,
    ...
    "DatetimeEpoch": {
        "$date": "1970-01-01T00:00:00.000Z"
    },
    ...
}
</code></pre>
<h2 id="motivation-for-change-2"><a class="header" href="#motivation-for-change-2">Motivation for Change</a></h2>
<p>There existed many Extended JSON parser and generator implementations prior to this specification that used conflicting
formats, since there was no agreement on the precise format of Extended JSON. This resulted in problems where the output
of some generators could not be consumed by some parsers.</p>
<p>MongoDB drivers needed a single, standard Extended JSON format for testing that covers all BSON types. However, there
were BSON types that had no defined Extended JSON representation. This spec primarily addresses that need, but provides
for slightly broader use as well.</p>
<h2 id="design-rationale-3"><a class="header" href="#design-rationale-3">Design Rationale</a></h2>
<h3 id="of-relaxed-and-canonical-formats"><a class="header" href="#of-relaxed-and-canonical-formats">Of Relaxed and Canonical Formats</a></h3>
<p>There are various use cases for expressing BSON documents in a text rather that binary format. They broadly fall into
two categories:</p>
<ul>
<li>Type preserving: for things like testing, where one has to describe the expected form of a BSON document, it's helpful
to be able to precisely specify expected types. In particular, numeric types need to differentiate between Int32,
Int64 and Double forms.</li>
<li>JSON-like: for things like a web API, where one is sending a document (or a projection of a document) that only uses
ordinary JSON type primitives, it's desirable to represent numbers in the native JSON format. This output is also the
most human readable and is useful for debugging and documentation.</li>
</ul>
<p>The two formats in this specification address these two categories of use cases.</p>
<h3 id="of-parsers-and-generators"><a class="header" href="#of-parsers-and-generators">Of Parsers and Generators</a></h3>
<p>Parsers need to accept any valid Extended JSON string that a generator can produce. Parsers and generators are permitted
to accept and output strings in other formats as well for backwards compatibility.</p>
<p><span id="levels of nesting"></span></p>
<p>Acceptable nesting depth has implications for resource usage so unlimited nesting is not permitted.</p>
<p>Generators support at least 100 levels of nesting in a BSON document being transformed to Extended JSON. This aligns
with MongoDB's own limitation of 100 levels of nesting.</p>
<p>Parsers support at least 200 levels of nesting in Extended JSON text, since the Extended JSON language can double the
level of apparent nesting of a BSON document by wrapping certain types in their own documents.</p>
<h3 id="of-canonical-type-wrapper-formats"><a class="header" href="#of-canonical-type-wrapper-formats">Of Canonical Type Wrapper Formats</a></h3>
<p>Prior to this specification, BSON types fell into three categories with respect to Legacy Extended JSON:</p>
<ol>
<li>A single, portable representation for the type already existed.</li>
<li>Multiple representations for the type existed among various Extended JSON generators, and those representations were
in conflict with each other or with current portability goals.</li>
<li>No Legacy Extended JSON representation existed.</li>
</ol>
<p>If a BSON type fell into category (1), this specification just declares that form to be canonical, since all drivers,
tools, and libraries already know how to parse or output this form. There are two exceptions:</p>
<h4 id="regularexpression"><a class="header" href="#regularexpression">RegularExpression</a></h4>
<p>The form <code>{"$regex: &lt;string&gt;, $options: &lt;string&gt;"}</code> has until this specification been canonical. The change to
<code>{"$regularExpression": {pattern: &lt;string&gt;, "options": &lt;string&gt;"}}</code> is motivated by a conflict between the previous
canonical form and the <code>$regex</code> MongoDB query operator. The form specified here disambiguates between the two, such that
a parser can accept any MongoDB query filter, even one containing the <code>$regex</code> operator.</p>
<h4 id="binary"><a class="header" href="#binary">Binary</a></h4>
<p>The form <code>{"$binary": "AQIDBAU=", "$type": "80"}</code> has until this specification been canonical. The change to
<code>{"$binary": {"base64": "AQIDBAU=", "subType": "80"}}</code> is motivated by a conflict between the previous canonical form
and the <code>$type</code> MongoDB query operator. The form specified here disambiguates between the two, such that a parser can
accept any MongoDB query filter, even one containing the <code>$type</code> operator.</p>
<h4 id="reconciled-type-wrappers"><a class="header" href="#reconciled-type-wrappers">Reconciled type wrappers</a></h4>
<p>If a BSON type fell into category (2), this specification selects a new common representation for the type to be
canonical. Conflicting formats were gathered by surveying a number of Extended JSON generators, including the MongoDB
Java Driver (version 3.3.0), the MongoDB Python Driver (version 3.4.0.dev0), the MongoDB Extended JSON module on NPM
(version 1.7.1), and each minor version of mongoexport from 2.4.14 through 3.3.12. When possible, we set the "strict"
option on the JSON codec. The following BSON types had conflicting Extended JSON representations:</p>
<h5 id="binary-1"><a class="header" href="#binary-1">Binary</a></h5>
<p>Some implementations write the Extended JSON form of a Binary object with a strict two-hexadecimal digit subtype (e.g.
they output a leading <code>0</code> for subtypes &lt; 16). However, the NPM mongodb-extended-json module and Java driver use a
single hexadecimal digit to represent subtypes less than 16. This specification makes both one- and two-digit
representations acceptable.</p>
<h5 id="code"><a class="header" href="#code">Code</a></h5>
<p>Mongoexport 2.4 does not quote the <code>Code</code> value when writing out the extended JSON form of a BSON Code object. All other
implementations do so. This spec canonicalises the form where the Javascript code is quoted, since the latter form
adheres to the JSON specification and the former does not. As an additional note, the NPM mongodb-extended-json module
uses the form <code>{"code": "&lt;javascript code&gt;"}</code>, omitting the dollar sign (<code>$</code>) from the key. This specification does not
accommodate the eccentricity of a single library.</p>
<h5 id="codewithscope"><a class="header" href="#codewithscope">CodeWithScope</a></h5>
<p>In addition to the same variants as BSON Code types, there are other variations when turning CodeWithScope objects into
Extended JSON. Mongoexport 2.4 and 2.6 omit the scope portion of CodeWithScope if it is empty, making the output
indistinguishable from a Code type. All other implementations include the empty scope. This specification therefore
canonicalises the form where the scope is always included. The presence of <code>$scope</code> is what differentiates Code from
CodeWithScope.</p>
<h5 id="datetime"><a class="header" href="#datetime">Datetime</a></h5>
<p>Mongoexport 2.4 and the Java driver always transform a Datetime object into an Extended JSON string of the form
<code>{"$date": &lt;ms since epoch&gt;}</code>. This form has the problem of a potential loss of precision or range on the Datetimes that
can be represented. Mongoexport 2.6 transforms Datetime objects into an extended JSON string of the form
<code>{"$date": &lt;ISO-8601 date string in local time&gt;}</code>for dates starting at or after the Unix epoch (UTC). Dates prior to the
epoch take the form <code>{"$date": {"$numberLong": "&lt;ms since epoch&gt;"}}</code>. Starting in version 3.0, mongoexport always turns
Datetime objects into strings of the form <code>{"$date": &lt;ISO-8601 date string in UTC&gt;}</code>. The NPM mongodb-extended-json
module does the same. The Python driver can also transform Datetime objects into strings like
<code>{"$date": {"$numberLong": "&lt;ms since epoch&gt;"}}</code>. This specification canonicalises this form, since this form is the
most portable. In Relaxed Extended JSON format, this specification provides for ISO-8601 representation for better
readability, but limits it to a portable subset, from the epoch to the end of the largest year that can be represented
with four digits. This should encompass most typical use of dates in applications.</p>
<h5 id="dbpointer"><a class="header" href="#dbpointer">DBPointer</a></h5>
<p>Mongoexport 2.4 and 2.6 use the form<code>{"$ref": &lt;namespace&gt;, "$id": &lt;hex string&gt;}</code>. All other implementations studied
include the canonical <code>ObjectId</code> form:<code>{"$ref": &lt;namespace&gt;, "$id": {"$oid": &lt;hex string&gt;}}</code>. Neither of these forms are
distinguishable from that of DBRef, so this specification creates a new format:
<code>{"$dbPointer": {"$ref": &lt;namespace&gt;, "$id": {"$oid": &lt;hex string&gt;}}}</code>.</p>
<h5 id="newly-added-type-wrappers-"><a class="header" href="#newly-added-type-wrappers-">Newly-added type wrappers .</a></h5>
<p>If a BSON type fell into category (3), above, this specification creates a type wrapper format for the type. The
following new Extended JSON type wrappers are introduced by this spec:</p>
<ul>
<li>
<p><code>$dbPointer</code>- See above.</p>
</li>
<li>
<p><code>$numberInt</code> - This is used to preserve the "int32" BSON type in Canonical Extended JSON. Without using <code>$numberInt</code>,
this type will be indistinguishable from a double in certain languages where the distinction does not exist, such as
Javascript.</p>
</li>
<li>
<p><code>$numberDouble</code> - This is used to preserve the <code>double</code>type in Canonical Extended JSON, as some JSON generators might
omit a trailing ".0" for integral types.</p>
<p>It also supports representing non-finite values like NaN or Infinity which are prohibited in the JSON specification
for numbers.</p>
</li>
<li>
<p><code>$symbol</code> - The use of the <code>$symbol</code> key preserves the symbol type in Canonical Extended JSON, distinguishing it from
JSON strings.</p>
</li>
</ul>
<h3 id="reference-implementation-1"><a class="header" href="#reference-implementation-1">Reference Implementation</a></h3>
<p>[<em>Canonical Extended JSON format reference implementation needs to be updated</em>] PyMongo implements the Canonical
Extended JSON format, which must be chosen by selecting the right option on the <code>JSONOptions</code> object::</p>
<pre><code class="language-python">from bson.json_util import dumps, DatetimeRepresentation, CANONICAL_JSON_OPTIONS    
dumps(document, json_options=CANONICAL_JSON_OPTIONS)  
</code></pre>
<p>[<em>Relaxed Extended JSON format reference implementation is TBD</em>]</p>
<h3 id="implementation-notes-1"><a class="header" href="#implementation-notes-1">Implementation Notes</a></h3>
<h4 id="json-file-format"><a class="header" href="#json-file-format">JSON File Format</a></h4>
<p>Some applications like mongoexport may wish to write multiple Extended JSON documents to a single file. One way to do
this is to list each JSON document one-per-line. When doing this, it is important to ensure that special characters like
newlines are encoded properly (e.g.<code>n</code>).</p>
<h4 id="duplicate-keys"><a class="header" href="#duplicate-keys">Duplicate Keys</a></h4>
<p>The BSON specification does not prohibit duplicate key names within the same BSON document, but provides no semantics
for the interpretation of duplicate keys. The JSON specification says that names within an object should be unique, and
many JSON libraries are incapable of handling this scenario. This specification is silent on the matter, so as not to
conflict with a future change by either specification.</p>
<h3 id="future-work"><a class="header" href="#future-work">Future Work</a></h3>
<p>This specification will need to be amended if future BSON types are added to the BSON specification.</p>
<h2 id="qa-1"><a class="header" href="#qa-1">Q&amp;A</a></h2>
<p><strong>Q</strong>. Why was version 2 of the spec necessary?</p>
<p><strong>A</strong>. After Version 1 was released, several stakeholders raised concerns that not providing an option to output BSON
numbers as ordinary JSON numbers limited the utility of Extended JSON for common historical uses. We decided to provide
a second format option and more clearly distinguish the use cases (and limitations) inherent in each format.</p>
<p><strong>Q</strong>. My BSON parser doesn't distinguish every BSON type. Does my Extended JSON generator need to distinguish these
types?</p>
<p><strong>A</strong>. No. Some BSON parsers do not emit a unique type for each BSON type, making round-tripping BSON through such
libraries impossible without changing the document. For example, a <code>DBPointer</code> will be parsed into a <code>DBRef</code> by PyMongo.
In such cases, a generator must emit the Extended JSON form for whatever type the BSON parser emitted. It does not need
to preserve type information when that information has been lost by the BSON parser.</p>
<p><strong>Q</strong>. How can implementations which require backwards compatibility with Legacy Extended JSON, in which BSON regular
expressions were represented with <code>$regex</code>, handle parsing of extended JSON test representing a MongoDB query filter
containing the <code>$regex</code> operator?</p>
<p><strong>A</strong>. An implementation can handle this in a number of ways: - Introduce an enumeration that determines the behavior of
the parser. If the value is LEGACY, it will parse <code>$regex</code>and not treat <code>$regularExpression</code> specially, and if the value
is CANONICAL, it will parse <code>$regularExpression</code> and not treat <code>$regex</code> specially. - Support both legacy and canonical
forms in the parser without requiring the application to specify one or the other. Making that work for the <code>$regex</code>
query operator use case will require that the rules set forth in the 1.0.0 version of this specification are followed
for <code>$regex</code>; specifically, that a document with a <code>$regex</code> key whose value is a JSON object should be parsed as a
normal document and not reported as an error.</p>
<h2 id="q-how-can-implementations-which-require-backwards-compatibility-with-legacy-extended-json-in-which-bson-binary-values-were-represented-like-binary-aqidbau-type-80-handle-parsing-of-extended-json-test-representing-a-mongodb-query-filter-containing-the-typeoperator"><a class="header" href="#q-how-can-implementations-which-require-backwards-compatibility-with-legacy-extended-json-in-which-bson-binary-values-were-represented-like-binary-aqidbau-type-80-handle-parsing-of-extended-json-test-representing-a-mongodb-query-filter-containing-the-typeoperator"><strong>Q</strong>. How can implementations which require backwards compatibility with Legacy Extended JSON, in which BSON binary values were represented like <code>{"$binary": "AQIDBAU=", "$type": "80"}</code>, handle parsing of extended JSON test representing a MongoDB query filter containing the <code>$type</code>operator?</a></h2>
<p><strong>A</strong>. An implementation can handle this in a number of ways:</p>
<p>Introduce an enumeration that determines the behavior of the parser. If the value is LEGACY, it will parse the new
binary form and not treat the legacy one specially, and if the value is CANONICAL, it will parse the new form and not
treat the legacy form specially. - Support both legacy and canonical forms in the parser without requiring the
application to specify one or the other. Making that work for the <code>$type</code> query operator use case will require that the
rules set forth in the 1.0.0 version of this specification are followed for <code>$type</code>; specifically, that a document with
a <code>$type</code> key whose value is an integral type, or a document with a <code>$type</code> key but without a <code>$binary</code> key, should be
parsed as a normal document and not reported as an error.</p>
<p><strong>Q</strong>. Sometimes I see the term "extjson" used in other specifications. Is "extjson" related to this specification?</p>
<p><strong>A</strong>. Yes, "extjson" is short for "Extended JSON".</p>
<h3 id="changelog-4"><a class="header" href="#changelog-4">Changelog</a></h3>
<ul>
<li>2024-05-29: Migrated from reStructuredText to Markdown.</li>
<li>2022-10-05: Remove spec front matter and reformat changelog.</li>
<li>2021-05-26:
<ul>
<li>Remove any mention of extra dollar-prefixed keys being prohibited in a DBRef. MongoDB 5.0 and compatible drivers no
longer enforce such restrictions.</li>
<li>Objects that resemble a DBRef without fully complying to its structure should be left as-is during parsing. -
2020-09-01: Note that <code>$</code>-prefixed keys not matching a known type MUST be left as-is when parsing. This is
patch-level change as this behavior was already required in the BSON corpus tests ("Document with keys that start
with $").</li>
</ul>
</li>
<li>2020-09-08:
<ul>
<li>Added support for parsing <code>$uuid</code> fields as BSON Binary subtype 4.</li>
<li>Changed the example to using the MongoDB Python Driver. It previously used the MongoDB Java Driver. The new example
excludes the following BSON types that are unsupported in Python - <code>Symbol</code>,<code>SpecialFloat</code>,<code>DBPointer</code>, and
<code>Undefined</code>. Transformations for these types are now only documented in the <a href="extended-json/extended-json.html#conversion-table">Conversion table</a></li>
</ul>
</li>
<li>2017-07-20:
<ul>
<li>Bumped specification to version 2.0.</li>
<li>Added "Relaxed" format.</li>
<li>Changed BSON timestamp type wrapper back to <code>{"t": *int*, "i": *int*}</code> for backwards compatibility. (The change in
v1 to unsigned 64-bit string was premature optimization)</li>
<li>Changed BSON regular expression type wrapper to <code>{"$regularExpression": {pattern: *string*, "options": *string*"}}</code>.</li>
<li>Changed BSON binary type wrapper to
<code>{"$binary": {"base64": &lt;base64-encoded payload as a *string*&gt;, "subType": &lt;BSON binary type as a one- or two-character *hex string*&gt;}}</code></li>
<li>Added "Restrictions and limitations" section.</li>
<li>Clarified parser and generator rules.</li>
</ul>
</li>
<li>2017-02-01: Initial specification version 1.0.</li>
</ul>
<div class="footnote-definition" id="1"><sup class="footnote-definition-label">1</sup>
<p>This MUST conform to the <a href="extended-json/../bson-decimal128/decimal128.html#writing-to-extended-json">Decimal128 specification</a></p>
</div>
<div class="footnote-definition" id="2"><sup class="footnote-definition-label">2</sup>
<p>BSON Regular Expression options MUST be in alphabetical order.</p>
</div>
<div class="footnote-definition" id="3"><sup class="footnote-definition-label">3</sup>
<p>See <a href="https://www.mongodb.com/docs/manual/reference/glossary/#term-namespace">the docs manual</a></p>
</div>
<div class="footnote-definition" id="4"><sup class="footnote-definition-label">4</sup>
<p>See <a href="https://tools.ietf.org/html/rfc3339#section-5.6">https://tools.ietf.org/html/rfc3339#section-5.6</a></p>
</div>
<div class="footnote-definition" id="5"><sup class="footnote-definition-label">5</sup>
<p>Fractional seconds SHOULD have exactly 3 decimal places if the fractional part is non-zero. Otherwise, fractional
seconds SHOULD be omitted if zero.</p>
</div>
<div class="footnote-definition" id="6"><sup class="footnote-definition-label">6</sup>
<p>See <a href="https://www.mongodb.com/docs/manual/reference/database-references/#dbrefs">the docs manual</a></p>
</div>
<div style="break-before: page; page-break-before: always;"></div><h1 id="op_msg"><a class="header" href="#op_msg">OP_MSG</a></h1>
<ul>
<li>Status: Accepted</li>
<li>Minimum Server Version: 3.6</li>
</ul>
<h3 id="abstract-5"><a class="header" href="#abstract-5">Abstract</a></h3>
<p><code>OP_MSG</code> is a bi-directional wire protocol opcode introduced in MongoDB 3.6 with the goal of replacing most existing
opcodes, merging their use into one extendable opcode.</p>
<h3 id="meta-5"><a class="header" href="#meta-5">META</a></h3>
<p>The keywords "MUST", "MUST NOT", "REQUIRED", "SHALL", "SHALL NOT", "SHOULD", "SHOULD NOT", "RECOMMENDED", "MAY", and
"OPTIONAL" in this document are to be interpreted as described in <a href="https://www.ietf.org/rfc/rfc2119.txt">RFC 2119</a>.</p>
<h3 id="specification-5"><a class="header" href="#specification-5">Specification</a></h3>
<h4 id="usage"><a class="header" href="#usage">Usage</a></h4>
<p><code>OP_MSG</code> is only available in MongoDB 3.6 (<code>maxWireVersion &gt;= 6</code>) and later. MongoDB drivers MUST perform the MongoDB
handshake using <code>OP_MSG</code> if an API version was declared on the client.</p>
<p>If no API version was declared, drivers that have historically supported MongoDB 3.4 and earlier MUST perform the
handshake using <code>OP_QUERY</code> to determine if the node supports <code>OP_MSG</code>. Drivers that have only ever supported MongoDB 3.6
and newer MAY default to using <code>OP_MSG</code>.</p>
<p>If the node supports <code>OP_MSG</code>, any and all messages MUST use <code>OP_MSG</code>, optionally compressed with <code>OP_COMPRESSED</code>.
Authentication messages MUST also use <code>OP_MSG</code> when it is supported, but MUST NOT use <code>OP_COMPRESSED</code>.</p>
<h4 id="op_msg-1"><a class="header" href="#op_msg-1">OP_MSG</a></h4>
<p>Types used in this document</p>
<div class="table-wrapper"><table><thead><tr><th>Type</th><th>Meaning</th></tr></thead><tbody>
<tr><td>document</td><td>A BSON document</td></tr>
<tr><td>cstring</td><td>NULL terminated string</td></tr>
<tr><td>int32</td><td>4 bytes (32-bit signed integer, two's complement)</td></tr>
<tr><td>uint8</td><td>1 byte (8-bit unsigned integer)</td></tr>
<tr><td>uint32</td><td>4 bytes (32-bit unsigned integer)</td></tr>
<tr><td>union</td><td>One of the listed members</td></tr>
</tbody></table>
</div>
<p>Elements inside brackets (<code>[</code> <code>]</code>) are optional parts of the message.</p>
<ul>
<li>Zero or more instances: <code>*</code></li>
<li>One or more instances: <code>+</code></li>
</ul>
<p>The new opcode, called <code>OP_MSG</code>, has the following structure:</p>
<pre><code class="language-c">struct Section {
    uint8 payloadType;
    union payload {
        document  document; // payloadType == 0
        struct sequence { // payloadType == 1
            int32      size;
            cstring    identifier;
            document*  documents;
        };
    };
};

struct OP_MSG {
    struct MsgHeader {
        int32  messageLength;
        int32  requestID;
        int32  responseTo;
        int32  opCode = 2013;
    };
    uint32      flagBits;
    Section+    sections;
    [uint32     checksum;]
};
</code></pre>
<p>Each <code>OP_MSG</code> MUST NOT exceed the <code>maxMessageSizeBytes</code> as configured by the MongoDB Handshake.</p>
<p>Each <code>OP_MSG</code> MUST have one section with <code>Payload Type 0</code>, and zero or more <code>Payload Type 1</code>. Bulk writes SHOULD use
<code>Payload Type 1</code>, and MUST do so when the batch contains more than one entry.</p>
<p>Sections may exist in any order. Each <code>OP_MSG</code> MAY contain a checksum, and MUST set the relevant <code>flagBits</code> when that
field is included.</p>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td>flagBits</td><td>Network level flags, such as signaling recipient that another message is incoming without any other actions in the meantime, and availability of message checksums</td></tr>
<tr><td>sections</td><td>An array of one or more sections</td></tr>
<tr><td>checksum</td><td>crc32c message checksum. When present, the appropriate flag MUST be set in the flagBits.</td></tr>
</tbody></table>
</div>
<h5 id="flagbits"><a class="header" href="#flagbits">flagBits</a></h5>
<p>flagBits contains a bit vector of specialized network flags. The low 16 bits declare what the current message contains,
and what the expectations of the recipient are. The high 16 bits are designed to declare optional attributes of the
current message and expectations of the recipient.</p>
<p>All unused bits MUST be set to 0.</p>
<p>Clients MUST error if any unsupported or undefined required bits are set to 1 and MUST ignore all undefined optional
bits.</p>
<p>The currently defined flags are:</p>
<div class="table-wrapper"><table><thead><tr><th>Bit</th><th>Name</th><th>Request</th><th>Response</th><th>Description</th></tr></thead><tbody>
<tr><td>0</td><td>checksumPresent</td><td>x</td><td>x</td><td>Checksum present</td></tr>
<tr><td>1</td><td>moreToCome</td><td>x</td><td>x</td><td>Sender will send another message and is not prepared for overlapping messages</td></tr>
<tr><td>-16</td><td>exhaustAllowed</td><td>x</td><td></td><td>Client is prepared for multiple replies (using the moreToCome bit) to this request</td></tr>
</tbody></table>
</div>
<h5 id="checksumpresent"><a class="header" href="#checksumpresent">checksumPresent</a></h5>
<p>This is a reserved field for future support of <code>crc32c</code> checksums.</p>
<h5 id="moretocome"><a class="header" href="#moretocome">moreToCome</a></h5>
<p>The <code>OP_MSG</code> message is essentially a request-response protocol, one message per turn. However, setting the <code>moreToCome</code>
flag indicates to the recipient that the sender is not ready to give up its turn and will send another message.</p>
<h5 id="moretocome-on-requests"><a class="header" href="#moretocome-on-requests">moreToCome On Requests</a></h5>
<p>When the <code>moreToCome</code> flag is set on a request it signals to the recipient that the sender does not want to know the
outcome of the message. There is no response to a request where <code>moreToCome</code> has been set. Clients doing unacknowledged
writes MUST set the <code>moreToCome</code> flag, and MUST set the writeConcern to <code>w=0</code>.</p>
<p>If, during the processing of a <code>moreToCome</code> flagged write request, a server discovers that it is no longer primary, then
the server will close the connection. All other errors during processing will be silently dropped, and will not result
in the connection being closed.</p>
<h5 id="moretocome-on-responses"><a class="header" href="#moretocome-on-responses">moreToCome On Responses</a></h5>
<p>When the <code>moreToCome</code> flag is set on a response it signals to the recipient that the sender will send additional
responses on the connection. The recipient MUST continue to read responses until it reads a response with the
<code>moreToCome</code> flag not set, and MUST NOT send any more requests on this connection until it reads a response with the
<code>moreToCome</code> flag not set. The client MUST either consume all messages with the <code>moreToCome</code> flag set or close the
connection.</p>
<p>When the server sends responses with the <code>moreToCome</code> flag set, each of these responses will have a unique <code>messageId</code>,
and the <code>responseTo</code> field of every follow-up response will be the <code>messageId</code> of the previous response.</p>
<p>The client MUST be prepared to receive a response without <code>moreToCome</code> set prior to completing iteration of a cursor,
even if an earlier response for the same cursor had the <code>moreToCome</code> flag set. To continue iterating such a cursor, the
client MUST issue an explicit <code>getMore</code> request.</p>
<p><span id="exhaustAllowed"></span></p>
<h5 id="exhaustallowed"><a class="header" href="#exhaustallowed">exhaustAllowed</a></h5>
<p>Setting this flag on a request indicates to the recipient that the sender is prepared to handle multiple replies (using
the <code>moreToCome</code> bit) to this request. The server will never produce replies with the <code>moreToCome</code> bit set unless the
request has the <code>exhaustAllowed</code> bit set.</p>
<p>Setting the <code>exhaustAllowed</code> bit on a request does not guarantee that the responses will have the <code>moreToCome</code> bit set.</p>
<p>MongoDB server only handles the <code>exhaustAllowed</code> bit on the following operations. A driver MUST NOT set the
<code>exhaustAllowed</code> bit on other operations.</p>
<div class="table-wrapper"><table><thead><tr><th>Operation</th><th>Minimum MongoDB Version</th></tr></thead><tbody>
<tr><td>getMore</td><td>4.2</td></tr>
<tr><td>hello (including legacy hello)</td><td>4.4 (discoverable via topologyVersion)</td></tr>
</tbody></table>
</div>
<h5 id="sections"><a class="header" href="#sections">sections</a></h5>
<p>Each message contains one or more sections. A section is composed of an uint8 which determines the payload's type, and a
separate payload field. The payload size for payload type 0 and 1 is determined by the first 4 bytes of the payload
field (includes the 4 bytes holding the size but not the payload type).</p>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td>type</td><td>A byte indicating the layout and semantics of payload</td></tr>
<tr><td>payload</td><td>The payload of a section can either be a single document, or a document sequence.</td></tr>
</tbody></table>
</div>
<p>When the Payload Type is 0, the content of the payload is:</p>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td>document</td><td>The BSON document. The payload size is inferred from the document's leading int32.</td></tr>
</tbody></table>
</div>
<p>When the Payload Type is 1, the content of the payload is:</p>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td>size</td><td>Payload size (includes this 4-byte field)</td></tr>
<tr><td>identifier</td><td>A unique identifier (for this message). Generally the name of the "command argument" it contains the value for</td></tr>
<tr><td>documents</td><td>0 or more BSON documents. Each BSON document cannot be larger than <code>maxBSONObjectSize</code>.</td></tr>
</tbody></table>
</div>
<p>Any unknown Payload Types MUST result in an error and the socket MUST be closed. There is no ordering implied by payload
types. A section with payload type 1 can be serialized before payload type 0.</p>
<p>A fully constructed <code>OP_MSG</code> MUST contain exactly one <code>Payload Type 0</code>, and optionally any number of <code>Payload Type 1</code>
where each identifier MUST be unique per message.</p>
<h4 id="command-arguments-as-payload"><a class="header" href="#command-arguments-as-payload">Command Arguments As Payload</a></h4>
<p>Certain commands support "pulling out" certain arguments to the command, and providing them as <code>Payload Type 1</code>, where
the <code>identifier</code> is the command argument's name. Specifying a command argument as a separate payload removes the need to
use a BSON Array. For example, <code>Payload Type 1</code> allows an array of documents to be specified as a sequence of BSON
documents on the wire without the overhead of array keys.</p>
<p>MongoDB 3.6 only allows certain command arguments to be provided this way. These are:</p>
<div class="table-wrapper"><table><thead><tr><th>Command Name</th><th>Command Argument</th></tr></thead><tbody>
<tr><td>insert</td><td>documents</td></tr>
<tr><td>update</td><td>updates</td></tr>
<tr><td>delete</td><td>deletes</td></tr>
</tbody></table>
</div>
<h4 id="global-command-arguments"><a class="header" href="#global-command-arguments">Global Command Arguments</a></h4>
<p>The new opcode contains no field for providing the database name. Instead, the protocol now has the concept of global
command arguments. These global command arguments can be passed to all MongoDB commands alongside the rest of the
command arguments.</p>
<p>Currently defined global arguments:</p>
<div class="table-wrapper"><table><thead><tr><th>Argument Name</th><th>Default Value</th><th>Description</th></tr></thead><tbody>
<tr><td>$db</td><td></td><td>The database name to execute the command on. MUST be provided and be a valid database name.</td></tr>
<tr><td><code>$readPreference</code></td><td><code>{ "mode": "primary" }</code></td><td>Determines server selection, and also whether a secondary server permits reads or responds "not writable primary". See Server Selection Spec for rules about when read preference must or must not be included, and for rules about when read preference "primaryPreferred" must be added automatically.</td></tr>
</tbody></table>
</div>
<p>Additional global arguments are likely to be introduced in the future and defined in their own specs.</p>
<h3 id="user-originating-commands"><a class="header" href="#user-originating-commands">User originating commands</a></h3>
<p>Drivers MUST NOT mutate user provided command documents in any way, whether it is adding required arguments, pulling out
arguments, compressing it, adding supplemental APM data or any other modification.</p>
<h3 id="examples-1"><a class="header" href="#examples-1">Examples</a></h3>
<h4 id="command-arguments-as-payload-examples"><a class="header" href="#command-arguments-as-payload-examples">Command Arguments As Payload Examples</a></h4>
<p>For example, an insert can be represented like:</p>
<pre><code>{
   "insert": "collectionName",
   "documents": [
      {"_id": "Document#1", "example": 1},
      {"_id": "Document#2", "example": 2},
      {"_id": "Document#3", "example": 3}
   ],
   "writeConcern": { w: "majority" }
}
</code></pre>
<p>Or, pulling out the <code>"documents"</code> argument out of the command document and Into <code>Payload Type 1</code>. The <code>Payload Type 0</code>
would then be:</p>
<pre><code>{
   "insert": "collectionName",
   "$db": "databaseName",
   "writeConcern": { w: "majority" }
}
</code></pre>
<p>And <code>Payload Type 1</code>:</p>
<pre><code>identifier: "documents"
documents: {"_id": "Document#1", "example": 1}{"_id": "Document#2", "example": 2}{"_id": "Document#3", "example": 3}
</code></pre>
<p>Note that the BSON documents are placed immediately after each other, not with any separator. The writeConcern is also
left intact as a command argument in the <code>Payload Type 0</code> section. The command name MUST continue to be the first key of
the command arguments in the <code>Payload Type 0</code> section.</p>
<hr />
<p>An update can for example be represented like:</p>
<pre><code>{
   "update": "collectionName",
   "updates": [
      {
         "q": {"example": 1},
         "u": { "$set": { "example": 4} }
      },
      {
         "q": {"example": 2},
         "u": { "$set": { "example": 5} }
      }
   ]
}
</code></pre>
<p>Or, pulling out the <code>"update"</code> argument out of the command document and Into <code>Payload Type 1</code>. The <code>Payload Type 0</code>
would then be:</p>
<pre><code>{
   "update": "collectionName",
   "$db": "databaseName"
}
</code></pre>
<p>And <code>Payload Type 1</code>:</p>
<pre><code>identifier: updates
documents: {"q": {"example": 1}, "u": { "$set": { "example": 4}}}{"q": {"example": 2}, "u": { "$set": { "example": 5}}}
</code></pre>
<p>Note that the BSON documents are placed immediately after each other, not with any separator.</p>
<hr />
<p>A delete can for example be represented like:</p>
<pre><code>{
   "delete": "collectionName",
   "deletes": [
      {
         "q": {"example": 3},
         "limit": 1
      },
      {
         "q": {"example": 4},
         "limit": 1
      }
   ]
}
</code></pre>
<p>Or, pulling out the <code>"deletes"</code> argument out of the command document and into <code>Payload Type 1</code>. The <code>Payload Type 0</code>
would then be:</p>
<pre><code>{
   "delete": "collectionName",
   "$db": "databaseName"
}
</code></pre>
<p>And <code>Payload Type 1</code>:</p>
<pre><code>identifier: delete
documents: {"q": {"example": 3}, "limit": 1}{"q": {"example": 4}, "limit": 1}
</code></pre>
<p>Note that the BSON documents are placed immediately after each other, not with any separator.</p>
<h3 id="test-plan-4"><a class="header" href="#test-plan-4">Test Plan</a></h3>
<ul>
<li>Create a single document and insert it over <code>OP_MSG</code>, ensure it works</li>
<li>Create two documents and insert them over <code>OP_MSG</code>, ensure each document is pulled out and presented as document
sequence.</li>
<li>hello.maxWriteBatchSize might change and be bumped to 100,000</li>
<li>Repeat the previous 5 tests as updates, and then deletes.</li>
<li>Create one small document, and one large 16mb document. Ensure they are inserted, updated and deleted in one
roundtrip.</li>
</ul>
<h3 id="motivation-for-change-3"><a class="header" href="#motivation-for-change-3">Motivation For Change</a></h3>
<p>MongoDB clients are currently required to work around various issues that each current opcode has, such as having to
determine what sort of node is on the other end as it affects the actual structure of certain messages. MongoDB 3.6
introduces a new wire protocol opcode, <code>OP_MSG</code>, which aims to resolve most historical issues along with providing a
future compatible and extendable opcode.</p>
<h3 id="backwards-compatibility-2"><a class="header" href="#backwards-compatibility-2">Backwards Compatibility</a></h3>
<p>The hello.maxWriteBatchSize is being bumped, which also affects <code>OP_QUERY</code>, not only <code>OP_MSG</code>. As a sideeffect, write
errors will now have the message truncated, instead of overflowing the maxMessageSize, if the server determines it would
overflow the allowed size. This applies to all commands that write. The error documents are structurally the same, with
the error messages simply replaced with empty strings.</p>
<h3 id="reference-implementations-1"><a class="header" href="#reference-implementations-1">Reference Implementations</a></h3>
<ul>
<li>mongoc</li>
<li>.net</li>
</ul>
<h3 id="future-work-1"><a class="header" href="#future-work-1">Future Work</a></h3>
<p>In the near future, this opcode is expected to be extended and include support for:</p>
<ul>
<li>Message checksum (crc32c)</li>
<li>Output document sequences</li>
<li><code>moreToCome</code> can also be used for other commands, such as <code>killCursors</code> to restore <code>OP_KILL_CURSORS</code> behaviour as
currently any errors/replies are ignored.</li>
</ul>
<h3 id="q--a-1"><a class="header" href="#q--a-1">Q &amp; A</a></h3>
<ul>
<li>
<p>Has the maximum number of documents per batch changed ?</p>
<ul>
<li>The maximum number of documents per batch is dictated by the <code>maxWriteBatchSize</code> value returned during the MongoDB
Handshake. It is likely this value will be bumped from 1,000 to 100,000.</li>
</ul>
</li>
<li>
<p>Has the maximum size of the message changed?</p>
<ul>
<li>No. The maximum message size is still the <code>maxMessageSizeBytes</code> value returned during the MongoDB Handshake.</li>
</ul>
</li>
<li>
<p>Is everything still little-endian?</p>
<ul>
<li>Yes. As with BSON, all MongoDB opcodes must be serialized in little-endian format.</li>
</ul>
</li>
<li>
<p>How does fire-and-forget (w=0 / unacknowledged write) work over <code>OP_MSG</code>?</p>
<ul>
<li>The client sets the <code>moreToCome</code> flag on the request. The server will not send a response to such requests.</li>
<li>Malformed operation or errors such as duplicate key errors are not discoverable and will be swallowed by the server.</li>
<li>Write errors due to not-primary will close the connection, which clients will pickup on next time it uses the
connection. This means at least one unacknowledged write operation will be lost as the client does not discover the
failover until next time the socket is used.</li>
</ul>
</li>
<li>
<p>Should we provide <code>runMoreToComeCommand()</code> helpers? Since the protocol allows any command to be tagged with
<code>moreToCome</code>, effectively allowing any operation to become <code>fire &amp; forget</code>, it might be a good idea to add such
helper, rather then adding wire protocol headers as options to the existing <code>runCommand</code> helpers.</p>
</li>
</ul>
<h3 id="changelog-5"><a class="header" href="#changelog-5">Changelog</a></h3>
<ul>
<li>2024-04-30: Convert from RestructuredText to Markdown.</li>
<li>2022-10-05: Remove spec front matter.</li>
<li>2022-01-13: Clarify that <code>OP_MSG</code> must be used when using stable API</li>
<li>2021-12-16: Clarify that old drivers should default to OP_QUERY handshakes</li>
<li>2021-04-20: Suggest using OP_MSG for initial handshake when using stable API</li>
<li>2021-04-06: Updated to use hello and not writable primary</li>
<li>2017-11-12: Specify read preferences for OP_MSG with direct connection</li>
<li>2017-08-17: Added the <code>User originating command</code> section</li>
<li>2017-07-18: Published initial version</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="run-command"><a class="header" href="#run-command">Run Command</a></h1>
<ul>
<li>Status: Accepted</li>
<li>Minimum Server Version: N/A</li>
</ul>
<hr />
<h2 id="abstract-6"><a class="header" href="#abstract-6">Abstract</a></h2>
<p>This specification defines requirements and behaviors for drivers' run command and related APIs.</p>
<h2 id="meta-6"><a class="header" href="#meta-6">META</a></h2>
<p>The keywords "MUST", "MUST NOT", "REQUIRED", "SHALL", "SHALL NOT", "SHOULD", "SHOULD NOT", "RECOMMENDED", "MAY", and
"OPTIONAL" in this document are to be interpreted as described in <a href="https://www.ietf.org/rfc/rfc2119.txt">RFC 2119</a>.</p>
<h2 id="specification-6"><a class="header" href="#specification-6">Specification</a></h2>
<h3 id="terms-2"><a class="header" href="#terms-2">Terms</a></h3>
<p>Command<br />
A structure representing a BSON document that has a shape matching a supported MongoDB operation.</p>
<h3 id="implementation-requirements"><a class="header" href="#implementation-requirements">Implementation requirements</a></h3>
<p>All drivers MAY offer the operations defined in the following sections. This does not preclude a driver from offering
more.</p>
<h3 id="deviations"><a class="header" href="#deviations">Deviations</a></h3>
<p>Please refer to <a href="run-command/../crud/crud.html#guidance">The CRUD specification's Guidance</a> on how APIs may deviate between languages.</p>
<p>Cursor iterating APIs MAY be offered via language syntax or predefined iterable methods.</p>
<h3 id="runcommand"><a class="header" href="#runcommand"><code>runCommand</code></a></h3>
<p>The following represents how a runCommand API SHOULD be exposed.</p>
<pre><code class="language-typescript">interface Database {
  /**
   * Takes an argument representing an arbitrary BSON document and executes it against the server.
   */
  runCommand(command: BSONDocument, options: RunCommandOptions): BSONDocument;
}

interface RunCommandOptions {
  /**
   * An optional readPreference setting to apply to server selection logic.
   * This value MUST be applied to the command document as the $readPreference global command argument if not set to primary.
   *
   * @defaultValue ReadPreference(mode: primary)
   *
   * @see ../server-selection/server-selection.md#read-preference
   */
  readPreference?: ReadPreference;

  /**
   * An optional explicit client session.
   * The associated logical session id (`lsid`) the driver MUST apply to the command.
   *
   * @see ../sessions/driver-sessions.md#clientsession
   */
  session?: ClientSession;

  /**
   * An optional timeout option to govern the amount of time that a single operation can execute before control is returned to the user.
   * This timeout applies to all of the work done to execute the operation, including but not limited to server selection, connection checkout, and server-side execution.
   *
   * @ see https://github.com/mongodb/specifications/blob/master/source/client-side-operations-timeout/client-side-operations-timeout.md
   */
  timeoutMS?: number;
}
</code></pre>
<h4 id="runcommand-implementation-details"><a class="header" href="#runcommand-implementation-details">RunCommand implementation details</a></h4>
<p>RunCommand provides a way to access MongoDB server commands directly without requiring a driver to implement a bespoke
helper. The API is intended to take a document from a user and apply a number of common driver internal concerns before
forwarding the command to a server. A driver MUST not inspect the user's command, this includes checking for the fields
a driver MUST attach to the command sent as described below. Depending on a driver's BSON implementation this can result
in these fields being overwritten or duplicated, a driver SHOULD document that using these fields has undefined
behavior. A driver MUST not modify the user's command, a clone SHOULD be created before the driver attaches any of the
required fields to the command.</p>
<p>Drivers that have historically modified user input SHOULD strive to instead clone the input such that appended fields do
not affect the user's input in their next major version.</p>
<h5 id="op_msg-2"><a class="header" href="#op_msg-2">OP_MSG</a></h5>
<p>The <code>$db</code> global command argument MUST be set on the command sent to the server and it MUST equal the database name
RunCommand was invoked on.</p>
<ul>
<li>See OP_MSG's section on <a href="run-command/../message/OP_MSG.html#global-command-arguments">Global Command Arguments</a></li>
</ul>
<h5 id="readpreference"><a class="header" href="#readpreference">ReadPreference</a></h5>
<p>For the purposes of server selection RunCommand MUST assume all commands are read operations. To facilitate server
selection the RunCommand operation MUST accept an optional <code>readPreference</code> option.</p>
<ul>
<li>See Server Selection's section on
<a href="run-command/../server-selection/server-selection.html#use-of-read-preferences-with-commands">Use of read preferences with commands</a></li>
</ul>
<p>If the provided ReadPreference is NOT <code>{mode: primary}</code> and the selected server is NOT a standalone, the command sent
MUST include the <code>$readPreference</code> global command argument.</p>
<ul>
<li>See OP_MSG's section on <a href="run-command/../message/OP_MSG.html#global-command-arguments">Global Command Arguments</a></li>
</ul>
<h5 id="driver-sessions"><a class="header" href="#driver-sessions">Driver Sessions</a></h5>
<p>A driver's RunCommand MUST provide an optional session option to support explicit sessions and transactions. If a
session is not provided the driver MUST attach an implicit session if the connection supports sessions. Drivers MUST NOT
attempt to check the command document for the presence of an <code>lsid</code>.</p>
<p>Every ClientSession has a corresponding logical session ID representing the server-side session ID. The logical session
ID MUST be included under <code>lsid</code> in the command sent to the server without modifying user input.</p>
<ul>
<li>See Driver Sessions' section on
<a href="run-command/../sessions/driver-sessions.html#sending-the-session-id-to-the-server-on-all-commands">Sending the session ID to the server on all commands</a></li>
</ul>
<p>The command sent to the server MUST gossip the <code>$clusterTime</code> if cluster time support is detected.</p>
<ul>
<li>See Driver Sessions' section on
<a href="run-command/../sessions/driver-sessions.html#gossipping-the-cluster-time">Gossipping the cluster time</a></li>
</ul>
<h5 id="transactions"><a class="header" href="#transactions">Transactions</a></h5>
<p>If RunCommand is used within a transaction the read preference MUST be sourced from the transaction's options. The
command sent to the server MUST include the transaction specific fields, summarized as follows:</p>
<ul>
<li>If <code>runCommand</code> is executing within a transaction:
<ul>
<li><code>autocommit</code> - The autocommit flag MUST be set to false.</li>
<li><code>txnNumber</code> - MUST be set.</li>
</ul>
</li>
<li>If <code>runCommand</code> is the first operation of the transaction:
<ul>
<li><code>startTransaction</code> - MUST be set to true.</li>
<li><code>readConcern</code> - MUST be set to the transaction's read concern if it is NOT the default.</li>
</ul>
</li>
<li>See
<a href="run-command/../transactions/transactions.html#generic-runcommand-helper-within-a-transaction">Generic RunCommand helper within a transaction</a>
in the Transactions specification.</li>
</ul>
<h5 id="readconcern-and-writeconcern"><a class="header" href="#readconcern-and-writeconcern">ReadConcern and WriteConcern</a></h5>
<p>RunCommand MUST NOT support read concern and write concern options. Drivers MUST NOT attempt to check the command
document for the presence of a <code>readConcern</code> and <code>writeConcern</code> field.</p>
<p>Additionally, unless executing within a transaction, RunCommand MUST NOT set the <code>readConcern</code> or <code>writeConcern</code> fields
in the command document. For example, default values MUST NOT be inherited from client, database, or collection options.</p>
<p>If the user-provided command document already includes <code>readConcern</code> or <code>writeConcern</code> fields, the values MUST be left
as-is.</p>
<ul>
<li>See Read Concern's section on
<a href="run-command/../read-write-concern/read-write-concern.html#generic-command-method">Generic Command Method</a></li>
<li>See Write Concern's section on
<a href="run-command/../read-write-concern/read-write-concern.html#generic-command-method">Generic Command Method</a></li>
</ul>
<h5 id="retryability"><a class="header" href="#retryability">Retryability</a></h5>
<p>All commands executed via RunCommand are non-retryable operations. Drivers MUST NOT inspect the command to determine if
it is a write and MUST NOT attach a <code>txnNumber</code>.</p>
<ul>
<li>See Retryable Reads' section on
<a href="run-command/../retryable-reads/retryable-reads.html#unsupported-read-operations">Unsupported Read Operations</a></li>
<li>See Retryable Writes' section on
<a href="run-command/../retryable-writes/retryable-writes.html#behavioral-changes-for-write-commands">Behavioral Changes for Write Commands</a></li>
</ul>
<h5 id="stable-api"><a class="header" href="#stable-api">Stable API</a></h5>
<p>The command sent MUST attach stable API fields as configured on the MongoClient.</p>
<ul>
<li>See Stable API's section on
<a href="run-command/../versioned-api/versioned-api.html#generic-command-helper">Generic Command Helper Behaviour</a></li>
</ul>
<h5 id="client-side-operations-timeout"><a class="header" href="#client-side-operations-timeout">Client Side Operations Timeout</a></h5>
<p>RunCommand MUST provide an optional <code>timeoutMS</code> option to support client side operations timeout. Drivers MUST NOT
attempt to check the command document for the presence of a <code>maxTimeMS</code> field. Drivers MUST document the behavior of
RunCommand if a <code>maxTimeMS</code> field is already set on the command (such as overwriting the command field).</p>
<ul>
<li>See Client Side Operations Timeout's section on
<a href="run-command/../client-side-operations-timeout/client-side-operations-timeout.html#runcommand">runCommand</a></li>
<li>See Client Side Operations Timeout's section on
<a href="run-command/../client-side-operations-timeout/client-side-operations-timeout.html#runcommand-behavior">runCommand behavior</a></li>
</ul>
<h3 id="runcursorcommand"><a class="header" href="#runcursorcommand"><code>runCursorCommand</code></a></h3>
<p>Drivers MAY expose a runCursorCommand API with the following syntax.</p>
<pre><code class="language-typescript">interface Database {
  /**
   * Takes an argument representing an arbitrary BSON document and executes it against the server.
   */
  runCursorCommand(command: BSONDocument, options: RunCursorCommandOptions): RunCommandCursor;
}

interface RunCursorCommandOptions extends RunCommandOptions {
  /**
   * This option is an enum with possible values CURSOR_LIFETIME and ITERATION.
   * For operations that create cursors, timeoutMS can either cap the lifetime of the cursor or be applied separately to the original operation and all subsequent calls.
   * To support both of these use cases, these operations MUST support a timeoutMode option.
   *
   * @defaultValue CURSOR_LIFETIME
   *
   * @see https://github.com/mongodb/specifications/blob/master/source/client-side-operations-timeout/client-side-operations-timeout.md
   */
  timeoutMode?: ITERATION | CURSOR_LIFETIME;

  /**
   * See the `cursorType` enum defined in the crud specification.
   * @see https://github.com/mongodb/specifications/blob/master/source/crud/crud.md#read
   *
   * Identifies the type of cursor this is for client side operations timeout to properly apply timeoutMode settings.
   *
   * A tailable cursor can receive empty `nextBatch` arrays in `getMore` responses.
   * However, subsequent `getMore` operations may return documents if new data has become available.
   *
   * A tailableAwait cursor is an enhancement where instead of dealing with empty responses the server will block until data becomes available.
   *
   * @defaultValue NON_TAILABLE
   */
  cursorType?: CursorType;
}

/**
 * The following are the configurations a driver MUST provide to control how getMores are constructed.
 * How the options are controlled should be idiomatic to the driver's language.
 * See Executing ``getMore`` Commands.
 */
interface RunCursorCommandGetMoreOptions {
  /** Any positive integer is permitted. */
  batchSize?: int;
  /** Any non-negative integer is permitted. */
  maxTimeMS?: int;
  comment?: BSONValue;
}
</code></pre>
<h4 id="runcursorcommand-implementation-details"><a class="header" href="#runcursorcommand-implementation-details">RunCursorCommand implementation details</a></h4>
<p>RunCursorCommand provides a way to access MongoDB server commands that return a cursor directly without requiring a
driver to implement a bespoke cursor implementation. The API is intended to be built upon RunCommand and take a document
from a user and apply a number of common driver internal concerns before forwarding the command to a server. A driver
can expect that the result from running this command will return a document with a <code>cursor</code> field and MUST provide the
caller with a language native abstraction to continue iterating the results from the server. If the response from the
server does not include a <code>cursor</code> field the driver MUST throw an error either before returning from <code>runCursorCommand</code>
or upon first iteration of the cursor.</p>
<p>High level RunCursorCommand steps:</p>
<ul>
<li>Run the cursor creating command provided by the caller and retain the ClientSession used as well as the server the
command was executed on.</li>
<li>Create a local cursor instance and store the <code>firstBatch</code>, <code>ns</code>, and <code>id</code> from the response.</li>
<li>When the current batch has been fully iterated, execute a <code>getMore</code> using the same server the initial command was
executed on.</li>
<li>Store the <code>nextBatch</code> from the <code>getMore</code> response and update the cursor's <code>id</code>.</li>
<li>Continue to execute <code>getMore</code> commands as needed when the caller empties local batches until the cursor is exhausted
or closed (i.e. <code>id</code> is zero).</li>
</ul>
<h5 id="driver-sessions-1"><a class="header" href="#driver-sessions-1">Driver Sessions</a></h5>
<p>A driver MUST create an implicit ClientSession if none is provided and it MUST be attached for the duration of the
cursor's lifetime. All <code>getMore</code> commands constructed for this cursor MUST send the same <code>lsid</code> used on the initial
command. A cursor is considered exhausted or closed when the server reports its <code>id</code> as zero. When the cursor is
exhausted the client session MUST be ended and the server session returned to the pool as early as possible rather than
waiting for a caller to completely iterate the final batch.</p>
<ul>
<li>See Drivers Sessions' section on <a href="run-command/../sessions/driver-sessions.html#sessions-and-cursors">Sessions and Cursors</a></li>
</ul>
<h5 id="server-selection"><a class="header" href="#server-selection">Server Selection</a></h5>
<p>RunCursorCommand MUST support a <code>readPreference</code> option that MUST be used to determine server selection. The selected
server MUST be used for subsequent <code>getMore</code> commands.</p>
<h5 id="load-balancers"><a class="header" href="#load-balancers">Load Balancers</a></h5>
<p>When in <code>loadBalanced</code> mode, a driver MUST pin the connection used to execute the initial operation, and reuse it for
subsequent <code>getMore</code> operations.</p>
<ul>
<li>See Load Balancer's section on <a href="run-command/../load-balancers/load-balancers.html#behaviour-with-cursors">Behaviour With Cursors</a></li>
</ul>
<h5 id="iterating-the-cursor"><a class="header" href="#iterating-the-cursor">Iterating the Cursor</a></h5>
<p>Drivers MUST provide an API, typically, a method named <code>next()</code>, that returns one document per invocation. If the
cursor's batch is empty and the cursor id is nonzero, the driver MUST perform a <code>getMore</code> operation.</p>
<h5 id="executing-getmore-commands"><a class="header" href="#executing-getmore-commands">Executing <code>getMore</code> Commands</a></h5>
<p>The cursor API returned to the caller MUST offer an API to configure <code>batchSize</code>, <code>maxTimeMS</code>, and <code>comment</code> options
that are sent on subsequent <code>getMore</code> commands. If it is idiomatic for a driver to allow setting these options in
<code>RunCursorCommandOptions</code>, the driver MUST document that the options only pertain to <code>getMore</code> commands. A driver MAY
permit users to change <code>getMore</code> field settings at any time during the cursor's lifetime and subsequent <code>getMore</code>
commands MUST be constructed with the changes to those fields. If that API is offered drivers MUST write tests asserting
<code>getMore</code> commands are constructed with any updated fields.</p>
<ul>
<li>See Find, getMore and killCursors commands' section on
<a href="run-command/../find_getmore_killcursors_commands/find_getmore_killcursors_commands.html#getmore">GetMore</a></li>
</ul>
<h5 id="tailable-and-tailableawait"><a class="header" href="#tailable-and-tailableawait">Tailable and TailableAwait</a></h5>
<ul>
<li><strong>See first:</strong> Find, getMore and killCursors commands's section on
<a href="run-command/../find_getmore_killcursors_commands/find_getmore_killcursors_commands.html#tailable-cursors">Tailable cursors</a></li>
</ul>
<p>It is the responsibility of the caller to construct their initial command with <code>awaitData</code> and <code>tailable</code> flags <strong>as
well as</strong> inform RunCursorCommand of the <code>cursorType</code> that should be constructed. Requesting a <code>cursorType</code> that does
not align with the fields sent to the server on the initial command SHOULD be documented as undefined behavior.</p>
<h5 id="resource-cleanup"><a class="header" href="#resource-cleanup">Resource Cleanup</a></h5>
<p>Drivers MUST provide an explicit mechanism for releasing the cursor resources, typically a <code>.close()</code> method. If the
cursor id is nonzero a KillCursors operation MUST be attempted, the result of the operation SHOULD be ignored. The
ClientSession associated with the cursor MUST be ended and the ServerSession returned to the pool.</p>
<ul>
<li>See Driver Sessions' section on
<a href="run-command/../sessions/driver-sessions.html#when-sending-a-killcursors-command">When sending a killCursors command</a></li>
<li>See Find, getMore and killCursors commands' section on
<a href="run-command/../find_getmore_killcursors_commands/find_getmore_killcursors_commands.html#killcursors">killCursors</a></li>
</ul>
<h5 id="client-side-operations-timeout-1"><a class="header" href="#client-side-operations-timeout-1">Client Side Operations Timeout</a></h5>
<p>RunCursorCommand MUST provide an optional <code>timeoutMS</code> option to support client side operations timeout. Drivers MUST NOT
attempt to check the command document for the presence of a <code>maxTimeMS</code> field. Drivers MUST document the behavior of
RunCursorCommand if a <code>maxTimeMS</code> field is already set on the command. Drivers SHOULD raise an error if both <code>timeoutMS</code>
and the <code>getMore</code>-specific <code>maxTimeMS</code> option are specified (see:
<a href="run-command/run-command.html#executing-getmore-commands">Executing getMore Commands</a>). Drivers MUST document that attempting to set both options
can have undefined behavior and is not supported.</p>
<p>When <code>timeoutMS</code> and <code>timeoutMode</code> are provided the driver MUST support timeout functionality as described in the CSOT
specification.</p>
<ul>
<li>See Client Side Operations Timeout's section on
<a href="run-command/../client-side-operations-timeout/client-side-operations-timeout.html#cursors">Cursors</a></li>
</ul>
<h2 id="changelog-6"><a class="header" href="#changelog-6">Changelog</a></h2>
<ul>
<li>2024-09-02: Migrated from reStructuredText to Markdown.</li>
<li>2023-05-10: Add runCursorCommand API specification.</li>
<li>2023-05-08: <code>$readPreference</code> is not sent to standalone servers</li>
<li>2023-04-20: Add run command specification.</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="connection-string-spec"><a class="header" href="#connection-string-spec">Connection String Spec</a></h1>
<ul>
<li>Status: Accepted</li>
<li>Minimum Server Version: N/A</li>
</ul>
<hr />
<h2 id="abstract-7"><a class="header" href="#abstract-7">Abstract</a></h2>
<p>The purpose of the Connection String is to provide a machine readable way of configuring a MongoClient, allowing users
to configure and change the connection to their MongoDB system without requiring any application code changes.</p>
<p>This specification defines how the connection string is constructed and parsed. The aim is not to list all of connection
string options and their semantics. Rather it defines the syntax of the connection string, including rules for parsing,
naming conventions for options, and standard data types.</p>
<p>It should be noted that while the connection string specification is inspired by the URI specification as described in
<a href="http://tools.ietf.org/html/rfc3986">RFC 3986</a> and uses similar terminology, it does not conform to that specification.</p>
<h3 id="definitions"><a class="header" href="#definitions">Definitions</a></h3>
<h4 id="meta-7"><a class="header" href="#meta-7">META</a></h4>
<p>The keywords "MUST", "MUST NOT", "REQUIRED", "SHALL", "SHALL NOT", "SHOULD", "SHOULD NOT", "RECOMMENDED", "MAY", and
"OPTIONAL" in this document are to be interpreted as described in <a href="https://www.ietf.org/rfc/rfc2119.txt">RFC 2119</a>.</p>
<h3 id="general-syntax"><a class="header" href="#general-syntax">General Syntax</a></h3>
<p>In general we follow URI style conventions, however unlike a URI the connection string supports multiple hosts.</p>
<pre><code class="language-text">mongodb://username:password@example.com:27017,example2.com:27017,...,example.comN:27017/database?key=value&amp;keyN=valueN
\_____/   \_______________/ \_________/ \__/  \_______________________________________/ \______/ \_/ \___/
  |             |             |           |                    |                          |       |    |
Scheme          |            Host        Port        Alternative host identifiers         |      Key Value
             Userinfo       \_____________/                                               |      \_______/
                                   |                                              Auth database      |
                              Host Identifier                                                    Key Value Pair
                             \_______________________________________________________/          \___________________/
                                                      |                                                   |
                                                 Host Information                                  Connection Options
</code></pre>
<h3 id="scheme"><a class="header" href="#scheme">Scheme</a></h3>
<p>The scheme <code>mongodb</code> represents that this is a connection string for a MongoClient.</p>
<p>Other schemes are also possible and are introduced through additional specifications. These additional schemes build on
top of the connection string as documented in this specification.</p>
<p>For example the <code>mongodb+srv</code> specification, introduced with
<a href="connection-string/../initial-dns-seedlist-discovery/initial-dns-seedlist-discovery.html">Initial DNS Seedlist Discovery</a>, obtains
information from DNS in addition to just the connection string.</p>
<h3 id="userinfo-optional"><a class="header" href="#userinfo-optional">Userinfo (optional)</a></h3>
<p>The user information if present, is followed by a commercial at-sign ("@") that delimits it from the host.</p>
<p>A password may be supplied as part of the user information and is anything after the first colon (":") up until the end
of the user information.</p>
<p>RFC 3986 has guidance for encoding user information in
<a href="https://tools.ietf.org/html/rfc3986#section-2.1">Section 2.1 ("Percent-Encoding")</a>,
<a href="https://tools.ietf.org/html/rfc3986#section-2.2">Section 2.2 ("Reserved Characters")</a>, and
<a href="https://tools.ietf.org/html/rfc3986#section-3.2.1">Section 3.2.1 ("User Information")</a>.</p>
<p>Specifically, Section 3.2.1 provides for the following allowed characters:</p>
<pre><code>userinfo    = *( unreserved / pct-encoded / sub-delims / ":" )
</code></pre>
<p>If the user information contains an at-sign ("@"), more than one colon (":"), or a percent-sign ("%") that does not
match the rules for "pct-encoded", then an exception MUST be thrown informing the user that the username and password
must be URL encoded.</p>
<p>Above and beyond that restriction, drivers SHOULD require connection string user information to follow the "userinfo"
encoding rules of RFC 3986 and SHOULD throw an exception if disallowed characters are detected. However, for
backwards-compatibility reasons, drivers MAY allow reserved characters other than "@" and ":" to be present in user
information without percent-encoding.</p>
<h3 id="host-information"><a class="header" href="#host-information">Host Information</a></h3>
<p>Unlike a standard URI, the connection string allows for identifying multiple hosts. The host information section of the
connection string MAY be delimited by the trailing slash ("/") or end of string.</p>
<p>The host information must contain at least one host identifier but may contain more (see the alternative hosts / ports
in the general syntax diagram above). Multiple host identifiers are delimited by a comma (",").</p>
<h4 id="host-identifier"><a class="header" href="#host-identifier">Host Identifier</a></h4>
<p>A host identifier consists of a host and an optional port.</p>
<h5 id="host"><a class="header" href="#host">Host</a></h5>
<p>Identifies a server address to connect to. It can identify either a hostname, IP address, IP Literal, or UNIX domain
socket. For definitions of hostname, IP address and IP Literal formats see
<a href="http://tools.ietf.org/html/rfc3986#section-3.2.2">RFC 3986 Section 3.2.2</a> .</p>
<p>UNIX domain sockets MUST end in ".sock" and MUST be URL encoded, for example:</p>
<pre><code>mongodb://user:pass@%2Ftmp%2Fmongodb-27017.sock/authDB?replicaSet=rs
</code></pre>
<p>The host information cannot contain an unescaped slash ("/"), if it does then an exception MUST be thrown informing
users that paths must be URL encoded. For example:</p>
<pre><code>Unsupported host '/tmp/mongodb-27017.sock', UNIX socket domain paths must be URL encoded.
</code></pre>
<p>Support for UNIX domain sockets and IP Literals is OPTIONAL.</p>
<p>Unsupported host types MUST throw an exception informing the user they are not supported.</p>
<p>This specification does not define how host types should be differentiated (e.g. determining if a parsed host string is
a socket path or hostname). It is merely concerned with extracting the host identifiers from the URI.</p>
<h5 id="port-optional"><a class="header" href="#port-optional">Port (optional)</a></h5>
<p>The port is an integer between 1 and 65535 (inclusive) that identifies the port to connect to. See
<a href="http://tools.ietf.org/html/rfc3986#section-3.2.3">RFC 3986 3.2.3</a>.</p>
<h3 id="auth-database-optional"><a class="header" href="#auth-database-optional">Auth Database (optional)</a></h3>
<p>The database to authenticate against. If provided it is everything after the Host Information (ending with "/") and up
to the first question mark ("?") or end of string. The auth database MUST be URL decoded by the parser.</p>
<p>The following characters MUST NOT appear in the database name, once it has been decoded: slash ("/"), backslash (""),
space (" "), double-quote ("""), or dollar sign ("$"). The MongoDB Manual
<a href="https://www.mongodb.com/docs/manual/reference/limits/#Restrictions-on-Field-Names">says that</a> period (".") is also
prohibited, but drivers MAY allow periods in order to express a namespace (database and collection name, perhaps
containing multiple periods) in this part of the URL.</p>
<p>The presence of the auth database component without other credential data such as Userinfo or authentication parameters
in connection options MUST NOT be interpreted as a request for authentication.</p>
<h3 id="connection-options-optional"><a class="header" href="#connection-options-optional">Connection Options (optional)</a></h3>
<p>Any extra options to configure the MongoClient connection can be specified in the connection options part of the
connection string. If provided, it is everything after the Host Information (ending with "/"), optional auth database,
and first question mark ("?") to the end of the string. Connection Options consist of an ordered list of Key Value Pairs
that are delimited by an ampersand ("&amp;"). A delimiter of a semi colon (";") MAY also be supported for connection options
for legacy reasons.</p>
<h4 id="key-value-pair"><a class="header" href="#key-value-pair">Key Value Pair</a></h4>
<p>A key value pair represents the option key and its associated value. The key is everything up to the first equals sign
("=") and the value is everything afterwards. Key values contain the following information:</p>
<ul>
<li>Key:</li>
</ul>
<p>The connection option's key string. Keys should be normalised and character case should be ignored.</p>
<ul>
<li>Value: (optional)</li>
</ul>
<p>The value if provided otherwise it defaults to an empty string.</p>
<h3 id="defining-connection-options"><a class="header" href="#defining-connection-options">Defining connection options</a></h3>
<p>Connection option key values MUST be defined in the relevant specification that describes the usage of the key and
value. The value data type MUST also be defined there. The value's default value SHOULD also be defined if it is
relevant.</p>
<h4 id="keys"><a class="header" href="#keys">Keys</a></h4>
<p>Keys are strings and the character case must be normalized by lower casing the uppercase ASCII characters A through Z;
other characters are left as-is.</p>
<p>When defining and documenting keys, specifications should follow the camelCase naming convention with the first letter
in lowercase, snake_case MUST not be used. Keys that aren't supported by a driver MUST be ignored.</p>
<p>Keys that aren't supported by a driver MUST be ignored. A WARN level logging message MUST be issued for unsupported
keys. For example:</p>
<pre><code>Unsupported option 'connectMS'.
</code></pre>
<p>Keys should be descriptive and follow existing conventions:</p>
<h5 id="time-based-keys"><a class="header" href="#time-based-keys">Time based keys</a></h5>
<p>If a key represents a unit of time it MUST end with that unit of time.</p>
<p>Key authors SHOULD follow the existing convention of defaulting to using milliseconds as the unit of time (e.g.
<code>connectionTimeoutMS</code>).</p>
<h4 id="values"><a class="header" href="#values">Values</a></h4>
<p>The values in connection options MUST be URL decoded by the parser. The values can represent the following data types:</p>
<ul>
<li>
<p>Strings: The value</p>
</li>
<li>
<p>Integer: The value parsed as a integer. If the value is the empty string, the key MUST be ignored.</p>
</li>
<li>
<p>Boolean: "true" and "false" strings MUST be supported. If the value is the empty string, the key MUST be ignored.</p>
<ul>
<li>For legacy reasons it is RECOMMENDED that alternative values for true and false be supported:
<ul>
<li>true: "1", "yes", "y" and "t"</li>
<li>false: "0", "-1", "no", "n" and "f".</li>
</ul>
</li>
</ul>
<p>Alternative values are deprecated and MUST be removed from documentation and examples.</p>
<p>If any of these alternative values are used, drivers MUST log a deprecation notice or issue a logging message at the
WARNING level (as appropriate for your language). For example:</p>
<pre><code>Deprecated boolean value for "journal" : "1", please update to "journal=true"
</code></pre>
</li>
<li>
<p>Lists: Repeated keys represent a list in the Connection String consisting of the corresponding values in the same
order as they appear in the Connection String. For example:</p>
<pre><code>?readPreferenceTags=dc:ny,rack:1&amp;readPreferenceTags=dc:ny&amp;readPreferenceTags=
</code></pre>
</li>
<li>
<p>Key value pairs: A value that represents one or more key and value pairs. Multiple key value pairs are delimited by a
comma (","). The key is everything up to the first colon sign (":") and the value is everything afterwards.</p>
<p>For example:</p>
<pre><code>?readPreferenceTags=dc:ny,rack:1
</code></pre>
<p>Drivers MUST handle unencoded colon signs (":") within the value. For example, given the connection string option:</p>
<pre><code>authMechanismProperties=TOKEN_RESOURCE:mongodb://foo
</code></pre>
<p>the driver MUST interpret the key as <code>TOKEN_RESOURCE</code> and the value as <code>mongodb://foo</code>.</p>
<p>For any option key-value pair that may contain a comma (such as <code>TOKEN_RESOURCE</code>), drivers MUST document that: a value
containing a comma (",") MUST NOT be provided as part of the connection string. This prevents use of values that would
interfere with parsing.</p>
</li>
</ul>
<p>Any invalid Values for a given key MUST be ignored and MUST log a WARN level message. For example:</p>
<pre><code>Unsupported value for "fsync" : "ifPossible"
</code></pre>
<h3 id="repeated-keys"><a class="header" href="#repeated-keys">Repeated Keys</a></h3>
<p>If a key is repeated and the corresponding data type is not a List then the precedence of which key value pair will be
used is undefined except where defined otherwise by the <a href="connection-string/../uri-options/uri-options.html">URI options spec</a>.</p>
<p>Where possible, a warning SHOULD be raised to inform the user that multiple options were found for the same value.</p>
<h3 id="deprecated-key-value-pairs"><a class="header" href="#deprecated-key-value-pairs">Deprecated Key Value Pairs</a></h3>
<p>If a key name was deprecated due to renaming it MUST still be supported. Users aren't expected to be vigilant on changes
to key names.</p>
<p>If the renamed key is also defined in the connection string the deprecated key MUST NOT be applied and a WARN level
message MUST be logged. For example:</p>
<pre><code>Deprecated key "wtimeout" present and ignored as found replacement "wtimeoutms" value.
</code></pre>
<p>Deprecated keys MUST log a WARN level message informing the user that the option is deprecated and supply the
alternative key name. For example:</p>
<pre><code>Deprecated key "wtimeout" has been replaced with "wtimeoutms"
</code></pre>
<h3 id="legacy-support"><a class="header" href="#legacy-support">Legacy support</a></h3>
<p>Semi colon (";") query parameter delimiters and alternative string representations of Boolean values MAY be supported
only for legacy reasons.</p>
<p>As these options are not standard they might not be supported across all drivers. As such, these alternatives MUST NOT
be used as general examples or documentation.</p>
<h3 id="language-specific-connection-options"><a class="header" href="#language-specific-connection-options">Language specific connection options</a></h3>
<p>Connection strings are a mechanism to configure a MongoClient outside the user's application. As each driver may have
language specific configuration options, those options SHOULD also be supported via the connection string. Where
suitable, specifications MUST be updated to reflect new options.</p>
<p>Keys MUST follow existing connection option naming conventions as defined above. Values MUST also follow the existing,
specific data types.</p>
<p>Any options that are not supported MUST raise a WARN log level as described in the keys section.</p>
<h3 id="connection-options-precedence"><a class="header" href="#connection-options-precedence">Connection options precedence</a></h3>
<p>If a driver allows URI options to be specified outside of the connection string (e.g. dictionary parameter to the
MongoClient constructor) it MUST document the precedence rules between all such mechanisms. For instance, a driver MAY
allow a value for option <code>foo</code> in a dictionary parameter to override the value of <code>foo</code> in the connection string (or
vice versa) so long as that behavior is documented.</p>
<h3 id="test-plan-5"><a class="header" href="#test-plan-5">Test Plan</a></h3>
<p>See the <a href="connection-string/tests/README.html">README</a> for tests.</p>
<h3 id="motivation-for-change-4"><a class="header" href="#motivation-for-change-4">Motivation for Change</a></h3>
<p>The motivation for this specification is to publish how connection strings are formed and how they should be parsed.
This is important because although the connection string follows the terminology of a standard URI format (as described
in <a href="http://tools.ietf.org/html/rfc3986">RFC 3986</a>) it is not a standard URI and cannot be parsed by standard URI
parsers.</p>
<p>The specification also formalizes the standard practice for the definition of new connection options and where the
responsibility for their definition should be.</p>
<h3 id="design-rationale-4"><a class="header" href="#design-rationale-4">Design Rationale</a></h3>
<p>The rationale for the Connection String is to provide a consistent, driver independent way to define the connection to a
MongoDB system outside of the application. The connection string is an existing standard and is already widely used.</p>
<h3 id="backwards-compatibility-3"><a class="header" href="#backwards-compatibility-3">Backwards Compatibility</a></h3>
<p>Connection Strings are already generally supported across languages and driver implementations. As the responsibility
for the definitions of connections options relies on the specifications defining them, there should be no backwards
compatibility breaks caused by this specification with regards to options.</p>
<p>Connection options precedence may cause some backwards incompatibilities as existing driver behaviour differs here. As
such, it is currently only a recommendation.</p>
<h3 id="reference-implementation-2"><a class="header" href="#reference-implementation-2">Reference Implementation</a></h3>
<p>The Java driver implements a <code>ConnectionString</code> class for the parsing of the connection string; however, it does not
support UNIX domain sockets. The Python driver's <code>uri_parser</code> module implements connection string parsing for both hosts
and UNIX domain sockets.</p>
<p>The following example parses a connection string into its components and can be used as a guide.</p>
<p>Given the string <code>mongodb://foo:bar%3A@mongodb.example.com,%2Ftmp%2Fmongodb-27018.sock/admin?w=1</code>:</p>
<ol>
<li>Validate and remove the scheme prefix <code>mongodb://</code>, leaving:
<code>foo:bar%3A@mongodb.example.com,%2Ftmp%2Fmongodb-27018.sock/admin?w=1</code></li>
<li>Split the string by the first, unescaped <code>/</code> (if any), yielding:
<ol>
<li>User information and host identifiers: <code>foo:bar%3A@mongodb.example.com,%2Ftmp%2Fmongodb-27018.sock</code>.</li>
<li>Auth database and connection options: <code>admin?w=1</code>.</li>
</ol>
</li>
<li>Split the user information and host identifiers string by the last, unescaped <code>@</code>, yielding:
<ol>
<li>User information: <code>foo:bar%3A</code>.</li>
<li>Host identifiers: <code>mongodb.example.com,%2Ftmp%2Fmongodb-27018.sock</code>.</li>
</ol>
</li>
<li>Validate, split (if applicable), and URL decode the user information. In this example, the username and password
would be <code>foo</code> and <code>bar:</code>, respectively.</li>
<li>Validate, split, and URL decode the host identifiers. In this example, the hosts would be
<code>["mongodb.example.com", "/tmp/mongodb-27018.sock"]</code>.</li>
<li>Split the auth database and connection options string by the first, unescaped <code>?</code>, yielding:
<ol>
<li>Auth database: <code>admin</code>.</li>
<li>Connection options: <code>w=1</code>.</li>
</ol>
</li>
<li>URL decode the auth database. In this example, the auth database is <code>admin</code>.</li>
<li>Validate the database contains no prohibited characters.</li>
<li>Validate, split, and URL decode the connection options. In this example, the connection options are <code>{w: 1}</code>.</li>
</ol>
<h3 id="qa-2"><a class="header" href="#qa-2">Q&amp;A</a></h3>
<p>Q: What about existing Connection Options that aren't currently defined in a specification</p>
<p>Ideally all MongoClient options would already belong in their relevant specifications. As we iterate and produce more
specifications these options should be covered.</p>
<p>Q: Why is it recommended that Connection Options take precedence over application set options</p>
<p>This is only a recommendation but the reasoning is application code is much harder to change across deployments. By
making the Connection String take precedence from outside the application it would be easier for the application to be
portable across environments. The order of precedence of MongoClient hosts and options is recommended to be from low to
high:</p>
<ol>
<li>Default values</li>
<li>MongoClient hosts and options</li>
<li>Connection String hosts and options</li>
</ol>
<p>Q: Why WARN level warning on unknown options rather than throwing an exception</p>
<p>It is responsible to inform users of possible misconfigurations and both methods achieve that. However, there are
conflicting requirements of a Connection String. One goal is that any given driver should be configurable by a
connection string but different drivers and languages have different feature sets. Another goal is that Connection
Strings should be portable and as such some options supported by language X might not be relevant to language Y. Any
given driver does not know is an option is specific to a different driver or is misspelled or just not supported. So the
only way to stay portable and support configuration of all options is to not throw an exception but rather log a
warning.</p>
<p>Q: How long should deprecation options be supported</p>
<p>This is not declared in this specification. It's not deemed responsible to give a single timeline for how long
deprecated options should be supported. As such any specifications that deprecate options that do have the context of
the decision should provide the timeline.</p>
<p>Q: Why can I not use a standard URI parser</p>
<p>The connection string format does not follow the standard URI format (as described in
<a href="http://tools.ietf.org/html/rfc3986">RFC 3986</a>) we differ in two key areas:</p>
<ol>
<li>
<p>Hosts</p>
<p>The connection string allows for multiple hosts for high availability reasons but standard URI's only ever define a
single host.</p>
</li>
<li>
<p>Query Parameters / Connection Options</p>
<p>The connection string provides a concreted definition on how the Connection Options are parsed, including definitions
of different data types. The <a href="http://tools.ietf.org/html/rfc3986">RFC 3986</a> only defines that they are <code>key=value</code>
pairs and gives no instruction on parsing. In fact different languages handle the parsing of query parameters in
different ways and as such there is no such thing as a standard URI parser.</p>
</li>
</ol>
<p>Q: Can the connection string contain non-ASCII characters</p>
<p>The connection string can contain non-ASCII characters. The connection string is text, which can be encoded in any way
appropriate for the application (e.g. the C Driver requires you to pass it a UTF-8 encoded connection string).</p>
<p>Q: Why does reference implementation check for a <code>.sock</code> suffix when parsing a socket path and possible auth database</p>
<p>To simplify parsing of a socket path followed by an auth database, we rely on MongoDB's
<a href="https://www.mongodb.com/docs/manual/reference/limits/#naming-restrictions">naming restrictions</a>), which do not allow
database names to contain a dot character, and the fact that socket paths must end with <code>.sock</code>. This allows us to
differentiate the last part of a socket path from a database name. While we could immediately rule out an auth database
on the basis of the dot alone, this specification is primarily concerned with breaking down the components of a URI
(e.g. hosts, auth database, options) in a deterministic manner, rather than applying strict validation to those parts
(e.g. host types, database names, allowed values for an option). Additionally, some drivers might allow a namespace
(e.g. <code>"db.collection"</code>) for the auth database part, so we do not want to be more strict than is necessary for parsing.</p>
<p>Q: Why throw an exception if the userinfo contains a percent sign ("%"), at-sign ("@"), or more than one colon (":")</p>
<p>This is done to help users format the connection string correctly. Although at-signs ("@") or colons (":") in the
username must be URL encoded, users may not be aware of that requirement. Take the following example:</p>
<pre><code>mongodb://anne:bob:pass@localhost:27017
</code></pre>
<p>Is the username <code>anne</code> and the password <code>bob:pass</code> or is the username <code>anne:bob</code> and the password <code>pass</code>? Accepting this
as the userinfo could cause authentication to fail, causing confusion for the user as to why. Allowing unescaped at-sign
and percent symbols would invite further ambiguity. By throwing an exception users are made aware and then update the
connection string so to be explicit about what forms the username and password.</p>
<p>Q: Why must UNIX domain sockets be URL encoded</p>
<p>This has been done to reduce ambiguity between the socket name and the database name. Take the following example:</p>
<pre><code>mongodb:///tmp/mongodb.sock/mongodb.sock
</code></pre>
<p>Is the host <code>/tmp/mongodb.sock</code> and the auth database <code>mongodb.sock</code> or does the connection string just contain the host
<code>/tmp/mongodb.sock/mongodb.sock</code> and no auth database? By enforcing URL encoding on UNIX domain sockets it makes users
be explicit about the host and the auth database. By requiring an exception to be thrown when the host contains a slash
("/") users can be informed on how to migrate their connection strings.</p>
<p>Q: Why must the auth database be URL decoded by the parser</p>
<p>On Linux systems database names can contain a question mark ("?"), in these rare cases the auth database must be URL
encoded. This disambiguates between the auth database and the connection options. Take the following example:</p>
<pre><code>mongodb://localhost/admin%3F?w=1
</code></pre>
<p>In this case the auth database would be <code>admin?</code> and the connection options <code>w=1</code>.</p>
<p>Q: How should the space character be encoded in a connection string</p>
<p>Space characters SHOULD be encoded as <code>%20</code> rather than <code>+</code>, this will be portable across all implementations.
Implementations MAY support decoding <code>+</code> into a space, as many languages treat strings as <code>x-www-form-urlencoded</code> data
by default.</p>
<h2 id="changelog-7"><a class="header" href="#changelog-7">Changelog</a></h2>
<ul>
<li>
<p>2024-05-29: Clarify handling of key-value pairs and add specification test.</p>
</li>
<li>
<p>2024-02-15: Migrated from reStructuredText to Markdown.</p>
</li>
<li>
<p>2016-07-22: In Port section, clarify that zero is not an acceptable port.</p>
</li>
<li>
<p>2017-01-09: In Userinfo section, clarify that percent signs must be encoded.</p>
</li>
<li>
<p>2017-06-10: In Userinfo section, require username and password to be fully URI encoded, not just "%", "@", and ":". In
Auth Database, list the prohibited characters. In Reference Implementation, split at the first "/", not the last.</p>
</li>
<li>
<p>2018-01-09: Clarified that space characters should be encoded to <code>%20</code>.</p>
</li>
<li>
<p>2018-06-04: Revised Userinfo section to provide an explicit list of allowed characters and clarify rules for
exceptions.</p>
</li>
<li>
<p>2019-02-04: In Repeated Keys section, clarified that the URI options spec may override the repeated key behavior
described here for certain options.</p>
</li>
<li>
<p>2019-03-04: Require drivers to document option precedence rules</p>
</li>
<li>
<p>2019-04-26: Database name in URI alone does not trigger authentication</p>
</li>
<li>
<p>2020-01-21: Clarified how empty values in a connection string are parsed.</p>
</li>
<li>
<p>2022-10-05: Remove spec front matter and reformat changelog.</p>
</li>
<li>
<p>2022-12-27: Note that host information ends with a "/" character in connection options description.</p>
</li>
<li>
<p>2023-08-02: Make delimiting slash between host information and connection options optional and update tests</p>
</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="uri-options-specification"><a class="header" href="#uri-options-specification">URI Options Specification</a></h1>
<ul>
<li>
<p>Status: Accepted</p>
</li>
<li>
<p>Minimum Server Version: N/A</p>
</li>
</ul>
<h2 id="abstract-8"><a class="header" href="#abstract-8">Abstract</a></h2>
<p>Historically, URI options have been defined in individual specs, and drivers have defined any additional options
independently of one another. Because of the frustration due to there not being a single place where all of the URI
options are defined, this spec aims to do just that—namely, provide a canonical list of URI options that each driver
defines.</p>
<p><strong>THIS SPEC DOES NOT REQUIRE DRIVERS TO MAKE ANY BREAKING CHANGES.</strong></p>
<h2 id="meta-8"><a class="header" href="#meta-8">META</a></h2>
<p>The keywords "MUST", "MUST NOT", "REQUIRED", "SHALL", "SHALL NOT", "SHOULD", "SHOULD NOT", "RECOMMENDED", "MAY", and
"OPTIONAL" in this document are to be interpreted as described in <a href="https://www.ietf.org/rfc/rfc2119.txt">RFC 2119</a>.</p>
<h2 id="specification-7"><a class="header" href="#specification-7">Specification</a></h2>
<h3 id="conflicting-tls-options"><a class="header" href="#conflicting-tls-options">Conflicting TLS options</a></h3>
<p>Per the <a href="uri-options/../connection-string/connection-string-spec.html#repeated-keys">Connection String spec</a>, the behavior of
duplicates of most URI options is undefined. However, due to the security implications of certain options, drivers MUST
raise an error to the user during parsing if any of the following circumstances occur:</p>
<ol>
<li>Both <code>tlsInsecure</code> and <code>tlsAllowInvalidCertificates</code> appear in the URI options.</li>
<li>Both <code>tlsInsecure</code> and <code>tlsAllowInvalidHostnames</code> appear in the URI options.</li>
<li>Both <code>tlsInsecure</code> and <code>tlsDisableOCSPEndpointCheck</code> appear in the URI options.</li>
<li>Both <code>tlsInsecure</code> and <code>tlsDisableCertificateRevocationCheck</code> appear in the URI options.</li>
<li>Both <code>tlsAllowInvalidCertificates</code> and <code>tlsDisableOCSPEndpointCheck</code> appear in the URI options.</li>
<li>Both <code>tlsAllowInvalidCertificates</code> and <code>tlsDisableCertificateRevocationCheck</code> appear in the URI options.</li>
<li>Both <code>tlsDisableOCSPEndpointCheck</code> and <code>tlsDisableCertificateRevocationCheck</code> appear in the URI options.</li>
<li>All instances of <code>tls</code> and <code>ssl</code> in the URI options do not have the same value. If all instances of <code>tls</code> and <code>ssl</code>
have the same value, an error MUST NOT be raised.</li>
</ol>
<h3 id="directconnection-uri-option-with-multiple-seeds-or-srv-uri"><a class="header" href="#directconnection-uri-option-with-multiple-seeds-or-srv-uri">directConnection URI option with multiple seeds or SRV URI</a></h3>
<p>The driver MUST report an error if the <code>directConnection=true</code> URI option is specified with multiple seeds.</p>
<p>The driver MUST report an error if the <code>directConnection=true</code> URI option is specified with an SRV URI, because the URI
may resolve to multiple hosts. The driver MUST allow specifying <code>directConnection=false</code> URI option with an SRV URI.</p>
<h3 id="srvservicename-and-srvmaxhosts-uri-options"><a class="header" href="#srvservicename-and-srvmaxhosts-uri-options">srvServiceName and srvMaxHosts URI options</a></h3>
<p>For URI option validation pertaining to <code>srvServiceName</code> and <code>srvMaxHosts</code>, please see the
<a href="uri-options/../initial-dns-seedlist-discovery/initial-dns-seedlist-discovery.html#uri-validation">Initial DNS Seedlist Discovery spec</a>
for details.</p>
<h3 id="load-balancer-mode"><a class="header" href="#load-balancer-mode">Load Balancer Mode</a></h3>
<p>For URI option validation in Load Balancer mode (i.e. <code>loadBalanced=true</code>), please see the
<a href="uri-options/../load-balancers/load-balancers.html#uri-validation">Load Balancer spec</a> for details.</p>
<h3 id="socks5-options"><a class="header" href="#socks5-options">SOCKS5 options</a></h3>
<p>For URI option validation pertaining to <code>proxyHost</code>, <code>proxyPort</code>, <code>proxyUsername</code> and <code>proxyPassword</code> please see the
<a href="uri-options/../socks5-support/socks5.html#mongoclient-configuration">SOCKS5 support spec</a> for details.</p>
<h3 id="list-of-specified-options"><a class="header" href="#list-of-specified-options">List of specified options</a></h3>
<p>Each driver option below MUST be implemented in each driver unless marked as optional. If an option is marked as
optional, a driver MUST meet any conditions specified for leaving it out if it is not included. If a driver already
provides the option under a different name, the driver MAY implement the old and new names as aliases. All keys and
values MUST be encoded in UTF-8. All integer options are 32-bit unless specified otherwise. Note that all requirements
and recommendations described in the <a href="uri-options/../connection-string/connection-string-spec.html">Connection String spec</a> pertaining
to URI options apply here.</p>
<p><span id="uri.options"></span></p>
<div class="table-wrapper"><table><thead><tr><th>Name</th><th>Accepted Values</th><th>Default Value</th><th>Optional to implement?</th><th>Description</th></tr></thead><tbody>
<tr><td>appname</td><td>any string that meets the criteria listed in the <a href="uri-options/../mongodb-handshake/handshake.html#client-application-name">handshake spec</a></td><td>no appname specified</td><td>no</td><td>Passed into the server in the client metadata as part of the connection handshake</td></tr>
<tr><td>authMechanism</td><td>any string; valid values are defined in the <a href="uri-options/../auth/auth.html#supported-authentication-methods">auth spec</a></td><td>None; default values for authentication exist for constructing authentication credentials per the <a href="uri-options/../auth/auth.html#supported-authentication-methods">auth spec</a>, but there is no default for the URI option itself.</td><td>no</td><td>The authentication mechanism method to use for connection to the server</td></tr>
<tr><td>authMechanismProperties</td><td>comma separated key:value pairs, e.g. "opt1:val1,opt2:val2"</td><td>no properties specified</td><td>no</td><td>Additional options provided for authentication (e.g. to enable hostname canonicalization for GSSAPI)</td></tr>
<tr><td>authSource</td><td>any string</td><td>None; default values for authentication exist for constructing authentication credentials per the <a href="uri-options/../auth/auth.html#supported-authentication-methods">auth spec</a>, but there is no default for the URI option itself.</td><td>no</td><td>The database that connections should authenticate against</td></tr>
<tr><td>compressors</td><td>comma separated list of strings, e.g. "snappy,zlib"</td><td>defined in <a href="uri-options/../compression/OP_COMPRESSED.html#compressors">compression spec</a></td><td>no</td><td>The list of allowed compression types for wire protocol messages sent or received from the server</td></tr>
<tr><td>connectTimeoutMS</td><td>non-negative integer; 0 means "no timeout"</td><td>10,000 ms (unless a driver already has a different default)</td><td>no</td><td>Amount of time to wait for a single TCP socket connection to the server to be established before erroring; note that this applies to <a href="uri-options/../mongodb-handshake/handshake.html">SDAM hello and legacy hello operations</a></td></tr>
<tr><td>directConnection</td><td>"true" or "false"</td><td>defined in <a href="uri-options/../server-discovery-and-monitoring/server-discovery-and-monitoring.html#initial-topologytype">SDAM spec</a></td><td>no</td><td>Whether to connect to the deployment in Single topology.</td></tr>
<tr><td>heartbeatFrequencyMS</td><td>integer greater than or equal to 500</td><td>defined in <a href="uri-options/../server-discovery-and-monitoring/server-discovery-and-monitoring.html#heartbeatfrequencyms">SDAM spec</a></td><td>no</td><td>the interval between regular server monitoring checks</td></tr>
<tr><td>journal</td><td>"true" or "false"</td><td>no "j" field specified</td><td>no</td><td>Default write concern "j" field for the client</td></tr>
<tr><td>loadBalanced</td><td>"true" or "false"</td><td>defined in <a href="uri-options/../load-balancers/load-balancers.html#loadbalanced">Load Balancer spec</a></td><td>no</td><td>Whether the driver is connecting to a load balancer.</td></tr>
<tr><td>localThresholdMS</td><td>non-negative integer; 0 means 0 ms (i.e. the fastest eligible server must be selected)</td><td>defined in the <a href="uri-options/../server-selection/server-selection.html#localthresholdms">server selection spec</a></td><td>no</td><td>The amount of time beyond the fastest round trip time that a given server’s round trip time can take and still be eligible for server selection</td></tr>
<tr><td>maxIdleTimeMS</td><td>non-negative integer; 0 means no minimum</td><td>defined in the <a href="uri-options/../connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection-pool-options">Connection Pooling spec</a></td><td>required for drivers with connection pools</td><td>The amount of time a connection can be idle before it's closed</td></tr>
<tr><td>maxPoolSize</td><td>non-negative integer; 0 means no maximum</td><td>defined in the <a href="uri-options/../connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection-pool-options">Connection Pooling spec</a></td><td>required for drivers with connection pools</td><td>The maximum number of clients or connections able to be created by a pool at a given time. This count includes connections which are currently checked out.</td></tr>
<tr><td>maxConnecting</td><td>positive integer</td><td>defined in the <a href="uri-options/../connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection-pool-options">Connection Pooling spec</a></td><td>required for drivers with connection pools</td><td>The maximum number of Connections a Pool may be establishing concurrently.</td></tr>
<tr><td>maxStalenessSeconds</td><td>-1 (no max staleness check) or integer &gt;= 90</td><td>defined in <a href="uri-options/../max-staleness/max-staleness.html#api">max staleness spec</a></td><td>no</td><td>The maximum replication lag, in wall clock time, that a secondary can suffer and still be eligible for server selection</td></tr>
<tr><td>minPoolSize</td><td>non-negative integer</td><td>defined in the <a href="uri-options/../connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection-pool-options">Connection Pooling spec</a></td><td>required for drivers with connection pools</td><td>The number of connections the driver should create and maintain in the pool even when no operations are occurring. This count includes connections which are currently checked out.</td></tr>
<tr><td>proxyHost</td><td>any string</td><td>defined in the <a href="uri-options/../socks5-support/socks5.html#mongoclient-configuration">SOCKS5 support spec</a></td><td>no</td><td>The IPv4/IPv6 address or domain name of a SOCKS5 proxy server used for connecting to MongoDB services.</td></tr>
<tr><td>proxyPort</td><td>non-negative integer</td><td>defined in the <a href="uri-options/../socks5-support/socks5.html#mongoclient-configuration">SOCKS5 support spec</a></td><td>no</td><td>The port of the SOCKS5 proxy server specified in <code>proxyHost</code>.</td></tr>
<tr><td>proxyUsername</td><td>any string</td><td>defined in the <a href="uri-options/../socks5-support/socks5.html#mongoclient-configuration">SOCKS5 support spec</a></td><td>no</td><td>The username for username/password authentication to the SOCKS5 proxy server specified in <code>proxyHost</code>.</td></tr>
<tr><td>proxyPassword</td><td>any string</td><td>defined in the <a href="uri-options/../socks5-support/socks5.html#mongoclient-configuration">SOCKS5 support spec</a></td><td>no</td><td>The password for username/password authentication to the SOCKS5 proxy server specified in <code>proxyHost</code>.</td></tr>
<tr><td>readConcernLevel</td><td>any string (<a href="uri-options/../read-write-concern/read-write-concern.html#unknown-levels-and-additional-options-for-string-based-readconcerns">to allow for forwards compatibility with the server</a>)</td><td>no read concern specified</td><td>no</td><td>Default read concern for the client</td></tr>
<tr><td>readPreference</td><td>any string; currently supported values are defined in the <a href="uri-options/../server-selection/server-selection.html#mode">server selection spec</a>, but must be lowercase camelCase, e.g. "primaryPreferred"</td><td>defined in <a href="uri-options/../server-selection/server-selection.html#mode">server selection spec</a></td><td>no</td><td>Default read preference for the client (excluding tags)</td></tr>
<tr><td>readPreferenceTags</td><td>comma-separated key:value pairs (e.g. "dc:ny,rack:1" and "dc:ny)<br><br>can be specified multiple times; each instance of this key is a separate tag set</td><td>no tags specified</td><td>no</td><td>Default read preference tags for the client; only valid if the read preference mode is not primary<br><br>The order of the tag sets in the read preference is the same as the order they are specified in the URI</td></tr>
<tr><td>replicaSet</td><td>any string</td><td>no replica set name provided</td><td>no</td><td>The name of the replica set to connect to</td></tr>
<tr><td>retryReads</td><td>"true" or "false"</td><td>defined in <a href="uri-options/../retryable-reads/retryable-reads.html#retryreads">retryable reads spec</a></td><td>no</td><td>Enables retryable reads on server 3.6+</td></tr>
<tr><td>retryWrites</td><td>"true" or "false"</td><td>defined in <a href="uri-options/../retryable-writes/retryable-writes.html#retrywrites">retryable writes spec</a></td><td>no</td><td>Enables retryable writes on server 3.6+</td></tr>
<tr><td>serverMonitoringMode</td><td>"stream", "poll", or "auto"</td><td>defined in <a href="uri-options/../server-discovery-and-monitoring/server-monitoring.html#servermonitoringmode">SDAM spec</a></td><td>required for multi-threaded or asynchronous drivers</td><td>Configures which server monitoring protocol to use.</td></tr>
<tr><td>serverSelectionTimeoutMS</td><td>positive integer; a driver may also accept 0 to be used for a special case, provided that it documents the meaning</td><td>defined in <a href="uri-options/../server-selection/server-selection.html#serverselectiontimeoutms">server selection spec</a></td><td>no</td><td>A timeout in milliseconds to block for server selection before raising an error</td></tr>
<tr><td>serverSelectionTryOnce</td><td>"true" or "false"</td><td>defined in <a href="uri-options/../server-selection/server-selection.html#serverselectiontryonce">server selection spec</a></td><td>required for single-threaded drivers</td><td>Scan the topology only once after a server selection failure instead of repeatedly until the server selection times out</td></tr>
<tr><td>socketTimeoutMS</td><td>non-negative integer; 0 means no timeout</td><td>no timeout</td><td>no</td><td>NOTE: This option is deprecated in favor of <a href="uri-options/../client-side-operations-timeout/client-side-operations-timeout.html#timeoutms">timeoutMS</a><br><br>Amount of time spent attempting to send or receive on a socket before timing out; note that this only applies to application operations, not SDAM.</td></tr>
<tr><td>srvMaxHosts</td><td>non-negative integer; 0 means no maximum</td><td>defined in the <a href="uri-options/../initial-dns-seedlist-discovery/initial-dns-seedlist-discovery.html#srvmaxhosts">Initial DNS Seedlist Discovery spec</a></td><td>no</td><td>The maximum number of SRV results to randomly select when initially populating the seedlist or, during SRV polling, adding new hosts to the topology.</td></tr>
<tr><td>srvServiceName</td><td>a valid SRV service name according to <a href="https://datatracker.ietf.org/doc/html/rfc6335#section-5.1">RFC 6335</a></td><td>"mongodb"</td><td>no</td><td>the service name to use for SRV lookup in <a href="uri-options/../initial-dns-seedlist-discovery/initial-dns-seedlist-discovery.html#srvservicename">initial DNS seedlist discovery</a> and <a href="uri-options/../polling-srv-records-for-mongos-discovery/polling-srv-records-for-mongos-discovery.html">SRV polling</a></td></tr>
<tr><td>ssl</td><td>"true" or "false"</td><td>same as "tls"</td><td>no</td><td>alias of "tls"; required to ensure that Atlas connection strings continue to work</td></tr>
<tr><td></td><td></td><td></td><td></td><td></td></tr>
<tr><td>tls</td><td>"true" or "false"</td><td>TLS required if "mongodb+srv" scheme; otherwise, drivers may may enable TLS by default if other "tls"-prefixed options are present<br><br>Drivers MUST clearly document the conditions under which TLS is enabled implicitly</td><td>no</td><td>Whether or not to require TLS for connections to the server</td></tr>
<tr><td>tlsAllowInvalidCertificates</td><td>"true" or "false"</td><td>error on invalid certificates</td><td>required if the driver’s language/runtime allows bypassing hostname verification</td><td>Specifies whether or not the driver should error when the server’s TLS certificate is invalid</td></tr>
<tr><td>tlsAllowInvalidHostnames</td><td>"true" or "false"</td><td>error on invalid certificates</td><td>required if the driver’s language/runtime allows bypassing hostname verification</td><td>Specifies whether or not the driver should error when there is a mismatch between the server’s hostname and the hostname specified by the TLS certificate</td></tr>
<tr><td>tlsCAFile</td><td>any string</td><td>no certificate authorities specified</td><td>required if the driver's language/runtime allows non-global configuration</td><td>Path to file with either a single or bundle of certificate authorities to be considered trusted when making a TLS connection</td></tr>
<tr><td>tlsCertificateKeyFile</td><td>any string</td><td>no client certificate specified</td><td>required if the driver's language/runtime allows non-global configuration</td><td>Path to the client certificate file or the client private key file; in the case that they both are needed, the files should be concatenated</td></tr>
<tr><td>tlsCertificateKeyFilePassword</td><td>any string</td><td>no password specified</td><td>required if the driver's language/runtime allows non-global configuration</td><td>Password to decrypt the client private key to be used for TLS connections</td></tr>
<tr><td>tlsDisableCertificateRevocationCheck</td><td>"true" or "false"</td><td>false i.e. driver will reach check a certificate's revocation status</td><td>Yes</td><td>Controls whether or not the driver will check a certificate's revocation status via CRLs or OCSP. See the <a href="uri-options/../ocsp-support/ocsp-support.html#tlsdisablecertificaterevocationcheck">OCSP Support Spec</a> for additional information.</td></tr>
<tr><td>tlsDisableOCSPEndpointCheck</td><td>"true" or "false"</td><td>false i.e. driver will reach out to OCSP endpoints <a href="uri-options/../ocsp-support/ocsp-support.html#tlsdisableocspendpointcheck">if needed</a>.</td><td>Yes</td><td>Controls whether or not the driver will reach out to OCSP endpoints if needed. See the <a href="uri-options/../ocsp-support/ocsp-support.html#tlsdisableocspendpointcheck">OCSP Support Spec</a> for additional information.</td></tr>
<tr><td>tlsInsecure</td><td>"true" or "false"</td><td>No TLS constraints are relaxed</td><td>no</td><td>Relax TLS constraints as much as possible (e.g. allowing invalid certificates or hostname mismatches); drivers must document the exact constraints which are relaxed by this option being true</td></tr>
<tr><td>w</td><td>non-negative integer or string</td><td>no "w" value specified</td><td>no</td><td>Default write concern "w" field for the client</td></tr>
<tr><td>waitQueueTimeoutMS</td><td>positive number</td><td>defined in the <a href="uri-options/../connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection-pool-options">Connection Pooling spec</a></td><td>required for drivers with connection pools, with exceptions described in the <a href="uri-options/../connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection-pool-options">Connection Pooling spec</a></td><td>NOTE: This option is deprecated in favor of <a href="uri-options/../client-side-operations-timeout/client-side-operations-timeout.html#timeoutms">timeoutMS</a><br><br>Amount of time spent attempting to check out a connection from a server's connection pool before timing out</td></tr>
<tr><td>wTimeoutMS</td><td>non-negative 64-bit integer; 0 means no timeout</td><td>no timeout</td><td>no</td><td>NOTE: This option is deprecated in favor of <a href="uri-options/../client-side-operations-timeout/client-side-operations-timeout.html#timeoutms">timeoutMS</a><br><br>Default write concern "wtimeout" field for the client</td></tr>
<tr><td>zlibCompressionLevel</td><td>integer between -1 and 9 (inclusive)</td><td>-1 (default compression level of the driver)</td><td>no</td><td>Specifies the level of compression when using zlib to compress wire protocol messages; -1 signifies the default level, 0 signifies no compression, 1 signifies the fastest speed, and 9 signifies the best compression</td></tr>
</tbody></table>
</div>
<h2 id="test-plan-6"><a class="header" href="#test-plan-6">Test Plan</a></h2>
<p>Tests are implemented and described in the <a href="uri-options/tests/README.html">tests</a> directory.</p>
<h2 id="design-rationale-5"><a class="header" href="#design-rationale-5">Design Rationale</a></h2>
<h3 id="why-allow-drivers-to-provide-the-canonical-names-as-aliases-to-existing-options"><a class="header" href="#why-allow-drivers-to-provide-the-canonical-names-as-aliases-to-existing-options">Why allow drivers to provide the canonical names as aliases to existing options?</a></h3>
<p>First and foremost, this spec aims not to introduce any breaking changes to drivers. Forcing a driver to change the name
of an option that it provides will break any applications that use the old option. Moreover, it is already possible to
provide duplicate options in the URI by specifying the same option more than once; drivers can use the same semantics to
resolve the conflicts as they did before, whether it's raising an error, using the first option provided, using the last
option provided, or simply telling users that the behavior is not defined.</p>
<h3 id="why-use-tls-as-the-prefix-instead-of-ssl-for-related-options"><a class="header" href="#why-use-tls-as-the-prefix-instead-of-ssl-for-related-options">Why use "tls" as the prefix instead of "ssl" for related options?</a></h3>
<p>Technically speaking, drivers already only support TLS, which supersedes SSL. While SSL is commonly used in parlance to
refer to TLS connections, the fact remains that SSL is a weaker cryptographic protocol than TLS, and we want to
accurately reflect the strict requirements that drivers have in ensuring the security of a TLS connection.</p>
<h3 id="why-use-the-names-tlsallowinvalidhostnames-and-tlsallowinvalidcertificates"><a class="header" href="#why-use-the-names-tlsallowinvalidhostnames-and-tlsallowinvalidcertificates">Why use the names "tlsAllowInvalidHostnames" and "tlsAllowInvalidCertificates"?</a></h3>
<p>The "tls" prefix is used for the same reasons described above. The use of the terms "AllowInvalidHostnames" and
"AllowInvalidCertificates" is an intentional choice in order to convey the inherent unsafety of these options, which
should only be used for testing purposes. Additionally, both the server and the shell use "AllowInvalid" for their
equivalent options.</p>
<h3 id="why-provide-multiple-implementation-options-for-the-insecure-tls-options-ie-tlsinsecure-vs-tlsallowinvalidhostnamestlsallowinvalidcertificates"><a class="header" href="#why-provide-multiple-implementation-options-for-the-insecure-tls-options-ie-tlsinsecure-vs-tlsallowinvalidhostnamestlsallowinvalidcertificates">Why provide multiple implementation options for the insecure TLS options (i.e. "tlsInsecure" vs. "tlsAllowInvalidHostnames"/"tlsAllowInvalidCertificates"?</a></h3>
<p>Some TLS libraries (e.g. Go's standard library implementation) do not provide the ability to distinguish between allow
invalid certificates and hostnames, meaning they either both are allowed, or neither are. However, when more granular
options are available, it's better to expose these to the user to allow them to relax security constraints as little as
they need.</p>
<h3 id="why-leave-the-decision-up-to-drivers-to-enable-tls-implicitly-when-tls-options-are-present"><a class="header" href="#why-leave-the-decision-up-to-drivers-to-enable-tls-implicitly-when-tls-options-are-present">Why leave the decision up to drivers to enable TLS implicitly when TLS options are present?</a></h3>
<p>It can be useful to turn on TLS implicitly when options such as "tlsCAFile" are present and "tls" is not present.
However, with options such as "tlsAllowInvalidHostnames", some drivers may not have the ability to distinguish between
"false" being provided and the option not being specified. To keep the implicit enabling of TLS consistent between such
options, we defer the decision to enable TLS based on the presence of "tls"-prefixed options (besides "tls" itself) to
drivers.</p>
<h2 id="reference-implementations-2"><a class="header" href="#reference-implementations-2">Reference Implementations</a></h2>
<p>Ruby and Python</p>
<h2 id="security-implication"><a class="header" href="#security-implication">Security Implication</a></h2>
<p>Each of the "insecure" TLS options (i.e. "tlsInsecure", "tlsAllowInvalidHostnames", "tlsAllowInvalidCertificates",
"tlsDisableOCSPEndpointCheck", and "tlsDisableCertificateRevocationCheck") default to the more secure option when TLS is
enabled. In order to be backwards compatible with existing driver behavior, neither TLS nor authentication is enabled by
default.</p>
<h2 id="future-work-2"><a class="header" href="#future-work-2">Future Work</a></h2>
<p>This specification is intended to represent the current state of drivers URI options rather than be a static description
of the options at the time it was written. Whenever another specification is written or modified in a way that changes
the name or the semantics of a URI option or adds a new URI option, this specification MUST be updated to reflect those
changes.</p>
<h2 id="changelog-8"><a class="header" href="#changelog-8">Changelog</a></h2>
<ul>
<li>
<p>2024-05-08: Migrated from reStructuredText to Markdown.</p>
</li>
<li>
<p>2023-08-21: Add serverMonitoringMode option.</p>
</li>
<li>
<p>2022-10-05: Remove spec front matter and reformat changelog.</p>
</li>
<li>
<p>2022-01-19: Add the timeoutMS option and deprecate some existing timeout options</p>
</li>
<li>
<p>2021-12-14: Add SOCKS5 options</p>
</li>
<li>
<p>2021-11-08: Add maxConnecting option.</p>
</li>
<li>
<p>2021-10-14: Add srvMaxHosts option. Merge headings discussing URI validation for directConnection option.</p>
</li>
<li>
<p>2021-09-15: Add srvServiceName option</p>
</li>
<li>
<p>2021-09-13: Fix link to load balancer spec</p>
</li>
<li>
<p>2021-04-15: Adding in behaviour for load balancer mode.</p>
</li>
<li>
<p>2021-04-08: Updated to refer to hello and legacy hello</p>
</li>
<li>
<p>2020-03-03: Add tlsDisableCertificateRevocationCheck option</p>
</li>
<li>
<p>2020-02-26: Add tlsDisableOCSPEndpointCheck option</p>
</li>
<li>
<p>2019-09-08: Add retryReads option</p>
</li>
<li>
<p>2019-04-26: authSource and authMechanism have no default value</p>
</li>
<li>
<p>2019-02-04: Specified errors for conflicting TLS-related URI options</p>
</li>
<li>
<p>2019-01-25: Updated to reflect new Connection Monitoring and Pooling Spec</p>
</li>
</ul>
<hr />
<div style="break-before: page; page-break-before: always;"></div><h1 id="ocsp-support"><a class="header" href="#ocsp-support">OCSP Support</a></h1>
<ul>
<li>Status: Accepted</li>
<li>Minimum Server Version: 4.4</li>
</ul>
<hr />
<h2 id="abstract-9"><a class="header" href="#abstract-9">Abstract</a></h2>
<p>This specification is about the ability for drivers to to support
<a href="https://en.wikipedia.org/wiki/Online_Certificate_Status_Protocol">OCSP</a>—Online Certificate Status Protocol
(<a href="https://tools.ietf.org/html/rfc6960">RFC 6960</a>)—and two of its related extensions:
<a href="https://en.wikipedia.org/wiki/OCSP_stapling">OCSP stapling</a> (<a href="https://tools.ietf.org/html/rfc6066">RFC 6066</a>) and
<a href="https://scotthelme.co.uk/ocsp-must-staple/">Must-Staple</a> (<a href="https://tools.ietf.org/html/rfc7633">RFC 7633</a>).</p>
<h2 id="meta-9"><a class="header" href="#meta-9">META</a></h2>
<p>The keywords "MUST", "MUST NOT", "REQUIRED", "SHALL", "SHALL NOT", "SHOULD", "SHOULD NOT", "RECOMMENDED", "MAY", and
"OPTIONAL" in this document are to be interpreted as described in <a href="https://www.ietf.org/rfc/rfc2119.txt">RFC 2119</a>.</p>
<h2 id="specification-8"><a class="header" href="#specification-8">Specification</a></h2>
<h3 id="required-server-versions"><a class="header" href="#required-server-versions">Required Server Versions</a></h3>
<p>The server supports attaching a stapled OCSP response with versions ≥ 4.4. Future backports will bring stapling support
to server versions ≥ 3.6. Drivers need not worry about the version of the server as a driver's TLS library should
automatically perform the proper certificate revocation checking behavior once OCSP is enabled.</p>
<h3 id="enabling-ocsp-support-by-default"><a class="header" href="#enabling-ocsp-support-by-default">Enabling OCSP Support by Default</a></h3>
<p>Drivers whose TLS libraries utilize application-wide settings for OCSP MUST respect the application's settings and MUST
NOT change any OCSP settings. Otherwise:</p>
<ul>
<li>If a driver's TLS library supports OCSP, OCSP MUST be enabled by default whenever possible (even if this also enables
Certificate Revocation List (CRL) checking).</li>
<li>If a driver's TLS library supports verifying stapled OCSP responses, this option MUST be enabled by default whenever
possible (even if this also enables CRL checking).</li>
</ul>
<h3 id="suggested-ocsp-behavior"><a class="header" href="#suggested-ocsp-behavior">Suggested OCSP Behavior</a></h3>
<p>Drivers SHOULD implement the OCSP behavior defined below to the extent that their TLS library allows. At any point in
the steps defined below, if a certificate in or necessary to validate the chain is found to be invalid, the driver
SHOULD end the connection.</p>
<ol>
<li>If a driver's TLS library supports Stapled OCSP, the server has a Must-Staple certificate and the server does not
present a stapled OCSP response, a driver SHOULD end the connection.</li>
<li>If a driver's TLS library supports Stapled OCSP and the server staples an OCSP response that does not cover the
certificate it presents or is invalid per <a href="https://tools.ietf.org/html/rfc6960#section-3.2">RFC 6960 Section 3.2</a>, a
driver SHOULD end the connection.</li>
<li>If a driver's TLS library supports Stapled OCSP and the server staples an OCSP response that does cover the
certificate it presents, a driver SHOULD accept the stapled OCSP response and validate all of the certificates that
are presented in the response.</li>
<li>If any unvalidated certificates in the chain remain and the client possesses an OCSP cache, the driver SHOULD
attempt to validate the status of the unvalidated certificates using the cache.</li>
<li>If any unvalidated certificates in the chain remain and the driver has a user specified CRL, the driver SHOULD
attempt to validate the status of the unvalidated certificates using the user-specified CRL.</li>
<li>If any unvalidated certificates in the chain remain and the driver has access to cached CRLs (e.g.
OS-level/application-level/user-level caches), the driver SHOULD attempt to validate the status of the unvalidated
certificates using the cached CRLs.</li>
<li>If the server's certificate remains unvalidated, that certificate has a list of OCSP responder endpoints, and
<code>tlsDisableOCSPEndpointCheck</code> or <code>tlsDisableCertificateRevocationCheck</code> is false
(<a href="ocsp-support/ocsp-support.html#mongoclient-configuration">if the driver supports these options</a>), the driver SHOULD send HTTP requests to the
responders in parallel. The first valid response that concretely marks the certificate status as good or revoked
should be used. A timeout should be applied to requests per the
<a href="ocsp-support/../client-side-operations-timeout/client-side-operations-timeout.html">Client Side Operations Timeout</a> specification,
with a default timeout of five seconds. The status for a response should only be checked if the response is valid
per <a href="https://tools.ietf.org/html/rfc6960#section-3.2">RFC 6960 Section 3.2</a></li>
<li>If any unvalidated intermediate certificates remain and those certificates have OCSP endpoints, for each
certificate, the driver SHOULD NOT reach out to the OCSP endpoint specified and attempt to validate that
certificate.*</li>
<li>If any unvalidated intermediate certificates remain and those certificates have CRL distribution points, the driver
SHOULD NOT download those CRLs and attempt to validate the status of all the other certificates using those CRLs.*</li>
<li>Finally, the driver SHOULD continue the connection, even if the status of all the unvalidated certificates has not
been confirmed yet. This means that the driver SHOULD default to "soft fail" behavior, connecting as long as there
are no explicitly invalid certificates—i.e. the driver will connect even if the status of all the unvalidated
certificates has not been confirmed yet (e.g. because an OCSP responder is down).</li>
</ol>
<p>*: See <a href="ocsp-support/ocsp-support.html#suggested-ocsp-behavior">Design Rationale: Suggested OCSP Behavior</a></p>
<h3 id="suggested-ocsp-response-validation-behavior"><a class="header" href="#suggested-ocsp-response-validation-behavior">Suggested OCSP Response Validation Behavior</a></h3>
<p>Drivers SHOULD validate OCSP Responses in the manner specified in
<a href="https://tools.ietf.org/html/rfc6960#section-3.2">RFC 6960: 3.2</a> to the extent that their TLS library allows.</p>
<h3 id="suggested-ocsp-caching-behavior"><a class="header" href="#suggested-ocsp-caching-behavior">Suggested OCSP Caching Behavior</a></h3>
<p>Drivers with sufficient control over their TLS library's OCSP behavior SHOULD implement an OCSP cache. The key for this
cache SHOULD be the certificate identifier (CertID) of the OCSP request as specified in
<a href="https://tools.ietf.org/html/rfc6960#section-4.1.1">RFC 6960: 4.1.1</a>. For convenience, the relevant section has been
duplicated below:</p>
<pre><code>CertID          ::=     SEQUENCE {
    hashAlgorithm       AlgorithmIdentifier,
    issuerNameHash      OCTET STRING, -- Hash of issuer's DN
    issuerKeyHash       OCTET STRING, -- Hash of issuer's public key
    serialNumber        CertificateSerialNumber }
</code></pre>
<p>If a driver would accept a conclusive OCSP response (stapled or non-stapled), the driver SHOULD cache that response. We
define a conclusive OCSP response as an OCSP response that indicates that a certificate is either valid or revoked.
Thus, an unknown certificate status SHOULD NOT be considered conclusive, and the corresponding OCSP response SHOULD NOT
be cached.</p>
<p>In accordance with <a href="https://tools.ietf.org/html/rfc6960#section-3.2">RFC: 6960: 3.2</a>, a cached response SHOULD be
considered valid up to and excluding the time specified in the response's <code>nextUpdate</code> field. In other words, if the
current time is <em>t</em>, then the cache entry SHOULD be considered valid if <em>thisUpdate ⩽ t &lt; nextUpdate</em>.</p>
<p>If a driver would accept a stapled OCSP response and that response has a later <code>nextUpdate</code> than the response already in
the cache, drivers SHOULD replace the older entry in the cache with the fresher response.</p>
<h3 id="mongoclient-configuration"><a class="header" href="#mongoclient-configuration">MongoClient Configuration</a></h3>
<p>This specification introduces the client-level configuration options defined below.</p>
<h4 id="tlsdisableocspendpointcheck"><a class="header" href="#tlsdisableocspendpointcheck">tlsDisableOCSPEndpointCheck</a></h4>
<p>Drivers that can, on a per MongoClient basis, disable non-stapled OCSP while keeping stapled OCSP enabled MUST implement
this option.</p>
<p>This boolean option determines whether a MongoClient should refrain from reaching out to an OCSP endpoint i.e. whether
non-stapled OCSP should be disabled. When set to true, a driver MUST NOT reach out to OCSP endpoints. When set to false,
a driver MUST reach out to OCSP endpoints if needed (as described in
<a href="ocsp-support/ocsp-support.html#suggested-ocsp-behavior">Specification: Suggested OCSP Behavior</a>).</p>
<p>For drivers that pass the <a href="ocsp-support/tests/README.html#integration-tests-permutations-to-be-tested">"Soft Fail Test"</a>, this option
MUST default to false.</p>
<p>For drivers that fail the "Soft Fail Test" because their TLS library exhibits hard-fail behavior when a responder is
unreachable, this option MUST default to true, and a driver MUST document this behavior. If this hard-failure behavior
is specific to a particular platform (e.g. the TLS library hard-fails only on Windows) then this option MUST default to
true only on the platform where the driver exhibits hard-fail behavior, and a driver MUST document this behavior.</p>
<h4 id="tlsdisablecertificaterevocationcheck"><a class="header" href="#tlsdisablecertificaterevocationcheck">tlsDisableCertificateRevocationCheck</a></h4>
<p>Drivers whose TLS libraries support an option to toggle general certificate revocation checking must implement this
option if enabling general certificate revocation checking causes hard-fail behavior when no revocation mechanisms are
available (i.e. no methods are defined or the CRL distribution points/OCSP endpoints are unreachable).</p>
<p>This boolean option determines whether a MongoClient should refrain checking certificate revocation status. When set to
true, a driver MUST NOT check certificate revocation status via CRLs or OCSP. When set to false, a driver MUST check
certificate revocation status, reach out to OCSP endpoints if needed (as described in
<a href="ocsp-support/ocsp-support.html#suggested-ocsp-behavior">Specification: Suggested OCSP Behavior</a>).</p>
<p>For drivers that pass the <a href="ocsp-support/tests/README.html#integration-tests-permutations-to-be-tested">"Soft Fail Test"</a> , this option
MUST default to false.</p>
<p>If a driver does not support <code>tlsDisableOCSPEndpointCheck</code> and that driver fails the "Soft Fail Test" because their TLS
library exhibits hard-fail behavior when a responder is unreachable, then that driver must default
<code>tlsDisableCertificateRevocationCheck</code> to true. Such a driver also MUST document this behavior. If this hard-failure
behavior is specific to a particular platform (e.g. the TLS library hard-fails only on Windows) then this option MUST
default to true only on the platform where the driver exhibits hard-fail behavior, and a driver MUST document this
behavior.</p>
<h4 id="naming-deviations-1"><a class="header" href="#naming-deviations-1">Naming Deviations</a></h4>
<p>Drivers MUST use the defined names of <code>tlsDisableOCSPEndpointCheck</code> and <code>tlsDisableCertificateRevocationCheck</code> for the
connection string parameters to ensure portability of connection strings across applications and drivers. If drivers
solicit MongoClient options through another mechanism (e.g. an options dictionary provided to the MongoClient
constructor), drivers SHOULD use the defined name but MAY deviate to comply with their existing conventions. For
example, a driver may use <code>tls_disable_ocsp_endpoint_check</code> instead of <code>tlsDisableOCSPEndpointCheck</code>.</p>
<h3 id="how-ocsp-interacts-with-existing-configuration-options"><a class="header" href="#how-ocsp-interacts-with-existing-configuration-options">How OCSP interacts with existing configuration options</a></h3>
<p>The following requirements apply only to drivers that are able to enable/disable OCSP on a per MongoClient basis.</p>
<ol>
<li>If a connection string specifies <code>tlsInsecure=true</code> then the driver MUST disable OCSP.</li>
<li>If a connection string contains both <code>tlsInsecure</code> and <code>tlsDisableOCSPEndpointCheck</code> then the driver MUST throw an
error.</li>
<li>If a driver supports <code>tlsAllowInvalidCertificates</code>, and a connection string specifies
<code>tlsAllowInvalidCertificates=true</code>, then the driver MUST disable OCSP.</li>
<li>If a driver supports <code>tlsAllowInvalidCertificates</code>, and a connection string specifies both
<code>tlsAllowInvalidCertificates</code> and <code>tlsDisableOCSPEndpointCheck</code>, then the driver MUST throw an error.</li>
</ol>
<p>The remaining requirements in this section apply only to drivers that expose an option to enable/disable certificate
revocation checking on a per MongoClient basis.</p>
<ol>
<li>Driver MUST enable OCSP support (with stapling if possible) when certificate revocation checking is enabled
<strong>unless</strong> their driver exhibits hard-fail behavior (see
<a href="ocsp-support/ocsp-support.html#tlsdisablecertificaterevocationcheck">tlsDisableCertificateRevocationCheck</a>). In such a case, a driver MUST disable
OCSP support on the platforms where its TLS library exhibits hard-fail behavior.</li>
<li>Drivers SHOULD throw an error if any of <code>tlsInsecure=true</code> or <code>tlsAllowInvalidCertificates=true</code> or
<code>tlsDisableOCSPEndpointCheck=true</code> is specified alongside the option to enable certificate revocation checking.</li>
<li>If a connection string contains both <code>tlsInsecure</code> and <code>tlsDisableCertificateRevocationCheck</code> then the driver MUST
throw an error.</li>
<li>If a driver supports <code>tlsAllowInvalidCertificates</code> and a connection string specifies both
<code>tlsAllowInvalidCertificates</code> and <code>tlsDisableCertificateRevocationCheck</code>, then the driver MUST throw an error.</li>
<li>If a driver supports <code>tlsDisableOCSPEndpointCheck</code>, and a connection string specifies
<code>tlsDisableCertificateRevocationCheck</code>, then the driver MUST throw an error.</li>
</ol>
<h3 id="tls-requirements"><a class="header" href="#tls-requirements">TLS Requirements</a></h3>
<p><a href="https://en.wikipedia.org/wiki/Server_Name_Indication">Server Name Indication</a> (SNI) MUST BE used in the TLS connection
that obtains the server's certificate, otherwise the server may present the incorrect certificate. This requirement is
especially relevant to drivers whose TLS libraries allow for finer-grained control over their TLS behavior (e.g. Python,
C).</p>
<h3 id="documentation-requirements"><a class="header" href="#documentation-requirements">Documentation Requirements</a></h3>
<p>Drivers that cannot support OCSP MUST document this lack of support. Additionally, such drivers MUST document the
following:</p>
<ul>
<li>They MUST document that they will be unable to support certificate revocation checking with Atlas when Atlas moves to
OCSP-only certificates.</li>
<li>They MUST document that users should be aware that if they use a Certificate Authority (CA) that issues OCSP-only
certificates, then the driver cannot perform certificate revocation checking.</li>
</ul>
<p>Drivers that support OCSP without stapling MUST document this lack of support for stapling. They also MUST document
their behavior when an OCSP responder is unavailable and a server has a Must-Staple certificate. If a driver is able to
connect in such a scenario due to the prevalence of
"<a href="https://www.imperialviolet.org/2014/04/19/revchecking.html">soft-fail</a>" behavior in TLS libraries (where a certificate
is accepted when an answer from an OCSP responder cannot be obtained), they additionally MUST document that this ability
to connect to a server with a Must-Staple certificate when an OCSP responder is unavailable differs from the mongo shell
or a driver that does support OCSP-stapling, both of which will fail to connect (i.e. "hard-fail") in such a scenario.</p>
<p>If a driver (e.g. <a href="https://www.mongodb.com/docs/languages/python/pymongo-driver/current/connect/tls/">Python</a>,
<a href="http://mongoc.org/libmongoc/current/mongoc_ssl_opt_t.html">C</a>) allows the user to provide their own certificate
revocation list (CRL), then that driver MUST document their TLS library's preference between the user-provided CRL and
OCSP.</p>
<p>Drivers that cannot enable OCSP by default on a per MongoClient basis (e.g. Java) MUST document this limitation.</p>
<p>Drivers that fail either of the "Malicious Server Tests" (i.e. the driver connects to a test server without TLS
constraints being relaxed) as defined in the test plan below MUST document that their chosen TLS library will connect in
the case that a server with a Must-Staple certificate does not staple a response.</p>
<p>Drivers that fail "Malicious Server Test 2" (i.e. the driver connects to the test server without TLS constraints being
relaxed) as defined in the test plan below MUST document that their chosen TLS library will connect in the case that a
server with a Must-Staple certificate does not staple a response and the OCSP responder is down.</p>
<p>Drivers that fail "Soft Fail Test" MUST document that their driver's TLS library utilizes "hard fail" behavior in the
case of an unavailable OCSP responder in contrast to the mongo shell and drivers that utilize "soft fail" behavior. They
also MUST document the change in defaults for the applicable options (see
<a href="ocsp-support/ocsp-support.html#mongoclient-configuration">MongoClient Configuration</a>).</p>
<p>If any changes related to defaults for OCSP behavior are made after a driver version that supports OCSP has been
released, the driver MUST document potential backwards compatibility issues as noted in the
<a href="ocsp-support/ocsp-support.html#backwards-compatibility">Backwards Compatibility</a> section.</p>
<h2 id="test-plan-7"><a class="header" href="#test-plan-7">Test Plan</a></h2>
<p>See <a href="ocsp-support/tests/README.html">tests/README</a> for tests.</p>
<h2 id="motivation-for-change-5"><a class="header" href="#motivation-for-change-5">Motivation for Change</a></h2>
<p>MongoDB Atlas intends to use <a href="https://letsencrypt.org/">LetsEncrypt</a>, a Certificate Authority (CA) that does not use
CRLs and only uses OCSP. (Atlas currently uses DigiCert certificates which specify both OCSP endpoints and CRL
distribution points.) Therefore, the MongoDB server is adding support for OCSP, and drivers need to support OCSP in
order for applications to continue to have the ability to verify the revocation status of an Atlas server's certificate.
Other CAs have also stopped using CRLs, so enabling OCSP support will ensure that a customer's choice in CAs is not
limited by a driver's lack of OCSP support.</p>
<p>OCSP stapling will also help applications deployed behind a firewall with an outbound allowList. It's a very natural
mistake to neglect to allowList the CRL distribution points and the OCSP endpoints, which can prevent an application
from connecting to a MongoDB instance if certificate revocation checking is enabled but the driver does not support OCSP
stapling.</p>
<p>Finally, drivers whose TLS libraries support <a href="https://en.wikipedia.org/wiki/OCSP_stapling">OCSP stapling</a> extension will
be able to minimize the number of network round trips for the client because the driver's TLS library will read an OCSP
response stapled to the server's certificate that the server provides as part of the TLS handshake. Drivers whose TLS
libraries support OCSP but not stapling will need to make an additional round trip to contact the OCSP endpoint.</p>
<h2 id="design-rationale-6"><a class="header" href="#design-rationale-6">Design Rationale</a></h2>
<p>We have chosen not to force drivers whose TLS libraries do not support OCSP/stapling "out of the box" to implement OCSP
support due to the extra work and research that this might require. Similarly, this specification uses "SHOULD" more
commonly (when other specs would prefer "MUST") to account for the fact that some drivers may not be able to fully
customize OCSP behavior in their TLS library.</p>
<p>We are requiring drivers to support both stapled OCSP and non-stapled OCSP in order to support revocation checking for
server versions in Atlas that do not support stapling, especially after Atlas switches to Let's Encrypt certificates
(which do not have CRLs). Additionally, even when servers do support stapling, in the case of a non-"Must Staple"
certificate (which is the type that Atlas is planning to use), if the server is unable to contact the OCSP responder
(e.g. due to a network error) and staple a certificate, the driver being able to query the certificate's OCSP endpoint
allows for one final chance to attempt to verify the certificate's validity.</p>
<h3 id="malicious-server-tests"><a class="header" href="#malicious-server-tests">Malicious Server Tests</a></h3>
<p>"Malicious Server Test 2" is designed to reveal the behavior of TLS libraries of drivers in one of the worst case
scenarios. Since a majority of the drivers will not have fine-grained control over their OCSP behavior, this test case
provides signal about the soft/hard fail behavior in a driver's TLS library so that we can document this.</p>
<p>A driver with control over its OCSP behavior will react the same in "Malicious Server Test 1" and "Malicious Server Test
2", terminating the connection as long as TLS constraints have not been relaxed.</p>
<h3 id="atlas-connectivity-tests"><a class="header" href="#atlas-connectivity-tests">Atlas Connectivity Tests</a></h3>
<p>No additional Atlas connectivity tests will be added because the existing tests should provide sufficient coverage
(provided that one of the non-free tier clusters is upgraded ≥ 3.6).</p>
<h3 id="suggested-ocsp-behavior-1"><a class="header" href="#suggested-ocsp-behavior-1">Suggested OCSP Behavior</a></h3>
<p>For drivers with finer-grain control over their OCSP behavior, the suggested OCSP behavior was chosen as a balance
between security and availability, erring on availability while minimizing network round trips. Therefore, in order to
minimize network round trips, drivers are advised not to reach out to OCSP endpoints and CRL distribution points in
order to verify the revocation status of intermediate certificates.</p>
<h2 id="backwards-compatibility-4"><a class="header" href="#backwards-compatibility-4">Backwards Compatibility</a></h2>
<p>An application behind a firewall with an outbound allowList that upgrades to a driver implementing this specification
may experience connectivity issues when OCSP is enabled. This is because the driver may need to contact OCSP endpoints
or CRL distribution points<sup class="footnote-reference"><a href="#1">1</a></sup> specified in the server's certificate and if these OCSP endpoints and/or CRL distribution
points are not accessible, then the connection to the server may fail. (N.B.: TLS libraries
<a href="https://blog.hboeck.de/archives/886-The-Problem-with-OCSP-Stapling-and-Must-Staple-and-why-Certificate-Revocation-is-still-broken.html">typically implement "soft fail"</a>
such that connections can continue even if the OCSP server is inaccessible, so this issue is much more likely in the
case of a server with a certificate that only contains CRL distribution points.) In such a scenario, connectivity may be
able to be restored by disabling non-stapled OCSP via <code>tlsDisableOCSPEndpointCheck</code> or by disabling certificate
revocation checking altogether via <code>tlsDisableCertificateRevocationCheck</code>.</p>
<p>An application that uses a driver that utilizes hard-fail behavior when there are no certificate revocation mechanisms
available may also experience connectivity issue. Cases in which no certificate revocation mechanisms being available
include:</p>
<ol>
<li>When a server's certificate defines neither OCSP endpoints nor CRL distribution points</li>
<li>When a certificate defines CRL distribution points and/or OCSP endpoints but these points are unavailable (e.g. the
points are down or the application is deployed behind a restrictive firewall).</li>
</ol>
<p>In such a scenario, connectivity may be able to be restored by disabling non-stapled OCSP via
<code>tlsDisableOCSPEndpointCheck</code> or by disabling certificate revocation checking via
<code>tlsDisableCertificateRevocationCheck</code>.</p>
<h2 id="reference-implementation-3"><a class="header" href="#reference-implementation-3">Reference Implementation</a></h2>
<p>The .NET/C#, Python, C, and Go drivers will provide the reference implementations. See
<a href="https://jira.mongodb.org/browse/CSHARP-2817">CSHARP-2817</a>, <a href="https://jira.mongodb.org/browse/PYTHON-2093">PYTHON-2093</a>,
<a href="https://jira.mongodb.org/browse/CDRIVER-3408">CDRIVER-3408</a> and
<a href="http://jira.mongodb.org/browse/GODRIVER-1467">GODRIVER-1467</a>.</p>
<h2 id="security-implications"><a class="header" href="#security-implications">Security Implications</a></h2>
<p>Customers should be aware that if they choose to use CA that only supports OCSP, they will not be able to check
certificate validity in drivers that cannot support OCSP.</p>
<p>In the case that the server has a Must-Staple certificate and its OCSP responder is down (for longer than the server is
able to cache and staple a previously acquired response), the mongo shell or a driver that supports OCSP stapling will
not be able to connect while a driver that supports OCSP but not stapling will be able to connect.</p>
<p>TLS libraries may implement "<a href="https://www.imperialviolet.org/2014/04/19/revchecking.html">soft-fail</a>" in the case of
non-stapled OCSP which may be undesirable in highly secure contexts.</p>
<p>Drivers that fail the "Malicious Server" tests as defined in Test Plan will connect in the case that server with a
Must-Staple certificate does not staple a response.</p>
<h3 id="testing-against-valid-certificate-chains"><a class="header" href="#testing-against-valid-certificate-chains">Testing Against Valid Certificate Chains</a></h3>
<p>Some TLS libraries are stricter about the types of certificate chains they're willing to accept (and it can be difficult
to debug why a particular certificate chain is considered invalid by a TLS library). Clients and servers with more
control over their OCSP implementation may run into fewer up front costs, but this may be at the cost of not fully
implementing every single aspect of OCSP.</p>
<p>For example, the server team's certificate generation tool generated X509 V1 certificates which were used for testing
OCSP without any issues in the server team's tests. However, while we were creating a test plan for drivers, we
discovered that Java's keytool refused to import X509 V1 certificates into its trust store and thus had to modify the
server team's certificate generation tool to generate V3 certificates.</p>
<p>Another example comes from <a href="https://github.com/dotnet/corefx/issues/41475">.NET on Linux</a>, which currently enforces the
CA/Browser forum requirement that while a leaf certificate can be covered solely by OCSP, "public CAs have to have
CRL[s] covering their issuing CAs". This requirement is not enforced with Java's default TLS libraries. See also:
<a href="ocsp-support/ocsp-support.html#cabrowser-forum-requirements-complications">Future Work: CA/Browser Forum Requirements Complications</a>.</p>
<h2 id="future-work-3"><a class="header" href="#future-work-3">Future Work</a></h2>
<p>When the server work is backported, drivers will need to update their prose tests so that tests are run against a wider
range of compatible servers.</p>
<p>Automated Atlas connectivity tests (<a href="https://jira.mongodb.org/browse/DRIVERS-382">DRIVERS-382</a>) may be updated with
additional OCSP-related URIs when 4.4 becomes available for Atlas; alternatively, the clusters behind those URIs may be
updated to 4.4 (or an earlier version where OCSP has been backported). Note: While the free tier cluster used for the
Automated Atlas connectivity tests will automatically get updated to 4.4 when it is available, Atlas currently does not
plan to enable OCSP for free and shared tier instances (i.e. Atlas Proxy).</p>
<p>Options to configure failure behavior (e.g. to maximize security or availability) may be added in the future.</p>
<h3 id="cabrowser-forum-requirements-complications"><a class="header" href="#cabrowser-forum-requirements-complications">CA/Browser Forum Requirements Complications</a></h3>
<p>The test plan may need to be reworked if we discover that a driver's TLS library strictly implements CA/Browser forum
requirements (e.g. <a href="https://github.com/dotnet/corefx/issues/41475">.NET on Linux</a>). This is because our current chain of
certificates does not fulfill the following requirement: while a leaf certificate can be covered solely by OCSP, "public
CAs have to have CRL[s] covering their issuing CAs." This rework of the test plan may happen during the initial
implementation of OCSP support or happen later if a driver's TLS library implements the relevant CA/Browser forum
requirement.</p>
<p>Extending the chain to fulfill the CA/Browser requirement should solve this issue, although drivers that don't support
manually supplying a CRL may need to host a web server that serves the required CRL during testing.</p>
<h2 id="qa-3"><a class="header" href="#qa-3">Q&amp;A</a></h2>
<h3 id="can-we-use-one-evergreen-task-combined-with-distinct-certificates-for-each-column-in-the-test-matrix-to-prevent-ocsp-caching-from-affecting-testing"><a class="header" href="#can-we-use-one-evergreen-task-combined-with-distinct-certificates-for-each-column-in-the-test-matrix-to-prevent-ocsp-caching-from-affecting-testing">Can we use one Evergreen task combined with distinct certificates for each column in the test matrix to prevent OCSP caching from affecting testing?</a></h3>
<p>No. This is because Evergreen may reuse a host with an OCSP cache from a previous execution, so using distinct
certificates per column would not obviate the need to clear all relevant OCSP caches prior to each test run. Since
Evergreen does perform some cleanup between executions, having separate tasks for each test column offers an additional
layer of safety in protecting against stale data in OCSP caches.</p>
<h3 id="should-drivers-use-a-nonce-when-creating-an-ocsp-request"><a class="header" href="#should-drivers-use-a-nonce-when-creating-an-ocsp-request">Should drivers use a nonce when creating an OCSP request?</a></h3>
<p>A driver MAY use a nonce if desired, but
<a href="https://tools.ietf.org/html/rfc6960#section-4.4.1">including a nonce in an OCSP request</a> is not required as the server
does not explicitly support nonces.</p>
<h3 id="should-drivers-utilize-a-tolerance-period-when-accepting-ocsp-responses"><a class="header" href="#should-drivers-utilize-a-tolerance-period-when-accepting-ocsp-responses">Should drivers utilize a tolerance period when accepting OCSP responses?</a></h3>
<p>No. Although
<a href="https://tools.ietf.org/html/rfc5019">RFC 5019, The Lightweight Online Certificate Status Protocol (OCSP) Profile for High-Volume Environments,</a>
allows for the configuration of a tolerance period for the acceptance of OCSP responses after <code>nextUpdate</code>, this spec is
not adhering to that RFC.</p>
<h3 id="why-was-the-decision-made-to-allow-ocsp-endpoint-checking-to-be-enableddisabled-via-a-uri-option"><a class="header" href="#why-was-the-decision-made-to-allow-ocsp-endpoint-checking-to-be-enableddisabled-via-a-uri-option">Why was the decision made to allow OCSP endpoint checking to be enabled/disabled via a URI option?</a></h3>
<p>We initially hoped that we would be able to not expose any options specifically related to OCSP to the user, in
accordance with the "No Knobs" <a href="ocsp-support/../driver-mantras.html">drivers mantra</a> However, we later decided that users may benefit
from having the ability to disable OCSP endpoint checking when applications are deployed behind restrictive firewall
with outbound allowLists, and this benefit is worth adding another URI option.</p>
<h2 id="appendix"><a class="header" href="#appendix">Appendix</a></h2>
<h3 id="os-level-ocsp-cache-manipulation"><a class="header" href="#os-level-ocsp-cache-manipulation">OS-Level OCSP Cache Manipulation</a></h3>
<h4 id="windows"><a class="header" href="#windows">Windows</a></h4>
<p>On Windows, the OCSP cache can be viewed like so:</p>
<pre><code class="language-bash">certutil -urlcache
</code></pre>
<p>To search the cache for "Lets Encrypt" OCSP cache entries, the following command could be used:</p>
<pre><code class="language-bash">certutil -urlcache | findstr letsencrypt.org
</code></pre>
<p>On Windows, the OCSP cache can be cleared like so:</p>
<pre><code class="language-bash">certutil -urlcache * delete
</code></pre>
<p>To delete only "Let's Encrypt" related entries, the following command could be used:</p>
<pre><code class="language-bash">certutil -urlcache letsencrypt.org delete
</code></pre>
<h4 id="macos"><a class="header" href="#macos">macOS</a></h4>
<p>On macOS 10.14, the OCSP cache can be viewed like so:</p>
<pre><code class="language-bash">find ~/profile/Library/Keychains -name 'ocspcache.sqlite3' \
-exec sqlite3 "{}" 'SELECT responderURI FROM responses;' \;
</code></pre>
<p>To search the cache for "Let's Encrypt" OCSP cache entries, the following command could be used:</p>
<pre><code class="language-bash">find ~/profile/Library/Keychains \
-name 'ocspcache.sqlite3' \
-exec sqlite3 "{}" \
'SELECT responderURI FROM responses WHERE responderURI LIKE "http://%.letsencrypt.org%";' \;
</code></pre>
<p>On macOS 10.14, the OCSP cache can be cleared like so:</p>
<pre><code class="language-bash">find ~/profile/Library/Keychains -name 'ocspcache.sqlite3' \
-exec sqlite3 "{}" 'DELETE FROM responses ;' \;
</code></pre>
<p>To delete only "Let's Encrypt" related entries, the following command could be used:</p>
<pre><code class="language-bash">find ~/profile/Library/Keychains -name 'ocspcache.sqlite3' \
-exec sqlite3 "{}" \
'DELETE FROM responses WHERE responderURI LIKE "http://%.letsencrypt.org%";' \;
</code></pre>
<h3 id="optional-quick-manual-validation-tests-of-ocsp-support"><a class="header" href="#optional-quick-manual-validation-tests-of-ocsp-support">Optional Quick Manual Validation Tests of OCSP Support</a></h3>
<p>These optional validation tests are not a required part of the test plan. However, these optional tests may be useful
for drivers trying to quickly determine if their TLS library supports OCSP and/or as an initial manual testing goal when
implementing OCSP support.</p>
<h4 id="optional-test-to-ensure-that-the-drivers-tls-library-supports-ocsp-stapling"><a class="header" href="#optional-test-to-ensure-that-the-drivers-tls-library-supports-ocsp-stapling">Optional test to ensure that the driver's TLS library supports OCSP stapling</a></h4>
<p>Create a test application with a connection string with TLS enabled that connects to any server that has OCSP-only
certificate and supports OCSP stapling.</p>
<p>For example, the test application could connect to C<sub>V</sub>, one of the special testing Atlas clusters with a valid
OCSP-only certificate. see Future Work for additional information).</p>
<p>Alternatively, the test application can attempt to connect to a <strong>non-mongod server</strong> that supports OCSP-stapling and
has a valid an OCSP-only certificate. The connection will fail of course, but we are only interested in the TLS
handshake and the OCSP requests that may follow. For example, the following connection string could be used:
<code>mongodb://valid-isrgrootx1.letsencrypt.org:443/?tls=true</code></p>
<p>Run the test application and verify through packet analysis that the driver's ClientHello message's TLS extension
section includes the <code>status_request</code> extension, thus indicating that the driver is advertising that it supports OCSP
stapling.</p>
<p>Note: If using <a href="https://www.wireshark.org/">WireShark</a> as your chosen packet analyzer, the <code>tls</code> (case-sensitive)
display filter may be useful in this endeavor.</p>
<h4 id="ocsp-caching-and-the-optional-test-to-ensure-that-the-drivers-tls-library-supports-non-stapled-ocsp"><a class="header" href="#ocsp-caching-and-the-optional-test-to-ensure-that-the-drivers-tls-library-supports-non-stapled-ocsp">OCSP Caching and the optional test to ensure that the driver's TLS library supports non-stapled OCSP</a></h4>
<p>The "Optional test to ensure that the driver's TLS library supports non-stapled OCSP" is complicated by the fact that
OCSP allows the client to <a href="https://tools.ietf.org/html/rfc5019#section-6.1">cache the OCSP responses</a>, so clearing an
OCSP cache may be needed in order to force the TLS library to reach out to an OCSP endpoint. This cache may exist at the
OS-level, application-level and/or at the user-level.</p>
<h4 id="optional-test-to-ensure-that-the-drivers-tls-library-supports-non-stapled-ocsp"><a class="header" href="#optional-test-to-ensure-that-the-drivers-tls-library-supports-non-stapled-ocsp">Optional test to ensure that the driver's TLS library supports non-stapled OCSP</a></h4>
<p>Create a test application with a connection string with TLS enabled that connects to any server with an OCSP-only
certificate.</p>
<p>Alternatively, the test application can attempt to connect to a <strong>non-mongod server</strong> that does not support
OCSP-stapling and has a valid an OCSP-only certificate. The connection will fail of course, but we are only interested
in the TLS handshake and the OCSP requests that may follow.</p>
<p>Alternatively, if it's known that a driver's TLS library does not support stapling or if stapling support can be toggled
off, then any <strong>non-mongod server</strong> that has a valid an OCSP-only certificate will work, including the example shown in
the "Optional test to ensure that the driver's TLS library supports OCSP stapling."</p>
<p>Clear the OS/user/application OCSP cache, if one exists and the TLS library makes use of it.</p>
<p>Run the test application and ensure that the TLS handshake succeeds. connection succeeds. Ensure that the driver's TLS
library has contacted the OCSP endpoint specified in the server's certificate. Two simple ways of checking this are:</p>
<ul>
<li>Use a packet analyzer while the test application is running to ensure that the driver's TLS library contacts the OCSP
endpoint. When using WireShark, the <code>ocsp</code> and <code>tls</code> (case-sensitive) display filters may be useful in this endeavor.</li>
<li>If the TLS library utilizes an OCSP cache and the cache was cleared prior to starting the test application, check the
OCSP cache for a response from an OCSP endpoint specified in the server's certificate.</li>
</ul>
<h2 id="changelog-9"><a class="header" href="#changelog-9">Changelog</a></h2>
<ul>
<li>
<p>2024-08-20: Migrated from reStructuredText to Markdown.</p>
</li>
<li>
<p>2022-10-05: Remove spec front matter and reformat changelog.</p>
</li>
<li>
<p>2022-01-19: Require that timeouts be applied per the client-side operations timeout spec.</p>
</li>
<li>
<p>2021-04-07: Updated terminology to use allowList.</p>
</li>
<li>
<p>2020-07-01: Default tlsDisableOCSPEndpointCheck or tlsDisableCertificateRevocationCheck to true in the case that a
driver's TLS library exhibits hard-fail behavior and add provision for platform-specific defaults.</p>
</li>
<li>
<p>2020-03-20: Clarify OCSP documentation requirements for drivers unable to enable OCSP by default on a per MongoClient
basis.</p>
</li>
<li>
<p>2020-03-03: Add tlsDisableCertificateRevocationCheck URI option. Add Go as a reference implementation. Add hard-fail
backwards compatibility documentation requirements.</p>
</li>
<li>
<p>2020-02-26: Add tlsDisableOCSPEndpointCheck URI option.</p>
</li>
<li>
<p>2020-02-19: Clarify behavior for reaching out to OCSP responders.</p>
</li>
<li>
<p>2020-02-10: Add cache requirement.</p>
</li>
<li>
<p>2020-01-31: Add SNI requirement and clarify design rationale regarding minimizing round trips.</p>
</li>
<li>
<p>2020-01-28: Clarify behavior regarding nonces and tolerance periods.</p>
</li>
<li>
<p>2020-01-16: Initial commit.</p>
</li>
</ul>
<h2 id="endnotes"><a class="header" href="#endnotes">Endnotes</a></h2>
<div class="footnote-definition" id="1"><sup class="footnote-definition-label">1</sup>
<p>Since this specification mandates that a driver must enable OCSP when possible, this may involve enabling
certificate revocation checking in general, and thus the accessibility of CRL distribution points can become a
factor.</p>
</div>
<div style="break-before: page; page-break-before: always;"></div><h1 id="mongodb-handshake"><a class="header" href="#mongodb-handshake">MongoDB Handshake</a></h1>
<ul>
<li>Status: Accepted</li>
<li>Minimum Server Version: 3.4</li>
</ul>
<hr />
<h2 id="abstract-10"><a class="header" href="#abstract-10">Abstract</a></h2>
<p>MongoDB 3.4 has the ability to annotate connections with metadata provided by the connecting client. The intent of this
metadata is to be able to identify client level information about the connection, such as application name, driver name
and version. The provided information will be logged through the <code>mongo[d|s].log</code> and the profile logs; this should
enable sysadmins to easily backtrack log entries the offending application. The active connection data will also be
queryable through aggregation pipeline, to enable collecting and analyzing driver trends.</p>
<p>After connecting to a MongoDB node a hello command (if Stable API is requested) or a legacy hello command is issued,
followed by authentication, if appropriate. This specification augments this handshake and defines certain arguments
that clients provide as part of the handshake.</p>
<p>This spec furthermore adds a new connection string argument for applications to declare its application name to the
server.</p>
<h2 id="meta-10"><a class="header" href="#meta-10">META</a></h2>
<p>The keywords "MUST", "MUST NOT", "REQUIRED", "SHALL", "SHALL NOT", "SHOULD", "SHOULD NOT", "RECOMMENDED", "MAY", and
"OPTIONAL" in this document are to be interpreted as described in <a href="https://www.ietf.org/rfc/rfc2119.txt">RFC 2119</a>.</p>
<h2 id="terms-3"><a class="header" href="#terms-3">Terms</a></h2>
<p><strong>hello command</strong></p>
<p>The command named <code>hello</code>. It is the preferred and modern command for handshakes and topology monitoring.</p>
<p><strong>legacy hello command</strong></p>
<p>The command named <code>isMaster</code>. It is the deprecated equivalent of the <code>hello</code> command. It was deprecated in MongoDB 5.0.</p>
<p><strong>isMaster / ismaster</strong></p>
<p>The correct casing is <code>isMaster</code>, but servers will accept the alternate casing <code>ismaster</code>. Other case variations result
in <code>CommandNotFound</code>. Drivers MUST take this case variation into account when determining which commands to encrypt,
redact, or otherwise treat specially.</p>
<h2 id="specification-9"><a class="header" href="#specification-9">Specification</a></h2>
<h3 id="connection-handshake"><a class="header" href="#connection-handshake">Connection handshake</a></h3>
<p>MongoDB uses the <code>hello</code> or <code>isMaster</code> commands for handshakes and topology monitoring. <code>hello</code> is the modern and
preferred command. <code>hello</code> must always be sent using the <code>OP_MSG</code> protocol. <code>isMaster</code> is referred to as "legacy hello"
and is maintained for backwards compatibility with servers that do not support the <code>hello</code> command.</p>
<p>If a <a href="mongodb-handshake/../versioned-api/versioned-api.html">server API version</a> is requested or <code>loadBalanced: True</code>, drivers MUST use the
<code>hello</code> command for the initial handshake and use the <code>OP_MSG</code> protocol. If server API version is not requested and
<code>loadBalanced: False</code>, drivers MUST use legacy hello for the first message of the initial handshake with the <code>OP_QUERY</code>
protocol (before switching to <code>OP_MSG</code> if the <code>maxWireVersion</code> indicates compatibility), and include <code>helloOk:true</code> in
the handshake request.</p>
<p>ASIDE: If the legacy handshake response includes <code>helloOk: true</code>, then subsequent topology monitoring commands MUST use
the <code>hello</code> command. If the legacy handshake response does not include <code>helloOk: true</code>, then subsequent topology
monitoring commands MUST use the legacy hello command. See the
<a href="mongodb-handshake/../server-discovery-and-monitoring/server-discovery-and-monitoring-summary.html">Server Discovery and Monitoring spec</a>
for further information.</p>
<p>The initial handshake MUST be performed on every socket to any and all servers upon establishing the connection to
MongoDB, including reconnects of dropped connections and newly discovered members of a cluster. It MUST be the first
command sent over the respective socket. If the command fails the client MUST disconnect. Timeouts MUST be applied to
this command per the
<a href="mongodb-handshake/../client-side-operations-timeout/client-side-operations-timeout.html">Client Side Operations Timeout</a> specification.</p>
<p><code>hello</code> and legacy hello commands issued after the initial connection handshake MUST NOT contain handshake arguments.
Any subsequent <code>hello</code> or legacy hello calls, such as the ones for topology monitoring purposes, MUST NOT include this
argument.</p>
<h4 id="example-implementation"><a class="header" href="#example-implementation">Example Implementation</a></h4>
<p>Consider the following pseudo-code for establishing a new connection:</p>
<pre><code class="language-python">conn = Connection()
conn.connect()  # Connect via TCP / TLS
if stable_api_configured or client_options.load_balanced:
    cmd = {"hello": 1}
    conn.supports_op_msg = True  # Send the initial command via OP_MSG.
else:
    cmd = {"legacy hello": 1, "helloOk": 1}
    conn.supports_op_msg = False  # Send the initial command via OP_QUERY.
cmd["client"] = client_metadata
if client_options.compressors:
    cmd["compression"] = client_options.compressors
if client_options.load_balanced:
    cmd["loadBalanced"] = True
creds = client_options.credentials
if creds:
    # Negotiate auth mechanism and perform speculative auth. See Auth spec for details.
    if not creds.has_mechanism_configured():
        cmd["saslSupportedMechs"] = ...
    cmd["speculativeAuthenticate"] = ...

reply = conn.send_command("admin", cmd)

if reply["maxWireVersion"] &gt;= 6:
    # Use OP_MSG for all future commands, including authentication.
    conn.supports_op_msg = True

# Store the negotiated compressor, see OP_COMPRESSED spec.
if reply.get("compression"):
    conn.compressor = reply["compression"][0]

# Perform connection authentication. See Auth spec for details.
negotiated_mechs = reply.get("saslSupportedMechs")
speculative_auth = reply.get("speculativeAuthenticate")
conn.authenticate(creds, negotiated_mechs, speculative_auth)
</code></pre>
<h4 id="hello-command"><a class="header" href="#hello-command">Hello Command</a></h4>
<p>The initial handshake, as of MongoDB 3.4, supports a new argument, <code>client</code>, provided as a BSON object. This object has
the following structure:</p>
<pre><code class="language-javascript">    {
        hello: 1,
        helloOk: true,
        client: {
            /* OPTIONAL. If present, the "name" is REQUIRED */
            application: {
                name: "&lt;string&gt;"
            },
            /* REQUIRED, including all sub fields */
            driver: {
                name: "&lt;string&gt;",
                version: "&lt;string&gt;"
            },
            /* REQUIRED */
            os: {
                type: "&lt;string&gt;",         /* REQUIRED */
                name: "&lt;string&gt;",         /* OPTIONAL */
                architecture: "&lt;string&gt;", /* OPTIONAL */
                version: "&lt;string&gt;"       /* OPTIONAL */
            },
            /* OPTIONAL */
            platform: "&lt;string&gt;",
            /* OPTIONAL */
            env: {
                name: "&lt;string&gt;",         /* OPTIONAL */
                timeout_sec: 42,          /* OPTIONAL */
                memory_mb: 1024,          /* OPTIONAL */
                region: "&lt;string&gt;",       /* OPTIONAL */
                /* OPTIONAL */
                container: {
                    runtime: "&lt;string&gt;",  /* OPTIONAL */
                    orchestrator: "&lt;string&gt;"  /* OPTIONAL */
                }
            }
        }
    }
</code></pre>
<p><span id="client-application-name"></span></p>
<h4 id="clientapplicationname"><a class="header" href="#clientapplicationname">client.application.name</a></h4>
<p>This value is application configurable.</p>
<p>The application name is printed to the mongod logs upon establishing the connection. It is also recorded in the slow
query logs and profile collections.</p>
<p>The recommended way for applications to provide this value is through the connection URI. The connection string key is
<code>appname</code>.</p>
<p>Example connection string:</p>
<pre><code>    mongodb://server:27017/db?appname=mongodump
</code></pre>
<p>This option MAY also be provided on the MongoClient itself, if normal for the driver. It is only valid to set this
attribute before any connection has been made to a server. Any attempt to set <code>client.application.name</code> MUST result in
an failure when doing so will either change the existing value, or have any connection to MongoDB reporting inconsistent
values.</p>
<p>Drivers MUST NOT provide a default value for this key.</p>
<h4 id="clientdrivername"><a class="header" href="#clientdrivername">client.driver.name</a></h4>
<p>This value is required and is not application configurable.</p>
<p>The internal driver name. For drivers written on-top of other core drivers, the underlying driver will typically expose
a function to append additional name to this field.</p>
<p>Example:</p>
<pre><code>- "pymongo"
- "mongoc / phongo"
</code></pre>
<h4 id="clientdriverversion"><a class="header" href="#clientdriverversion">client.driver.version</a></h4>
<p>This value is required and is not application configurable.</p>
<p>The internal driver version. The version formatting is not defined. For drivers written on-top of other core drivers,
the underlying driver will typically expose a function to append additional name to this field.</p>
<p>Example:</p>
<pre><code>- "1.1.2-beta0"
- "1.4.1 / 1.2.0"
</code></pre>
<h4 id="clientostype"><a class="header" href="#clientostype">client.os.type</a></h4>
<p>This value is required and is not application configurable.</p>
<p>The Operating System primary identification type the client is running on. Equivalent to <code>uname -s</code> on POSIX systems.
This field is REQUIRED and clients must default to <code>unknown</code> when an appropriate value cannot be determined.</p>
<p>Example:</p>
<pre><code>- "Linux"
- "Darwin"
- "Windows"
- "BSD"
- "Unix"
</code></pre>
<h4 id="clientosname"><a class="header" href="#clientosname">client.os.name</a></h4>
<p>This value is optional, but RECOMMENDED, it is not application configurable.</p>
<p>Detailed name of the Operating System's, such as fully qualified distribution name. On systemd systems, this is
typically <code>PRETTY_NAME</code> of <code>os-release(5)</code> (<code>/etc/os-release</code>) or the <code>DISTRIB_DESCRIPTION</code> (<code>/etc/lsb-release</code>,
<code>lsb_release(1) --description</code>) on LSB systems. The exact value and method to determine this value is undefined.</p>
<p>Example:</p>
<pre><code>- "Ubuntu 16.04 LTS"
- "macOS"
- "CygWin"
- "FreeBSD"
- "AIX"
</code></pre>
<h4 id="clientosarchitecture"><a class="header" href="#clientosarchitecture">client.os.architecture</a></h4>
<p>This value is optional, but RECOMMENDED, it is not application configurable. The machine hardware name. Equivalent to
<code>uname -m</code> on POSIX systems.</p>
<p>Example:</p>
<pre><code>- "x86_64"
- "ppc64le"
</code></pre>
<h4 id="clientosversion"><a class="header" href="#clientosversion">client.os.version</a></h4>
<p>This value is optional and is not application configurable.</p>
<p>The Operating System version.</p>
<p>Example:</p>
<pre><code>- "10"
- "8.1"
- "16.04.1"
</code></pre>
<h4 id="clientplatform"><a class="header" href="#clientplatform">client.platform</a></h4>
<p>This value is optional and is not application configurable.</p>
<p>Driver specific platform details.</p>
<p>Example:</p>
<pre><code>- clang 3.8.0 CFLAGS="-mcpu=power8 -mtune=power8 -mcmodel=medium"
- "Oracle JVM EE 9.1.1"
</code></pre>
<p><span id="client-env"></span></p>
<h4 id="clientenv"><a class="header" href="#clientenv">client.env</a></h4>
<p>This value is optional and is not application configurable.</p>
<p>Information about the execution environment, including Function-as-a-Service (FaaS) identification and container
runtime.</p>
<p>The contents of <code>client.env</code> MUST be adjusted to keep the handshake below the size limit; see
<a href="mongodb-handshake/handshake.html#limitations">Limitations</a> for specifics.</p>
<p>If no fields of <code>client.env</code> would be populated, <code>client.env</code> MUST be entirely omitted.</p>
<h5 id="faas"><a class="header" href="#faas">FaaS</a></h5>
<p>FaaS details are captured in the <code>name</code>, <code>timeout_sec</code>, <code>memory_mb</code>, and <code>region</code> fields of <code>client.env</code>. The <code>name</code>
field is determined by which of the following environment variables are populated:</p>
<div class="table-wrapper"><table><thead><tr><th>Name</th><th>Environment Variable</th></tr></thead><tbody>
<tr><td><code>aws.lambda</code></td><td><code>AWS_EXECUTION_ENV</code><sup class="footnote-reference"><a href="#1">1</a></sup> or <code>AWS_LAMBDA_RUNTIME_API</code></td></tr>
<tr><td><code>azure.func</code></td><td><code>FUNCTIONS_WORKER_RUNTIME</code></td></tr>
<tr><td><code>gcp.func</code></td><td><code>K_SERVICE</code> or <code>FUNCTION_NAME</code></td></tr>
<tr><td><code>vercel</code></td><td><code>VERCEL</code></td></tr>
</tbody></table>
</div>
<p>If none of those variables are populated the other FaaS values MUST be entirely omitted. When variables for multiple
<code>client.env.name</code> values are present, <code>vercel</code> takes precedence over <code>aws.lambda</code>; any other combination MUST cause the
other FaaS values to be entirely omitted.</p>
<p>Depending on which <code>client.env.name</code> has been selected, other FaaS fields in <code>client.env</code> SHOULD be populated:</p>
<div class="table-wrapper"><table><thead><tr><th>Name</th><th>Field</th><th>Environment Variable</th><th>Expected Type</th></tr></thead><tbody>
<tr><td><code>aws.lambda</code></td><td><code>client.env.region</code></td><td><code>AWS_REGION</code></td><td>string</td></tr>
<tr><td></td><td><code>client.env.memory_mb</code></td><td><code>AWS_LAMBDA_FUNCTION_MEMORY_SIZE</code></td><td>int32</td></tr>
<tr><td><code>gcp.func</code></td><td><code>client.env.memory_mb</code></td><td><code>FUNCTION_MEMORY_MB</code></td><td>int32</td></tr>
<tr><td></td><td><code>client.env.timeout_sec</code></td><td><code>FUNCTION_TIMEOUT_SEC</code></td><td>int32</td></tr>
<tr><td></td><td><code>client.env.region</code></td><td><code>FUNCTION_REGION</code></td><td>string</td></tr>
<tr><td><code>vercel</code></td><td><code>client.env.region</code></td><td><code>VERCEL_REGION</code></td><td>string</td></tr>
</tbody></table>
</div>
<p>Missing variables or variables with values not matching the expected type MUST cause the corresponding <code>client.env</code>
field to be omitted and MUST NOT cause a user-visible error.</p>
<h5 id="container"><a class="header" href="#container">Container</a></h5>
<p>Container runtime information is captured in <code>client.env.container</code>.</p>
<p><code>client.env.container.runtime</code> MUST be set to <code>"docker"</code> if the file <code>.dockerenv</code> exists in the root directory.</p>
<p><code>client.env.container.orchestrator</code> MUST be set to <code>"kubernetes"</code> if the environment variable <code>KUBERNETES_SERVICE_HOST</code>
is populated.</p>
<p>If no fields of <code>client.env.container</code> would be populated, <code>client.env.container</code> MUST be entirely omitted.</p>
<h3 id="speculative-authentication"><a class="header" href="#speculative-authentication">Speculative Authentication</a></h3>
<ul>
<li>Since: 4.4</li>
</ul>
<p>The initial handshake supports a new argument, <code>speculativeAuthenticate</code>, provided as a BSON document. Clients
specifying this argument to <code>hello</code> or legacy hello will speculatively include the first command of an authentication
handshake. This command may be provided to the server in parallel with any standard request for supported authentication
mechanisms (i.e. <code>saslSupportedMechs</code>). This would permit clients to merge the contents of their first authentication
command with their initial handshake request, and receive the first authentication reply along with the initial
handshake reply.</p>
<p>When the mechanism is <code>MONGODB-X509</code>, <code>speculativeAuthenticate</code> has the same structure as seen in the MONGODB-X509
conversation section in the <a href="mongodb-handshake/../auth/auth.html#supported-authentication-methods">Driver Authentication spec</a>.</p>
<p>When the mechanism is <code>SCRAM-SHA-1</code> or <code>SCRAM-SHA-256</code>, <code>speculativeAuthenticate</code> has the same fields as seen in the
conversation subsection of the SCRAM-SHA-1 and SCRAM-SHA-256 sections in the
<a href="mongodb-handshake/../auth/auth.html#supported-authentication-methods">Driver Authentication spec</a> with an additional <code>db</code> field to specify
the name of the authentication database.</p>
<p>When the mechanism is <code>MONGODB-OIDC</code>, <code>speculativeAuthenticate</code> has the same structure as seen in the MONGODB-OIDC
conversation section in the <a href="mongodb-handshake/../auth/auth.html#supported-authentication-methods">Driver Authentication spec</a>.</p>
<p>If the initial handshake command with a <code>speculativeAuthenticate</code> argument succeeds, the client should proceed with the
next step of the exchange. If the initial handshake response does not include a <code>speculativeAuthenticate</code> reply and the
<code>ok</code> field in the initial handshake response is set to 1, drivers MUST authenticate using the standard authentication
handshake.</p>
<p>The <code>speculativeAuthenticate</code> reply has the same fields, except for the <code>ok</code> field, as seen in the conversation sections
for MONGODB-X509, SCRAM-SHA-1 and SCRAM-SHA-256 in the
<a href="mongodb-handshake/../auth/auth.html#supported-authentication-methods">Driver Authentication spec</a>.</p>
<p>Drivers MUST NOT validate the contents of the <code>saslSupportedMechs</code> attribute of the initial handshake reply. Drivers
MUST NOT raise an error if the <code>saslSupportedMechs</code> attribute of the reply includes an unknown mechanism.</p>
<p>If an authentication mechanism is not provided either via connection string or code, but a credential is provided,
drivers MUST use the SCRAM-SHA-256 mechanism for speculative authentication and drivers MUST send <code>saslSupportedMechs</code>.</p>
<p>Older servers will ignore the <code>speculativeAuthenticate</code> argument. New servers will participate in the standard
authentication conversation if this argument is missing.</p>
<h2 id="supporting-wrapping-libraries"><a class="header" href="#supporting-wrapping-libraries">Supporting Wrapping Libraries</a></h2>
<p>Drivers MUST allow libraries which wrap the driver to append to the client metadata generated by the driver. The
following class definition defines the options which MUST be supported:</p>
<pre><code class="language-typescript">class DriverInfoOptions {
    /**
    * The name of the library wrapping the driver.
    */
    name: String;

    /**
    * The version of the library wrapping the driver.
    */
    version: Optional&lt;String&gt;;

    /**
    * Optional platform information for the wrapping driver.
    */
    platform: Optional&lt;String&gt;;
}
</code></pre>
<p>Note that how these options are provided to a driver is left up to the implementer.</p>
<p>If provided, these options MUST NOT replace the values used for metadata generation. The provided options MUST be
appended to their respective fields, and be delimited by a <code>|</code> character. For example, when
<a href="https://www.mongodb.com/docs/drivers/motor/">Motor</a> wraps PyMongo, the following fields are updated to include Motor's
"driver info":</p>
<pre><code class="language-typescript">{
    client: {
        driver: {
            name: "PyMongo|Motor",
            version: "3.6.0|2.0.0"
        }
    }
}
</code></pre>
<p><strong>NOTE:</strong> All strings provided as part of the driver info MUST NOT contain the delimiter used for metadata concatention.
Drivers MUST throw an error if any of these strings contains that character.</p>
<h3 id="deviations-1"><a class="header" href="#deviations-1">Deviations</a></h3>
<p>Some drivers have already implemented such functionality, and should not be required to make breaking changes to comply
with the requirements set forth here. A non-exhaustive list of acceptable deviations are as follows:</p>
<ul>
<li>The name of <code>DriverInfoOptions</code> is non-normative, implementers may feel free to name this whatever they like.</li>
<li>The choice of delimiter is not fixed, <code>|</code> is the recommended value, but some drivers currently use <code>/</code>.</li>
<li>For cases where we own a particular stack of drivers (more than two), it may be preferable to accept a <em>list</em> of
strings for each field.</li>
</ul>
<h2 id="limitations"><a class="header" href="#limitations">Limitations</a></h2>
<p>The entire <code>client</code> metadata BSON document MUST NOT exceed 512 bytes. This includes all BSON overhead. The
<code>client.application.name</code> cannot exceed 128 bytes. MongoDB will return an error if these limits are not adhered to,
which will result in handshake failure. Drivers MUST validate these values and truncate or omit driver provided values
if necessary. Implementers SHOULD cumulatively update fields in the following order until the document is under the size
limit:</p>
<ol>
<li>Omit fields from <code>env</code> except <code>env.name</code>.</li>
<li>Omit fields from <code>os</code> except <code>os.type</code>.</li>
<li>Omit the <code>env</code> document entirely.</li>
<li>Truncate <code>platform</code>.</li>
</ol>
<p>Additionally, implementers are encouraged to place high priority information about the platform earlier in the string,
in order to avoid possible truncating of those details.</p>
<h2 id="test-plan-8"><a class="header" href="#test-plan-8">Test Plan</a></h2>
<p>Drivers that capture values for <code>client.env</code> should test that a connection and hello command succeeds in the presence of
the following sets of environment variables:</p>
<ol>
<li>Valid AWS</li>
</ol>
<div class="table-wrapper"><table><thead><tr><th>Environment Variable</th><th>Value</th></tr></thead><tbody>
<tr><td><code>AWS_EXECUTION_ENV</code></td><td><code>AWS_Lambda_java8</code></td></tr>
<tr><td><code>AWS_REGION</code></td><td><code>us-east-2</code></td></tr>
<tr><td><code>AWS_LAMBDA_FUNCTION_MEMORY_SIZE</code></td><td><code>1024</code></td></tr>
</tbody></table>
</div>
<ol start="2">
<li>Valid Azure</li>
</ol>
<div class="table-wrapper"><table><thead><tr><th>Environment Variable</th><th>Value</th></tr></thead><tbody>
<tr><td><code>FUNCTIONS_WORKER_RUNTIME</code></td><td><code>node</code></td></tr>
</tbody></table>
</div>
<ol start="3">
<li>Valid GCP</li>
</ol>
<div class="table-wrapper"><table><thead><tr><th>Environment Variable</th><th>Value</th></tr></thead><tbody>
<tr><td><code>K_SERVICE</code></td><td><code>servicename</code></td></tr>
<tr><td><code>FUNCTION_MEMORY_MB</code></td><td><code>1024</code></td></tr>
<tr><td><code>FUNCTION_TIMEOUT_SEC</code></td><td><code>60</code></td></tr>
<tr><td><code>FUNCTION_REGION</code></td><td><code>us-central1</code></td></tr>
</tbody></table>
</div>
<ol start="4">
<li>Valid Vercel</li>
</ol>
<div class="table-wrapper"><table><thead><tr><th>Environment Variable</th><th>Value</th></tr></thead><tbody>
<tr><td><code>VERCEL</code></td><td><code>1</code></td></tr>
<tr><td><code>VERCEL_REGION</code></td><td><code>cdg1</code></td></tr>
</tbody></table>
</div>
<ol start="5">
<li>Invalid - multiple providers</li>
</ol>
<div class="table-wrapper"><table><thead><tr><th>Environment Variable</th><th>Value</th></tr></thead><tbody>
<tr><td><code>AWS_EXECUTION_ENV</code></td><td><code>AWS_Lambda_java8</code></td></tr>
<tr><td><code>FUNCTIONS_WORKER_RUNTIME</code></td><td><code>node</code></td></tr>
</tbody></table>
</div>
<ol start="6">
<li>Invalid - long string</li>
</ol>
<div class="table-wrapper"><table><thead><tr><th>Environment Variable</th><th>Value</th></tr></thead><tbody>
<tr><td><code>AWS_EXECUTION_ENV</code></td><td><code>AWS_Lambda_java8</code></td></tr>
<tr><td><code>AWS_REGION</code></td><td><code>a</code> repeated 512 times</td></tr>
</tbody></table>
</div>
<ol start="7">
<li>Invalid - wrong types</li>
</ol>
<div class="table-wrapper"><table><thead><tr><th>Environment Variable</th><th>Value</th></tr></thead><tbody>
<tr><td><code>AWS_EXECUTION_ENV</code></td><td><code>AWS_Lambda_java8</code></td></tr>
<tr><td><code>AWS_LAMBDA_FUNCTION_MEMORY_SIZE</code></td><td><code>big</code></td></tr>
</tbody></table>
</div>
<ol start="8">
<li>Invalid - <code>AWS_EXECUTION_ENV</code> does not start with <code>"AWS_Lambda_"</code></li>
</ol>
<div class="table-wrapper"><table><thead><tr><th>Environment Variable</th><th>Value</th></tr></thead><tbody>
<tr><td><code>AWS_EXECUTION_ENV</code></td><td><code>EC2</code></td></tr>
</tbody></table>
</div>
<h2 id="motivation-for-change-6"><a class="header" href="#motivation-for-change-6">Motivation For Change</a></h2>
<p>Being able to annotate individual connections with custom data will allow users and sysadmins to easily correlate events
happening on their MongoDB deployment to a specific application. For support engineers, it furthermore helps identify
potential problems in drivers or client platforms, and paves the way for providing proactive support via Cloud Manager
and/or Atlas to advise customers about out of date driver versions.</p>
<h2 id="design-rationale-7"><a class="header" href="#design-rationale-7">Design Rationale</a></h2>
<p>Drivers run on a multitude of platforms, languages, environments and systems. There is no defined list of data points
that may or may not be valuable to every system. Rather than specifying such a list it was decided we would report the
basics; something that everyone can discover and consider valuable. The obvious requirement here being the driver itself
and its version. Any additional information is generally very system specific. Scala may care to know the Java runtime,
while Python would like to know if it was built with C extensions - and C would like to know the compiler.</p>
<p>Having to define dozens of arguments that may or may not be useful to one or two drivers isn't a good idea. Instead, we
define a <code>platform</code> argument that is driver dependent. This value will not have defined value across drivers and is
therefore not generically queryable -- however, it will gain defined schema for that particular driver, and will
therefore over time gain defined structure that can be formatted and value extracted from.</p>
<h2 id="backwards-compatibility-5"><a class="header" href="#backwards-compatibility-5">Backwards Compatibility</a></h2>
<p>The legacy hello command currently ignores arguments. (i.e. If arguments are provided the legacy hello command discards
them without erroring out). Adding client metadata functionality has therefore no backwards compatibility concerns.</p>
<p>This also allows a driver to determine if the <code>hello</code> command is supported. On server versions that support the <code>hello</code>
command, the legacy hello command with <code>helloOk: true</code> will respond with <code>helloOk: true</code>. On server versions that do not
support the <code>hello</code> command, the <code>helloOk: true</code> argument is ignored and the legacy hello response will not contain
<code>helloOk: true</code>.</p>
<h2 id="reference-implementation-4"><a class="header" href="#reference-implementation-4">Reference Implementation</a></h2>
<p><a href="https://github.com/mongodb/mongo-c-driver/blob/master/src/libmongoc/src/mongoc/mongoc-handshake.c">C Driver</a>.</p>
<h2 id="qa-4"><a class="header" href="#qa-4">Q&amp;A</a></h2>
<ul>
<li>
<p>The 128 bytes application.name limit, does that include BSON overhead</p>
<ul>
<li>No, just the string itself</li>
</ul>
</li>
<li>
<p>The 512 bytes limit, does that include BSON overhead?</p>
<ul>
<li>Yes</li>
</ul>
</li>
<li>
<p>The 512 bytes limit, does it apply to the full initial handshake document or just the <code>client</code> subdocument</p>
<ul>
<li>Just the subdocument</li>
</ul>
</li>
<li>
<p>Should I really try to fill the 512 bytes with data?</p>
<ul>
<li>Not really. The server does not attempt to normalize or compress this data in anyway, so it will hold it in memory
as-is per connection. 512 bytes for 20,000 connections is ~ 10mb of memory the server will need.</li>
</ul>
</li>
<li>
<p>What happens if I pass new arguments in the legacy hello command to previous MongoDB versions?</p>
<ul>
<li>Nothing. Arguments passed to the legacy hello command to prior versions of MongoDB are not treated in any special
way and have no effect one way or another.</li>
</ul>
</li>
<li>
<p>Are there wire version bumps or anything accompanying this specification?</p>
<ul>
<li>No</li>
</ul>
</li>
<li>
<p>Is establishing the handshake required for connecting to MongoDB 3.4?</p>
<ul>
<li>No, it only augments the connection. MongoDB will not reject connections without it</li>
</ul>
</li>
<li>
<p>Does this affect SDAM implementations?</p>
<ul>
<li>Possibly. There are a couple of gotchas. If the application.name is not in the URI...
<ul>
<li>The SDAM monitoring cannot be launched until the user has had the ability to set the application name because the
application name has to be sent in the initial handshake. This means that the connection pool cannot be
established until the first user initiated command, or else some connections will have the application name while
other won't</li>
<li>The initial handshake must be called on all sockets, including administrative background sockets to MongoDB</li>
</ul>
</li>
</ul>
</li>
<li>
<p>My language doesn't have <code>uname</code>, but does instead provide its own variation of these values, is that OK?</p>
<ul>
<li>Absolutely. As long as the value is identifiable it is fine. The exact method and values are undefined by this
specification</li>
</ul>
</li>
</ul>
<h2 id="changelog-10"><a class="header" href="#changelog-10">Changelog</a></h2>
<ul>
<li>2024-08-16: Migrated from reStructuredText to Markdown.</li>
<li>2019-11-13: Added section about supporting wrapping libraries</li>
<li>2020-02-12: Added section about speculative authentication</li>
<li>2021-04-27: Updated to define <code>hello</code> and legacy hello</li>
<li>2022-01-13: Updated to disallow <code>hello</code> using <code>OP_QUERY</code></li>
<li>2022-01-19: Require that timeouts be applied per the client-side operations timeout spec.</li>
<li>2022-02-24: Rename Versioned API to Stable API</li>
<li>2022-10-05: Remove spec front matter and reformat changelog.</li>
<li>2023-03-13: Add <code>env</code> to <code>client</code> document</li>
<li>2023-04-03: Simplify truncation for metadata</li>
<li>2023-05-04: <code>AWS_EXECUTION_ENV</code> must start with <code>"AWS_Lambda_"</code></li>
<li>2023-08-24: Added container awareness</li>
<li>2024-04-22: Clarify that driver should not validate <code>saslSupportedMechs</code> content.</li>
</ul>
<div class="footnote-definition" id="1"><sup class="footnote-definition-label">1</sup>
<p><code>AWS_EXECUTION_ENV</code> must start with the string <code>"AWS_Lambda_"</code>.</p>
</div>
<div style="break-before: page; page-break-before: always;"></div><h1 id="wire-compression-in-drivers"><a class="header" href="#wire-compression-in-drivers">Wire Compression in Drivers</a></h1>
<ul>
<li>
<p>Status: Accepted</p>
</li>
<li>
<p>Minimum Server Version: 3.4</p>
</li>
</ul>
<h2 id="abstract-11"><a class="header" href="#abstract-11">Abstract</a></h2>
<p>This specification describes how to implement Wire Protocol Compression between MongoDB drivers and mongo[d|s].</p>
<p>Compression is achieved through a new bi-directional wire protocol opcode, referred to as OP_COMPRESSED.</p>
<p>Server side compressor support is checked during the initial MongoDB Handshake, and is compatible with all historical
versions of MongoDB. If a client detects a compatible compressor it will use the compressor for all valid requests.</p>
<h2 id="meta-11"><a class="header" href="#meta-11">META</a></h2>
<p>The keywords "MUST", "MUST NOT", "REQUIRED", "SHALL", "SHALL NOT", "SHOULD", "SHOULD NOT", "RECOMMENDED", "MAY", and
"OPTIONAL" in this document are to be interpreted as described in <a href="https://www.ietf.org/rfc/rfc2119.txt">RFC 2119</a>.</p>
<h2 id="terms-4"><a class="header" href="#terms-4">Terms</a></h2>
<p><em>Compressor</em> - A compression algorithm. There are currently three supported algorithms: snappy, zlib, and zstd.</p>
<h2 id="specification-10"><a class="header" href="#specification-10">Specification</a></h2>
<h3 id="mongodb-handshake-amendment"><a class="header" href="#mongodb-handshake-amendment">MongoDB Handshake Amendment</a></h3>
<p>The <a href="compression/../mongodb-handshake/handshake.html">MongoDB Handshake Protocol</a> describes an argument passed to the handshake
command, <code>client</code>. This specification adds an additional argument, <code>compression</code>, that SHOULD be provided to the
handshake command if a driver supports wire compression.</p>
<p>The value of this argument is an array of supported compressors.</p>
<p>Example:</p>
<pre><code class="language-javascript">    {
        hello: 1,
        client: {}, /* See MongoDB Handshake */
        compression: ["snappy", "zlib", "zstd"]
    }
</code></pre>
<p>When no compression is enabled on the client, drivers SHOULD send an empty compression argument.</p>
<p>Example:</p>
<pre><code class="language-javascript">    {
        hello: 1,
        client: {}, /* See MongoDB Handshake */
        compression: []
    }
</code></pre>
<p>Clients that want to compress their messages need to send a list of the algorithms - in the order they are specified in
the client configuration - that they are willing to support to the server during the initial handshake call. For
example, a client wishing to compress with the snappy algorithm, should send:</p>
<pre><code class="language-javascript">    { hello: 1, ... , compression: [ "snappy" ] }
</code></pre>
<p>The server will respond with the intersection of its list of supported compressors and the client's. For example, if the
server had both snappy and zlib enabled and the client requested snappy, it would respond with:</p>
<pre><code class="language-javascript">    { ... , compression: [ "snappy" ], ok: 1 }
</code></pre>
<p>If the client included both snappy and zlib, the server would respond with something like:</p>
<pre><code class="language-javascript">    { ... , compression: [ "snappy", "zlib" ], ok: 1 }
</code></pre>
<p>If the server has no compression algorithms in common with the client, it sends back a handshake response without a
compression field. Clients MAY issue a log level event to inform the user, but MUST NOT error.</p>
<p>When MongoDB server receives a compressor it can support it MAY reply to any and all requests using the selected
compressor, including the reply of the initial MongoDB Handshake. As each OP_COMPRESSED message contains the compressor
ID, clients MUST NOT assume which compressor each message uses, but MUST decompress the message using the compressor
identified in the OP_COMPRESSED opcode header.</p>
<p>When compressing, clients MUST use the first compressor in the client's configured compressors list that is also in the
servers list.</p>
<h3 id="connection-string-options"><a class="header" href="#connection-string-options">Connection String Options</a></h3>
<p>Two new connection string options:</p>
<h4 id="compressors"><a class="header" href="#compressors">compressors</a></h4>
<p>Comma separated list of compressors the client should present to the server. Unknown compressors MUST yield a warning,
as per the Connection String specification, and MUST NOT be included in the handshake. By default, no compressor is
configured and thus compression will not be used. When multiple compressors are provided, the list should be treated as
a priority ordered list of compressors to use, with highest priority given to the first compressor in the list, and
lowest priority to the last compressor in the list.</p>
<p>Example:</p>
<pre><code>    mongodb://localhost/?compressors=zstd,snappy,zlib
</code></pre>
<h4 id="zlibcompressionlevel"><a class="header" href="#zlibcompressionlevel">zlibCompressionLevel</a></h4>
<p>Integer value from <code>-1</code> - <code>9</code>. This configuration option only applies to the zlib compressor. When zlib is not one of
the compressors enumerated by the <code>compressors</code> configuration option then providing this option has no meaning, but
clients SHOULD NOT issue a warning.</p>
<div class="table-wrapper"><table><thead><tr><th>Level</th><th>Description</th></tr></thead><tbody>
<tr><td>-1</td><td>Default Compression (usually 6)</td></tr>
<tr><td>0</td><td>No compression</td></tr>
<tr><td>1</td><td>Best Speed</td></tr>
<tr><td>9</td><td>Best Compression</td></tr>
</tbody></table>
</div>
<p>Note that this value only applies to the client side compression level, not the response.</p>
<h3 id="op_compressed"><a class="header" href="#op_compressed">OP_COMPRESSED</a></h3>
<p>The new opcode, called OP_COMPRESSED, has the following structure:</p>
<pre><code class="language-c">    struct OP_COMPRESSED {
        struct MsgHeader {
            int32  messageLength;
            int32  requestID;
            int32  responseTo;
            int32  opCode = 2012;
        };
        int32_t  originalOpcode;
        int32_t  uncompressedSize;
        uint8_t  compressorId;
        char    *compressedMessage;
    };
</code></pre>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td>originalOpcode</td><td>Contains the value of the wrapped opcode.</td></tr>
<tr><td>uncompressedSize</td><td>The size of the deflated compressedMessage, which excludes the MsgHeader</td></tr>
<tr><td>compressorId</td><td>The ID of the compressor that compressed the message</td></tr>
<tr><td>compressedMessage</td><td>The opcode itself, excluding the MsgHeader</td></tr>
</tbody></table>
</div>
<h3 id="compressor-ids"><a class="header" href="#compressor-ids">Compressor IDs</a></h3>
<p>Each compressor is assigned a predefined compressor ID.</p>
<div class="table-wrapper"><table><thead><tr><th>compressorId</th><th>Handshake Value</th><th>Description</th></tr></thead><tbody>
<tr><td>0</td><td>noop</td><td>The content of the message is uncompressed.<br>This is realistically only used for testing</td></tr>
<tr><td>1</td><td>snappy</td><td>The content of the message is compressed using snappy.</td></tr>
<tr><td>2</td><td>zlib</td><td>The content of the message is compressed using zlib.</td></tr>
<tr><td>3</td><td>zstd</td><td>The content of the message is compressed using zstd.</td></tr>
<tr><td>4-255</td><td>reserved</td><td>Reserved for future use.</td></tr>
</tbody></table>
</div>
<h3 id="compressible-messages"><a class="header" href="#compressible-messages">Compressible messages</a></h3>
<p>Any opcode can be compressed and wrapped in an <code>OP_COMPRESSED</code> header. The <code>OP_COMPRESSED</code> is strictly a wire protocol
without regards to what opcode it wraps, be it <code>OP_QUERY</code>, <code>OP_REPLY</code>, <code>OP_MSG</code> or any other future or past opcode. The
<code>compressedMessage</code> contains the original opcode, excluding the standard <code>MsgHeader</code>. The <code>originalOpcode</code> value
therefore effectively replaces the standard <code>MsgHeader</code> of the compressed opcode.</p>
<p>There is no guarantee that a response will be compressed even though compression was negotiated for in the handshake.
Clients MUST be able to parse both compressed and uncompressed responses to both compressed and uncompressed requests.</p>
<p>MongoDB 3.4 will always reply with a compressed response when compression has been negotiated, but future versions may
not.</p>
<p>A client MAY choose to implement compression for only <code>OP_QUERY</code>, <code>OP_REPLY</code>, and <code>OP_MSG</code>, and perhaps for future
opcodes, but not to implement it for <code>OP_INSERT</code>, <code>OP_UPDATE</code>, <code>OP_DELETE</code>, <code>OP_GETMORE</code>, and <code>OP_KILLCURSORS</code>.</p>
<p>Note that certain messages, such as authentication commands, MUST NOT be compressed. All other messages MUST be
compressed, when compression has been negotiated and the driver has implemented compression for the opcode in use.</p>
<h3 id="messages-not-allowed-to-be-compressed"><a class="header" href="#messages-not-allowed-to-be-compressed">Messages not allowed to be compressed</a></h3>
<p>In efforts to mitigate against current and previous attacks, certain messages MUST NOT be compressed, such as
authentication requests.</p>
<p>Messages using the following commands MUST NOT be compressed:</p>
<ul>
<li>hello</li>
<li>legacy hello (see <a href="compression/../mongodb-handshake/handshake.html">MongoDB Handshake Protocol</a> for details)</li>
<li>saslStart</li>
<li>saslContinue</li>
<li>getnonce</li>
<li>authenticate</li>
<li>createUser</li>
<li>updateUser</li>
<li>copydbSaslStart</li>
<li>copydbgetnonce</li>
<li>copydb</li>
</ul>
<h2 id="test-plan-9"><a class="header" href="#test-plan-9">Test Plan</a></h2>
<p>There are no automated tests accompanying this specification, instead the following is a description of test scenarios
clients should implement.</p>
<p>In general, after implementing this functionality and the test cases, running the traditional client test suite against
a server with compression enabled, and ensuring the test suite is configured to provide a valid compressor as part of
the connection string, is a good idea. MongoDB-supported drivers MUST add such variant to their CI environment.</p>
<p>The following cases assume a standalone MongoDB 3.4 (or later) node configured with:</p>
<pre><code>    mongod --networkMessageCompressors "snappy" -vvv
</code></pre>
<p>Create an example application which connects to a provided connection string, runs <code>ping: 1</code>, and then quits the program
normally.</p>
<h3 id="connection-strings-and-results"><a class="header" href="#connection-strings-and-results">Connection strings, and results</a></h3>
<ul>
<li>
<p><a href="mongodb://localhost:27017/?compressors=snappy">mongodb://localhost:27017/?compressors=snappy</a></p>
<p>mongod should have logged the following (the exact log output may differ depending on server version):</p>
</li>
</ul>
<pre><code>      {"t":{"$date":"2021-04-08T13:28:38.885-06:00"},"s":"I",  "c":"NETWORK",  "id":22943,   "ctx":"listener","msg":"Connection accepted","attr":{"remote":"127.0.0.1:50635","uuid":"03961627-aec7-4543-8a17-9690f87273a6","connectionId":2,"connectionCount":1}}
      {"t":{"$date":"2021-04-08T13:28:38.886-06:00"},"s":"D3", "c":"EXECUTOR", "id":22983,   "ctx":"listener","msg":"Starting new executor thread in passthrough mode"}
      {"t":{"$date":"2021-04-08T13:28:38.887-06:00"},"s":"D3", "c":"-",        "id":5127801, "ctx":"thread27","msg":"Setting the Client","attr":{"client":"conn2"}}
      {"t":{"$date":"2021-04-08T13:28:38.887-06:00"},"s":"D2", "c":"COMMAND",  "id":21965,   "ctx":"conn2","msg":"About to run the command","attr":{"db":"admin","commandArgs":{"hello":1,"client":{"application":{"name":"MongoDB Shell"},"driver":{"name":"MongoDB Internal Client","version":"4.9.0-alpha7-555-g623aa8f"},"os":{"type":"Darwin","name":"Mac OS X","architecture":"x86_64","version":"19.6.0"}},"compression":["snappy"],"apiVersion":"1","apiStrict":true,"$db":"admin"}}}
      {"t":{"$date":"2021-04-08T13:28:38.888-06:00"},"s":"I",  "c":"NETWORK",  "id":51800,   "ctx":"conn2","msg":"client metadata","attr":{"remote":"127.0.0.1:50635","client":"conn2","doc":{"application":{"name":"MongoDB Shell"},"driver":{"name":"MongoDB Internal Client","version":"4.9.0-alpha7-555-g623aa8f"},"os":{"type":"Darwin","name":"Mac OS X","architecture":"x86_64","version":"19.6.0"}}}}
      {"t":{"$date":"2021-04-08T13:28:38.889-06:00"},"s":"D3", "c":"NETWORK",  "id":22934,   "ctx":"conn2","msg":"Starting server-side compression negotiation"}
      {"t":{"$date":"2021-04-08T13:28:38.889-06:00"},"s":"D3", "c":"NETWORK",  "id":22937,   "ctx":"conn2","msg":"supported compressor","attr":{"compressor":"snappy"}}
      {"t":{"$date":"2021-04-08T13:28:38.889-06:00"},"s":"I",  "c":"COMMAND",  "id":51803,   "ctx":"conn2","msg":"Slow query","attr":{"type":"command","ns":"admin.$cmd","appName":"MongoDB Shell","command":{"hello":1,"client":{"application":{"name":"MongoDB Shell"},"driver":{"name":"MongoDB Internal Client","version":"4.9.0-alpha7-555-g623aa8f"},"os":{"type":"Darwin","name":"Mac OS X","architecture":"x86_64","version":"19.6.0"}},"compression":["snappy"],"apiVersion":"1","apiStrict":true,"$db":"admin"},"numYields":0,"reslen":351,"locks":{},"remote":"127.0.0.1:50635","protocol":"op_query","durationMillis":1}}
      {"t":{"$date":"2021-04-08T13:28:38.890-06:00"},"s":"D2", "c":"QUERY",    "id":22783,   "ctx":"conn2","msg":"Received interrupt request for unknown op","attr":{"opId":596,"knownOps":[]}}
      {"t":{"$date":"2021-04-08T13:28:38.890-06:00"},"s":"D3", "c":"-",        "id":5127803, "ctx":"conn2","msg":"Released the Client","attr":{"client":"conn2"}}
      {"t":{"$date":"2021-04-08T13:28:38.890-06:00"},"s":"D3", "c":"-",        "id":5127801, "ctx":"conn2","msg":"Setting the Client","attr":{"client":"conn2"}}
      {"t":{"$date":"2021-04-08T13:28:38.891-06:00"},"s":"D3", "c":"NETWORK",  "id":22927,   "ctx":"conn2","msg":"Decompressing message","attr":{"compressor":"snappy"}}
      {"t":{"$date":"2021-04-08T13:28:38.891-06:00"},"s":"D2", "c":"COMMAND",  "id":21965,   "ctx":"conn2","msg":"About to run the command","attr":{"db":"admin","commandArgs":{"whatsmyuri":1,"apiStrict":false,"$db":"admin","apiVersion":"1"}}}
      {"t":{"$date":"2021-04-08T13:28:38.892-06:00"},"s":"I",  "c":"COMMAND",  "id":51803,   "ctx":"conn2","msg":"Slow query","attr":{"type":"command","ns":"admin.$cmd","appName":"MongoDB Shell","command":{"whatsmyuri":1,"apiStrict":false,"$db":"admin","apiVersion":"1"},"numYields":0,"reslen":63,"locks":{},"remote":"127.0.0.1:50635","protocol":"op_msg","durationMillis":0}}
      {"t":{"$date":"2021-04-08T13:28:38.892-06:00"},"s":"D2", "c":"QUERY",    "id":22783,   "ctx":"conn2","msg":"Received interrupt request for unknown op","attr":{"opId":597,"knownOps":[]}}
      {"t":{"$date":"2021-04-08T13:28:38.892-06:00"},"s":"D3", "c":"NETWORK",  "id":22925,   "ctx":"conn2","msg":"Compressing message","attr":{"compressor":"snappy"}}
      {"t":{"$date":"2021-04-08T13:28:38.893-06:00"},"s":"D3", "c":"-",        "id":5127803, "ctx":"conn2","msg":"Released the Client","attr":{"client":"conn2"}}
      {"t":{"$date":"2021-04-08T13:28:38.893-06:00"},"s":"D3", "c":"-",        "id":5127801, "ctx":"conn2","msg":"Setting the Client","attr":{"client":"conn2"}}
      {"t":{"$date":"2021-04-08T13:28:38.895-06:00"},"s":"D3", "c":"NETWORK",  "id":22927,   "ctx":"conn2","msg":"Decompressing message","attr":{"compressor":"snappy"}}
      {"t":{"$date":"2021-04-08T13:28:38.895-06:00"},"s":"D2", "c":"COMMAND",  "id":21965,   "ctx":"conn2","msg":"About to run the command","attr":{"db":"admin","commandArgs":{"buildinfo":1.0,"apiStrict":false,"$db":"admin","apiVersion":"1"}}}
      {"t":{"$date":"2021-04-08T13:28:38.896-06:00"},"s":"I",  "c":"COMMAND",  "id":51803,   "ctx":"conn2","msg":"Slow query","attr":{"type":"command","ns":"admin.$cmd","appName":"MongoDB Shell","command":{"buildinfo":1.0,"apiStrict":false,"$db":"admin","apiVersion":"1"},"numYields":0,"reslen":2606,"locks":{},"remote":"127.0.0.1:50635","protocol":"op_msg","durationMillis":0}}
      {"t":{"$date":"2021-04-08T13:28:38.896-06:00"},"s":"D2", "c":"QUERY",    "id":22783,   "ctx":"conn2","msg":"Received interrupt request for unknown op","attr":{"opId":598,"knownOps":[]}}
      {"t":{"$date":"2021-04-08T13:28:38.897-06:00"},"s":"D3", "c":"NETWORK",  "id":22925,   "ctx":"conn2","msg":"Compressing message","attr":{"compressor":"snappy"}}
      {"t":{"$date":"2021-04-08T13:28:38.897-06:00"},"s":"D3", "c":"-",        "id":5127803, "ctx":"conn2","msg":"Released the Client","attr":{"client":"conn2"}}
      {"t":{"$date":"2021-04-08T13:28:38.897-06:00"},"s":"D3", "c":"-",        "id":5127801, "ctx":"conn2","msg":"Setting the Client","attr":{"client":"conn2"}}
      {"t":{"$date":"2021-04-08T13:28:38.898-06:00"},"s":"D3", "c":"NETWORK",  "id":22927,   "ctx":"conn2","msg":"Decompressing message","attr":{"compressor":"snappy"}}
      {"t":{"$date":"2021-04-08T13:28:38.899-06:00"},"s":"D2", "c":"COMMAND",  "id":21965,   "ctx":"conn2","msg":"About to run the command","attr":{"db":"admin","commandArgs":{"endSessions":[{"id":{"$uuid":"c4866af5-ed6b-4f01-808b-51a3f8aaaa08"}}],"$db":"admin","apiVersion":"1","apiStrict":true}}}
      {"t":{"$date":"2021-04-08T13:28:38.899-06:00"},"s":"I",  "c":"COMMAND",  "id":51803,   "ctx":"conn2","msg":"Slow query","attr":{"type":"command","ns":"admin.$cmd","appName":"MongoDB Shell","command":{"endSessions":[{"id":{"$uuid":"c4866af5-ed6b-4f01-808b-51a3f8aaaa08"}}],"$db":"admin","apiVersion":"1","apiStrict":true},"numYields":0,"reslen":38,"locks":{},"remote":"127.0.0.1:50635","protocol":"op_msg","durationMillis":0}}
      {"t":{"$date":"2021-04-08T13:28:38.900-06:00"},"s":"D2", "c":"QUERY",    "id":22783,   "ctx":"conn2","msg":"Received interrupt request for unknown op","attr":{"opId":599,"knownOps":[]}}
      {"t":{"$date":"2021-04-08T13:28:38.900-06:00"},"s":"D3", "c":"NETWORK",  "id":22925,   "ctx":"conn2","msg":"Compressing message","attr":{"compressor":"snappy"}}
      {"t":{"$date":"2021-04-08T13:28:38.900-06:00"},"s":"D3", "c":"-",        "id":5127803, "ctx":"conn2","msg":"Released the Client","attr":{"client":"conn2"}}
      {"t":{"$date":"2021-04-08T13:28:38.901-06:00"},"s":"D3", "c":"-",        "id":5127801, "ctx":"conn2","msg":"Setting the Client","attr":{"client":"conn2"}}
      {"t":{"$date":"2021-04-08T13:28:38.901-06:00"},"s":"D2", "c":"NETWORK",  "id":22986,   "ctx":"conn2","msg":"Session from remote encountered a network error during SourceMessage","attr":{"remote":"127.0.0.1:50635","error":{"code":6,"codeName":"HostUnreachable","errmsg":"Connection closed by peer"}}}
      {"t":{"$date":"2021-04-08T13:28:38.902-06:00"},"s":"D1", "c":"-",        "id":23074,   "ctx":"conn2","msg":"User assertion","attr":{"error":"HostUnreachable: Connection closed by peer","file":"src/mongo/transport/service_state_machine.cpp","line":410}}
      {"t":{"$date":"2021-04-08T13:28:38.902-06:00"},"s":"W",  "c":"EXECUTOR", "id":4910400, "ctx":"conn2","msg":"Terminating session due to error","attr":{"error":{"code":6,"codeName":"HostUnreachable","errmsg":"Connection closed by peer"}}}
      {"t":{"$date":"2021-04-08T13:28:38.902-06:00"},"s":"I",  "c":"NETWORK",  "id":5127900, "ctx":"conn2","msg":"Ending session","attr":{"error":{"code":6,"codeName":"HostUnreachable","errmsg":"Connection closed by peer"}}}
      {"t":{"$date":"2021-04-08T13:28:38.903-06:00"},"s":"I",  "c":"NETWORK",  "id":22944,   "ctx":"conn2","msg":"Connection ended","attr":{"remote":"127.0.0.1:50635","uuid":"03961627-aec7-4543-8a17-9690f87273a6","connectionId":2,"connectionCount":0}}
      {"t":{"$date":"2021-04-08T13:28:38.903-06:00"},"s":"D3", "c":"-",        "id":5127803, "ctx":"conn2","msg":"Released the Client","attr":{"client":"conn2"}}
</code></pre>
<p>The result of the program should have been:</p>
<pre><code>      { "ok" : 1 }
</code></pre>
<ul>
<li>
<p><a href="mongodb://localhost:27017/?compressors=snoopy">mongodb://localhost:27017/?compressors=snoopy</a></p>
<p>mongod should have logged the following:</p>
</li>
</ul>
<pre><code>      {"t":{"$date":"2021-04-20T09:57:26.823-06:00"},"s":"D2", "c":"COMMAND",  "id":21965,   "ctx":"conn5","msg":"About to run the command","attr":{"db":"admin","commandArgs":{"hello":1,"client":{"driver":{"name":"mongo-csharp-driver","version":"2.12.2.0"},"os":{"type":"macOS","name":"Darwin 19.6.0 Darwin Kernel Version 19.6.0: Tue Jan 12 22:13:05 PST 2021; root:xnu-6153.141.16~1/RELEASE_X86_64","architecture":"x86_64","version":"19.6.0"},"platform":".NET 5.0.3"},"compression":[],"$readPreference":{"mode":"secondaryPreferred"},"$db":"admin"}}}
      {"t":{"$date":"2021-04-20T09:57:26.823-06:00"},"s":"I",  "c":"NETWORK",  "id":51800,   "ctx":"conn5","msg":"client metadata","attr":{"remote":"127.0.0.1:54372","client":"conn5","doc":{"driver":{"name":"mongo-csharp-driver","version":"2.12.2.0"},"os":{"type":"macOS","name":"Darwin 19.6.0 Darwin Kernel Version 19.6.0: Tue Jan 12 22:13:05 PST 2021; root:xnu-6153.141.16~1/RELEASE_X86_64","architecture":"x86_64","version":"19.6.0"},"platform":".NET 5.0.3"}}}
      {"t":{"$date":"2021-04-20T09:57:26.824-06:00"},"s":"D3", "c":"NETWORK",  "id":22934,   "ctx":"conn5","msg":"Starting server-side compression negotiation"}
      {"t":{"$date":"2021-04-20T09:57:26.824-06:00"},"s":"D3", "c":"NETWORK",  "id":22936,   "ctx":"conn5","msg":"No compressors provided"}
      {"t":{"$date":"2021-04-20T09:57:26.825-06:00"},"s":"I",  "c":"COMMAND",  "id":51803,   "ctx":"conn5","msg":"Slow query","attr":{"type":"command","ns":"admin.$cmd","command":{"hello":1,"client":{"driver":{"name":"mongo-csharp-driver","version":"2.12.2.0"},"os":{"type":"macOS","name":"Darwin 19.6.0 Darwin Kernel Version 19.6.0: Tue Jan 12 22:13:05 PST 2021; root:xnu-6153.141.16~1/RELEASE_X86_64","architecture":"x86_64","version":"19.6.0"},"platform":".NET 5.0.3"},"compression":[],"$readPreference":{"mode":"secondaryPreferred"},"$db":"admin"},"numYields":0,"reslen":319,"locks":{},"remote":"127.0.0.1:54372","protocol":"op_query","durationMillis":1}}
</code></pre>
<p>e.g., empty compression: [] array. No operations should have been compressed.</p>
<p>The results of the program should have been:</p>
<pre><code>      WARNING: Unsupported compressor: 'snoopy'
      { "ok" : 1 }
</code></pre>
<ul>
<li>
<p><a href="mongodb://localhost:27017/?compressors=snappy,zlib">mongodb://localhost:27017/?compressors=snappy,zlib</a></p>
<p>mongod should have logged the following:</p>
</li>
</ul>
<pre><code>      {"t":{"$date":"2021-04-08T13:28:38.898-06:00"},"s":"D3", "c":"NETWORK",  "id":22927,   "ctx":"conn2","msg":"Decompressing message","attr":{"compressor":"snappy"}}
</code></pre>
<p>The results of the program should have been:</p>
<pre><code>      { "ok" : 1 }
</code></pre>
<ul>
<li>
<p><a href="mongodb://localhost:27017/?compressors=zlib,snappy">mongodb://localhost:27017/?compressors=zlib,snappy</a></p>
<p>mongod should have logged the following:</p>
</li>
</ul>
<pre><code>      {"t":{"$date":"2021-04-08T13:28:38.898-06:00"},"s":"D3", "c":"NETWORK",  "id":22927,   "ctx":"conn2","msg":"Decompressing message","attr":{"compressor":"zlib"}}
</code></pre>
<p>The results of the program should have been:</p>
<pre><code>      { "ok" : 1 }
</code></pre>
<ul>
<li>
<p>Create example program that authenticates to the server using SCRAM-SHA-1, then creates another user (MONGODB-CR),
then runs hello followed with serverStatus.</p>
</li>
<li>
<p>Reconnect to the same server using the created MONGODB-CR credentials. Observe that the only command that was
decompressed on the server was <code>serverStatus</code>, while the server replied with OP_COMPRESSED for at least the
serverStatus command.</p>
</li>
</ul>
<h2 id="motivation-for-change-7"><a class="header" href="#motivation-for-change-7">Motivation For Change</a></h2>
<p>Drivers provide the canonical interface to MongoDB. Most tools for MongoDB are written with the aid of MongoDB drivers.
There exist a lot of tools for MongoDB that import massive datasets which could stand to gain a lot from compression.
Even day-to-day applications stand to gain from reduced bandwidth utilization at low cpu costs, especially when doing
large reads off the network.</p>
<p>Not all use cases fit compression, but we will allow users to decide if wire compression is right for them.</p>
<h2 id="design-rationale-8"><a class="header" href="#design-rationale-8">Design rationale</a></h2>
<p>Snappy has minimal cost and provides a reasonable compression ratio, but it is not expected to be available for all
languages MongoDB Drivers support. Supporting zlib is therefore important to the ecosystem, but for languages that do
support snappy we expected it to be the default choice. While snappy has no knobs to tune, zlib does have support for
specifying the compression level (tuned from speed to compression). As we don’t anticipate adding support for
compression libraries with complex knobs to tune this specification has opted not to define a complex configuration
structure and only define the currently relevant <code>zlibCompressionLevel</code>. When other compression libraries are supported,
adding support for configuring that library (if any is needed) should be handled on a case by case basis.</p>
<p>More recently, the MongoDB server added Zstandard (zstd) support for another modern alternative to zlib.</p>
<h2 id="backwards-compatibility-6"><a class="header" href="#backwards-compatibility-6">Backwards Compatibility</a></h2>
<p>The new argument provided to the MongoDB Handshake has no backwards compatible implications as servers that do not
expect it will simply ignore it. This means a server will therefore never reply with a list of acceptable compressors
which in turns means a client CANNOT use the OP_COMPRESSED opcode.</p>
<h2 id="reference-implementation-5"><a class="header" href="#reference-implementation-5">Reference Implementation</a></h2>
<ul>
<li><a href="https://jira.mongodb.org/browse/CDRIVER-2116">mongoc</a></li>
</ul>
<h2 id="future-work-4"><a class="header" href="#future-work-4">Future Work</a></h2>
<p>Possible future improvements include defining an API to determine compressor and configuration per operation, rather
than needing to create two different client pools, one for compression and one without, when the user is expecting only
needing to (not) compress very few operations.</p>
<h2 id="q--a-2"><a class="header" href="#q--a-2">Q &amp; A</a></h2>
<ul>
<li>
<p>Statistics?</p>
<ul>
<li>See <a href="https://www.mongodb.com/docs/manual/reference/command/serverStatus/">serverStatus</a> in the server</li>
</ul>
</li>
<li>
<p>How to try this/enable it?</p>
<ul>
<li><code>mongod --networkMessageCompressors "snappy"</code></li>
</ul>
</li>
<li>
<p>The server MAY reply with compressed data even if the request was not compressed?</p>
<ul>
<li>Yes, and this is in fact the behaviour of MongoDB 3.4</li>
</ul>
</li>
<li>
<p>Can drivers compress the initial MongoDB Handshake/hello request?</p>
<ul>
<li>No.</li>
</ul>
</li>
<li>
<p>Can the server reply to the MongoDB Handshake/hello compressed?</p>
<ul>
<li>Yes, yes it can. Be aware it is completely acceptable for the server to use compression for any and all replies,
using any supported compressor, when the client announced support for compression - this includes the reply to the
actual MongoDB Handshake/hello where the support was announced.</li>
</ul>
</li>
<li>
<p>This is billed a MongoDB 3.6 feature -- but I hear it works with MongoDB3.4?</p>
<ul>
<li>Yes, it does. All MongoDB versions support the <code>compression</code> argument to the initial handshake and all MongoDB
versions will reply with an intersection of compressors it supports. This works even with MongoDB 3.0, as it will
not reply with any compressors. It also works with MongoDB 3.4 which will reply with <code>snappy</code> if it was part of the
driver's list. MongoDB 3.6 will likely include zlib support.</li>
</ul>
</li>
<li>
<p>Which compressors are currently supported?</p>
<ul>
<li>MongoDB 3.4 supports <code>snappy</code></li>
<li>MongoDB 3.6 supports <code>snappy</code> and <code>zlib</code></li>
<li>MongoDB 4.2 supports <code>snappy</code>, <code>zlib</code>, and <code>zstd</code></li>
</ul>
</li>
<li>
<p>My language supports xyz compressor, should I announce them all in the handshake?</p>
<ul>
<li>No. But you are allowed to if you really want to make sure you can use that compressor with MongoDB 42 and your
current driver versions.</li>
</ul>
</li>
<li>
<p>My language does not support xzy compressor. What do I do?</p>
<ul>
<li>That is OK. You don’t have to support xyz.</li>
</ul>
</li>
<li>
<p>No MongoDB supported compressors are available for my language</p>
<ul>
<li>That is OK. You don’t have to support compressors you can’t support. All it means is you can’t compress the request,
and since you never declared support for any compressor, you won’t be served with compressed responses either.</li>
</ul>
</li>
<li>
<p>Why did the server not support zlib in MongoDB 3.4?</p>
<ul>
<li>Snappy was selected for its very low performance hit, while giving reasonable compression, resulting in quite
significant bandwidth reduction. Zlib characteristics are slightly different out-of-the-box and did not make sense
for the initial goal of reducing bandwidth between replica set nodes.</li>
</ul>
</li>
<li>
<p>If snappy is preferable to zlib, why add support for zlib in MongoDB 3.6?</p>
<ul>
<li>Zlib is available on every platform known to man. Snappy is not. Having zlib support makes sense for client traffic,
which could originate on any type of platform, which may or may not support snappy.</li>
</ul>
</li>
</ul>
<h2 id="changelog-11"><a class="header" href="#changelog-11">Changelog</a></h2>
<ul>
<li>2024-02-16: Migrated from reStructuredText to Markdown.</li>
<li>2022-10-05: Remove spec front matter and reformat changelog.</li>
<li>2021-04-06: Use 'hello' command</li>
<li>2019-05-13: Add zstd as supported compression algorithm</li>
<li>2017-06-13: Don't require clients to implement legacy opcodes</li>
<li>2017-05-10: Initial commit.</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="socks5-support"><a class="header" href="#socks5-support">SOCKS5 Support</a></h1>
<ul>
<li>Status: Accepted</li>
<li>Minimum Server Version: N/A</li>
</ul>
<hr />
<h2 id="abstract-12"><a class="header" href="#abstract-12">Abstract</a></h2>
<p>SOCKS5 is a standardized protocol for connecting to network services through a separate proxy server. It can be used for
connecting to hosts that would otherwise be unreachable from the local network by connecting to a proxy server, which
receives the intended target host's address from the client and then connects to that address.</p>
<p>This specification defines driver behaviour when connecting to MongoDB services through a SOCKS5 proxy.</p>
<h2 id="meta-12"><a class="header" href="#meta-12">META</a></h2>
<p>The keywords "MUST", "MUST NOT", "REQUIRED", "SHALL", "SHALL NOT", "SHOULD", "SHOULD NOT", "RECOMMENDED", "MAY", and
"OPTIONAL" in this document are to be interpreted as described in <a href="https://www.ietf.org/rfc/rfc2119.txt">RFC 2119</a>.</p>
<h2 id="specification-11"><a class="header" href="#specification-11">Specification</a></h2>
<h3 id="terms-5"><a class="header" href="#terms-5">Terms</a></h3>
<h4 id="socks5"><a class="header" href="#socks5">SOCKS5</a></h4>
<p>The SOCKS protocol, version 5, as defined in <a href="https://datatracker.ietf.org/doc/html/rfc1928">RFC1928</a>, restricted to
either no authentication or username/password authentication as defined in
<a href="https://datatracker.ietf.org/doc/html/rfc1929">RFC1929</a>.</p>
<h3 id="mongoclient-configuration-1"><a class="header" href="#mongoclient-configuration-1">MongoClient Configuration</a></h3>
<h4 id="proxyhost"><a class="header" href="#proxyhost">proxyHost</a></h4>
<p>To specify to the driver to connect using a SOCKS5 proxy, a connection string option of <code>proxyHost=host</code> MUST be added
to the connection string or passed through an equivalent <code>MongoClient</code> option. This option specifies a domain name or
IPv4 or IPv6 address on which a SOCKS5 proxy is listening. This option MUST only be configurable at the level of a
<code>MongoClient</code>.</p>
<h4 id="proxyport"><a class="header" href="#proxyport">proxyPort</a></h4>
<p>To specify to the driver to connect using a SOCKS5 proxy listening on a non-default port, a connection string option of
<code>proxyPort=port</code> MUST be added to the connection string or passed through an equivalent <code>MongoClient</code> option. This
option specifies a TCP port number. The default for this option MUST be <code>1080</code>. This option MUST only be configurable at
the level of a <code>MongoClient</code>. Drivers MUST error if this option was specified and <code>proxyHost</code> was not specified.</p>
<h4 id="proxyusername"><a class="header" href="#proxyusername">proxyUsername</a></h4>
<p>To specify to the driver to connect using a SOCKS5 proxy requiring username/password authentication, a connection string
option of - Code:<code>proxyUsername=username</code> MUST be added to the connection string or passed through an equivalent
<code>MongoClient</code> option. This option specifies a string of non-zero length. Drivers MUST ignore this option if it specifies
a zero-length string. Drivers MUST error if this option was specified and <code>proxyHost</code> was not specified or
<code>proxyPassword</code> was not specified.</p>
<h4 id="proxypassword"><a class="header" href="#proxypassword">proxyPassword</a></h4>
<p>To specify to the driver to connect using a SOCKS5 proxy requiring username/password authentication, a connection string
option of - Code:<code>proxyPassword=password</code> MUST be added to the connection string or passed through an equivalent
<code>MongoClient</code> option. This option specifies a string of non-zero length. Drivers MUST ignore this option if it specifies
a zero-length string. Drivers MUST error if this option was specified and <code>proxyHost</code> was not specified or
<code>proxyUsername</code> was not specified.</p>
<h3 id="connection-pooling"><a class="header" href="#connection-pooling">Connection Pooling</a></h3>
<h4 id="connection-establishment"><a class="header" href="#connection-establishment">Connection Establishment</a></h4>
<p>When establishing a new outgoing TCP connection, drivers MUST perform the following steps if <code>proxyHost</code> was specified:</p>
<ol>
<li>
<p>Connect to the SOCKS5 proxy host, using <code>proxyHost</code> and <code>proxyPort</code> as specified.</p>
</li>
<li>
<p>Perform a SOCKS5 handshake as specified in RFC1928.</p>
<blockquote>
<p>If <code>proxyUsername</code> and <code>proxyPassword</code> were passed, drivers MUST indicate in the handshake that both "no
authentication" and "username/password authentication" are supported. Otherwise, drivers MUST indicate support for
"no authentication" only.</p>
<p>Drivers MUST NOT attempt to perform DNS A or AAAA record resolution of the destination hostname and instead pass
the hostname to the proxy as-is.</p>
</blockquote>
</li>
<li>
<p>Continue with connection establishment as if the connection was one to the destination host.</p>
</li>
</ol>
<p>Drivers MUST use the SOCKS5 proxy for connections to MongoDB services and
<a href="socks5-support/../client-side-encryption/client-side-encryption.html#kms-provider">client-side field-level encryption KMS servers</a>.</p>
<p>Drivers MUST NOT use the SOCKS5 proxy for connections to - Code:<code>mongocryptd</code> processes spawned for automatic
client-side field-level encryption.</p>
<p>Drivers MUST treat a connection failure when connecting to the SOCKS5 proxy or a SOCKS5 handshake or authentication
failure the same as a network error (e.g. <code>ECONNREFUSED</code>).</p>
<h3 id="events"><a class="header" href="#events">Events</a></h3>
<p>SOCKS5 proxies are fully transparent to connection monitoring events. In particular, in <code>CommandStartedEvent</code>,
<code>CommandSucceededEvent</code>, and - Code:<code>CommandFailedEvent</code>, the driver SHOULD NOT reference the SOCKS5 proxy as part of
the <code>connectionId</code> field or other fields.</p>
<h3 id="qa-5"><a class="header" href="#qa-5">Q&amp;A</a></h3>
<h4 id="why-not-include-dns-requests-in-the-set-of-proxied-network-communication"><a class="header" href="#why-not-include-dns-requests-in-the-set-of-proxied-network-communication">Why not include DNS requests in the set of proxied network communication?</a></h4>
<p>While SOCKS5 as a protocol does support UDP forwarding, using this feature has a number of downsides. Notably, only a
subset of SOCKS5 client libraries and SOCKS5 server implementations support UDP forwarding (e.g. the OpenSSH client's
dynamic forwarding feature does not). This would also considerably increase implementation complexity in drivers that do
not use DNS libraries in which the driver is in control of how the UDP packets are sent and received.</p>
<h4 id="why-not-support-other-proxy-protocols-such-as-socks4socks4a-http-connect-proxies-etc"><a class="header" href="#why-not-support-other-proxy-protocols-such-as-socks4socks4a-http-connect-proxies-etc">Why not support other proxy protocols, such as Socks4/Socks4a, HTTP Connect proxies, etc.?</a></h4>
<p>SOCKS5 is a powerful, standardized and widely used proxy protocol. It is likely that almost all users which require
tunneling/proxying of some sort will be able to use it, and those who require another protocol or a more advanced setup
like proxy chaining, can work around that by using a local SOCKS5 intermediate proxy.</p>
<h4 id="why-are-the-connection-string-parameters-generic-with-no-explicit-mention-of-socks5"><a class="header" href="#why-are-the-connection-string-parameters-generic-with-no-explicit-mention-of-socks5">Why are the connection string parameters generic, with no explicit mention of SOCKS5?</a></h4>
<p>In the case that future changes will enable drivers using other proxy protocols, keeping the option names generic allows
their re-use. In that case, another option would specify the protocol and SOCKS5 would be the implied default. However,
since there is no reason to believe that such additions will be made in the foreseeable future, no option for specifying
the proxy protocol is introduced here.</p>
<h4 id="why-is-support-for-authentication-methods-limited-to-no-authentication-and-usernamepassword-authentication"><a class="header" href="#why-is-support-for-authentication-methods-limited-to-no-authentication-and-usernamepassword-authentication">Why is support for authentication methods limited to no authentication and username/password authentication?</a></h4>
<p>This matches the set of authentication methods most commonly implemented by SOCKS5 client libraries and thus reduces
implementation complexity for drivers. This advantage is sufficient to ignore the possible advantages that would come
with enabling other authentication methods.</p>
<h3 id="design-rationales"><a class="header" href="#design-rationales">Design Rationales</a></h3>
<h3 id="alternative-designs"><a class="header" href="#alternative-designs">Alternative Designs</a></h3>
<h2 id="changelog-12"><a class="header" href="#changelog-12">Changelog</a></h2>
<ul>
<li>2024-09-04: Migrated from reStructuredText to Markdown.</li>
<li>2022-10-05: Remove spec front matter</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="initial-dns-seedlist-discovery"><a class="header" href="#initial-dns-seedlist-discovery">Initial DNS Seedlist Discovery</a></h1>
<ul>
<li>Status: Accepted</li>
<li>Minimum Server Version: N/A</li>
</ul>
<hr />
<h2 id="abstract-13"><a class="header" href="#abstract-13">Abstract</a></h2>
<p>Presently, seeding a driver with an initial list of ReplicaSet or MongoS addresses is somewhat cumbersome, requiring a
comma-delimited list of host names to attempt connections to. A standardized answer to this problem exists in the form
of SRV records, which allow administrators to configure a single SRV record to return a list of host names. Supporting
this feature would assist our users by decreasing maintenance load, primarily by removing the need to maintain seed
lists at an application level.</p>
<p>This specification builds on the <a href="initial-dns-seedlist-discovery/../connection-string/connection-string-spec.html">Connection String</a> specification. It
adds a new protocol scheme and modifies how the
<a href="initial-dns-seedlist-discovery/../connection-string/connection-string-spec.html#host-information">Host Information</a> is interpreted.</p>
<h2 id="meta-13"><a class="header" href="#meta-13">META</a></h2>
<p>The keywords "MUST", "MUST NOT", "REQUIRED", "SHALL", "SHALL NOT", "SHOULD", "SHOULD NOT", "RECOMMENDED", "MAY", and
"OPTIONAL" in this document are to be interpreted as described in <a href="https://www.ietf.org/rfc/rfc2119.txt">RFC 2119</a>.</p>
<h2 id="specification-12"><a class="header" href="#specification-12">Specification</a></h2>
<h3 id="connection-string-format"><a class="header" href="#connection-string-format">Connection String Format</a></h3>
<p>The connection string parser in the driver is extended with a new protocol <code>mongodb+srv</code> as a logical pre-processing
step before it considers the connection string and SDAM specifications. In this protocol, the comma separated list of
host names is replaced with a single host name. The format is:</p>
<pre><code>mongodb+srv://{hostname}/{options} 
</code></pre>
<p><code>{options}</code> refers to the optional elements from the <a href="initial-dns-seedlist-discovery/../connection-string/connection-string-spec.html">Connection String</a>
specification following the <code>Host Information</code>. This includes the <code>Auth database</code> and <code>Connection Options</code>.</p>
<p>For the purposes of this document, <code>{hostname}</code> will be divided using the following terminology. If an SRV <code>{hostname}</code>
has:</p>
<ol>
<li>
<p>Three or more <code>.</code> separated parts, then the left-most part is the <code>{subdomain}</code> and the remaining portion is the
<code>{domainname}</code>.</p>
<ul>
<li>Examples:
<ul>
<li>
<p><code>{hostname}</code> = <code>cluster_1.tests.mongodb.co.uk</code></p>
<ul>
<li><code>{subdomain}</code> = <code>cluster_1</code></li>
<li><code>{domainname}</code> = <code>tests.mongodb.co.uk</code></li>
</ul>
</li>
<li>
<p><code>{hostname}</code> = <code>hosts_34.example.com</code></p>
<ul>
<li><code>{subdomain}</code> = <code>hosts_34</code></li>
<li><code>{domainname}</code> = <code>example.com</code></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p>One or two <code>.</code> separated part(s), then the <code>{hostname}</code> is equivalent to the <code>{domainname}</code>, and there is no
subdomain.</p>
<ul>
<li>Examples:
<ul>
<li><code>{hostname}</code> = <code>{domainname}</code> = <code>localhost</code></li>
<li><code>{hostname}</code> = <code>{domainname}</code> = <code>mongodb.local</code></li>
</ul>
</li>
</ul>
</li>
</ol>
<p>Only <code>{domainname}</code> is used during SRV record verification and <code>{subdomain}</code> is ignored.</p>
<h3 id="mongoclient-configuration-2"><a class="header" href="#mongoclient-configuration-2">MongoClient Configuration</a></h3>
<h4 id="srvmaxhosts"><a class="header" href="#srvmaxhosts">srvMaxHosts</a></h4>
<p>This option is used to limit the number of mongos connections that may be created for sharded topologies. This option
limits the number of SRV records used to populate the seedlist during initial discovery, as well as the number of
additional hosts that may be added during
<a href="initial-dns-seedlist-discovery/../polling-srv-records-for-mongos-discovery/polling-srv-records-for-mongos-discovery.html">SRV polling</a>. This option
requires a non-negative integer and defaults to zero (i.e. no limit). This option MUST only be configurable at the level
of a <code>MongoClient</code>.</p>
<h4 id="srvservicename"><a class="header" href="#srvservicename">srvServiceName</a></h4>
<p>This option specifies a valid SRV service name according to
<a href="https://datatracker.ietf.org/doc/html/rfc6335#section-5.1">RFC 6335</a>, with the exception that it may exceed 15
characters as long as the 63rd (62nd with prepended underscore) character DNS query limit is not surpassed. This option
requires a string value and defaults to "mongodb". This option MUST only be configurable at the level of a
<code>MongoClient</code>.</p>
<h4 id="uri-validation"><a class="header" href="#uri-validation">URI Validation</a></h4>
<p>The driver MUST report an error if either the <code>srvServiceName</code> or <code>srvMaxHosts</code> URI options are specified with a non-SRV
URI (i.e. scheme other than <code>mongodb+srv</code>). The driver MUST allow specifying the <code>srvServiceName</code> and <code>srvMaxHosts</code> URI
options with an SRV URI (i.e. <code>mongodb+srv</code> scheme).</p>
<p>If <code>srvMaxHosts</code> is a positive integer, the driver MUST throw an error in the following cases:</p>
<ul>
<li>The connection string contains a <code>replicaSet</code> option.</li>
<li>The connection string contains a <code>loadBalanced</code> option with a value of <code>true</code>.</li>
</ul>
<p>When validating URI options, the driver MUST first do the SRV and TXT lookup and then perform the validation. For
drivers that do SRV lookup asynchronously this may result in a <code>MongoClient</code> being instantiated but erroring later
during operation execution.</p>
<h3 id="seedlist-discovery"><a class="header" href="#seedlist-discovery">Seedlist Discovery</a></h3>
<h4 id="validation-before-querying-dns"><a class="header" href="#validation-before-querying-dns">Validation Before Querying DNS</a></h4>
<p>It is an error to specify a port in a connection string with the <code>mongodb+srv</code> protocol, and the driver MUST raise a
parse error and MUST NOT do DNS resolution or contact hosts.</p>
<p>It is an error to specify more than one host name in a connection string with the <code>mongodb+srv</code> protocol, and the driver
MUST raise a parse error and MUST NOT do DNS resolution or contact hosts.</p>
<p>If <code>mongodb+srv</code> is used, a driver MUST implicitly also enable TLS. Clients can turn this off by passing <code>tls=false</code> in
either the Connection String, or options passed in as parameters in code to the MongoClient constructor (or equivalent
API for each driver), but not through a TXT record (discussed in a later section).</p>
<h4 id="querying-dns"><a class="header" href="#querying-dns">Querying DNS</a></h4>
<p>In this preprocessing step, the driver will query the DNS server for SRV records on the hostname, prefixed with the SRV
service name and protocol. The SRV service name is provided in the <code>srvServiceName</code> URI option and defaults to
<code>mongodb</code>. The protocol is always <code>tcp</code>. After prefixing, the URI should look like: <code>_{srvServiceName}._tcp.{hostname}</code>.
This DNS query is expected to respond with one or more SRV records.</p>
<p>The priority and weight fields in returned SRV records MUST be ignored.</p>
<p>If the DNS result returns no SRV records, or no records at all, or a DNS error happens, an error MUST be raised
indicating that the URI could not be used to find hostnames. The error SHALL include the reason why they could not be
found.</p>
<p>A driver MUST verify that the host names returned through SRV records share the original SRV's <code>{domainname}</code>. In
addition, SRV records with fewer than three <code>.</code> separated parts, the returned hostname MUST have at least one more
domain level than the SRV record hostname. Drivers MUST raise an error and MUST NOT initiate a connection to any
returned hostname which does not fulfill these requirements.</p>
<p>The driver MUST NOT attempt to connect to any hosts until the DNS query has returned its results.</p>
<p>If <code>srvMaxHosts</code> is zero or greater than or equal to the number of hosts in the DNS result, the driver MUST populate the
seedlist with all hosts.</p>
<p>If <code>srvMaxHosts</code> is greater than zero and less than the number of hosts in the DNS result, the driver MUST randomly
select that many hosts and use them to populate the seedlist. Drivers SHOULD use the
<a href="https://en.wikipedia.org/wiki/Fisher%E2%80%93Yates_shuffle#The_modern_algorithm">Fisher-Yates shuffle</a> for
randomization.</p>
<h3 id="default-connection-string-options"><a class="header" href="#default-connection-string-options">Default Connection String Options</a></h3>
<p>As a second preprocessing step, a Client MUST also query the DNS server for TXT records on <code>{hostname}</code>. If available, a
TXT record provides default connection string options. The maximum length of a TXT record string is 255 characters, but
there can be multiple strings per TXT record. A Client MUST support multiple TXT record strings and concatenate them as
if they were one single string in the order they are defined in each TXT record. The order of multiple character strings
in each TXT record is guaranteed. A Client MUST NOT allow multiple TXT records for the same host name and MUST raise an
error when multiple TXT records are encountered.</p>
<p>Information returned within a TXT record is a simple URI string, just like the <code>{options}</code> in a connection string.</p>
<p>A Client MUST only support the <code>authSource</code>, <code>replicaSet</code>, and <code>loadBalanced</code> options through a TXT record, and MUST
raise an error if any other option is encountered. Although using <code>mongodb+srv://</code> implicitly enables TLS, a Client MUST
NOT allow the <code>ssl</code> option to be set through a TXT record option.</p>
<p>TXT records MAY be queried either before, in parallel, or after SRV records. Clients MUST query both the SRV and the TXT
records before attempting any connection to MongoDB.</p>
<p>A Client MUST use options specified in the Connection String, and options passed in as parameters in code to the
MongoClient constructor (or equivalent API for each driver), to override options provided through TXT records.</p>
<p>If any connection string option in a TXT record is incorrectly formatted, a Client MUST throw a parse exception.</p>
<p>This specification does not change the behaviour of handling unknown keys or incorrect values as is set out in the
<a href="initial-dns-seedlist-discovery/../connection-string/connection-string-spec.html#defining-connection-options">Connection String spec</a>. Unknown keys or
incorrect values in default options specified through TXT records MUST be handled in the same way as unknown keys or
incorrect values directly specified through a Connection String. For example, if a driver that does not support the
<code>authSource</code> option finds <code>authSource=db</code> in a TXT record, it MUST handle the unknown option according to the rules in
the Connection String spec.</p>
<h3 id="cname-not-supported"><a class="header" href="#cname-not-supported">CNAME not supported</a></h3>
<p>The use of DNS CNAME records is not supported. Clients MUST NOT check for a CNAME record on <code>{hostname}</code>. A system's DNS
resolver could transparently handle CNAME, but because of how clients validate records returned from SRV queries, use of
CNAME could break validation. Seedlist discovery therefore does not recommend or support the use of CNAME records in
concert with SRV or TXT records.</p>
<h2 id="example"><a class="header" href="#example">Example</a></h2>
<p>If we provide the following URI:</p>
<pre><code>mongodb+srv://server.mongodb.com/
</code></pre>
<p>The driver needs to request the DNS server for the SRV record <code>_mongodb._tcp.server.mongodb.com</code>. This could return:</p>
<pre><code>Record                            TTL   Class    Priority Weight Port  Target
_mongodb._tcp.server.mongodb.com. 86400 IN SRV   0        5      27317 mongodb1.mongodb.com.
_mongodb._tcp.server.mongodb.com. 86400 IN SRV   0        5      27017 mongodb2.mongodb.com.
</code></pre>
<p>The returned host names (<code>mongodb1.mongodb.com</code> and <code>mongodb2.mongodb.com</code>) must share the same domainname
(<code>mongodb.com</code>) as the provided host name (<code>server.mongodb.com</code>).</p>
<p>The driver also needs to request the DNS server for the TXT records on <code>server.mongodb.com</code>. This could return:</p>
<pre><code>Record              TTL   Class    Text
server.mongodb.com. 86400 IN TXT   "replicaSet=replProduction&amp;authSource=authDB"
</code></pre>
<p>From the DNS results, the driver now MUST treat the host information as if the following URI was used instead:</p>
<pre><code>mongodb://mongodb1.mongodb.com:27317,mongodb2.mongodb.com:27107/?ssl=true&amp;replicaSet=replProduction&amp;authSource=authDB
</code></pre>
<p>If we provide the following URI with the same DNS (SRV and TXT) records:</p>
<pre><code>mongodb+srv://server.mongodb.com/?authSource=otherDB
</code></pre>
<p>Then the default in the TXT record for <code>authSource</code> is not used as the value in the connection string overrides it. The
Client MUST treat the host information as if the following URI was used instead:</p>
<pre><code>mongodb://mongodb1.mongodb.com:27317,mongodb2.mongodb.com:27107/?ssl=true&amp;replicaSet=replProduction&amp;authSource=otherDB
</code></pre>
<h2 id="test-plan-10"><a class="header" href="#test-plan-10">Test Plan</a></h2>
<h3 id="prose-tests"><a class="header" href="#prose-tests">Prose Tests</a></h3>
<p>See README.md in the accompanying <a href="initial-dns-seedlist-discovery/tests/README.html">test directory</a>.</p>
<h3 id="spec-tests"><a class="header" href="#spec-tests">Spec Tests</a></h3>
<p>See README.md in the accompanying <a href="initial-dns-seedlist-discovery/tests/README.html">test directory</a>.</p>
<p>Additionally, see the <code>mongodb+srv</code> test <code>invalid-uris.yml</code> in the
<a href="initial-dns-seedlist-discovery/../connection-string/tests/README.html">Connection String Spec tests</a>.</p>
<h2 id="motivation"><a class="header" href="#motivation">Motivation</a></h2>
<p>Several of our users have asked for this through tickets:</p>
<ul>
<li><a href="https://jira.mongodb.org/browse/DRIVERS-201">https://jira.mongodb.org/browse/DRIVERS-201</a></li>
<li><a href="https://jira.mongodb.org/browse/NODE-865">https://jira.mongodb.org/browse/NODE-865</a></li>
<li><a href="https://jira.mongodb.org/browse/CSHARP-536">https://jira.mongodb.org/browse/CSHARP-536</a></li>
</ul>
<h2 id="design-rationale-9"><a class="header" href="#design-rationale-9">Design Rationale</a></h2>
<p>The design specifically calls for a pre-processing stage of the processing of connection URLs to minimize the impact on
existing functionality.</p>
<h2 id="justifications"><a class="header" href="#justifications">Justifications</a></h2>
<h3 id="why-are-multiple-key-value-pairs-allowed-in-one-txt-record"><a class="header" href="#why-are-multiple-key-value-pairs-allowed-in-one-txt-record">Why Are Multiple Key-Value Pairs Allowed in One TXT Record?</a></h3>
<p>One could imagine an alternative design in which each TXT record would allow only one URI option. No <code>&amp;</code> character would
be allowed as a delimiter within TXT records.</p>
<p>In this spec we allow multiple key-value pairs within one TXT record, delimited by <code>&amp;</code>, because it will be common for
all options to fit in a single 255-character TXT record, and it is much more convenient to configure one record in this
case than to configure several.</p>
<p>Secondly, in some cases the order in which options occur is important. For example, readPreferenceTags can appear both
multiple times, and the order in which they appear is significant. Because DNS servers may return TXT records in any
order, it is only possible to guarantee the order in which readPreferenceTags keys appear by having them in the same TXT
record.</p>
<h3 id="why-is-there-no-mention-of-utf-8-characters"><a class="header" href="#why-is-there-no-mention-of-utf-8-characters">Why Is There No Mention of UTF-8 Characters?</a></h3>
<p>Although DNS TXT records allow any octet to exist in its value, many DNS providers do not allow non-ASCII characters to
be configured. As it is unlikely that any option names or values in the connection string have non-ASCII characters, we
left the behaviour of supporting UTF-8 characters as unspecified.</p>
<h2 id="reference-implementation-6"><a class="header" href="#reference-implementation-6">Reference Implementation</a></h2>
<p>None yet.</p>
<h2 id="backwards-compatibility-7"><a class="header" href="#backwards-compatibility-7">Backwards Compatibility</a></h2>
<p>There are no backwards compatibility concerns.</p>
<h2 id="future-work-5"><a class="header" href="#future-work-5">Future Work</a></h2>
<p>In the future we could consider using the priority and weight fields of the SRV records.</p>
<h2 id="changelog-13"><a class="header" href="#changelog-13">ChangeLog</a></h2>
<ul>
<li>
<p>2024-09-24: Removed requirement for URI to have three '.' separated parts; these SRVs have stricter parent domain
matching requirements for security. Create terminology section. Remove usage of term <code>{TLD}</code>. The <code>{hostname}</code> now
refers to the entire hostname, not just the <code>{subdomain}</code>.</p>
</li>
<li>
<p>2024-03-06: Migrated from reStructuredText to Markdown.</p>
</li>
<li>
<p>2022-10-05: Revise spec front matter and reformat changelog.</p>
</li>
<li>
<p>2021-10-14: Add <code>srvMaxHosts</code> MongoClient option and restructure Seedlist Discovery section. Improve documentation for
the <code>srvServiceName</code> MongoClient option and add a new URI Validation section.</p>
</li>
<li>
<p>2021-09-15: Clarify that service name only defaults to <code>mongodb</code>, and should be defined by the <code>srvServiceName</code> URI
option.</p>
</li>
<li>
<p>2021-04-15: Adding in behaviour for load balancer mode.</p>
</li>
<li>
<p>2019-03-07: Clarify that CNAME is not supported</p>
</li>
<li>
<p>2018-02-08: Clarify that <code>{options}}</code> in the <a href="initial-dns-seedlist-discovery/initial-dns-seedlist-discovery.html#specification">Specification</a> section includes all the optional
elements from the Connection String specification.</p>
</li>
<li>
<p>2017-11-21: Add clause that using <code>mongodb+srv://</code> implies enabling TLS. Add restriction that only <code>authSource</code> and
<code>replicaSet</code> are allows in TXT records. Add restriction that only one TXT record is supported share the same parent
domain name as the given host name.</p>
</li>
<li>
<p>2017-11-17: Add new rule that indicates that host names in returned SRV records MUST share the same parent domain name
as the given host name. Remove language and tests for non-ASCII characters.</p>
</li>
<li>
<p>2017-11-07: Clarified that all parts of listable options such as readPreferenceTags are ignored if they are also
present in options to the MongoClient constructor. Clarified which host names to use for SRV and TXT DNS queries.</p>
</li>
<li>
<p>2017-11-01: Clarified that individual TXT records can have multiple strings.</p>
</li>
<li>
<p>2017-10-31: Added a clause that specifying two host names with a <code>mongodb+srv://</code> URI is not allowed. Added a few more
test cases.</p>
</li>
<li>
<p>2017-10-18: Removed prohibition of raising DNS related errors when parsing the URI.</p>
</li>
<li>
<p>2017-10-04: Removed from <a href="initial-dns-seedlist-discovery/initial-dns-seedlist-discovery.html#future-work">Future Work</a> the line about multiple MongoS discovery. The current
specification already allows for it, as multiple host names which are all MongoS servers is already allowed under
SDAM. And this specification does not modify SDAM. Added support for connection string options through TXT records.</p>
</li>
<li>
<p>2017-09-19: Clarify that host names in <code>mongodb+srv://</code> URLs work like normal host specifications.</p>
</li>
<li>
<p>2017-09-01: Updated test plan with YAML tests, and moved prose tests for URI parsing into invalid-uris.yml in the
Connection String Spec tests.</p>
</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="server-discovery-and-monitoring"><a class="header" href="#server-discovery-and-monitoring">Server Discovery And Monitoring</a></h1>
<ul>
<li>Status: Accepted</li>
<li>Minimum Server Version: 2.4</li>
</ul>
<hr />
<h2 id="abstract-14"><a class="header" href="#abstract-14">Abstract</a></h2>
<p>This spec defines how a MongoDB client discovers and monitors one or more servers. It covers monitoring a single server,
a set of mongoses, or a replica set. How does the client determine what type of servers they are? How does it keep this
information up to date? How does the client find an entire replica set from a seed list, and how does it respond to a
stepdown, election, reconfiguration, or network error?</p>
<p>All drivers must answer these questions the same. Or, where platforms' limitations require differences among drivers,
there must be as few answers as possible and each must be clearly explained in this spec. Even in cases where several
answers seem equally good, drivers must agree on one way to do it.</p>
<p>MongoDB users and driver authors benefit from having one way to discover and monitor servers. Users can substantially
understand their driver's behavior without inspecting its code or asking its author. Driver authors can avoid subtle
mistakes when they take advantage of a design that has been well-considered, reviewed, and tested.</p>
<p>The server discovery and monitoring method is specified in four sections. First, a client is
<a href="server-discovery-and-monitoring/server-discovery-and-monitoring.html#configuration">configured</a>. Second, it begins <a href="server-discovery-and-monitoring/server-discovery-and-monitoring.html#monitoring">monitoring</a> by calling
<a href="server-discovery-and-monitoring/../mongodb-handshake/handshake.html#terms">hello or legacy hello</a> on all servers. (Multi-threaded and asynchronous
monitoring is described first, then single-threaded monitoring.) Third, as hello or legacy hello responses are received
the client <a href="server-discovery-and-monitoring/server-discovery-and-monitoring.html#parsing-a-hello-or-legacy-hello-response">parses them</a>, and fourth, it updates its view of the topology.</p>
<p>Finally, this spec describes how drivers update their topology view in response to errors, and includes generous
implementation notes for driver authors.</p>
<p>This spec does not describe how a client chooses a server for an operation; that is the domain of the Server Selection
Spec. But there is a section describing the interaction between monitoring and server selection.</p>
<p>There is no discussion of driver architecture and data structures, nor is there any specification of a user-facing API.
This spec is only concerned with the algorithm for monitoring the server topology.</p>
<h2 id="meta-14"><a class="header" href="#meta-14">Meta</a></h2>
<p>The key words "MUST", "MUST NOT", "REQUIRED", "SHALL", "SHALL NOT", "SHOULD", "SHOULD NOT", "RECOMMENDED", "MAY", and
"OPTIONAL" in this document are to be interpreted as described in <a href="https://www.ietf.org/rfc/rfc2119.txt">RFC 2119</a>.</p>
<h2 id="specification-13"><a class="header" href="#specification-13">Specification</a></h2>
<h3 id="general-requirements"><a class="header" href="#general-requirements">General Requirements</a></h3>
<p><strong>Direct connections:</strong> A client MUST be able to connect to a single server of any type. This includes querying hidden
replica set members, and connecting to uninitialized members (see <a href="server-discovery-and-monitoring/server-discovery-and-monitoring.html#rsghost-and-rsother">RSGhost</a>) in order to run
"replSetInitiate". Setting a read preference MUST NOT be necessary to connect to a secondary. Of course, the secondary
will reject all operations done with the PRIMARY read preference because the secondaryOk bit is not set, but the initial
connection itself succeeds. Drivers MAY allow direct connections to arbiters (for example, to run administrative
commands).</p>
<p><strong>Replica sets:</strong> A client MUST be able to discover an entire replica set from a seed list containing one or more
replica set members. It MUST be able to continue monitoring the replica set even when some members go down, or when
reconfigs add and remove members. A client MUST be able to connect to a replica set while there is no primary, or the
primary is down.</p>
<p><strong>Mongos:</strong> A client MUST be able to connect to a set of mongoses and monitor their availability and
<a href="server-discovery-and-monitoring/server-discovery-and-monitoring.html#round-trip-time">round trip time</a>. This spec defines how mongoses are discovered and monitored, but does not define
which mongos is selected for a given operation.</p>
<h3 id="terms-6"><a class="header" href="#terms-6">Terms</a></h3>
<h4 id="server"><a class="header" href="#server">Server</a></h4>
<p>A mongod or mongos process, or a load balancer.</p>
<h4 id="deployment"><a class="header" href="#deployment">Deployment</a></h4>
<p>One or more servers: either a standalone, a replica set, or one or more mongoses.</p>
<h4 id="topology"><a class="header" href="#topology">Topology</a></h4>
<p>The state of the deployment: its type (standalone, replica set, or sharded), which servers are up, what type of servers
they are, which is primary, and so on.</p>
<h4 id="client"><a class="header" href="#client">Client</a></h4>
<p>Driver code responsible for connecting to MongoDB.</p>
<h4 id="seed-list"><a class="header" href="#seed-list">Seed list</a></h4>
<p>Server addresses provided to the client in its initial configuration, for example from the
<a href="https://www.mongodb.com/docs/manual/reference/connection-string/">connection string</a>.</p>
<h4 id="data-bearing-server-type"><a class="header" href="#data-bearing-server-type">Data-Bearing Server Type</a></h4>
<p>A server type from which a client can receive application data:</p>
<ul>
<li>Mongos</li>
<li>RSPrimary</li>
<li>RSSecondary</li>
<li>Standalone</li>
<li>LoadBalanced</li>
</ul>
<h4 id="round-trip-time"><a class="header" href="#round-trip-time">Round trip time</a></h4>
<p>Also known as RTT.</p>
<p>The client's measurement of the duration of one hello or legacy hello call. The round trip time is used to support the
"localThresholdMS"<sup class="footnote-reference"><a href="#1">1</a></sup> option in the Server Selection Spec.</p>
<h4 id="hello-or-legacy-hello-outcome"><a class="header" href="#hello-or-legacy-hello-outcome">hello or legacy hello outcome</a></h4>
<p>The result of an attempt to call the hello or legacy hello command on a server. It consists of three elements: a boolean
indicating the success or failure of the attempt, a document containing the command response (or null if it failed), and
the round trip time to execute the command (or null if it failed).</p>
<h4 id="check"><a class="header" href="#check">check</a></h4>
<p>The client checks a server by attempting to call hello or legacy hello on it, and recording the outcome.</p>
<h4 id="scan"><a class="header" href="#scan">scan</a></h4>
<p>The process of checking all servers in the deployment.</p>
<h4 id="suitable"><a class="header" href="#suitable">suitable</a></h4>
<p>A server is judged "suitable" for an operation if the client can use it for a particular operation. For example, a write
requires a standalone, primary, or mongos. Suitability is fully specified in the
<a href="server-discovery-and-monitoring/../server-selection/server-selection.html">Server Selection Spec</a>.</p>
<h4 id="address"><a class="header" href="#address">address</a></h4>
<p>The hostname or IP address, and port number, of a MongoDB server.</p>
<h4 id="network-error"><a class="header" href="#network-error">network error</a></h4>
<p>An error that occurs while reading from or writing to a network socket.</p>
<h4 id="network-timeout"><a class="header" href="#network-timeout">network timeout</a></h4>
<p>A timeout that occurs while reading from or writing to a network socket.</p>
<h4 id="minheartbeatfrequencyms"><a class="header" href="#minheartbeatfrequencyms">minHeartbeatFrequencyMS</a></h4>
<p>Defined in the <a href="server-discovery-and-monitoring/server-monitoring.html">Server Monitoring spec</a>. This value MUST be 500 ms, and it MUST NOT be
configurable.</p>
<h4 id="pool-generation-number"><a class="header" href="#pool-generation-number">pool generation number</a></h4>
<p>The pool's generation number which starts at 0 and is incremented each time the pool is cleared. Defined in the
<a href="server-discovery-and-monitoring/../connection-monitoring-and-pooling/connection-monitoring-and-pooling.html">Connection Monitoring and Pooling spec</a>.</p>
<h4 id="connection-generation-number"><a class="header" href="#connection-generation-number">connection generation number</a></h4>
<p>The pool's generation number at the time this connection was created. Defined in the
<a href="server-discovery-and-monitoring/../connection-monitoring-and-pooling/connection-monitoring-and-pooling.html">Connection Monitoring and Pooling spec</a>.</p>
<h4 id="error-generation-number"><a class="header" href="#error-generation-number">error generation number</a></h4>
<p>The error's generation number is the generation of the connection on which the application error occurred. Note that
when a network error occurs before the handshake completes then the error's generation number is the generation of the
pool at the time the connection attempt was started.</p>
<h4 id="state-change-error"><a class="header" href="#state-change-error">State Change Error</a></h4>
<p>A server reply document indicating a "not writable primary" or "node is recovering" error. Starting in MongoDB 4.4 these
errors may also include a <a href="server-discovery-and-monitoring/server-discovery-and-monitoring.html#topologyversion">topologyVersion</a> field.</p>
<h3 id="data-structures"><a class="header" href="#data-structures">Data structures</a></h3>
<p>This spec uses a few data structures to describe the client's view of the topology. It must be emphasized that a driver
is free to implement the same behavior using different data structures. This spec uses these enums and structs in order
to describe driver <strong>behavior</strong>, not to mandate how a driver represents the topology, nor to mandate an API.</p>
<h4 id="constants"><a class="header" href="#constants">Constants</a></h4>
<h5 id="clientminwireversion-and-clientmaxwireversion"><a class="header" href="#clientminwireversion-and-clientmaxwireversion">clientMinWireVersion and clientMaxWireVersion</a></h5>
<p>Integers. The wire protocol range supported by the client.</p>
<h4 id="enums"><a class="header" href="#enums">Enums</a></h4>
<h5 id="topologytype"><a class="header" href="#topologytype">TopologyType</a></h5>
<p>Single, ReplicaSetNoPrimary, ReplicaSetWithPrimary, Sharded, LoadBalanced, or Unknown.</p>
<p>See <a href="server-discovery-and-monitoring/server-discovery-and-monitoring.html#updating-the-topologydescription">updating the TopologyDescription</a>.</p>
<h5 id="servertype"><a class="header" href="#servertype">ServerType</a></h5>
<p>Standalone, Mongos, PossiblePrimary, RSPrimary, RSSecondary, RSArbiter, RSOther, RSGhost, LoadBalancer or Unknown.</p>
<p>See <a href="server-discovery-and-monitoring/server-discovery-and-monitoring.html#parsing-a-hello-or-legacy-hello-response">parsing a hello or legacy hello response</a>.</p>
<blockquote>
<p>[!NOTE]
Single-threaded clients use the PossiblePrimary type to maintain proper
<a href="server-discovery-and-monitoring/server-monitoring.html#scanning-order">scanning order</a>. Multi-threaded and asynchronous clients do not need this
ServerType; it is synonymous with Unknown.</p>
</blockquote>
<p><span id="TopologyDescription"></span></p>
<h4 id="topologydescription"><a class="header" href="#topologydescription">TopologyDescription</a></h4>
<p>The client's representation of everything it knows about the deployment's topology.</p>
<p>Fields:</p>
<ul>
<li>type: a <a href="server-discovery-and-monitoring/server-discovery-and-monitoring.html#topologytype">TopologyType</a> enum value. See <a href="server-discovery-and-monitoring/server-discovery-and-monitoring.html#initial-topologytype">initial TopologyType</a>.</li>
<li>setName: the replica set name. Default null.</li>
<li>maxElectionId: an ObjectId or null. The largest electionId ever reported by a primary. Default null. Part of the
(<code>electionId</code>, <code>setVersion</code>) tuple.</li>
<li>maxSetVersion: an integer or null. The largest setVersion ever reported by a primary. It may not monotonically
increase, as electionId takes precedence in ordering Default null. Part of the (<code>electionId</code>, <code>setVersion</code>) tuple.</li>
<li>servers: a set of ServerDescription instances. Default contains one server: "localhost:27017", ServerType Unknown.</li>
<li>stale: a boolean for single-threaded clients, whether the topology must be re-scanned. (Not related to
maxStalenessSeconds, nor to stale primaries.)</li>
<li>compatible: a boolean. False if any server's wire protocol version range is incompatible with the client's. Default
true.</li>
<li>compatibilityError: a string. The error message if "compatible" is false, otherwise null.</li>
<li>logicalSessionTimeoutMinutes: integer or null. Default null. See <a href="server-discovery-and-monitoring/server-discovery-and-monitoring.html#logical-session-timeout">logical session timeout</a>.</li>
</ul>
<h4 id="serverdescription"><a class="header" href="#serverdescription">ServerDescription</a></h4>
<p>The client's view of a single server, based on the most recent hello or legacy hello outcome.</p>
<p>Again, drivers may store this information however they choose; this data structure is defined here merely to describe
the monitoring algorithm.</p>
<p>Fields:</p>
<ul>
<li>address: the hostname or IP, and the port number, that the client connects to. Note that this is <strong>not</strong> the "me"
field in the server's hello or legacy hello response, in the case that the server reports an address different from
the address the client uses.</li>
<li>(=) error: information about the last error related to this server. Default null.</li>
<li>roundTripTime: the duration of the hello or legacy hello call. Default null.</li>
<li>minRoundTripTime: the minimum RTT for the server. Default null.</li>
<li>lastWriteDate: a 64-bit BSON datetime or null. The "lastWriteDate" from the server's most recent hello or legacy hello
response.</li>
<li>opTime: an opTime or null. An opaque value representing the position in the oplog of the most recently seen write.
Default null. (Only mongos and shard servers record this field when monitoring config servers as replica sets, at
least until
<a href="server-discovery-and-monitoring/../max-staleness/max-staleness.html#future-feature-to-support-readconcern-afteroptime">drivers allow applications to use readConcern "afterOptime".</a>)</li>
<li>(=) type: a <a href="server-discovery-and-monitoring/server-discovery-and-monitoring.html#servertype">ServerType</a> enum value. Default Unknown.</li>
<li>(=) minWireVersion, maxWireVersion: the wire protocol version range supported by the server. Both default to 0.
<a href="server-discovery-and-monitoring/server-discovery-and-monitoring.html#checking-wire-protocol-compatibility">Use min and maxWireVersion only to determine compatibility</a>.</li>
<li>(=) me: The hostname or IP, and the port number, that this server was configured with in the replica set. Default
null.</li>
<li>(=) hosts, passives, arbiters: Sets of addresses. This server's opinion of the replica set's members, if any. These
<a href="server-discovery-and-monitoring/server-discovery-and-monitoring.html#hostnames-are-normalized-to-lower-case">hostnames are normalized to lower-case</a>. Default empty. The client monitors
all three types of servers in a replica set.</li>
<li>(=) tags: map from string to string. Default empty.</li>
<li>(=) setName: string or null. Default null.</li>
<li>(=) electionId: an ObjectId, if this is a MongoDB 2.6+ replica set member that believes it is primary. See
<a href="server-discovery-and-monitoring/server-discovery-and-monitoring.html#using-electionid-and-setversion-to-detect-stale-primaries">using electionId and setVersion to detect stale primaries</a>.
Default null.</li>
<li>(=) setVersion: integer or null. Default null.</li>
<li>(=) primary: an address. This server's opinion of who the primary is. Default null.</li>
<li>lastUpdateTime: when this server was last checked. Default "infinity ago".</li>
<li>(=) logicalSessionTimeoutMinutes: integer or null. Default null.</li>
<li>(=) topologyVersion: A topologyVersion or null. Default null. The "topologyVersion" from the server's most recent
hello or legacy hello response or <a href="server-discovery-and-monitoring/server-discovery-and-monitoring.html#state-change-error">State Change Error</a>.</li>
<li>(=) iscryptd: boolean indicating if the server is a
<a href="server-discovery-and-monitoring/../client-side-encryption/client-side-encryption.html#mongocryptd">mongocryptd</a> server. Default null.</li>
</ul>
<p>"Passives" are priority-zero replica set members that cannot become primary. The client treats them precisely the same
as other members.</p>
<p>Fields marked (=) are used for <a href="server-discovery-and-monitoring/server-discovery-and-monitoring.html#server-description-equality">Server Description Equality</a> comparison.</p>
<h3 id="configuration"><a class="header" href="#configuration">Configuration</a></h3>
<h4 id="no-breaking-changes"><a class="header" href="#no-breaking-changes">No breaking changes</a></h4>
<p>This spec does not intend to require any drivers to make breaking changes regarding what configuration options are
available, how options are named, or what combinations of options are allowed.</p>
<h4 id="initial-topologydescription"><a class="header" href="#initial-topologydescription">Initial TopologyDescription</a></h4>
<p>The default values for <a href="server-discovery-and-monitoring/server-discovery-and-monitoring.html#topologydescription">TopologyDescription</a> fields are described above. Users may override the
defaults as follows:</p>
<h5 id="initial-servers"><a class="header" href="#initial-servers">Initial Servers</a></h5>
<p>The user MUST be able to set the initial servers list to a <a href="server-discovery-and-monitoring/server-discovery-and-monitoring.html#seed-list">seed list</a> of one or more addresses.</p>
<p>The hostname portion of each address MUST be normalized to lower-case.</p>
<h5 id="initial-topologytype"><a class="header" href="#initial-topologytype">Initial TopologyType</a></h5>
<p>If the <code>directConnection</code> URI option is specified when a MongoClient is constructed, the TopologyType must be
initialized based on the value of the <code>directConnection</code> option and the presence of the <code>replicaSet</code> option according to
the following table:</p>
<div class="table-wrapper"><table><thead><tr><th>directConnection</th><th>replicaSet present</th><th>Initial TopologyType</th></tr></thead><tbody>
<tr><td>true</td><td>no</td><td>Single</td></tr>
<tr><td>true</td><td>yes</td><td>Single</td></tr>
<tr><td>false</td><td>no</td><td>Unknown</td></tr>
<tr><td>false</td><td>yes</td><td>ReplicaSetNoPrimary</td></tr>
</tbody></table>
</div>
<p>If the <code>directConnection</code> option is not specified, newly developed drivers MUST behave as if it was specified with the
false value.</p>
<p>Since changing the starting topology can reasonably be considered a backwards-breaking change, existing drivers SHOULD
stage implementation according to semantic versioning guidelines. Specifically, support for the <code>directConnection</code> URI
option can be added in a minor release. In a subsequent major release, the default starting topology can be changed to
Unknown. Drivers MUST document this in a prior minor release.</p>
<p>Existing drivers MUST deprecate other URI options, if any, for controlling topology discovery or specifying the
deployment topology. If such a legacy option is specified and the <code>directConnection</code> option is also specified, and the
values of the two options are semantically different, the driver MUST report an error during URI option parsing.</p>
<p>The API for initializing TopologyType using language-specific native options is not specified here. Drivers might
already have a convention, e.g. a single seed means Single, a setName means ReplicaSetNoPrimary, and a list of seeds
means Unknown. There are variations, however: In the Java driver a single seed means Single, but a <strong>list</strong> containing
one seed means Unknown, so it can transition to replica-set monitoring if the seed is discovered to be a replica set
member. In contrast, PyMongo requires a non-null setName in order to begin replica-set monitoring, regardless of the
number of seeds. This spec does not cover language-specific native options that a driver may provide.</p>
<h5 id="initial-setname"><a class="header" href="#initial-setname">Initial setName</a></h5>
<p>It is allowed to use <code>directConnection=true</code> in conjunction with the <code>replicaSet</code> URI option. The driver must connect in
Single topology and verify that setName matches the specified name, as per
<a href="server-discovery-and-monitoring/server-discovery-and-monitoring.html#verifying-setname-with-topologytype-single">verifying setName with TopologyType Single</a>.</p>
<p>When a MongoClient is initialized using language-specific native options, the user MUST be able to set the client's
initial replica set name. A driver MAY require the set name in order to connect to a replica set, or it MAY be able to
discover the replica set name as it connects.</p>
<h5 id="allowed-configuration-combinations"><a class="header" href="#allowed-configuration-combinations">Allowed configuration combinations</a></h5>
<p>Drivers MUST enforce:</p>
<ul>
<li>TopologyType Single cannot be used with multiple seeds.</li>
<li><code>directConnection=true</code> cannot be used with multiple seeds.</li>
<li>If setName is not null, only TopologyType ReplicaSetNoPrimary, and possibly Single, are allowed. (See
<a href="server-discovery-and-monitoring/server-discovery-and-monitoring.html#verifying-setname-with-topologytype-single">verifying setName with TopologyType Single</a>.)</li>
<li><code>loadBalanced=true</code> cannot be used in conjunction with <code>directConnection=true</code> or <code>replicaSet</code></li>
</ul>
<h5 id="handling-of-srv-uris-resolving-to-single-host"><a class="header" href="#handling-of-srv-uris-resolving-to-single-host">Handling of SRV URIs resolving to single host</a></h5>
<p>When a driver is given an SRV URI, if the <code>directConnection</code> URI option is not specified, and the <code>replicaSet</code> URI
option is not specified, the driver MUST start in Unknown topology, and follow the rules in the
<a href="server-discovery-and-monitoring/server-discovery-and-monitoring.html#topologytype-table">TopologyType table</a> for transitioning to other topologies. In particular, the driver MUST NOT use
the number of hosts from the initial SRV lookup to decide what topology to start in.</p>
<p><span id="heartbeatFrequencyMS"></span></p>
<h4 id="heartbeatfrequencyms"><a class="header" href="#heartbeatfrequencyms">heartbeatFrequencyMS</a></h4>
<p>The interval between server <a href="server-discovery-and-monitoring/server-discovery-and-monitoring.html#check">checks</a>, counted from the end of the previous check until the beginning of the next
one.</p>
<p>For multi-threaded and asynchronous drivers it MUST default to 10 seconds and MUST be configurable. For single-threaded
drivers it MUST default to 60 seconds and MUST be configurable. It MUST be called heartbeatFrequencyMS unless this
breaks backwards compatibility.</p>
<p>For both multi- and single-threaded drivers, the driver MUST NOT permit users to configure it less than
minHeartbeatFrequencyMS (500ms).</p>
<p>(See
<a href="server-discovery-and-monitoring/server-discovery-and-monitoring.html#heartbeatfrequencyms-defaults-to-10-seconds-or-60-seconds">heartbeatFrequencyMS defaults to 10 seconds or 60 seconds</a>
and <a href="server-discovery-and-monitoring/server-discovery-and-monitoring.html#whats-the-point-of-periodic-monitoring">what's the point of periodic monitoring?</a>)</p>
<h3 id="client-construction"><a class="header" href="#client-construction">Client construction</a></h3>
<p>Except for <a href="server-discovery-and-monitoring/../initial-dns-seedlist-discovery/initial-dns-seedlist-discovery.html">initial DNS seed list discovery</a> when
given a connection string with <code>mongodb+srv</code> scheme, the client's constructor MUST NOT do any I/O. This means that the
constructor does not throw an exception if servers are unavailable: the topology is not yet known when the constructor
returns. Similarly if a server has an incompatible wire protocol version, the constructor does not throw. Instead, all
subsequent operations on the client fail as long as the error persists.</p>
<p>See <a href="server-discovery-and-monitoring/server-discovery-and-monitoring.html#clients-do-no-io-in-the-constructor">clients do no I/O in the constructor</a> for the justification.</p>
<h4 id="multi-threaded-and-asynchronous-client-construction"><a class="header" href="#multi-threaded-and-asynchronous-client-construction">Multi-threaded and asynchronous client construction</a></h4>
<p>The constructor MAY start the monitors as background tasks and return immediately. Or the monitors MAY be started by
some method separate from the constructor; for example they MAY be started by some "initialize" method (by any name), or
on the first use of the client for an operation.</p>
<h4 id="single-threaded-client-construction"><a class="header" href="#single-threaded-client-construction">Single-threaded client construction</a></h4>
<p>Single-threaded clients do no I/O in the constructor. They MUST <a href="server-discovery-and-monitoring/server-discovery-and-monitoring.html#scan">scan</a> the servers on demand, when the first
operation is attempted.</p>
<h3 id="client-closing"><a class="header" href="#client-closing">Client closing</a></h3>
<p>When a client is closing, before it emits the <code>TopologyClosedEvent</code> as per the
<a href="server-discovery-and-monitoring/./server-discovery-and-monitoring-logging-and-monitoring.html#events-api">Events API</a>, it SHOULD <a href="server-discovery-and-monitoring/server-discovery-and-monitoring.html#remove">remove</a> all
servers from its <code>TopologyDescription</code> and set its <code>TopologyType</code> to <code>Unknown</code>, emitting the corresponding
<code>TopologyDescriptionChangedEvent</code>.</p>
<h3 id="monitoring"><a class="header" href="#monitoring">Monitoring</a></h3>
<p>See the <a href="server-discovery-and-monitoring/server-monitoring.html">Server Monitoring spec</a> for how a driver monitors each server. In summary, the client
monitors each server in the topology. The scope of server monitoring is to provide the topology with updated
ServerDescriptions based on hello or legacy hello command responses.</p>
<h3 id="parsing-a-hello-or-legacy-hello-response"><a class="header" href="#parsing-a-hello-or-legacy-hello-response">Parsing a hello or legacy hello response</a></h3>
<p>The client represents its view of each server with a <a href="server-discovery-and-monitoring/server-discovery-and-monitoring.html#serverdescription">ServerDescription</a>. Each time the client
<a href="server-discovery-and-monitoring/server-discovery-and-monitoring.html#check">checks</a> a server, it MUST replace its description of that server with a new one if and only if the new
ServerDescription's <a href="server-discovery-and-monitoring/server-discovery-and-monitoring.html#topologyversion">topologyVersion</a> is greater than or equal to the current ServerDescription's
<a href="server-discovery-and-monitoring/server-discovery-and-monitoring.html#topologyversion">topologyVersion</a>.</p>
<p>(See <a href="server-discovery-and-monitoring/server-discovery-and-monitoring.html#replacing-the-topologydescription">Replacing the TopologyDescription</a> for an example implementation.)</p>
<p>This replacement MUST happen even if the new server description compares equal to the previous one, in order to keep
client-tracked attributes like last update time and round trip time up to date.</p>
<p>Drivers MUST be able to handle responses to both <code>hello</code> and legacy hello commands. When checking results, drivers MUST
first check for the <code>isWritablePrimary</code> field and fall back to checking for an <code>ismaster</code> field if <code>isWritablePrimary</code>
was not found.</p>
<p>ServerDescriptions are created from hello or legacy hello outcomes as follows:</p>
<h4 id="type"><a class="header" href="#type">type</a></h4>
<p>The new ServerDescription's type field is set to a <a href="server-discovery-and-monitoring/server-discovery-and-monitoring.html#servertype">ServerType</a>. Note that these states do <strong>not</strong> exactly
correspond to <a href="https://www.mongodb.com/docs/manual/reference/replica-states/">replica set member states</a>. For example,
some replica set member states like STARTUP and RECOVERING are identical from the client's perspective, so they are
merged into "RSOther". Additionally, states like Standalone and Mongos are not replica set member states at all.</p>
<div class="table-wrapper"><table><thead><tr><th>State</th><th>Symptoms</th></tr></thead><tbody>
<tr><td>Unknown</td><td>Initial, or after a network error or failed hello or legacy hello call, or "ok: 1" not in hello or legacy hello response.</td></tr>
<tr><td>Standalone</td><td>No "msg: isdbgrid", no setName, and no "isreplicaset: true".</td></tr>
<tr><td>Mongos</td><td>"msg: isdbgrid".</td></tr>
<tr><td>PossiblePrimary</td><td>Not yet checked, but another member thinks it is the primary.</td></tr>
<tr><td>RSPrimary</td><td>"isWritablePrimary: true" or "ismaster: true", "setName" in response.</td></tr>
<tr><td>RSSecondary</td><td>"secondary: true", "setName" in response.</td></tr>
<tr><td>RSArbiter</td><td>"arbiterOnly: true", "setName" in response.</td></tr>
<tr><td>RSOther</td><td>"setName" in response, "hidden: true" or not primary, secondary, nor arbiter.</td></tr>
<tr><td>RSGhost</td><td>"isreplicaset: true" in response.</td></tr>
<tr><td>LoadBalanced</td><td>"loadBalanced=true" in URI.</td></tr>
</tbody></table>
</div>
<p>A server can transition from any state to any other. For example, an administrator could shut down a secondary and bring
up a mongos in its place.</p>
<h5 id="rsghost-and-rsother"><a class="header" href="#rsghost-and-rsother">RSGhost and RSOther</a></h5>
<p>The client MUST monitor replica set members even when they cannot be queried. These members are in state RSGhost or
RSOther.</p>
<p><strong>RSGhost</strong> members occur in at least three situations:</p>
<ul>
<li>briefly during server startup,</li>
<li>in an uninitialized replica set,</li>
<li>or when the server is shunned (removed from the replica set config).</li>
</ul>
<p>An RSGhost server has no hosts list nor setName. Therefore the client MUST NOT attempt to use its hosts list nor check
its setName (see <a href="https://jira.mongodb.org/browse/JAVA-1161">JAVA-1161</a> or
<a href="https://jira.mongodb.org/browse/CSHARP-671">CSHARP-671</a>.) However, the client MUST keep the RSGhost member in its
TopologyDescription, in case the client's only hope for staying connected to the replica set is that this member will
transition to a more useful state.</p>
<p>For simplicity, this is the rule: any server is an RSGhost that reports "isreplicaset: true".</p>
<p>Non-ghost replica set members have reported their setNames since MongoDB 1.6.2. See
<a href="server-discovery-and-monitoring/server-discovery-and-monitoring.html#only-support-replica-set-members-running-mongodb-162-or-later">only support replica set members running MongoDB 1.6.2 or later</a>.</p>
<blockquote>
<p>[!NOTE]
The Java driver does not have a separate state for RSGhost; it is an RSOther server with no hosts list.</p>
</blockquote>
<p><strong>RSOther</strong> servers may be hidden, starting up, or recovering. They cannot be queried, but their hosts lists are useful
for discovering the current replica set configuration.</p>
<p>If a <a href="https://www.mongodb.com/docs/manual/core/replica-set-hidden-member/">hidden member</a> is provided as a seed, the
client can use it to find the primary. Since the hidden member does not appear in the primary's host list, it will be
removed once the primary is checked.</p>
<h4 id="error"><a class="header" href="#error">error</a></h4>
<p>If the client experiences any error when checking a server, it stores error information in the ServerDescription's error
field.</p>
<h4 id="roundtriptime"><a class="header" href="#roundtriptime">roundTripTime</a></h4>
<p>Drivers MUST record the server's <a href="server-discovery-and-monitoring/server-discovery-and-monitoring.html#round-trip-time">round trip time</a> (RTT) after each successful call to hello or legacy
hello. The Server Selection Spec describes how RTT is averaged and how it is used in server selection. Drivers MUST also
record the server's minimum RTT per <a href="server-discovery-and-monitoring/server-monitoring.html#measuring-rtt">Server Monitoring (Measuring RTT)</a>.</p>
<p>If a hello or legacy hello call fails, the RTT is not updated. Furthermore, while a server's type is Unknown its RTT is
null, and if it changes from a known type to Unknown its RTT is set to null. However, if it changes from one known type
to another (e.g. from RSPrimary to RSSecondary) its RTT is updated normally, not set to null nor restarted from scratch.</p>
<h4 id="lastwritedate-and-optime"><a class="header" href="#lastwritedate-and-optime">lastWriteDate and opTime</a></h4>
<p>The hello or legacy hello response of a replica set member running MongoDB 3.4 and later contains a <code>lastWrite</code>
subdocument with fields <code>lastWriteDate</code> and <code>opTime</code> (<a href="https://jira.mongodb.org/browse/SERVER-8858">SERVER-8858</a>). If
these fields are available, parse them from the hello or legacy hello response, otherwise set them to null.</p>
<p>Clients MUST NOT attempt to compensate for the network latency between when the server generated its hello or legacy
hello response and when the client records <code>lastUpdateTime</code>.</p>
<h4 id="lastupdatetime"><a class="header" href="#lastupdatetime">lastUpdateTime</a></h4>
<p>Clients SHOULD set lastUpdateTime with a monotonic clock.</p>
<h4 id="hostnames-are-normalized-to-lower-case"><a class="header" href="#hostnames-are-normalized-to-lower-case">Hostnames are normalized to lower-case</a></h4>
<p>The same as with seeds provided in the initial configuration, all hostnames in the hello or legacy hello response's
"me", "hosts", "passives", and "arbiters" entries MUST be lower-cased.</p>
<p>This prevents unnecessary work rediscovering a server if a seed "A" is provided and the server responds that "a" is in
the replica set.</p>
<p><a href="http://tools.ietf.org/html/rfc4343">RFC 4343</a>:</p>
<blockquote>
<p>Domain Name System (DNS) names are "case insensitive".</p>
</blockquote>
<h4 id="logicalsessiontimeoutminutes"><a class="header" href="#logicalsessiontimeoutminutes">logicalSessionTimeoutMinutes</a></h4>
<p>MongoDB 3.6 and later include a <code>logicalSessionTimeoutMinutes</code> field if logical sessions are enabled in the deployment.
Clients MUST check for this field and set the ServerDescription's logicalSessionTimeoutMinutes field to this value, or
to null otherwise.</p>
<h4 id="topologyversion"><a class="header" href="#topologyversion">topologyVersion</a></h4>
<p>MongoDB 4.4 and later include a <code>topologyVersion</code> field in all hello or legacy hello and
<a href="server-discovery-and-monitoring/server-discovery-and-monitoring.html#state-change-error">State Change Error</a> responses. Clients MUST check for this field and set the ServerDescription's
topologyVersion field to this value, if present. The topologyVersion helps the client and server determine the relative
freshness of topology information in concurrent messages. (See
<a href="server-discovery-and-monitoring/server-discovery-and-monitoring.html#what-is-the-purpose-of-topologyversion">What is the purpose of topologyVersion?</a>)</p>
<p>The topologyVersion is a subdocument with two fields, "processId" and "counter":</p>
<pre><code class="language-typescript">{
    topologyVersion: {processId: &lt;ObjectId&gt;, counter: &lt;int64&gt;},
    ( ... other fields ...)
}
</code></pre>
<h5 id="topologyversion-comparison"><a class="header" href="#topologyversion-comparison">topologyVersion Comparison</a></h5>
<p>To compare a topologyVersion from a hello or legacy hello or State Change Error response to the current
ServerDescription's topologyVersion:</p>
<ol>
<li>If the response topologyVersion is unset or the ServerDescription's topologyVersion is null, the client MUST assume
the response is more recent.</li>
<li>If the response's topologyVersion.processId is not equal to the ServerDescription's, the client MUST assume the
response is more recent.</li>
<li>If the response's topologyVersion.processId is equal to the ServerDescription's, the client MUST use the counter
field to determine which topologyVersion is more recent.</li>
</ol>
<p>See <a href="server-discovery-and-monitoring/server-discovery-and-monitoring.html#replacing-the-topologydescription">Replacing the TopologyDescription</a> for an example implementation of
topologyVersion comparison.</p>
<h4 id="serviceid"><a class="header" href="#serviceid">serviceId</a></h4>
<p>MongoDB 5.0 and later, as well as any mongos-like service, include a <code>serviceId</code> field when the service is configured
behind a load balancer.</p>
<h4 id="other-serverdescription-fields"><a class="header" href="#other-serverdescription-fields">Other ServerDescription fields</a></h4>
<p>Other required fields defined in the <a href="server-discovery-and-monitoring/server-discovery-and-monitoring.html#serverdescription">ServerDescription</a> data structure are parsed from the hello or
legacy hello response in the obvious way.</p>
<h4 id="server-description-equality"><a class="header" href="#server-description-equality">Server Description Equality</a></h4>
<p>For the purpose of determining whether to publish SDAM events, two server descriptions having the same address MUST be
considered equal if and only if the values of <a href="server-discovery-and-monitoring/server-discovery-and-monitoring.html#serverdescription">ServerDescription</a> fields marked (=) are respectively
equal.</p>
<p>This specification does not prescribe how to compare server descriptions with different addresses for equality.</p>
<h3 id="updating-the-topologydescription"><a class="header" href="#updating-the-topologydescription">Updating the TopologyDescription</a></h3>
<p>Each time the client checks a server, it processes the outcome (successful or not) to create a
<a href="server-discovery-and-monitoring/server-discovery-and-monitoring.html#serverdescription">ServerDescription</a>, and then it processes the ServerDescription to update its
<a href="server-discovery-and-monitoring/server-discovery-and-monitoring.html#topologydescription">TopologyDescription</a>.</p>
<p>The TopologyDescription's <a href="server-discovery-and-monitoring/server-discovery-and-monitoring.html#topologytype">TopologyType</a> influences how the ServerDescription is processed. The following
subsection specifies how the client updates its TopologyDescription when the TopologyType is Single. The next subsection
treats the other types.</p>
<h4 id="topologytype-single"><a class="header" href="#topologytype-single">TopologyType Single</a></h4>
<p>The TopologyDescription's type was initialized as Single and remains Single forever. There is always one
ServerDescription in TopologyDescription.servers.</p>
<p>Whenever the client checks a server (successfully or not), and regardless of whether the new server description is equal
to the previous server description as defined in <a href="server-discovery-and-monitoring/server-discovery-and-monitoring.html#server-description-equality">Server Description Equality</a>, the
ServerDescription in TopologyDescription.servers MUST be replaced with the new ServerDescription.</p>
<p><span id="checking-wire-protocol-compatibility"></span></p>
<h5 id="checking-wire-protocol-compatibility"><a class="header" href="#checking-wire-protocol-compatibility">Checking wire protocol compatibility</a></h5>
<p>A ServerDescription which is not Unknown is incompatible if:</p>
<ul>
<li>minWireVersion &gt; clientMaxWireVersion, or</li>
<li>maxWireVersion &lt; clientMinWireVersion</li>
</ul>
<p>If any ServerDescription is incompatible, the client MUST set the TopologyDescription's "compatible" field to false and
fill out the TopologyDescription's "compatibilityError" field like so:</p>
<ul>
<li>
<p>if ServerDescription.minWireVersion &gt; clientMaxWireVersion:</p>
<p>"Server at $host:$port requires wire version $minWireVersion, but this version of $driverName only supports up to
$clientMaxWireVersion."</p>
</li>
<li>
<p>if ServerDescription.maxWireVersion &lt; clientMinWireVersion:</p>
<p>"Server at $host:$port reports wire version $maxWireVersion, but this version of $driverName requires at least
$clientMinWireVersion (MongoDB $mongoVersion)."</p>
</li>
</ul>
<p>Replace $mongoVersion with the appropriate MongoDB minor version, for example if clientMinWireVersion is 2 and it
connects to MongoDB 2.4, format the error like:</p>
<blockquote>
<p>"Server at example.com:27017 reports wire version 0, but this version of My Driver requires at least 2 (MongoDB 2.6)."</p>
</blockquote>
<p>In this second case, the exact required MongoDB version is known and can be named in the error message, whereas in the
first case the implementer does not know which MongoDB versions will be compatible or incompatible in the future.</p>
<h5 id="verifying-setname-with-topologytype-single"><a class="header" href="#verifying-setname-with-topologytype-single">Verifying setName with TopologyType Single</a></h5>
<p>A client MAY allow the user to supply a setName with an initial TopologyType of Single. In this case, if the
ServerDescription's setName is null or wrong, the ServerDescription MUST be replaced with a default ServerDescription of
type Unknown.</p>
<h4 id="topologytype-loadbalanced"><a class="header" href="#topologytype-loadbalanced">TopologyType LoadBalanced</a></h4>
<p>See the <a href="server-discovery-and-monitoring/../load-balancers/load-balancers.html#server-discovery-logging-and-monitoring">Load Balancer Specification</a> for
details.</p>
<h4 id="other-topologytypes"><a class="header" href="#other-topologytypes">Other TopologyTypes</a></h4>
<p>If the TopologyType is <strong>not</strong> Single, the topology can contain zero or more servers. The state of topology containing
zero servers is terminal (because servers can only be added if they are reported by a server already in the topology). A
client SHOULD emit a warning if it is constructed with no seeds in the initial seed list. A client SHOULD emit a warning
when, in the process of updating its topology description, it removes the last server from the topology.</p>
<p>Whenever a client completes a hello or legacy hello call, it creates a new ServerDescription with the proper
<a href="server-discovery-and-monitoring/server-discovery-and-monitoring.html#servertype">ServerType</a>. It replaces the server's previous description in TopologyDescription.servers with the new
one.</p>
<p>Apply the logic for <a href="server-discovery-and-monitoring/server-discovery-and-monitoring.html#checking-wire-protocol-compatibility">checking wire protocol compatibility</a> to each
ServerDescription in the topology. If any server's wire protocol version range does not overlap with the client's, the
client updates the "compatible" and "compatibilityError" fields as described above for TopologyType Single. Otherwise
"compatible" is set to true.</p>
<p>It is possible for a multi-threaded client to receive a hello or legacy hello outcome from a server after the server has
been removed from the TopologyDescription. For example, a monitor begins checking a server "A", then a different monitor
receives a response from the primary claiming that "A" has been removed from the replica set, so the client removes "A"
from the TopologyDescription. Then, the check of server "A" completes.</p>
<p>In all cases, the client MUST ignore hello or legacy hello outcomes from servers that are not in the
TopologyDescription.</p>
<p>The following subsections explain in detail what actions the client takes after replacing the ServerDescription.</p>
<h5 id="topologytype-table"><a class="header" href="#topologytype-table">TopologyType table</a></h5>
<p>The new ServerDescription's type is the vertical axis, and the current TopologyType is the horizontal. Where a
ServerType and a TopologyType intersect, the table shows what action the client takes.</p>
<p>"no-op" means, do nothing <strong>after</strong> replacing the server's old description with the new one.</p>
<div class="table-wrapper"><table><thead><tr><th></th><th>TopologyType Unknown</th><th>TopologyType Sharded</th><th>TopologyType ReplicaSetNoPrimary</th><th>TopologyType ReplicaSetWithPrimary</th></tr></thead><tbody>
<tr><td>ServerType Unknown</td><td>no-op</td><td>no-op</td><td>no-op</td><td><a href="server-discovery-and-monitoring/server-discovery-and-monitoring.html#checkifhasprimary">checkIfHasPrimary</a></td></tr>
<tr><td>ServerType Standalone</td><td><a href="server-discovery-and-monitoring/server-discovery-and-monitoring.html#updateunknownwithstandalone">updateUnknownWithStandalone</a></td><td><a href="server-discovery-and-monitoring/server-discovery-and-monitoring.html#remove">remove</a></td><td><a href="server-discovery-and-monitoring/server-discovery-and-monitoring.html#remove">remove</a></td><td><a href="server-discovery-and-monitoring/server-discovery-and-monitoring.html#remove">remove</a> and <a href="server-discovery-and-monitoring/server-discovery-and-monitoring.html#checkifhasprimary">checkIfHasPrimary</a></td></tr>
<tr><td>ServerType Mongos</td><td>Set topology type to Sharded</td><td>no-op</td><td><a href="server-discovery-and-monitoring/server-discovery-and-monitoring.html#remove">remove</a></td><td><a href="server-discovery-and-monitoring/server-discovery-and-monitoring.html#remove">remove</a> and <a href="server-discovery-and-monitoring/server-discovery-and-monitoring.html#checkifhasprimary">checkIfHasPrimary</a></td></tr>
<tr><td>ServerType RSPrimary</td><td>Set topology type to ReplicaSetWithPrimary then <a href="server-discovery-and-monitoring/server-discovery-and-monitoring.html#updatersfromprimary">updateRSFromPrimary</a></td><td><a href="server-discovery-and-monitoring/server-discovery-and-monitoring.html#remove">remove</a></td><td>Set topology type to ReplicaSetWithPrimary then <a href="server-discovery-and-monitoring/server-discovery-and-monitoring.html#updatersfromprimary">updateRSFromPrimary</a></td><td><a href="server-discovery-and-monitoring/server-discovery-and-monitoring.html#updatersfromprimary">updateRSFromPrimary</a></td></tr>
<tr><td>ServerType RSSecondary</td><td>Set topology type to ReplicaSetNoPrimary then <a href="server-discovery-and-monitoring/server-discovery-and-monitoring.html#updaterswithoutprimary">updateRSWithoutPrimary</a></td><td><a href="server-discovery-and-monitoring/server-discovery-and-monitoring.html#remove">remove</a></td><td><a href="server-discovery-and-monitoring/server-discovery-and-monitoring.html#updaterswithoutprimary">updateRSWithoutPrimary</a></td><td><a href="server-discovery-and-monitoring/server-discovery-and-monitoring.html#updaterswithprimaryfrommember">updateRSWithPrimaryFromMember</a></td></tr>
<tr><td>ServerType RSArbiter</td><td>Set topology type to ReplicaSetNoPrimary then <a href="server-discovery-and-monitoring/server-discovery-and-monitoring.html#updaterswithoutprimary">updateRSWithoutPrimary</a></td><td><a href="server-discovery-and-monitoring/server-discovery-and-monitoring.html#remove">remove</a></td><td><a href="server-discovery-and-monitoring/server-discovery-and-monitoring.html#updaterswithoutprimary">updateRSWithoutPrimary</a></td><td><a href="server-discovery-and-monitoring/server-discovery-and-monitoring.html#updaterswithprimaryfrommember">updateRSWithPrimaryFromMember</a></td></tr>
<tr><td>ServerType RSOther</td><td>Set topology type to ReplicaSetNoPrimary then <a href="server-discovery-and-monitoring/server-discovery-and-monitoring.html#updaterswithoutprimary">updateRSWithoutPrimary</a></td><td><a href="server-discovery-and-monitoring/server-discovery-and-monitoring.html#remove">remove</a></td><td><a href="server-discovery-and-monitoring/server-discovery-and-monitoring.html#updaterswithoutprimary">updateRSWithoutPrimary</a></td><td><a href="server-discovery-and-monitoring/server-discovery-and-monitoring.html#updaterswithprimaryfrommember">updateRSWithPrimaryFromMember</a></td></tr>
<tr><td>ServerType RSGhost</td><td>no-op<sup class="footnote-reference"><a href="#2">2</a></sup></td><td><a href="server-discovery-and-monitoring/server-discovery-and-monitoring.html#remove">remove</a></td><td>no-op</td><td><a href="server-discovery-and-monitoring/server-discovery-and-monitoring.html#checkifhasprimary">checkIfHasPrimary</a></td></tr>
</tbody></table>
</div>
<h5 id="topologytype-explanations"><a class="header" href="#topologytype-explanations">TopologyType explanations</a></h5>
<p>This subsection complements the <a href="server-discovery-and-monitoring/server-discovery-and-monitoring.html#topologytype-table">TopologyType table</a> with prose explanations of the TopologyTypes
(besides Single and LoadBalanced).</p>
<p><strong>TopologyType Unknown</strong></p>
<p>A starting state.</p>
<p><strong>Actions</strong>:</p>
<ul>
<li>If the incoming ServerType is Unknown (that is, the hello or legacy hello call failed), keep the server in
TopologyDescription.servers. The TopologyType remains Unknown.</li>
<li>The
<a href="server-discovery-and-monitoring/server-discovery-and-monitoring.html#topologytype-remains-unknown-when-an-rsghost-is-discovered">TopologyType remains Unknown when an RSGhost is discovered</a>,
too.</li>
<li>If the type is Standalone, run <a href="server-discovery-and-monitoring/server-discovery-and-monitoring.html#updateunknownwithstandalone">updateUnknownWithStandalone</a>.</li>
<li>If the type is Mongos, set the TopologyType to Sharded.</li>
<li>If the type is RSPrimary, record its setName and call <a href="server-discovery-and-monitoring/server-discovery-and-monitoring.html#updatersfromprimary">updateRSFromPrimary</a>.</li>
<li>If the type is RSSecondary, RSArbiter or RSOther, record its setName, set the TopologyType to ReplicaSetNoPrimary, and
call <a href="server-discovery-and-monitoring/server-discovery-and-monitoring.html#updaterswithoutprimary">updateRSWithoutPrimary</a>.</li>
</ul>
<p><strong>TopologyType Sharded</strong></p>
<p>A steady state. Connected to one or more mongoses.</p>
<p><strong>Actions</strong>:</p>
<ul>
<li>If the server is Unknown or Mongos, keep it.</li>
<li>Remove others.</li>
</ul>
<p><strong>TopologyType ReplicaSetNoPrimary</strong></p>
<p>A starting state. The topology is definitely a replica set, but no primary is known.</p>
<p><strong>Actions</strong>:</p>
<ul>
<li>Keep Unknown servers.</li>
<li>Keep RSGhost servers: they are members of some replica set, perhaps this one, and may recover. (See
<a href="server-discovery-and-monitoring/server-discovery-and-monitoring.html#rsghost-and-rsother">RSGhost and RSOther</a>.)</li>
<li>Remove any Standalones or Mongoses.</li>
<li>If the type is RSPrimary call <a href="server-discovery-and-monitoring/server-discovery-and-monitoring.html#updatersfromprimary">updateRSFromPrimary</a>.</li>
<li>If the type is RSSecondary, RSArbiter or RSOther, run <a href="server-discovery-and-monitoring/server-discovery-and-monitoring.html#updaterswithoutprimary">updateRSWithoutPrimary</a>.</li>
</ul>
<p><strong>TopologyType ReplicaSetWithPrimary</strong></p>
<p>A steady state. The primary is known.</p>
<p><strong>Actions</strong>:</p>
<ul>
<li>If the server type is Unknown, keep it, and run <a href="server-discovery-and-monitoring/server-discovery-and-monitoring.html#checkifhasprimary">checkIfHasPrimary</a>.</li>
<li>Keep RSGhost servers: they are members of some replica set, perhaps this one, and may recover. (See
<a href="server-discovery-and-monitoring/server-discovery-and-monitoring.html#rsghost-and-rsother">RSGhost and RSOther</a>.) Run <a href="server-discovery-and-monitoring/server-discovery-and-monitoring.html#checkifhasprimary">checkIfHasPrimary</a>.</li>
<li>Remove any Standalones or Mongoses and run <a href="server-discovery-and-monitoring/server-discovery-and-monitoring.html#checkifhasprimary">checkIfHasPrimary</a>.</li>
<li>If the type is RSPrimary run <a href="server-discovery-and-monitoring/server-discovery-and-monitoring.html#updatersfromprimary">updateRSFromPrimary</a>.</li>
<li>If the type is RSSecondary, RSArbiter or RSOther, run <a href="server-discovery-and-monitoring/server-discovery-and-monitoring.html#updaterswithprimaryfrommember">updateRSWithPrimaryFromMember</a>.</li>
</ul>
<h4 id="actions"><a class="header" href="#actions">Actions</a></h4>
<h5 id="updateunknownwithstandalone"><a class="header" href="#updateunknownwithstandalone">updateUnknownWithStandalone</a></h5>
<p>This subroutine is executed with the ServerDescription from Standalone when the TopologyType is Unknown:</p>
<pre><code class="language-python">if description.address not in topologyDescription.servers:
    return

if settings.seeds has one seed:
    topologyDescription.type = Single
else:
    remove this server from topologyDescription and stop monitoring it
</code></pre>
<p>See
<a href="server-discovery-and-monitoring/server-discovery-and-monitoring.html#topologytype-remains-unknown-when-one-of-the-seeds-is-a-standalone">TopologyType remains Unknown when one of the seeds is a Standalone</a>.</p>
<p><span id="updateRSWithoutPrimary"></span></p>
<h5 id="updaterswithoutprimary"><a class="header" href="#updaterswithoutprimary">updateRSWithoutPrimary</a></h5>
<p>This subroutine is executed with the ServerDescription from an RSSecondary, RSArbiter, or RSOther when the TopologyType
is ReplicaSetNoPrimary:</p>
<pre><code class="language-python">if description.address not in topologyDescription.servers:
    return

if topologyDescription.setName is null:
    topologyDescription.setName = description.setName

else if topologyDescription.setName != description.setName:
    remove this server from topologyDescription and stop monitoring it
    return

for each address in description's "hosts", "passives", and "arbiters":
    if address is not in topologyDescription.servers:
        add new default ServerDescription of type "Unknown"
        begin monitoring the new server

if description.primary is not null:
    find the ServerDescription in topologyDescription.servers whose
    address equals description.primary

    if its type is Unknown, change its type to PossiblePrimary

if description.address != description.me:
    remove this server from topologyDescription and stop monitoring it
    return
</code></pre>
<p>Unlike <a href="server-discovery-and-monitoring/server-discovery-and-monitoring.html#updatersfromprimary">updateRSFromPrimary</a>, this subroutine does <strong>not</strong> remove any servers from the
TopologyDescription based on the list of servers in the "hosts" field of the hello or legacy hello response. The only
server that might be removed is the server itself that the hello or legacy hello response is from.</p>
<p>The special handling of description.primary ensures that a single-threaded client <a href="server-discovery-and-monitoring/server-discovery-and-monitoring.html#scan">scans</a> the possible primary
before other members.</p>
<p>See <a href="server-discovery-and-monitoring/server-discovery-and-monitoring.html#replica-set-monitoring-with-and-without-a-primary">replica set monitoring with and without a primary</a>.</p>
<h5 id="updaterswithprimaryfrommember"><a class="header" href="#updaterswithprimaryfrommember">updateRSWithPrimaryFromMember</a></h5>
<p>This subroutine is executed with the ServerDescription from an RSSecondary, RSArbiter, or RSOther when the TopologyType
is ReplicaSetWithPrimary:</p>
<pre><code class="language-python">if description.address not in topologyDescription.servers:
    # While we were checking this server, another thread heard from the
    # primary that this server is not in the replica set.
    return

# SetName is never null here.
if topologyDescription.setName != description.setName:
    remove this server from topologyDescription and stop monitoring it
    checkIfHasPrimary()
    return

if description.address != description.me:
    remove this server from topologyDescription and stop monitoring it
    checkIfHasPrimary()
    return

# Had this member been the primary?
if there is no primary in topologyDescription.servers:
    topologyDescription.type = ReplicaSetNoPrimary

    if description.primary is not null:
        find the ServerDescription in topologyDescription.servers whose
        address equals description.primary

        if its type is Unknown, change its type to PossiblePrimary
</code></pre>
<p>The special handling of description.primary ensures that a single-threaded client <a href="server-discovery-and-monitoring/server-discovery-and-monitoring.html#scan">scans</a> the possible primary
before other members.</p>
<p><span id="updateRSFromPrimary"></span></p>
<h5 id="updatersfromprimary"><a class="header" href="#updatersfromprimary">updateRSFromPrimary</a></h5>
<p>This subroutine is executed with a ServerDescription of type RSPrimary:</p>
<pre><code class="language-python">if serverDescription.address not in topologyDescription.servers:
    return

if topologyDescription.setName is null:
    topologyDescription.setName = serverDescription.setName

else if topologyDescription.setName != serverDescription.setName:
    # We found a primary but it doesn't have the setName
    # provided by the user or previously discovered.
    remove this server from topologyDescription and stop monitoring it
    checkIfHasPrimary()
    return

# Election ids are ObjectIds, see
# see "Using electionId and setVersion to detect stale primaries"
# for comparison rules.

if serverDescription.maxWireVersion &gt;= 17:  # MongoDB 6.0+
    # Null values for both electionId and setVersion are always considered less than
    if serverDescription.electionId &gt; topologyDescription.maxElectionId or (
        serverDescription.electionId == topologyDescription.maxElectionId
        and serverDescription.setVersion &gt;= topologyDescription.maxSetVersion
    ):
        topologyDescription.maxElectionId = serverDescription.electionId
        topologyDescription.maxSetVersion = serverDescription.setVersion
    else:
        # Stale primary.
        # replace serverDescription with a default ServerDescription of type "Unknown"
        checkIfHasPrimary()
        return
else:
    # Maintain old comparison rules, namely setVersion is checked before electionId
    if serverDescription.setVersion is not null and serverDescription.electionId is not null:
        if (
            topologyDescription.maxSetVersion is not null
            and topologyDescription.maxElectionId is not null
            and (
                topologyDescription.maxSetVersion &gt; serverDescription.setVersion
                or (
                    topologyDescription.maxSetVersion == serverDescription.setVersion
                    and topologyDescription.maxElectionId &gt; serverDescription.electionId
                )
            )
        ):
            # Stale primary.
            # replace serverDescription with a default ServerDescription of type "Unknown"
            checkIfHasPrimary()
            return

        topologyDescription.maxElectionId = serverDescription.electionId

    if serverDescription.setVersion is not null and (
        topologyDescription.maxSetVersion is null
        or serverDescription.setVersion &gt; topologyDescription.maxSetVersion
    ):
        topologyDescription.maxSetVersion = serverDescription.setVersion


for each server in topologyDescription.servers:
    if server.address != serverDescription.address:
        if server.type is RSPrimary:
            # See note below about invalidating an old primary.
            replace the server with a default ServerDescription of type "Unknown"

for each address in serverDescription's "hosts", "passives", and "arbiters":
    if address is not in topologyDescription.servers:
        add new default ServerDescription of type "Unknown"
        begin monitoring the new server

for each server in topologyDescription.servers:
    if server.address not in serverDescription's "hosts", "passives", or "arbiters":
        remove the server and stop monitoring it

checkIfHasPrimary()
</code></pre>
<p>A note on invalidating the old primary: when a new primary is discovered, the client finds the previous primary (there
should be none or one) and replaces its description with a default ServerDescription of type "Unknown." A multi-threaded
client MUST <a href="server-discovery-and-monitoring/server-monitoring.html#requesting-an-immediate-check">request an immediate check</a> for that server as soon as
possible.</p>
<p>If the old primary server version is 4.0 or earlier, the client MUST clear its connection pool for the old primary, too:
the connections are all bad because the old primary has closed its sockets. If the old primary server version is 4.2 or
newer, the client MUST NOT clear its connection pool for the old primary.</p>
<p>See <a href="server-discovery-and-monitoring/server-discovery-and-monitoring.html#replica-set-monitoring-with-and-without-a-primary">replica set monitoring with and without a primary</a>.</p>
<p>If the server is primary with an obsolete electionId or setVersion, it is likely a stale primary that is going to step
down. Mark it Unknown and let periodic monitoring detect when it becomes secondary. See
<a href="server-discovery-and-monitoring/server-discovery-and-monitoring.html#using-electionid-and-setversion-to-detect-stale-primaries">using electionId and setVersion to detect stale primaries</a>.</p>
<p>A note on checking "me": Unlike <code>updateRSWithPrimaryFromMember</code>, there is no need to remove the server if the address is
not equal to "me": since the server address will not be a member of either "hosts", "passives", or "arbiters", the
server will already have been removed.</p>
<h5 id="checkifhasprimary"><a class="header" href="#checkifhasprimary">checkIfHasPrimary</a></h5>
<p>Set TopologyType to ReplicaSetWithPrimary if there is an RSPrimary in TopologyDescription.servers, otherwise set it to
ReplicaSetNoPrimary.</p>
<p>For example, if the TopologyType is ReplicaSetWithPrimary and the client is processing a new ServerDescription of type
Unknown, that could mean the primary just disconnected, so checkIfHasPrimary must run to check if the TopologyType
should become ReplicaSetNoPrimary.</p>
<p>Another example is if the client first reaches the primary via its external IP, but the response's host list includes
only internal IPs. In that case the client adds the primary's internal IP to the TopologyDescription and begins
monitoring it, and removes the external IP. Right after removing the external IP from the description, the TopologyType
MUST be ReplicaSetNoPrimary, since no primary is available at this moment.</p>
<h5 id="remove"><a class="header" href="#remove">remove</a></h5>
<p>Remove the server from TopologyDescription.servers and stop monitoring it.</p>
<p>In multi-threaded clients, a monitor may be currently checking this server and may not immediately abort. Once the check
completes, this server's hello or legacy hello outcome MUST be ignored, and the monitor SHOULD halt.</p>
<h4 id="logical-session-timeout"><a class="header" href="#logical-session-timeout">Logical Session Timeout</a></h4>
<p>Whenever a client updates the TopologyDescription from a hello or legacy hello response, it MUST set
TopologyDescription.logicalSessionTimeoutMinutes to the smallest logicalSessionTimeoutMinutes value among
ServerDescriptions of all data-bearing server types. If any have a null logicalSessionTimeoutMinutes, then
TopologyDescription.logicalSessionTimeoutMinutes MUST be set to null.</p>
<p>See the Driver Sessions Spec for the purpose of this value.</p>
<h3 id="connection-pool-management"><a class="header" href="#connection-pool-management">Connection Pool Management</a></h3>
<p>For drivers that support connection pools, after a server check is completed successfully, if the server is determined
to be <a href="server-discovery-and-monitoring/server-discovery-and-monitoring.html#data-bearing-server-type">data-bearing</a> or a
<a href="server-discovery-and-monitoring/server-discovery-and-monitoring.html#general-requirements">direct connection</a> to the server is requested, and does not
already have a connection pool, the driver MUST create the connection pool for the server. Additionally, if a driver
implements a CMAP compliant connection pool, the server's pool (even if it already existed) MUST be marked as "ready".
See the <a href="server-discovery-and-monitoring/server-monitoring.html">Server Monitoring spec</a> for more information.</p>
<p>Clearing the connection pool for a server MUST be synchronized with the update to the corresponding ServerDescription
(e.g. by holding the lock on the TopologyDescription when clearing the pool). This prevents a possible race between the
monitors and application threads. See
<a href="server-discovery-and-monitoring/server-discovery-and-monitoring.html#why-synchronize-clearing-a-servers-pool-with-updating-the-topology">Why synchronize clearing a server's pool with updating the topology?</a>
for more information.</p>
<h3 id="error-handling"><a class="header" href="#error-handling">Error handling</a></h3>
<h4 id="network-error-during-server-check"><a class="header" href="#network-error-during-server-check">Network error during server check</a></h4>
<p>See error handling in the <a href="server-discovery-and-monitoring/server-monitoring.html">Server Monitoring spec</a>.</p>
<h4 id="application-errors"><a class="header" href="#application-errors">Application errors</a></h4>
<p>When processing a network or command error, clients MUST first check the error's generation number. If the error's
generation number is equal to the pool's generation number then error handling MUST continue according to
<a href="server-discovery-and-monitoring/server-discovery-and-monitoring.html#network-error-when-reading-or-writing">Network error when reading or writing</a> or
<a href="server-discovery-and-monitoring/server-discovery-and-monitoring.html#not-writable-primary-and-node-is-recovering">"not writable primary" and "node is recovering"</a>. Otherwise, the error is
considered stale and the client MUST NOT update any topology state. (See
<a href="server-discovery-and-monitoring/server-discovery-and-monitoring.html#why-ignore-errors-based-on-cmaps-generation-number">Why ignore errors based on CMAP's generation number?</a>)</p>
<h5 id="error-handling-pseudocode"><a class="header" href="#error-handling-pseudocode">Error handling pseudocode</a></h5>
<p>Application operations can fail in various places, for example:</p>
<ul>
<li>A network error, network timeout, or command error may occur while establishing a new connection. Establishing a
connection includes the MongoDB handshake and completing authentication (if configured).</li>
<li>A network error or network timeout may occur while reading or writing to an established connection.</li>
<li>A command error may be returned from the server.</li>
<li>A "writeConcernError" field may be included in the command response.</li>
</ul>
<p>Depending on the context, these errors may update SDAM state by marking the server Unknown and may clear the server's
connection pool. Some errors also require other side effects, like cancelling a check or requesting an immediate check.
Drivers may use the following pseudocode to guide their implementation:</p>
<pre><code class="language-python">def handleError(error):
    address = error.address
    topologyVersion = error.topologyVersion

    with client.lock:
        # Ignore stale errors based on generation and topologyVersion.
        if isStaleError(client.topologyDescription, error)
            return

        if isStateChangeError(error):
            # Don't mark server unknown in load balanced mode.
            if type != LoadBalanced
              # Mark the server Unknown
              unknown = new ServerDescription(type=Unknown, error=error, topologyVersion=topologyVersion)
              onServerDescriptionChanged(unknown, connection pool for server)
            if isShutdown(code) or (error was from &lt;4.2):
              # the pools must only be cleared while the lock is held.
              if type == LoadBalanced:
                clear connection pool for serviceId
              else:
                clear connection pool for server
            if multi-threaded:
                request immediate check
            else:
                # Check right now if this is "not writable primary", since it might be a
                # useful secondary. If it's "node is recovering" leave it for the
                # next full scan.
                if isNotWritablePrimary(error):
                    check failing server
        elif isNetworkError(error) or (not error.completedHandshake and (isNetworkTimeout(error) or isAuthError(error))):
            if type != LoadBalanced
              # Mark the server Unknown
              unknown = new ServerDescription(type=Unknown, error=error)
              onServerDescriptionChanged(unknown, connection pool for server)
              clear connection pool for server
            else
              if serviceId
                clear connection pool for serviceId
            # Cancel inprogress check
            cancel monitor check

def isStaleError(topologyDescription, error):
    currentServer = topologyDescription.servers[server.address]
    currentGeneration = currentServer.pool.generation
    generation = get connection generation from error
    if generation &lt; currentGeneration:
        # Stale generation number.
        return True

    currentTopologyVersion = currentServer.topologyVersion
    # True if the current error's topologyVersion is greater than the server's
    # We use &gt;= instead of &gt; because any state change should result in a new topologyVersion
    return compareTopologyVersion(currentTopologyVersion, error.commandResponse.get("topologyVersion")) &gt;= 0
</code></pre>
<p>The following pseudocode checks a response for a "not master" or "node is recovering" error:</p>
<pre><code class="language-python">recoveringCodes = [11600, 11602, 13436, 189, 91]
notWritablePrimaryCodes = [10107, 13435, 10058]
shutdownCodes = [11600, 91]

def isRecovering(message, code):
    if code:
        if code in recoveringCodes:
            return true
    else:
        # if no code, use the error message.
        return ("not master or secondary" in message
            or "node is recovering" in message)

def isNotWritablePrimary(message, code):
    if code:
        if code in notWritablePrimaryCodes:
          return true
    else:
      # if no code, use the error message.
      if isRecovering(message, None):
          return false
      return ("not master" in message)

def isShutdown(code):
    if code and code in shutdownCodes:
        return true
    return false

def isStateChangeError(error):
    message = error.errmsg
    code = error.code
    return isRecovering(message, code) or isNotWritablePrimary(message, code)

def parseGle(response):
    if "err" in response:
        handleError(CommandError(response, response["err"], response["code"]))

# Parse response to any command besides getLastError.
def parseCommandResponse(response):
    if not response["ok"]:
        handleError(CommandError(response, response["errmsg"], response["code"]))
    else if response["writeConcernError"]:
        wce = response["writeConcernError"]
        handleError(WriteConcernError(response, wce["errmsg"], wce["code"]))

def parseQueryResponse(response):
    if the "QueryFailure" bit is set in response flags:
        handleError(CommandError(response, response["$err"], response["code"]))
</code></pre>
<p>The following sections describe the handling of different classes of application errors in detail including network
errors, network timeout errors, state change errors, and authentication errors.</p>
<h5 id="network-error-when-reading-or-writing"><a class="header" href="#network-error-when-reading-or-writing">Network error when reading or writing</a></h5>
<p>To describe how the client responds to network errors during application operations, we distinguish two phases of
connecting to a server and using it for application operations:</p>
<ul>
<li><em>Before the handshake completes</em>: the client establishes a new connection to the server and completes an initial
handshake by calling "hello" or legacy hello and reading the response, and optionally completing authentication</li>
<li><em>After the handshake completes</em>: the client uses the established connection for application operations</li>
</ul>
<p>If there is a network error or timeout on the connection before the handshake completes, the client MUST replace the
server's description with a default ServerDescription of type Unknown when the TopologyType is not LoadBalanced, and
fill the ServerDescription's error field with useful information.</p>
<p>If there is a network error or timeout on the connection before the handshake completes, and the TopologyType is
LoadBalanced, the client MUST keep the ServerDescription as LoadBalancer.</p>
<p>If there is a network timeout on the connection after the handshake completes, the client MUST NOT mark the server
Unknown. (A timeout may indicate a slow operation on the server, rather than an unavailable server.) If, however, there
is some other network error on the connection after the handshake completes, the client MUST replace the server's
description with a default ServerDescription of type Unknown if the TopologyType is not LoadBalanced, and fill the
ServerDescription's error field with useful information, the same as if an error or timeout occurred before the
handshake completed.</p>
<p>When the client marks a server Unknown due to a network error or timeout, the Unknown ServerDescription MUST be sent
through the same process for <a href="server-discovery-and-monitoring/server-discovery-and-monitoring.html#updating-the-topologydescription">updating the TopologyDescription</a> as if it had been a
failed hello or legacy hello outcome from a server check: for example, if the TopologyType is ReplicaSetWithPrimary and
a write to the RSPrimary server fails because of a network error (other than timeout), then a new ServerDescription is
created for the primary, with type Unknown, and the client executes the proper subroutine for an Unknown server when the
TopologyType is ReplicaSetWithPrimary: referring to the table above we see the subroutine is
<a href="server-discovery-and-monitoring/server-discovery-and-monitoring.html#checkifhasprimary">checkIfHasPrimary</a>. The result is the TopologyType changes to ReplicaSetNoPrimary. See the test
scenario called "Network error writing to primary".</p>
<p>The client MUST close all idle sockets in its connection pool for the server: if one socket is bad, it is likely that
all are.</p>
<p>Clients MUST NOT request an immediate check of the server; since application sockets are used frequently, a network
error likely means the server has just become unavailable, so an immediate refresh is likely to get a network error,
too.</p>
<p>The server will not remain Unknown forever. It will be refreshed by the next periodic check or, if an application
operation needs the server sooner than that, then a re-check will be triggered by the server selection algorithm.</p>
<h5 id="not-writable-primary-and-node-is-recovering"><a class="header" href="#not-writable-primary-and-node-is-recovering">"not writable primary" and "node is recovering"</a></h5>
<p>These errors are detected from a getLastError response, write command response, or query response. Clients MUST check if
the server error is a "node is recovering" error or a "not writable primary" error.</p>
<p>If the response includes an error code, it MUST be solely used to determine if error is a "node is recovering" or "not
writable primary" error. Clients MUST match the errors by the numeric error code and not by the code name, as the code
name can change from one server version to the next.</p>
<p>The following error codes indicate a replica set member is temporarily unusable. These are called "node is recovering"
errors:</p>
<div class="table-wrapper"><table><thead><tr><th>Error Name</th><th>Error Code</th></tr></thead><tbody>
<tr><td>InterruptedAtShutdown</td><td>11600</td></tr>
<tr><td>InterruptedDueToReplStateChange</td><td>11602</td></tr>
<tr><td>NotPrimaryOrSecondary</td><td>13436</td></tr>
<tr><td>PrimarySteppedDown</td><td>189</td></tr>
<tr><td>ShutdownInProgress</td><td>91</td></tr>
</tbody></table>
</div>
<p>And the following error codes indicate a "not writable primary" error:</p>
<div class="table-wrapper"><table><thead><tr><th>Error Name</th><th>Error Code</th></tr></thead><tbody>
<tr><td>NotWritablePrimary</td><td>10107</td></tr>
<tr><td>NotPrimaryNoSecondaryOk</td><td>13435</td></tr>
<tr><td>LegacyNotPrimary</td><td>10058</td></tr>
</tbody></table>
</div>
<p>Clients MUST fallback to checking the error message if and only if the response does not include an error code. The
error is considered a "node is recovering" error if the substrings "node is recovering" or "not master or secondary" are
anywhere in the error message. Otherwise, if the substring "not master" is in the error message it is a "not writable
primary" error.</p>
<p>Additionally, if the response includes a write concern error, then the code and message of the write concern error MUST
be checked the same way a response error is checked above.</p>
<p>Errors contained within the writeErrors field MUST NOT be checked.</p>
<p>See the test scenario called "parsing 'not writable primary' and 'node is recovering' errors" for example response
documents.</p>
<p>When the client sees a "not writable primary" or "node is recovering" error and the error's
<a href="server-discovery-and-monitoring/server-discovery-and-monitoring.html#topologyversion">topologyVersion</a> is strictly greater than the current ServerDescription's topologyVersion it MUST
replace the server's description with a ServerDescription of type Unknown. Clients MUST store useful information in the
new ServerDescription's error field, including the error message from the server. Clients MUST store the error's
<a href="server-discovery-and-monitoring/server-discovery-and-monitoring.html#topologyversion">topologyVersion</a> field in the new ServerDescription if present. (See
<a href="server-discovery-and-monitoring/server-discovery-and-monitoring.html#what-is-the-purpose-of-topologyversion">What is the purpose of topologyVersion?</a>)</p>
<p>Multi-threaded and asynchronous clients MUST
<a href="server-discovery-and-monitoring/server-monitoring.html#requesting-an-immediate-check">request an immediate check</a> of the server. Unlike in the "network
error" scenario above, a "not writable primary" or "node is recovering" error means the server is available but the
client is wrong about its type, thus an immediate re-check is likely to provide useful information.</p>
<p>For single-threaded clients, in the case of a "not writable primary" or "node is shutting down" error, the client MUST
mark the topology as "stale" so the next server selection scans all servers. For a "node is recovering" error,
single-threaded clients MUST NOT mark the topology as "stale". If a node is recovering for some time, an immediate scan
may not gain useful information.</p>
<p>The following subset of "node is recovering" errors is defined to be "node is shutting down" errors:</p>
<div class="table-wrapper"><table><thead><tr><th>Error Name</th><th>Error Code</th></tr></thead><tbody>
<tr><td>InterruptedAtShutdown</td><td>11600</td></tr>
<tr><td>ShutdownInProgress</td><td>91</td></tr>
</tbody></table>
</div>
<p>When handling a "not writable primary" or "node is recovering" error, the client MUST clear the server's connection pool
if and only if the error is "node is shutting down" or the error originated from server version &lt; 4.2.</p>
<p>(See
<a href="server-discovery-and-monitoring/server-discovery-and-monitoring.html#when-does-a-client-see-not-writable-primary-or-node-is-recovering">when does a client see "not writable primary" or "node is recovering"?</a>,
<a href="server-discovery-and-monitoring/server-discovery-and-monitoring.html#use-error-messages-to-detect-not-master-and-node-is-recovering">use error messages to detect "not master" and "node is recovering"</a>,
and <a href="server-discovery-and-monitoring/server-discovery-and-monitoring.html#other-transient-errors">other transient errors</a> and
<a href="server-discovery-and-monitoring/server-discovery-and-monitoring.html#why-close-connections-when-a-node-is-shutting-down">Why close connections when a node is shutting down?</a>.)</p>
<h5 id="authentication-errors"><a class="header" href="#authentication-errors">Authentication errors</a></h5>
<p>If the authentication handshake fails for a connection, drivers MUST mark the server Unknown and clear the server's
connection pool if the TopologyType is not LoadBalanced. (See
<a href="server-discovery-and-monitoring/server-discovery-and-monitoring.html#why-mark-a-server-unknown-after-an-auth-error">Why mark a server Unknown after an auth error?</a>)</p>
<h3 id="monitoring-sdam-events"><a class="header" href="#monitoring-sdam-events">Monitoring SDAM events</a></h3>
<p>The required driver specification for providing lifecycle hooks into server discovery and monitoring for applications to
consume can be found in the <a href="server-discovery-and-monitoring/server-discovery-and-monitoring-logging-and-monitoring.html">SDAM Monitoring Specification</a>.</p>
<h3 id="implementation-notes-2"><a class="header" href="#implementation-notes-2">Implementation notes</a></h3>
<p>This section intends to provide generous guidance to driver authors. It is complementary to the reference
implementations. Words like "should", "may", and so on are used more casually here.</p>
<p>See also, the implementation notes in the <a href="server-discovery-and-monitoring/server-monitoring.html">Server Monitoring spec</a>.</p>
<h4 id="multi-threaded-or-asynchronous-server-selection"><a class="header" href="#multi-threaded-or-asynchronous-server-selection">Multi-threaded or asynchronous server selection</a></h4>
<p>While no suitable server is available for an operation,
<a href="server-discovery-and-monitoring/server-discovery-and-monitoring.html#the-client-must-re-check-all-servers-every-minheartbeatfrequencyms">the client MUST re-check all servers every minHeartbeatFrequencyMS</a>.
(See <a href="server-discovery-and-monitoring/server-monitoring.html#requesting-an-immediate-check">requesting an immediate check</a>.)</p>
<h4 id="single-threaded-server-selection"><a class="header" href="#single-threaded-server-selection">Single-threaded server selection</a></h4>
<p>When a client that uses <a href="server-discovery-and-monitoring/server-monitoring.html#single-threaded-monitoring">single-threaded monitoring</a> fails to select a
suitable server for any operation, it <a href="server-discovery-and-monitoring/server-discovery-and-monitoring.html#scan">scans</a> the servers, then attempts selection again, to see if the scan
discovered suitable servers. It repeats, waiting <a href="server-discovery-and-monitoring/server-discovery-and-monitoring.html#minheartbeatfrequencyms">minHeartbeatFrequencyMS</a> after each scan,
until a timeout.</p>
<h4 id="documentation"><a class="header" href="#documentation">Documentation</a></h4>
<h5 id="giant-seed-lists"><a class="header" href="#giant-seed-lists">Giant seed lists</a></h5>
<p>Drivers' manuals should warn against huge seed lists, since it will slow initialization for single-threaded clients and
generate load for multi-threaded and asynchronous drivers.</p>
<h4 id="multi-threaded"><a class="header" href="#multi-threaded">Multi-threaded</a></h4>
<h4 id="warning-about-the-maxwireversion-from-a-monitors-hello-or-legacy-hello-response"><a class="header" href="#warning-about-the-maxwireversion-from-a-monitors-hello-or-legacy-hello-response">Warning about the maxWireVersion from a monitor's hello or legacy hello response</a></h4>
<p>Clients consult some fields from a server's hello or legacy hello response to decide how to communicate with it:</p>
<ul>
<li>maxWireVersion</li>
<li>maxBsonObjectSize</li>
<li>maxMessageSizeBytes</li>
<li>maxWriteBatchSize</li>
</ul>
<p>It is tempting to take these values from the last hello or legacy hello response a <em>monitor</em> received and store them in
the ServerDescription, but this is an anti-pattern. Multi-threaded and asynchronous clients that do so are prone to
several classes of race, for example:</p>
<ul>
<li>Setup: A MongoDB 3.0 Standalone with authentication enabled, the client must log in with SCRAM-SHA-1.</li>
<li>The monitor thread discovers the server and stores maxWireVersion on the ServerDescription</li>
<li>An application thread wants a socket, selects the Standalone, and is about to check the maxWireVersion on its
ServerDescription when...</li>
<li>The monitor thread gets disconnected from server and marks it Unknown, with default maxWireVersion of 0.</li>
<li>The application thread resumes, creates a socket, and attempts to log in using MONGODB-CR, since maxWireVersion is
<em>now</em> reported as 0.</li>
<li>Authentication fails, the server requires SCRAM-SHA-1.</li>
</ul>
<p>Better to call hello or legacy hello for each new socket, as required by the <a href="server-discovery-and-monitoring/../auth/auth.html">Auth Spec</a>, and use the
hello or legacy hello response associated with that socket for maxWireVersion, maxBsonObjectSize, etc.: all the fields
required to correctly communicate with the server.</p>
<p>The hello or legacy hello responses received by monitors determine if the topology as a whole is compatible with the
driver, and which servers are suitable for selection. The monitors' responses should not be used to determine how to
format wire protocol messages to the servers.</p>
<h5 id="immutable-data"><a class="header" href="#immutable-data">Immutable data</a></h5>
<p>Multi-threaded drivers should treat ServerDescriptions and TopologyDescriptions as immutable: the client replaces them,
rather than modifying them, in response to new information about the topology. Thus readers of these data structures can
simply acquire a reference to the current one and read it, without holding a lock that would block a monitor from making
further updates.</p>
<h5 id="process-one-hello-or-legacy-hello-outcome-at-a-time"><a class="header" href="#process-one-hello-or-legacy-hello-outcome-at-a-time">Process one hello or legacy hello outcome at a time</a></h5>
<p>Although servers are checked in parallel, the function that actually creates the new TopologyDescription should be
synchronized so only one thread can run it at a time.</p>
<h5 id="replacing-the-topologydescription"><a class="header" href="#replacing-the-topologydescription">Replacing the TopologyDescription</a></h5>
<p>Drivers may use the following pseudocode to guide their implementation. The client object has a lock and a condition
variable. It uses the lock to ensure that only one new ServerDescription is processed at a time, and it must be acquired
before invoking this function. Once the client has taken the lock it must do no I/O:</p>
<pre><code class="language-python">def onServerDescriptionChanged(server, pool):
    # "server" is the new ServerDescription.
    # "pool" is the pool associated with the server

    if server.address not in client.topologyDescription.servers:
        # The server was once in the topologyDescription, otherwise
        # we wouldn't have been monitoring it, but an intervening
        # state-change removed it. E.g., we got a host list from
        # the primary that didn't include this server.
        return

    newTopologyDescription = client.topologyDescription.copy()

    # Ignore this update if the current topologyVersion is greater than
    # the new ServerDescription's.
    if isStaleServerDescription(td, server):
        return

    # Replace server's previous description.
    address = server.address
    newTopologyDescription.servers[address] = server

    # for drivers that implement CMAP, mark the connection pool as ready after a successful check
    if (server.type in (Mongos, RSPrimary, RSSecondary, Standalone, LoadBalanced))
            or (server.type != Unknown and newTopologyDescription.type == Single):
        pool.ready()

    take any additional actions,
    depending on the TopologyType and server...

    # Replace TopologyDescription and notify waiters.
    client.topologyDescription = newTopologyDescription
    client.condition.notifyAll()

def compareTopologyVersion(tv1, tv2):
    """Return -1 if tv1&lt;tv2, 0 if tv1==tv2, 1 if tv1&gt;tv2"""
    if tv1 is None or tv2 is None:
        # Assume greater.
        return -1
    pid1 = tv1['processId']
    pid2 = tv2['processId']
    if pid1 == pid2:
        counter1 = tv1['counter']
        counter2 = tv2['counter']
        if counter1 == counter2:
            return 0
        elif counter1 &lt; counter2:
            return -1
        else:
            return 1
    else:
        # Assume greater.
        return -1

def isStaleServerDescription(topologyDescription, server):
    # True if the new ServerDescription's topologyVersion is greater than
    # or equal to the current server's.
    currentServer = topologyDescription.servers[server.address]
    currentTopologyVersion = currentServer.topologyVersion
    return compareTopologyVersion(currentTopologyVersion, server.topologyVersion) &gt; 0
</code></pre>
<p>Notifying the condition unblocks threads waiting in the server-selection loop for a suitable server to be discovered.</p>
<blockquote>
<p>[!NOTE]
The Java driver uses a CountDownLatch instead of a condition variable, and it atomically swaps the old and new
CountDownLatches so it does not need "client.lock". It does, however, use a lock to ensure that only one thread runs
onServerDescriptionChanged at a time.</p>
</blockquote>
<h2 id="rationale"><a class="header" href="#rationale">Rationale</a></h2>
<h3 id="clients-do-no-io-in-the-constructor"><a class="header" href="#clients-do-no-io-in-the-constructor">Clients do no I/O in the constructor</a></h3>
<p>An alternative proposal was to distinguish between "discovery" and "monitoring". When discovery begins, the client
checks all its seeds, and discovery is complete once all servers have been checked, or after some maximum time.
Application operations cannot proceed until discovery is complete.</p>
<p>If the discovery phase is distinct, then single- and multi-threaded drivers could accomplish discovery in the
constructor, and throw an exception from the constructor if the deployment is unavailable or misconfigured. This is
consistent with prior behavior for many drivers. It will surprise some users that the constructor now succeeds, but all
operations fail.</p>
<p>Similarly for misconfigured seed lists: the client may discover a mix of mongoses and standalones, or find multiple
replica set names. It may surprise some users that the constructor succeeds and the client attempts to proceed with a
compatible subset of the deployment.</p>
<p>Nevertheless, this spec prohibits I/O in the constructor for the following reasons:</p>
<h4 id="common-case"><a class="header" href="#common-case">Common case</a></h4>
<p>In the common case, the deployment is available and usable. This spec favors allowing operations to proceed as soon as
possible in the common case, at the cost of surprising behavior in uncommon cases.</p>
<h4 id="simplicity"><a class="header" href="#simplicity">Simplicity</a></h4>
<p>It is simpler to omit a special discovery phase and treat all server <a href="server-discovery-and-monitoring/server-discovery-and-monitoring.html#check">checks</a> the same.</p>
<h4 id="consistency"><a class="header" href="#consistency">Consistency</a></h4>
<p>Asynchronous clients cannot do I/O in a constructor, so it is consistent to prohibit I/O in other clients' constructors
as well.</p>
<h4 id="restarts"><a class="header" href="#restarts">Restarts</a></h4>
<p>If clients can be constructed when the deployment is in some states but not in other states, it leads to an unfortunate
scenario: When the deployment is passing through a strange state, long-running clients may keep working, but any clients
restarted during this period fail.</p>
<p>Say an administrator changes one replica set member's setName. Clients that are already constructed remove the bad
member and stay usable, but if any client is restarted its constructor fails. Web servers that dynamically adjust their
process pools will show particularly undesirable behavior.</p>
<h3 id="heartbeatfrequencyms-defaults-to-10-seconds-or-60-seconds"><a class="header" href="#heartbeatfrequencyms-defaults-to-10-seconds-or-60-seconds">heartbeatFrequencyMS defaults to 10 seconds or 60 seconds</a></h3>
<p>Many drivers have different values. The time has come to standardize. Lacking a rigorous methodology for calculating the
best frequency, this spec chooses 10 seconds for multi-threaded or asynchronous drivers because some already use that
value.</p>
<p>Because scanning has a greater impact on the performance of single-threaded drivers, they MUST default to a longer
frequency (60 seconds).</p>
<p>An alternative is to check servers less and less frequently the longer they remain unchanged. This idea is rejected
because it is a goal of this spec to answer questions about monitoring such as,</p>
<ul>
<li>"How rapidly can I rotate a replica set to a new set of hosts?"</li>
<li>"How soon after I add a secondary will query load be rebalanced?"</li>
<li>"How soon will a client notice a change in round trip time, or tags?"</li>
</ul>
<p>Having a constant monitoring frequency allows us to answer these questions simply and definitively. Losing the ability
to answer these questions is not worth any minor gain in efficiency from a more complex scheduling method.</p>
<h3 id="the-client-must-re-check-all-servers-every-minheartbeatfrequencyms"><a class="header" href="#the-client-must-re-check-all-servers-every-minheartbeatfrequencyms">The client MUST re-check all servers every minHeartbeatFrequencyMS</a></h3>
<p>While an application is waiting to do an operation for which there is no suitable server, a multi-threaded client MUST
re-check all servers very frequently. The slight cost is worthwhile in many scenarios. For example:</p>
<ol>
<li>A client and a MongoDB server are started simultaneously.</li>
<li>The client checks the server before it begins listening, so the check fails.</li>
<li>The client waits in the server-selection loop for the topology to change.</li>
</ol>
<p>In this state, the client should check the server very frequently, to give it ample opportunity to connect to the server
before timing out in server selection.</p>
<h3 id="no-knobs-1"><a class="header" href="#no-knobs-1">No knobs</a></h3>
<p>This spec does not intend to introduce any new configuration options unless absolutely necessary.</p>
<h3 id="the-client-must-monitor-arbiters"><a class="header" href="#the-client-must-monitor-arbiters">The client MUST monitor arbiters</a></h3>
<p>Mongos 2.6 does not monitor arbiters, but it costs little to do so, and in the rare case that all data members are moved
to new hosts in a short time, an arbiter may be the client's last hope to find the new replica set configuration.</p>
<h3 id="only-support-replica-set-members-running-mongodb-162-or-later"><a class="header" href="#only-support-replica-set-members-running-mongodb-162-or-later">Only support replica set members running MongoDB 1.6.2 or later</a></h3>
<p>Replica set members began reporting their setNames in that version. Supporting earlier versions is impractical.</p>
<h3 id="topologytype-remains-unknown-when-an-rsghost-is-discovered"><a class="header" href="#topologytype-remains-unknown-when-an-rsghost-is-discovered">TopologyType remains Unknown when an RSGhost is discovered</a></h3>
<p>If the TopologyType is Unknown and the client receives a hello or legacy hello response from
an<a href="server-discovery-and-monitoring/server-discovery-and-monitoring.html#rsghost-and-rsother">RSGhost</a>, the TopologyType could be set to ReplicaSetNoPrimary. However, an RSGhost does not
report its setName, so the setName would still be unknown. This adds an additional state to the existing list:
"TopologyType ReplicaSetNoPrimary <strong>and</strong> no setName." The additional state adds substantial complexity without any
benefit, so this spec says clients MUST NOT change the TopologyType when an RSGhost is discovered.</p>
<h3 id="topologytype-remains-unknown-when-one-of-the-seeds-is-a-standalone"><a class="header" href="#topologytype-remains-unknown-when-one-of-the-seeds-is-a-standalone">TopologyType remains Unknown when one of the seeds is a Standalone</a></h3>
<p>If TopologyType is Unknown and there are multiple seeds, and one of them is discovered to be a standalone, it MUST be
removed. The TopologyType remains Unknown.</p>
<p>This rule supports the following common scenario:</p>
<ol>
<li>Servers A and B are in a replica set.</li>
<li>A seed list with A and B is stored in a configuration file.</li>
<li>An administrator removes B from the set and brings it up as standalone for maintenance, without changing its port
number.</li>
<li>The client is initialized with seeds A and B, TopologyType Unknown, and no setName.</li>
<li>The first hello or legacy hello response is from B, the standalone.</li>
</ol>
<p>What if the client changed TopologyType to Single at this point? It would be unable to use the replica set; it would
have to remove A from the TopologyDescription once A's hello or legacy hello response comes.</p>
<p>The user's intent in this case is clearly to use the replica set, despite the outdated seed list. So this spec requires
clients to remove B from the TopologyDescription and keep the TopologyType as Unknown. Then when A's response arrives,
the client can set its TopologyType to ReplicaSet (with or without primary).</p>
<p>On the other hand, if there is only one seed and the seed is discovered to be a Standalone, the TopologyType MUST be set
to Single.</p>
<p>See the "member brought up as standalone" test scenario.</p>
<h3 id="replica-set-monitoring-with-and-without-a-primary"><a class="header" href="#replica-set-monitoring-with-and-without-a-primary">Replica set monitoring with and without a primary</a></h3>
<p>The client strives to fill the "servers" list only with servers that the <strong>primary</strong> said were members of the replica
set, when the client most recently contacted the primary.</p>
<p>The primary's view of the replica set is authoritative for two reasons:</p>
<ol>
<li>The primary is never on the minority side of a network partition. During a partition it is the primary's list of
servers the client should use.</li>
<li>Since reconfigs must be executed on the primary, the primary is the first to know of them. Reconfigs propagate to
non-primaries eventually, but the client can receive hello or legacy hello responses from non-primaries that reflect
any past state of the replica set. See the "Replica set discovery" test scenario.</li>
</ol>
<p>If at any time the client believes there is no primary, the TopologyDescription's type is set to ReplicaSetNoPrimary.
While there is no known primary, the client MUST <strong>add</strong> servers from non-primaries' host lists, but it MUST NOT remove
servers from the TopologyDescription.</p>
<p>Eventually, when a primary is discovered, any hosts not in the primary's host list are removed.</p>
<h3 id="using-electionid-and-setversion-to-detect-stale-primaries"><a class="header" href="#using-electionid-and-setversion-to-detect-stale-primaries">Using electionId and setVersion to detect stale primaries</a></h3>
<p>Replica set members running MongoDB 2.6.10+ or 3.0+ include an integer called "setVersion" and an ObjectId called
"electionId" in their hello or legacy hello response. Starting with MongoDB 3.2.0, replica sets can use two different
replication protocol versions; electionIds from one protocol version must not be compared to electionIds from a
different protocol.</p>
<p>Because protocol version changes require replica set reconfiguration, clients use the tuple (electionId, setVersion) to
detect stale primaries. The tuple order comparison MUST be checked in the order of electionId followed by setVersion
since that order of comparison is guaranteed monotonicity.</p>
<p>The client remembers the greatest electionId and setVersion reported by a primary, and distrusts primaries from older
electionIds or from the same electionId but with lesser setVersion.</p>
<ul>
<li>It compares electionIds as 12-byte sequence i.e. memory comparison.</li>
<li>It compares setVersions as integer values.</li>
</ul>
<p>This prevents the client from oscillating between the old and new primary during a split-brain period, and helps provide
read-your-writes consistency with write concern "majority" and read preference "primary".</p>
<p>Prior to MongoDB server version 6.0 drivers had the logic opposite from the server side Replica Set Management logic by
ordering the tuple by <code>setVersion</code> before the <code>electionId</code>. In order to remain compatibility with backup systems, etc.
drivers continue to maintain the reversed logic when connected to a topology that reports a maxWireVersion less than
<code>17</code>. Server versions 6.0 and beyond MUST order the tuple by <code>electionId</code> then <code>setVersion</code>.</p>
<h4 id="requirements-for-read-your-writes-consistency"><a class="header" href="#requirements-for-read-your-writes-consistency">Requirements for read-your-writes consistency</a></h4>
<p>Using (electionId, setVersion) only provides read-your-writes consistency if:</p>
<ul>
<li>The application uses the same MongoClient instance for write-concern "majority" writes and read-preference "primary"
reads, and</li>
<li>All members use MongoDB 2.6.10+, 3.0.0+ or 3.2.0+ with replication protocol 0 and clocks are <em>less</em> than 30 seconds
skewed, or</li>
<li>All members run MongoDB 3.2.0 and replication protocol 1 and clocks are <em>less</em> skewed than the election timeout
(<code>electionTimeoutMillis</code>, which defaults to 10 seconds), or</li>
<li>All members run MongoDB 3.2.1+ and replication protocol 1 (in which case clocks need not be synchronized).</li>
</ul>
<h4 id="scenario"><a class="header" href="#scenario">Scenario</a></h4>
<p>Consider the following situation:</p>
<ol>
<li>Server A is primary.</li>
<li>A network partition isolates A from the set, but the client still sees it.</li>
<li>Server B is elected primary.</li>
<li>The client discovers that B is primary, does a write-concern "majority" write operation on B and receives
acknowledgment.</li>
<li>The client receives a hello or legacy hello response from A, claiming A is still primary.</li>
<li>If the client trusts that A is primary, the next read-preference "primary" read sees stale data from A that may <em>not</em>
include the write sent to B.</li>
</ol>
<p>See <a href="https://jira.mongodb.org/browse/SERVER-17975">SERVER-17975</a>, "Stale reads with WriteConcern Majority and
ReadPreference Primary."</p>
<h4 id="detecting-a-stale-primary"><a class="header" href="#detecting-a-stale-primary">Detecting a stale primary</a></h4>
<p>To prevent this scenario, the client uses electionId and setVersion to determine which primary was elected last. In this
case, it would not consider "A" a primary, nor read from it because server B will have a greater electionId but the same
setVersion.</p>
<h4 id="monotonicity"><a class="header" href="#monotonicity">Monotonicity</a></h4>
<p>The electionId is an ObjectId compared bytewise in order.</p>
<p>(ie. 000000000000000000000001 &gt; 000000000000000000000000, FF0000000000000000000000 &gt; FE0000000000000000000000 etc.)</p>
<p>In some server versions, it is monotonic with respect to a particular servers' system clock, but is not globally
monotonic across a deployment. However, if inter-server clock skews are small, it can be treated as a monotonic value.</p>
<p>In MongoDB 2.6.10+ (which has <a href="https://jira.mongodb.org/browse/SERVER-13542">SERVER-13542</a> backported), MongoDB 3.0.0+
or MongoDB 3.2+ (under replication protocol version 0), the electionId's leading bytes are a server timestamp. As long
as server clocks are skewed <em>less</em> than 30 seconds, electionIds can be reliably compared. (This is precise enough,
because in replication protocol version 0, servers are designed not to complete more than one election every 30 seconds.
Elections do not take 30 seconds--they are typically much faster than that--but there is a 30-second cooldown before the
next election can complete.)</p>
<p>Beginning in MongoDB 3.2.0, under replication protocol version 1, the electionId begins with a timestamp, but the
cooldown is shorter. As long as inter-server clock skew is <em>less</em> than the configured election timeout
(<code>electionTimeoutMillis</code>, which defaults to 10 seconds), then electionIds can be reliably compared.</p>
<p>Beginning in MongoDB 3.2.1, under replication protocol version 1, the electionId is guaranteed monotonic without relying
on any clock synchronization.</p>
<h3 id="using-me-field-to-detect-seed-list-members-that-do-not-match-host-names-in-the-replica-set-configuration"><a class="header" href="#using-me-field-to-detect-seed-list-members-that-do-not-match-host-names-in-the-replica-set-configuration">Using me field to detect seed list members that do not match host names in the replica set configuration</a></h3>
<p>Removal from the topology of seed list members where the "me" property does not match the address used to connect
prevents clients from being able to select a server, only to fail to re-select that server once the primary has
responded.</p>
<p>This scenario illustrates the problems that arise if this is NOT done:</p>
<ul>
<li>The client specifies a seed list of A, B, C</li>
<li>Server A responds as a secondary with hosts D, E, F</li>
<li>The client executes a query with read preference of secondary, and server A is selected</li>
<li>Server B responds as a primary with hosts D, E, F. Servers A, B, C are removed, as they don't appear in the primary's
hosts list</li>
<li>The client iterates the cursor and attempts to execute a getMore against server A.</li>
<li>Server selection fails because server A is no longer part of the topology.</li>
</ul>
<p>With checking for "me" in place, it looks like this instead:</p>
<ul>
<li>The client specifies a seed list of A, B, C</li>
<li>Server A responds as a secondary with hosts D, E, F, where "me" is D, and so the client adds D, E, F as type "Unknown"
and starts monitoring them, but removes A from the topology.</li>
<li>The client executes a query with read preference of secondary, and goes into the server selection loop</li>
<li>Server D responds as a secondary where "me" is D</li>
<li>Server selection completes by matching D</li>
<li>The client iterates the cursor and attempts to execute a getMore against server D.</li>
<li>Server selection completes by matching D.</li>
</ul>
<h3 id="ignore-setversion-unless-the-server-is-primary"><a class="header" href="#ignore-setversion-unless-the-server-is-primary">Ignore setVersion unless the server is primary</a></h3>
<p>It was thought that if all replica set members report a setVersion, and a secondary's response has a higher setVersion
than any seen, that the secondary's host list could be considered as authoritative as the primary's. (See
<a href="server-discovery-and-monitoring/server-discovery-and-monitoring.html#replica-set-monitoring-with-and-without-a-primary">Replica set monitoring with and without a primary</a>.)</p>
<p>This scenario illustrates the problem with setVersion:</p>
<ul>
<li>We have a replica set with servers A, B, and C.</li>
<li>Server A is the primary, with setVersion 4.</li>
<li>An administrator runs replSetReconfig on A, which increments its setVersion to 5.</li>
<li>The client checks Server A and receives the new config.</li>
<li>Server A crashes before any secondary receives the new config.</li>
<li>Server B is elected primary. It has the old setVersion 4.</li>
<li>The client ignores B's version of the config because its setVersion is not greater than 5.</li>
</ul>
<p>The client may never correct its view of the topology.</p>
<p>Even worse:</p>
<ul>
<li>An administrator runs replSetReconfig on Server B, which increments its setVersion to 5.</li>
<li>Server A restarts. This results in <em>two</em> versions of the config, both claiming to be version 5.</li>
</ul>
<p>If the client trusted the setVersion in this scenario, it would trust whichever config it received first.</p>
<p>mongos 2.6 ignores setVersion and only trusts the primary. This spec requires all clients to ignore setVersion from
non-primaries.</p>
<h3 id="use-error-messages-to-detect-not-master-and-node-is-recovering"><a class="header" href="#use-error-messages-to-detect-not-master-and-node-is-recovering">Use error messages to detect "not master" and "node is recovering"</a></h3>
<p>When error codes are not available, error messages are checked for the substrings "not master" and "node is recovering".
This is because older server versions returned unstable error codes or no error codes in many circumstances.</p>
<h3 id="other-transient-errors"><a class="header" href="#other-transient-errors">Other transient errors</a></h3>
<p>There are other transient errors a server may return, e.g. retryable errors listed in the retryable writes spec. SDAM
does not consider these because they do not imply the connected server should be marked as "Unknown". For example, the
following errors may be returned from a mongos when it cannot route to a shard:</p>
<div class="table-wrapper"><table><thead><tr><th>Error Name</th><th>Error Code</th></tr></thead><tbody>
<tr><td>HostNotFound</td><td>7</td></tr>
<tr><td>HostUnreachable</td><td>6</td></tr>
<tr><td>NetworkTimeout</td><td>89</td></tr>
<tr><td>SocketException</td><td>9001</td></tr>
</tbody></table>
</div>
<p>When these are returned, the mongos should <em>not</em> be marked as "Unknown", since it is more likely an issue with the
shard.</p>
<h3 id="why-ignore-errors-based-on-cmaps-generation-number"><a class="header" href="#why-ignore-errors-based-on-cmaps-generation-number">Why ignore errors based on CMAP's generation number?</a></h3>
<p>Using CMAP's generation number solves the following race condition among application threads and the monitor during
error handling:</p>
<ol>
<li>Two concurrent writes begin on application threads A and B.</li>
<li>The server restarts.</li>
<li>Thread A receives the first non-timeout network error, and the client marks the server Unknown, and clears the
server's pool.</li>
<li>The client re-checks the server and marks it Primary.</li>
<li>Thread B receives the second non-timeout network error and the client marks the server Unknown again.</li>
</ol>
<p>The core issue is that the client processes errors in arbitrary order and may overwrite fresh information about the
server's status with stale information. Using CMAP's generation number avoids the race condition because the duplicate
(or stale) network error can be identified (changes in <strong>bold</strong>):</p>
<ol>
<li>Two concurrent writes begin on application threads A and B, <strong>with generation 1</strong>.</li>
<li>The server restarts.</li>
<li>Thread A receives the first non-timeout network error, and the client marks the server Unknown, and clears the
server's pool. <strong>The pool's generation is now 2.</strong></li>
<li>The client re-checks the server and marks it Primary.</li>
<li>Thread B receives the second non-timeout network error, <strong>and the client ignores the error because the error
originated from a connection with generation 1.</strong></li>
</ol>
<h3 id="why-synchronize-clearing-a-servers-pool-with-updating-the-topology"><a class="header" href="#why-synchronize-clearing-a-servers-pool-with-updating-the-topology">Why synchronize clearing a server's pool with updating the topology?</a></h3>
<p>Doing so solves the following race condition among application threads and the monitor during error handling, similar to
the previous example:</p>
<ol>
<li>A write begins on an application thread.</li>
<li>The server restarts.</li>
<li>The application thread receives a non-timeout network error.</li>
<li>The application thread acquires the lock on the TopologyDescription, marks the Server as Unknown, and releases the
lock.</li>
<li>The monitor re-checks the server and marks it Primary and its pool as "ready".</li>
<li>Several other application threads enter the WaitQueue of the server's pool.</li>
<li>The application thread clears the server's pool, evicting all those new threads from the WaitQueue, causing them to
return errors or to retry. Additionally, the pool is now "paused", but the server is considered the Primary, meaning
future operations will be routed to the server and fail until the next heartbeat marks the pool as "ready" again.</li>
</ol>
<p>If marking the server as Unknown and clearing its pool were synchronized, then the monitor marking the server as Primary
after its check would happen after the pool was cleared and thus avoid putting it an inconsistent state.</p>
<h3 id="what-is-the-purpose-of-topologyversion"><a class="header" href="#what-is-the-purpose-of-topologyversion">What is the purpose of topologyVersion?</a></h3>
<p><a href="server-discovery-and-monitoring/server-discovery-and-monitoring.html#topologyversion">topologyVersion</a> solves the following race condition among application threads and the monitor when
handling State Change Errors:</p>
<ol>
<li>Two concurrent writes begin on application threads A and B.</li>
<li>The primary steps down.</li>
<li>Thread A receives the first State Change Error, the client marks the server Unknown.</li>
<li>The client re-checks the server and marks it Secondary.</li>
<li>Thread B receives a delayed State Change Error and the client marks the server Unknown again.</li>
</ol>
<p>The core issue is that the client processes errors in arbitrary order and may overwrite fresh information about the
server's status with stale information. Using topologyVersion avoids the race condition because the duplicate (or stale)
State Change Errors can be identified (changes in <strong>bold</strong>):</p>
<ol>
<li>Two concurrent writes begin on application threads A and B.
<ol>
<li><strong>The primary's ServerDescription.topologyVersion == tv1</strong></li>
</ol>
</li>
<li>The primary steps down <strong>and sets its topologyVersion to tv2</strong>.</li>
<li>Thread A receives the first State Change Error <strong>containing tv2</strong>, the client marks the server Unknown (<strong>with
topologyVersion: tv2</strong>).</li>
<li>The client re-checks the server and marks it Secondary (<strong>with topologyVersion: tv2</strong>).</li>
<li>Thread B receives a delayed State Change Error (<strong>with topologyVersion: tv2</strong>) <strong>and the client ignores the error
because the error's topologyVersion (tv2) is not greater than the current ServerDescription (tv2).</strong></li>
</ol>
<h3 id="why-mark-a-server-unknown-after-an-auth-error"><a class="header" href="#why-mark-a-server-unknown-after-an-auth-error">Why mark a server Unknown after an auth error?</a></h3>
<p>The <a href="server-discovery-and-monitoring/../auth/auth.html">Authentication spec</a> requires that when authentication fails on a server, the driver MUST clear
the server's connection pool. Clearing the pool without marking the server Unknown would leave the pool in the "paused"
state while the server is still selectable. When auth fails due to invalid credentials, marking the server Unknown also
serves to rate limit new connections; future operations will need to wait for the server to be rediscovered.</p>
<p>Note that authentication may fail for a variety of reasons, for example:</p>
<ul>
<li>A network error, or network timeout error may occur.</li>
<li>The server may return a <a href="server-discovery-and-monitoring/server-discovery-and-monitoring.html#state-change-error">State Change Error</a>.</li>
<li>The server may return a AuthenticationFailed command error (error code 18) indicating that the provided credentials
are invalid.</li>
</ul>
<p>Does this mean that authentication failures due to invalid credentials will manifest as server selection timeout errors?
No, authentication errors are still returned to the application immediately. A subsequent operation will block until the
server is rediscovered and immediately attempt authentication on a new connection.</p>
<h3 id="clients-use-the-hostnames-listed-in-the-replica-set-config-not-the-seed-list"><a class="header" href="#clients-use-the-hostnames-listed-in-the-replica-set-config-not-the-seed-list">Clients use the hostnames listed in the replica set config, not the seed list</a></h3>
<p>Very often users have DNS aliases they use in their <a href="server-discovery-and-monitoring/server-discovery-and-monitoring.html#seed-list">seed list</a> instead of the hostnames in the replica set
config. For example, the name "host_alias" might refer to a server also known as "host1", and the URI is:</p>
<pre><code>mongodb://host_alias/?replicaSet=rs
</code></pre>
<p>When the client connects to "host_alias", its hello or legacy hello response includes the list of hostnames from the
replica set config, which does not include the seed:</p>
<pre><code>{
   hosts: ["host1:27017", "host2:27017"],
   setName: "rs",
   ... other hello or legacy hello response fields ...
}
</code></pre>
<p>This spec requires clients to connect to the hostnames listed in the hello or legacy hello response. Furthermore, if the
response is from a primary, the client MUST remove all hostnames not listed. In this case, the client disconnects from
"host_alias" and tries "host1" and "host2". (See <a href="server-discovery-and-monitoring/server-discovery-and-monitoring.html#updatersfromprimary">updateRSFromPrimary</a>.)</p>
<p>Thus, replica set members must be reachable from the client by the hostnames listed in the replica set config.</p>
<p>An alternative proposal is for clients to continue using the hostnames in the seed list. It could add new hosts from the
hello or legacy hello response, and where a host is known by two names, the client can deduplicate them using the "me"
field and prefer the name in the seed list.</p>
<p>This proposal was rejected because it does not support key features of replica sets: failover and zero-downtime
reconfiguration.</p>
<p>In our example, if "host1" and "host2" are not reachable from the client, the client continues to use "host_alias" only.
If that server goes down or is removed by a replica set reconfig, the client is suddenly unable to reach the replica set
at all: by allowing the client to use the alias, we have hidden the fact that the replica set's failover feature will
not work in a crisis or during a reconfig.</p>
<p>In conclusion, to support key features of replica sets, we require that the hostnames used in a replica set config are
reachable from the client.</p>
<h2 id="backwards-compatibility-8"><a class="header" href="#backwards-compatibility-8">Backwards Compatibility</a></h2>
<p>The Java driver 2.12.1 has a "heartbeatConnectRetryFrequency". Since this spec recommends the option be named
"minHeartbeatFrequencyMS", the Java driver must deprecate its old option and rename it minHeartbeatFrequency (for
consistency with its other options which also lack the "MS" suffix).</p>
<h2 id="reference-implementation-7"><a class="header" href="#reference-implementation-7">Reference Implementation</a></h2>
<ul>
<li>Java driver 3.x</li>
<li>PyMongo 3.x</li>
<li>Perl driver 1.0.0 (in progress)</li>
</ul>
<h2 id="future-work-6"><a class="header" href="#future-work-6">Future Work</a></h2>
<p>MongoDB is likely to add some of the following features, which will require updates to this spec:</p>
<ul>
<li>Eventually consistent collections (SERVER-2956)</li>
<li>Mongos discovery (SERVER-1834)</li>
<li>Put individual databases into maintenance mode, instead of the whole server (SERVER-7826)</li>
<li>Put setVersion in write-command responses (SERVER-13909)</li>
</ul>
<h2 id="questions-and-answers"><a class="header" href="#questions-and-answers">Questions and Answers</a></h2>
<h3 id="when-does-a-client-see-not-writable-primary-or-node-is-recovering"><a class="header" href="#when-does-a-client-see-not-writable-primary-or-node-is-recovering">When does a client see "not writable primary" or "node is recovering"?</a></h3>
<p>These errors indicate one of these:</p>
<ul>
<li>A write was attempted on an unwritable server (arbiter, secondary, ghost, or recovering).</li>
<li>A read was attempted on an unreadable server (arbiter, ghost, or recovering) or a read was attempted on a read-only
server without the secondaryOk bit set.</li>
<li>An operation was attempted on a server that is now shutting down.</li>
</ul>
<p>In any case the error is a symptom that a ServerDescription's type no longer reflects reality.</p>
<p>On MongoDB 4.0 and earlier, a primary closes its connections when it steps down, so in many cases the next operation
causes a network error rather than "not writable primary". The driver can see a "not writable primary" error in the
following scenario:</p>
<ol>
<li>The client discovers the primary.</li>
<li>The primary steps down.</li>
<li>Before the client checks the server and discovers the stepdown, the application attempts an operation.</li>
<li>The client's connection pool is empty, either because it has never attempted an operation on this server, or because
all connections are in use by other threads.</li>
<li>The client creates a connection to the old primary.</li>
<li>The client attempts to write, or to read without the secondaryOk bit, and receives "not writable primary".</li>
</ol>
<p>See <a href="server-discovery-and-monitoring/server-discovery-and-monitoring.html#not-writable-primary-and-node-is-recovering">"not writable primary" and "node is recovering"</a>, and the test
scenario called "parsing 'not writable primary' and 'node is recovering' errors".</p>
<h3 id="why-close-connections-when-a-node-is-shutting-down"><a class="header" href="#why-close-connections-when-a-node-is-shutting-down">Why close connections when a node is shutting down?</a></h3>
<p>When a server shuts down, it will return one of the "node is shutting down" errors for each attempted operation and
eventually will close all connections. Keeping a connection to a server which is shutting down open would only produce
errors on this connection - such a connection will never be usable for any operations. In contrast, when a server 4.2 or
later returns "not writable primary" error the connection may be usable for other operations (such as secondary reads).</p>
<h3 id="whats-the-point-of-periodic-monitoring"><a class="header" href="#whats-the-point-of-periodic-monitoring">What's the point of periodic monitoring?</a></h3>
<p>Why not just wait until a "not writable primary" error or "node is recovering" error informs the client that its
TopologyDescription is wrong? Or wait until server selection fails to find a suitable server, and only scan all servers
then?</p>
<p>Periodic monitoring accomplishes three objectives:</p>
<ul>
<li>Update each server's type, tags, and <a href="server-discovery-and-monitoring/server-discovery-and-monitoring.html#round-trip-time">round trip time</a>. Read preferences and the mongos selection
algorithm require this information remains up to date.</li>
<li>Discover new secondaries so that secondary reads are evenly spread.</li>
<li>Detect incremental changes to the replica set configuration, so that the client remains connected to the set even
while it is migrated to a completely new set of hosts.</li>
</ul>
<p>If the application uses some servers very infrequently, monitoring can also proactively detect state changes (primary
stepdown, server becoming unavailable) that would otherwise cause future errors.</p>
<h3 id="why-is-auto-discovery-the-preferred-default"><a class="header" href="#why-is-auto-discovery-the-preferred-default">Why is auto-discovery the preferred default?</a></h3>
<p>Auto-discovery is most resilient and is therefore preferred.</p>
<h3 id="why-is-it-possible-for-maxsetversion-to-go-down"><a class="header" href="#why-is-it-possible-for-maxsetversion-to-go-down">Why is it possible for maxSetVersion to go down?</a></h3>
<p><code>maxElectionId</code> and <code>maxSetVersion</code> are actually considered a pair of values Drivers MAY consider implementing
comparison in code as a tuple of the two to ensure their always updated together:</p>
<pre><code class="language-typescript">// New tuple                        old tuple
{ electionId: 2, setVersion: 1 } &gt; { electionId: 1, setVersion: 50 }
</code></pre>
<p>In this scenario, the maxSetVersion goes from 50 to 1, but the maxElectionId is raised to 2.</p>
<h2 id="acknowledgments"><a class="header" href="#acknowledgments">Acknowledgments</a></h2>
<p>Jeff Yemin's code for the Java driver 2.12, and his patient explanation thereof, is the major inspiration for this spec.
Mathias Stearn's beautiful design for replica set monitoring in mongos 2.6 contributed as well. Bernie Hackett gently
oversaw the specification process.</p>
<h2 id="changelog-14"><a class="header" href="#changelog-14">Changelog</a></h2>
<ul>
<li>
<p>2024-08-16: Updated host b wire versions in <code>too_new</code> and <code>too_old</code> tests</p>
</li>
<li>
<p>2024-08-09: Updated wire versions in tests to 4.0+.</p>
</li>
<li>
<p>2024-05-08: Migrated from reStructuredText to Markdown.</p>
</li>
<li>
<p>2015-12-17: Require clients to compare (setVersion, electionId) tuples.</p>
</li>
<li>
<p>2015-10-09: Specify electionID comparison method.</p>
</li>
<li>
<p>2015-06-16: Added cooldownMS.</p>
</li>
<li>
<p>2016-05-04: Added link to SDAM monitoring.</p>
</li>
<li>
<p>2016-07-18: Replace mentions of the "Read Preferences Spec" with "Server Selection Spec", and
"secondaryAcceptableLatencyMS" with "localThresholdMS".</p>
</li>
<li>
<p>2016-07-21: Updated for Max Staleness support.</p>
</li>
<li>
<p>2016-08-04: Explain better why clients use the hostnames in RS config, not URI.</p>
</li>
<li>
<p>2016-08-31: Multi-threaded clients SHOULD use hello or legacy hello replies to update the topology when they handshake
application connections.</p>
</li>
<li>
<p>2016-10-06: In updateRSWithoutPrimary the hello or legacy hello response's "primary" field should be used to update
the topology description, even if address != me.</p>
</li>
<li>
<p>2016-10-29: Allow for idleWritePeriodMS to change someday.</p>
</li>
<li>
<p>2016-11-01: "Unknown" is no longer the default TopologyType, the default is now explicitly unspecified. Update
instructions for setting the initial TopologyType when running the spec tests.</p>
</li>
<li>
<p>2016-11-21: Revert changes that would allow idleWritePeriodMS to change in the future.</p>
</li>
<li>
<p>2017-02-28: Update "network error when reading or writing": timeout while connecting does mark a server Unknown,
unlike a timeout while reading or writing. Justify the different behaviors, and also remove obsolete reference to
auto-retry.</p>
</li>
<li>
<p>2017-06-13: Move socketCheckIntervalMS to Server Selection Spec.</p>
</li>
<li>
<p>2017-08-01: Parse logicalSessionTimeoutMinutes from hello or legacy hello reply.</p>
</li>
<li>
<p>2017-08-11: Clearer specification of "incompatible" logic.</p>
</li>
<li>
<p>2017-09-01: Improved incompatibility error messages.</p>
</li>
<li>
<p>2018-03-28: Specify that monitoring must not do mechanism negotiation or authentication.</p>
</li>
<li>
<p>2019-05-29: Renamed InterruptedDueToStepDown to InterruptedDueToReplStateChange</p>
</li>
<li>
<p>2020-02-13: Drivers must run SDAM flow even when server description is equal to the last one.</p>
</li>
<li>
<p>2020-03-31: Add topologyVersion to ServerDescription. Add rules for ignoring stale application errors.</p>
</li>
<li>
<p>2020-05-07: Include error field in ServerDescription equality comparison.</p>
</li>
<li>
<p>2020-06-08: Clarify reasoning behind how SDAM determines if a topologyVersion is stale.</p>
</li>
<li>
<p>2020-12-17: Mark the pool for a server as "ready" after performing a successful check. Synchronize pool clearing with
SDAM updates.</p>
</li>
<li>
<p>2021-01-17: Require clients to compare (electionId, setVersion) tuples.</p>
</li>
<li>
<p>2021-02-11: Errors encountered during auth are handled by SDAM. Auth errors mark the server Unknown and clear the
pool.</p>
</li>
<li>
<p>2021-04-12: Adding in behaviour for load balancer mode.</p>
</li>
<li>
<p>2021-05-03: Require parsing "isWritablePrimary" field in responses.</p>
</li>
<li>
<p>2021-06-09: Connection pools must be created and eventually marked ready for any server if a direct connection is
used.</p>
</li>
<li>
<p>2021-06-29: Updated to use modern terminology.</p>
</li>
<li>
<p>2022-01-19: Add iscryptd and 90th percentile RTT fields to ServerDescription.</p>
</li>
<li>
<p>2022-07-11: Convert integration tests to the unified format.</p>
</li>
<li>
<p>2022-09-30: Update <code>updateRSFromPrimary</code> to include logic before and after 6.0 servers</p>
</li>
<li>
<p>2022-10-05: Remove spec front matter, move footnote, and reformat changelog.</p>
</li>
<li>
<p>2022-11-17: Add minimum RTT tracking and remove 90th percentile RTT.</p>
</li>
<li>
<p>2024-01-17: Add section on expected client close behaviour</p>
</li>
</ul>
<hr />
<div class="footnote-definition" id="1"><sup class="footnote-definition-label">1</sup>
<p>"localThresholdMS" was called "secondaryAcceptableLatencyMS" in the Read Preferences Spec, before it was superseded
by the Server Selection Spec.</p>
</div>
<div class="footnote-definition" id="2"><sup class="footnote-definition-label">2</sup>
<p><a href="server-discovery-and-monitoring/server-discovery-and-monitoring.html#topologytype-remains-unknown-when-an-rsghost-is-discovered">TopologyType remains Unknown when an RSGhost is discovered</a>.</p>
</div>
<div style="break-before: page; page-break-before: always;"></div><h1 id="connection-monitoring-and-pooling"><a class="header" href="#connection-monitoring-and-pooling">Connection Monitoring and Pooling</a></h1>
<ul>
<li>Status: Accepted</li>
<li>Minimum Server Version: N/A</li>
</ul>
<h2 id="abstract-15"><a class="header" href="#abstract-15">Abstract</a></h2>
<p>Drivers currently support a variety of options that allow users to configure connection pooling behavior. Users are
confused by drivers supporting different subsets of these options. Additionally, drivers implement their connection
pools differently, making it difficult to design cross-driver pool functionality. By unifying and codifying pooling
options and behavior across all drivers, we will increase user comprehension and code base maintainability.</p>
<p>This specification does not apply to drivers that do not support multitasking.</p>
<h2 id="meta-15"><a class="header" href="#meta-15">META</a></h2>
<p>The keywords "MUST", "MUST NOT", "REQUIRED", "SHALL", "SHALL NOT", "SHOULD", "SHOULD NOT", "RECOMMENDED", "MAY", and
"OPTIONAL" in this document are to be interpreted as described in <a href="https://www.ietf.org/rfc/rfc2119.txt">RFC 2119</a>.</p>
<h2 id="definitions-1"><a class="header" href="#definitions-1">Definitions</a></h2>
<h3 id="connection"><a class="header" href="#connection">Connection</a></h3>
<p>A Connection (when linked) refers to the <code>Connection</code> type defined in the
<a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection-pool-members">Connection Pool Members</a> section of this specification. It does not refer to an actual TCP
connection to an Endpoint. A <code>Connection</code> will attempt to create and wrap such a TCP connection over the course of its
existence, but it is not equivalent to one nor does it wrap an active one at all times.</p>
<p>For the purposes of testing, a mocked <code>Connection</code> type could be used with the pool that never actually creates a TCP
connection or performs any I/O.</p>
<h3 id="endpoint"><a class="header" href="#endpoint">Endpoint</a></h3>
<p>For convenience, an Endpoint refers to either a <strong>mongod</strong> or <strong>mongos</strong> instance.</p>
<h3 id="thread"><a class="header" href="#thread">Thread</a></h3>
<p>For convenience, a Thread refers to:</p>
<ul>
<li>A shared-address-space process (a.k.a. a thread) in multi-threaded drivers</li>
<li>An Execution Frame / Continuation in asynchronous drivers</li>
<li>A goroutine in Go</li>
</ul>
<h2 id="behavioral-description"><a class="header" href="#behavioral-description">Behavioral Description</a></h2>
<h3 id="which-drivers-this-applies-to"><a class="header" href="#which-drivers-this-applies-to">Which Drivers this applies to</a></h3>
<p>This specification is solely concerned with drivers that implement a connection pool. A driver SHOULD implement a
connection pool, but is not required to.</p>
<h3 id="connection-pool-options"><a class="header" href="#connection-pool-options">Connection Pool Options</a></h3>
<p>All drivers that implement a connection pool MUST implement and conform to the same MongoClient options. There can be
slight deviation in naming to make the options idiomatic to the driver language.</p>
<h3 id="connection-pool-behaviors"><a class="header" href="#connection-pool-behaviors">Connection Pool Behaviors</a></h3>
<p>All driver connection pools MUST provide an API that allows the driver to check out a connection, check in a connection
back to the pool, and clear all connections in the pool. This API is for internal use only, and SHOULD NOT be documented
as a public API.</p>
<h3 id="connection-pool-monitoring"><a class="header" href="#connection-pool-monitoring">Connection Pool Monitoring</a></h3>
<p>All drivers that implement a connection pool MUST provide an API that allows users to subscribe to events emitted from
the pool. Conceptually, event emission is instantaneous, i.e., one may talk about the instant an event is emitted, and
represents the start of an activity of delivering the event to a subscribed user.</p>
<h2 id="detailed-design"><a class="header" href="#detailed-design">Detailed Design</a></h2>
<h3 id="connection-pool-options-1"><a class="header" href="#connection-pool-options-1">Connection Pool Options</a></h3>
<p>Drivers that implement a Connection Pool MUST support the following ConnectionPoolOptions:</p>
<pre><code class="language-typescript">interface ConnectionPoolOptions {
  /**
   *  The maximum number of Connections that may be associated
   *  with a pool at a given time. This includes in use and
   *  available connections.
   *  If specified, MUST be an integer &gt;= 0.
   *  A value of 0 means there is no limit.
   *  Defaults to 100.
   */
  maxPoolSize?: number;

  /**
   *  The minimum number of Connections that MUST exist at any moment
   *  in a single connection pool.
   *  If specified, MUST be an integer &gt;= 0. If maxPoolSize is &gt; 0
   *  then minPoolSize must be &lt;= maxPoolSize
   *  Defaults to 0.
   */
  minPoolSize?: number;

  /**
   *  The maximum amount of time a Connection should remain idle
   *  in the connection pool before being marked idle.
   *  If specified, MUST be a number &gt;= 0.
   *  A value of 0 means there is no limit.
   *  Defaults to 0.
   */
  maxIdleTimeMS?: number;

  /**
   *  The maximum number of Connections a Pool may be establishing concurrently.
   *  Establishment of a Connection is a part of its life cycle
   *  starting after a ConnectionCreatedEvent and ending before a ConnectionReadyEvent.
   *  If specified, MUST be a number &gt; 0.
   *  Defaults to 2.
   */
  maxConnecting?: number;
}
</code></pre>
<p>Additionally, Drivers that implement a Connection Pool MUST support the following ConnectionPoolOptions UNLESS that
driver meets ALL of the following conditions:</p>
<ul>
<li>The driver/language currently has an idiomatic timeout mechanism implemented</li>
<li>The timeout mechanism conforms to <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#waitqueue">the aggressive requirement of timing out a thread in the WaitQueue</a></li>
</ul>
<pre><code class="language-typescript">interface ConnectionPoolOptions {
  /**
   *  NOTE: This option has been deprecated in favor of timeoutMS.
   *
   *  The maximum amount of time a thread can wait for
   *  either an available non-perished connection (limited by `maxPoolSize`),
   *  or a pending connection (limited by `maxConnecting`).
   *  If specified, MUST be a number &gt;= 0.
   *  A value of 0 means there is no limit.
   *  Defaults to 0.
   */
  waitQueueTimeoutMS?: number;
}
</code></pre>
<p>These options MUST be specified at the MongoClient level, and SHOULD be named in a manner idiomatic to the driver's
language. All connection pools created by a MongoClient MUST use the same ConnectionPoolOptions.</p>
<p>When parsing a mongodb connection string, a user MUST be able to specify these options using the default names specified
above.</p>
<h4 id="deprecated-options"><a class="header" href="#deprecated-options">Deprecated Options</a></h4>
<p>The following ConnectionPoolOptions are considered deprecated. They MUST NOT be implemented if they do not already exist
in a driver, and they SHOULD be deprecated and removed from drivers that implement them as early as possible:</p>
<pre><code class="language-typescript">interface ConnectionPoolOptions {
  /**
   *  The maximum number of threads that can simultaneously wait
   *  for a Connection to become available.
   */
  waitQueueSize?: number;

  /**
   *  An alternative way of setting waitQueueSize, it specifies
   *  the maximum number of threads that can wait per connection.
   *  waitQueueSize === waitQueueMultiple * maxPoolSize
   */
  waitQueueMultiple?: number
}
</code></pre>
<h3 id="connection-pool-members"><a class="header" href="#connection-pool-members">Connection Pool Members</a></h3>
<h4 id="connection-1"><a class="header" href="#connection-1">Connection</a></h4>
<p>A driver-defined wrapper around a single TCP connection to an Endpoint. A <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connection</a> has the following
properties:</p>
<ul>
<li><strong>Single Endpoint:</strong> A <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connection</a> MUST be associated with a single Endpoint. A
<a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connection</a> MUST NOT be associated with multiple Endpoints.</li>
<li><strong>Single Lifetime:</strong> A <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connection</a> MUST NOT be used after it is closed.</li>
<li><strong>Single Owner:</strong> A <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connection</a> MUST belong to exactly one Pool, and MUST NOT be shared across multiple
pools</li>
<li><strong>Single Track:</strong> A <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connection</a> MUST limit itself to one request / response at a time. A
<a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connection</a> MUST NOT multiplex/pipeline requests to an Endpoint.</li>
<li><strong>Monotonically Increasing ID:</strong> A <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connection</a> MUST have an ID number associated with it.
<a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connection</a> IDs within a Pool MUST be assigned in order of creation, starting at 1 and increasing by 1
for each new Connection.</li>
<li><strong>Valid Connection:</strong> A connection MUST NOT be checked out of the pool until it has successfully and fully completed a
MongoDB Handshake and Authentication as specified in the <a href="connection-monitoring-and-pooling/../mongodb-handshake/handshake.html">Handshake</a>,
<a href="connection-monitoring-and-pooling/../compression/OP_COMPRESSED.html">OP_COMPRESSED</a>, and <a href="connection-monitoring-and-pooling/../auth/auth.html">Authentication</a> specifications.</li>
<li><strong>Perishable</strong>: it is possible for a <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connection</a> to become <strong>Perished</strong>. A <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connection</a> is
considered perished if any of the following are true:
<ul>
<li><strong>Stale:</strong> The <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connection</a> 's generation does not match the generation of the parent pool</li>
<li><strong>Idle:</strong> The <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connection</a> is currently "available" (as defined below) and has been for longer than
<strong>maxIdleTimeMS</strong>.</li>
<li><strong>Errored:</strong> The <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connection</a> has experienced an error that indicates it is no longer recommended for
use. Examples include, but are not limited to:
<ul>
<li>Network Error</li>
<li>Network Timeout</li>
<li>Endpoint closing the connection</li>
<li>Driver-Side Timeout</li>
<li>Wire-Protocol Error</li>
</ul>
</li>
</ul>
</li>
</ul>
<pre><code class="language-typescript">interface Connection {
  /**
   *  An id number associated with the Connection
   */
  id: number;

  /**
   *  The address of the pool that owns this Connection
   */
  address: string;

  /**
   *  An integer representing the "generation" of the pool
   *  when this Connection was created.
   */
  generation: number;

  /**
   * The current state of the Connection.
   *
   * Possible values are the following:
   *   - "pending":       The Connection has been created but has not yet been established. Contributes to
   *                      totalConnectionCount and pendingConnectionCount.
   *
   *   - "available":     The Connection has been established and is waiting in the pool to be checked
   *                      out. Contributes to both totalConnectionCount and availableConnectionCount.
   *
   *   - "in use":        The Connection has been established, checked out from the pool, and has yet
   *                      to be checked back in. Contributes to totalConnectionCount.
   *
   *   - "closed":        The Connection has had its socket closed and cannot be used for any future
   *                      operations. Does not contribute to any connection counts.
   *
   * Note: this field is mainly used for the purposes of describing state
   * in this specification. It is not required that drivers
   * actually include this field in their implementations of Connection.
   */
  state: "pending" | "available" | "in use" | "closed";
}
</code></pre>
<h4 id="waitqueue"><a class="header" href="#waitqueue">WaitQueue</a></h4>
<p>A concept that represents pending requests for <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connections</a>. When a thread requests a
<a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connection</a> from a Pool, the thread enters the Pool's WaitQueue. A thread stays in the WaitQueue until it
either receives a <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connection</a> or times out. A WaitQueue has the following traits:</p>
<ul>
<li><strong>Thread-Safe</strong>: When multiple threads attempt to enter or exit a WaitQueue, they do so in a thread-safe manner.</li>
<li><strong>Ordered/Fair</strong>: When <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connections</a> are made available, they are issued out to threads in the order that
the threads entered the WaitQueue.</li>
<li><strong>Timeout aggressively:</strong> Members of a WaitQueue MUST timeout if they are enqueued for longer than the computed
timeout and MUST leave the WaitQueue immediately in this case.</li>
</ul>
<p>The implementation details of a WaitQueue are left to the driver. Example implementations include:</p>
<ul>
<li>A fair Semaphore</li>
<li>A Queue of callbacks</li>
</ul>
<h4 id="connection-pool"><a class="header" href="#connection-pool">Connection Pool</a></h4>
<p>A driver-defined entity that encapsulates all non-monitoring <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connections</a> associated with a single
Endpoint. The pool has the following properties:</p>
<ul>
<li><strong>Thread Safe:</strong> All Pool behaviors MUST be thread safe.</li>
<li><strong>Not Fork-Safe:</strong> A Pool is explicitly not fork-safe. If a Pool detects that is it being used by a forked process, it
MUST immediately clear itself and update its pid</li>
<li><strong>Single Owner:</strong> A Pool MUST be associated with exactly one Endpoint, and MUST NOT be shared between Endpoints.</li>
<li><strong>Emit Events and Log Messages:</strong> A Pool MUST emit pool events and log messages when dictated by this spec (see
<a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection-pool-monitoring">Connection Pool Monitoring</a>). Users MUST be able to subscribe to emitted events and log
messages in a manner idiomatic to their language and driver.</li>
<li><strong>Closeable:</strong> A Pool MUST be able to be manually closed. When a Pool is closed, the following behaviors change:
<ul>
<li>Checking in a <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connection</a> to the Pool automatically closes the <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connection</a></li>
<li>Attempting to check out a <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connection</a> from the Pool results in an Error</li>
</ul>
</li>
<li><strong>Clearable:</strong> A Pool MUST be able to be cleared. Clearing the pool marks all pooled and checked out
<a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connections</a> as stale and lazily closes them as they are checkedIn or encountered in checkOut.
Additionally, all requests are evicted from the WaitQueue and return errors that are considered non-timeout network
errors.</li>
<li><strong>Pausable:</strong> A Pool MUST be able to be paused and resumed. A Pool is paused automatically when it is cleared, and it
can be resumed by being marked as "ready". While the Pool is paused, it exhibits the following behaviors:
<ul>
<li>Attempting to check out a <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connection</a> from the Pool results in a non-timeout network error</li>
<li>Connections are not created in the background to satisfy minPoolSize</li>
</ul>
</li>
<li><strong>Capped:</strong> a pool is capped if <strong>maxPoolSize</strong> is set to a non-zero value. If a pool is capped, then its total number
of <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connections</a> (including available and in use) MUST NOT exceed <strong>maxPoolSize</strong></li>
<li><strong>Rate-limited:</strong> A Pool MUST limit the number of <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connections</a> being
<a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#establishing-a-connection-internal-implementation">established</a> concurrently via the <strong>maxConnecting</strong>
<a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection-pool-options">pool option</a>.</li>
</ul>
<pre><code class="language-typescript">interface ConnectionPool {
  /**
   *  The Queue of threads waiting for a Connection to be available
   */
  waitQueue: WaitQueue;

  /**
   *  A generation number representing the SDAM generation of the pool.
   */
  generation: number;

  /**
   * A map representing the various generation numbers for various services
   * when in load balancer mode.
   */
  serviceGenerations: Map&lt;ObjectId, [number, number]&gt;;

  /**
   * The state of the pool.
   *
   * Possible values are the following:
   *   - "paused":        The initial state of the pool. Connections may not be checked out nor can they
   *                      be established in the background to satisfy minPoolSize. Clearing a pool
   *                      transitions it to this state.
   *
   *   - "ready":         The healthy state of the pool. It can service checkOut requests and create
   *                      connections in the background. The pool can be set to this state via the
   *                      ready() method.
   *
   *   - "closed":        The pool is destroyed. No more Connections may ever be checked out nor any
   *                      created in the background. The pool can be set to this state via the close()
   *                      method. The pool cannot transition to any other state after being closed.
   */
  state: "paused" | "ready" | "closed";

  // Any of the following connection counts may be computed rather than
  // actually stored on the pool.

  /**
   *  An integer expressing how many total Connections
   *  ("pending" + "available" + "in use") the pool currently has
   */
  totalConnectionCount: number;

  /**
   *  An integer expressing how many Connections are currently
   *  available in the pool.
   */
  availableConnectionCount: number;

  /**
   *  An integer expressing how many Connections are currently
   *  being established.
   */
  pendingConnectionCount: number;

  /**
   *  Returns a Connection for use
   */
  checkOut(): Connection;

  /**
   *  Check in a Connection back to the Connection pool
   */
  checkIn(connection: Connection): void;

  /**
   *  Mark all current Connections as stale, clear the WaitQueue, and mark the pool as "paused".
   *  No connections may be checked out or created in this pool until ready() is called again.
   *  interruptInUseConnections specifies whether the pool will force interrupt "in use" connections as part of the clear. 
   *  Default false.
   */
  clear(interruptInUseConnections: Optional&lt;Boolean&gt;): void;

  /**
   *  Mark the pool as "ready", allowing checkOuts to resume and connections to be created in the background.
   *  A pool can only transition from "paused" to "ready". A "closed" pool
   *  cannot be marked as "ready" via this method.
   */
  ready(): void;

  /**
   *  Marks the pool as "closed", preventing the pool from creating and returning new Connections
   */
  close(): void;
}
</code></pre>
<h3 id="connection-pool-behaviors-1"><a class="header" href="#connection-pool-behaviors-1">Connection Pool Behaviors</a></h3>
<h4 id="creating-a-connection-pool"><a class="header" href="#creating-a-connection-pool">Creating a Connection Pool</a></h4>
<p>This specification does not define how a pool is to be created, leaving it up to the driver. Creation of a connection
pool is generally an implementation detail of the driver, i.e., is not a part of the public API of the driver. The SDAM
specification defines
<a href="connection-monitoring-and-pooling/../server-discovery-and-monitoring/server-discovery-and-monitoring.html#connection-pool-management">when</a> the driver
should create connection pools.</p>
<p>When a pool is created, its state MUST initially be set to "paused". Even if minPoolSize is set, the pool MUST NOT begin
being <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#populating-the-pool-with-a-connection-internal-implementation">populated</a> with <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connections</a> until
it has been marked as "ready". SDAM will mark the pool as "ready" on each successful check. See
<a href="connection-monitoring-and-pooling/../server-discovery-and-monitoring/server-discovery-and-monitoring.html#connection-pool-management">Connection Pool Management</a>
section in the SDAM specification for more information.</p>
<pre><code>set generation to 0
set state to "paused"
emit PoolCreatedEvent and equivalent log message
</code></pre>
<h4 id="closing-a-connection-pool"><a class="header" href="#closing-a-connection-pool">Closing a Connection Pool</a></h4>
<p>When a pool is closed, it MUST first close all available <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connections</a> in that pool. This results in the
following behavior changes:</p>
<ul>
<li>In use <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connections</a> MUST be closed when they are checked in to the closed pool.</li>
<li>Attempting to check out a <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connection</a> MUST result in an error.</li>
</ul>
<pre><code>mark pool as "closed"
for connection in availableConnections:
  close connection
emit PoolClosedEvent and equivalent log message
</code></pre>
<h4 id="marking-a-connection-pool-as-ready"><a class="header" href="#marking-a-connection-pool-as-ready">Marking a Connection Pool as Ready</a></h4>
<p>Connection Pools start off as "paused", and they are marked as "ready" by monitors after they perform successful server
checks. Once a pool is "ready", it can start checking out <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connections</a> and populating them in the
background.</p>
<p>If the pool is already "ready" when this method is invoked, then this method MUST immediately return and MUST NOT emit a
PoolReadyEvent.</p>
<pre><code>mark pool as "ready"
emit PoolReadyEvent and equivalent log message
allow background thread to create connections
</code></pre>
<p>Note that the PoolReadyEvent MUST be emitted before the background thread is allowed to resume creating new connections,
and it must be the case that no observer is able to observe actions of the background thread related to creating new
connections before observing the PoolReadyEvent event.</p>
<h4 id="creating-a-connection-internal-implementation"><a class="header" href="#creating-a-connection-internal-implementation">Creating a Connection (Internal Implementation)</a></h4>
<p>When creating a <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connection</a>, the initial <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connection</a> is in a "pending" state. This only
creates a "virtual" <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connection</a>, and performs no I/O.</p>
<pre><code>connection = new Connection()
increment totalConnectionCount
increment pendingConnectionCount
set connection state to "pending"
tConnectionCreated = current instant (use a monotonic clock if possible)
emit ConnectionCreatedEvent and equivalent log message
return connection
</code></pre>
<h4 id="establishing-a-connection-internal-implementation"><a class="header" href="#establishing-a-connection-internal-implementation">Establishing a Connection (Internal Implementation)</a></h4>
<p>Before a <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connection</a> can be marked as either "available" or "in use", it must be established. This process
involves performing the initial handshake, handling OP_COMPRESSED, and performing authentication.</p>
<pre><code>try:
  connect connection via TCP / TLS
  perform connection handshake
  handle OP_COMPRESSED
  perform connection authentication
  tConnectionReady = current instant (use a monotonic clock if possible)
  emit ConnectionReadyEvent(duration = tConnectionReady - tConnectionCreated) and equivalent log message
  return connection
except error:
  close connection
  throw error # Propagate error in manner idiomatic to language.
</code></pre>
<h4 id="closing-a-connection-internal-implementation"><a class="header" href="#closing-a-connection-internal-implementation">Closing a Connection (Internal Implementation)</a></h4>
<p>When a <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connection</a> is closed, it MUST first be marked as "closed", removing it from being counted as
"available" or "in use". Once that is complete, the <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connection</a> can perform whatever teardown is necessary
to close its underlying socket. The Driver SHOULD perform this teardown in a non-blocking manner, such as via the use of
a background thread or async I/O.</p>
<pre><code>original state = connection state
set connection state to "closed"

if original state is "available":
  decrement availableConnectionCount
else if original state is "pending":
  decrement pendingConnectionCount

decrement totalConnectionCount
emit ConnectionClosedEvent and equivalent log message

# The following can happen at a later time (i.e. in background
# thread) or via non-blocking I/O.
connection.socket.close()
</code></pre>
<h4 id="marking-a-connection-as-available-internal-implementation"><a class="header" href="#marking-a-connection-as-available-internal-implementation">Marking a Connection as Available (Internal Implementation)</a></h4>
<p>A <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connection</a> is "available" if it is able to be checked out. A <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connection</a> MUST NOT be
marked as "available" until it has been established. The pool MUST keep track of the number of currently available
<a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connections</a>.</p>
<pre><code>increment availableConnectionCount
set connection state to "available"
add connection to availableConnections
</code></pre>
<h4 id="populating-the-pool-with-a-connection-internal-implementation"><a class="header" href="#populating-the-pool-with-a-connection-internal-implementation">Populating the Pool with a Connection (Internal Implementation)</a></h4>
<p>"Populating" the pool involves preemptively creating and establishing a <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connection</a> which is marked as
"available" for use in future operations.</p>
<p>Populating the pool MUST NOT block any application threads. For example, it could be performed on a background thread or
via the use of non-blocking/async I/O. Populating the pool MUST NOT be performed unless the pool is "ready".</p>
<p>If an error is encountered while populating a connection, it MUST be handled via the SDAM machinery according to the
<a href="connection-monitoring-and-pooling/../server-discovery-and-monitoring/server-discovery-and-monitoring.html#application-errors">Application Errors</a> section
in the SDAM specification.</p>
<p>If minPoolSize is set, the <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connection</a> Pool MUST be populated until it has at least minPoolSize total
<a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connections</a>. This MUST occur only while the pool is "ready". If the pool implements a background thread,
it can be used for this. If the pool does not implement a background thread, the checkOut method is responsible for
ensuring this requirement is met.</p>
<p>When populating the Pool, pendingConnectionCount has to be decremented after establishing a <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connection</a>
similarly to how it is done in <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#checking-out-a-connection">Checking Out a Connection</a> to signal that another
<a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connection</a> is allowed to be established. Such a signal MUST become observable to any <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#thread">Thread</a>
after the action that
<a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#marking-a-connection-as-available-internal-implementation">marks the established Connection as "available"</a> becomes
observable to the <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#thread">Thread</a>. Informally, this order guarantees that no <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#thread">Thread</a> tries to start
establishing a <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connection</a> when there is an "available" <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connection</a> established as a result
of populating the Pool.</p>
<pre><code>wait until pendingConnectionCount &lt; maxConnecting and pool is "ready"
create connection
try:
  establish connection
  mark connection as available
except error:
  # Defer error handling to SDAM.
  topology.handle_pre_handshake_error(error)
</code></pre>
<h4 id="checking-out-a-connection"><a class="header" href="#checking-out-a-connection">Checking Out a Connection</a></h4>
<p>A Pool MUST have a method that allows the driver to check out a <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connection</a>. Checking out a
<a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connection</a> involves submitting a request to the WaitQueue and, once that request reaches the front of the
queue, having the Pool find or create a <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connection</a> to fulfill that request. Requests MUST be subject to a
timeout which is computed per the rules in
<a href="connection-monitoring-and-pooling/../client-side-operations-timeout/client-side-operations-timeout.html#server-selection">Client Side Operations Timeout: Server Selection</a>.</p>
<p>To service a request for a <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connection</a>, the Pool MUST first iterate over the list of available
<a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connections</a>, searching for a non-perished one to be returned. If a perished <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connection</a> is
encountered, such a <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connection</a> MUST be closed (as described in
<a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#closing-a-connection-internal-implementation">Closing a Connection</a>) and the iteration of available
<a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connections</a> MUST continue until either a non-perished available <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connection</a> is found or the
list of available <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connections</a> is exhausted.</p>
<p>If the list is exhausted, the total number of <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connections</a> is less than maxPoolSize, and
pendingConnectionCount &lt; maxConnecting, the pool MUST create a <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connection</a>, establish it, mark it as "in
use" and return it. If totalConnectionCount == maxPoolSize or pendingConnectionCount == maxConnecting, then the pool
MUST wait to service the request until neither of those two conditions are met or until a <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connection</a>
becomes available, re-entering the checkOut loop in either case. This waiting MUST NOT prevent
<a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connections</a> from being checked into the pool. Additionally, the Pool MUST NOT service any newer checkOut
requests before fulfilling the original one which could not be fulfilled. For drivers that implement the WaitQueue via a
fair semaphore, a condition variable may also be needed to to meet this requirement. Waiting on the condition variable
SHOULD also be limited by the WaitQueueTimeout, if the driver supports one and it was specified by the user.</p>
<p>If the pool is "closed" or "paused", any attempt to check out a <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connection</a> MUST throw an Error. The error
thrown as a result of the pool being "paused" MUST be considered a retryable error and MUST NOT be an error that marks
the SDAM state unknown.</p>
<p>If the pool does not implement a background thread, the checkOut method is responsible for ensuring that the pool is
<a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#populating-the-pool-with-a-connection-internal-implementation">populated</a> with at least minPoolSize
<a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connections</a>.</p>
<p>A <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connection</a> MUST NOT be checked out until it is established. In addition, the Pool MUST NOT prevent
other threads from checking out <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connections</a> while establishing a <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connection</a>.</p>
<p>Before a given <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connection</a> is returned from checkOut, it must be marked as "in use", and the pool's
availableConnectionCount MUST be decremented.</p>
<pre><code class="language-python">connection = Null
tConnectionCheckOutStarted = current instant (use a monotonic clock if possible)
emit ConnectionCheckOutStartedEvent and equivalent log message
try:
  enter WaitQueue
  wait until at top of wait queue
  # Note that in a lock-based implementation of the wait queue would
  # only allow one thread in the following block at a time
  while connection is Null:
    if a connection is available:
      while connection is Null and a connection is available:
        connection = next available connection
        if connection is perished:
          close connection
          connection = Null
    else if totalConnectionCount &lt; maxPoolSize:
      if pendingConnectionCount &lt; maxConnecting:
        connection = create connection
      else:
        # this waiting MUST NOT prevent other threads from checking Connections
        # back in to the pool.
        wait until pendingConnectionCount &lt; maxConnecting or a connection is available
        continue

except pool is "closed":
  tConnectionCheckOutFailed = current instant (use a monotonic clock if possible)
  emit ConnectionCheckOutFailedEvent(reason="poolClosed", duration = tConnectionCheckOutFailed - tConnectionCheckOutStarted) and equivalent log message
  throw PoolClosedError
except pool is "paused":
  tConnectionCheckOutFailed = current instant (use a monotonic clock if possible)
  emit ConnectionCheckOutFailedEvent(reason="connectionError", duration = tConnectionCheckOutFailed - tConnectionCheckOutStarted) and equivalent log message
  throw PoolClearedError
except timeout:
  tConnectionCheckOutFailed = current instant (use a monotonic clock if possible)
  emit ConnectionCheckOutFailedEvent(reason="timeout", duration = tConnectionCheckOutFailed - tConnectionCheckOutStarted) and equivalent log message
  throw WaitQueueTimeoutError
finally:
  # This must be done in all drivers
  leave wait queue

# If the Connection has not been established yet (TCP, TLS,
# handshake, compression, and auth), it must be established
# before it is returned.
# This MUST NOT block other threads from acquiring connections.
if connection state is "pending":
  try:
    establish connection
  except connection establishment error:
    tConnectionCheckOutFailed = current instant (use a monotonic clock if possible)
    emit ConnectionCheckOutFailedEvent(reason="connectionError", duration = tConnectionCheckOutFailed - tConnectionCheckOutStarted) and equivalent log message
    decrement totalConnectionCount
    throw
  finally:
    decrement pendingConnectionCount
else:
    decrement availableConnectionCount
set connection state to "in use"

# If there is no background thread, the pool MUST ensure that
# there are at least minPoolSize total connections.
do asynchronously:
  while totalConnectionCount &lt; minPoolSize:
    populate the pool with a connection

tConnectionCheckedOut = current instant (use a monotonic clock if possible)
emit ConnectionCheckedOutEvent(duration = tConnectionCheckedOut - tConnectionCheckOutStarted) and equivalent log message
return connection
</code></pre>
<h4 id="checking-in-a-connection"><a class="header" href="#checking-in-a-connection">Checking In a Connection</a></h4>
<p>A Pool MUST have a method of allowing the driver to check in a <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connection</a>. The driver MUST NOT be allowed
to check in a <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connection</a> to a Pool that did not create that <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connection</a>, and MUST throw an
Error if this is attempted.</p>
<p>When the <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connection</a> is checked in, it MUST be <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#closing-a-connection-internal-implementation">closed</a> if
any of the following are true:</p>
<ul>
<li>The <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connection</a> is perished.</li>
<li>The pool has been closed.</li>
</ul>
<p>Otherwise, the <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connection</a> is marked as available.</p>
<pre><code>emit ConnectionCheckedInEvent and equivalent log message
if connection is perished OR pool is closed:
  close connection
else:
  mark connection as available
</code></pre>
<h4 id="clearing-a-connection-pool"><a class="header" href="#clearing-a-connection-pool">Clearing a Connection Pool</a></h4>
<p>Clearing the pool involves different steps depending on whether the pool is in load balanced mode or not. The
traditional / non-load balanced clearing behavior MUST NOT be used by pools in load balanced mode, and the load balanced
pool clearing behavior MUST NOT be used in non-load balanced pools.</p>
<h5 id="clearing-a-non-load-balanced-pool"><a class="header" href="#clearing-a-non-load-balanced-pool">Clearing a non-load balanced pool</a></h5>
<p>A Pool MUST have a method of clearing all <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connections</a> when instructed. Rather than iterating through
every <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connection</a>, this method should simply increment the generation of the Pool, implicitly marking all
current <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connections</a> as stale. It should also transition the pool's state to "paused" to halt the creation
of new connections until it is marked as "ready" again. The checkOut and checkIn algorithms will handle clearing out
stale <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connections</a>. If a user is subscribed to Connection Monitoring events and/or connection log
messages, a PoolClearedEvent and log message MUST be emitted after incrementing the generation / marking the pool as
"paused". If the pool is already "paused" when it is cleared, then the pool MUST NOT emit a PoolCleared event or log
message.</p>
<p>As part of clearing the pool, the WaitQueue MUST also be cleared, meaning all requests in the WaitQueue MUST fail with
errors indicating that the pool was cleared while the checkOut was being performed. The error returned as a result of
the pool being cleared MUST be considered a retryable error and MUST NOT be an error that marks the SDAM state unknown.
Clearing the WaitQueue MUST happen eagerly so that any operations waiting on <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connections</a> can retry as
soon as possible. The pool MUST NOT rely on WaitQueueTimeoutMS to clear requests from the WaitQueue.</p>
<p>The clearing method MUST provide the option to interrupt any in-use connections as part of the clearing (henceforth
referred to as the interruptInUseConnections flag in this specification). "Interrupting a Connection" is defined as
canceling whatever task the Connection is currently performing and marking the Connection as perished (e.g. by closing
its underlying socket). The interrupting of these Connections MUST be performed as soon as possible but MUST NOT block
the pool or prevent it from processing further requests. If the pool has a background thread, and it is responsible for
interrupting in-use connections, its next run MUST be scheduled as soon as possible.</p>
<p>The pool MUST only interrupt in-use Connections whose generation is less than or equal to the generation of the pool at
the moment of the clear (before the increment) that used the interruptInUseConnections flag. Any operations that have
their Connections interrupted in this way MUST fail with a retryable error. If possible, the error SHOULD be a
PoolClearedError with the following message: "Connection to <pool address> interrupted due to server monitor timeout".</p>
<h5 id="clearing-a-load-balanced-pool"><a class="header" href="#clearing-a-load-balanced-pool">Clearing a load balanced pool</a></h5>
<p>A Pool MUST also have a method of clearing all <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connections</a> for a specific <code>serviceId</code> for use when in
load balancer mode. This method increments the generation of the pool for that specific <code>serviceId</code> in the generation
map. A PoolClearedEvent and log message MUST be emitted after incrementing the generation. Note that this method MUST
NOT transition the pool to the "paused" state and MUST NOT clear the WaitQueue.</p>
<h4 id="load-balancer-mode-1"><a class="header" href="#load-balancer-mode-1">Load Balancer Mode</a></h4>
<p>For load-balanced deployments, pools MUST maintain a map from <code>serviceId</code> to a tuple of (generation, connection count)
where the connection count refers to the total number of connections that exist for a specific <code>serviceId</code>. The pool
MUST remove the entry for a <code>serviceId</code> once the connection count reaches 0. Once the MongoDB handshake is done, the
connection MUST get the generation number that applies to its <code>serviceId</code> from the map and update the map to increment
the connection count for this <code>serviceId</code>.</p>
<p>See the <a href="connection-monitoring-and-pooling/../load-balancers/load-balancers.html#connection-pooling">Load Balancer Specification</a> for details.</p>
<h4 id="forking"><a class="header" href="#forking">Forking</a></h4>
<p>A <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connection</a> is explicitly not fork-safe. The proper behavior in the case of a fork is to ResetAfterFork
by:</p>
<ul>
<li>clear all Connection Pools in the child process</li>
<li>closing all <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connections</a> in the child-process.</li>
</ul>
<p>Drivers that support forking MUST document that <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connections</a> to an Endpoint are not fork-safe, and
document the proper way to ResetAfterFork in the driver.</p>
<p>Drivers MAY aggressively ResetAfterFork if the driver detects it has been forked.</p>
<h4 id="optional-behaviors"><a class="header" href="#optional-behaviors">Optional Behaviors</a></h4>
<p>The following features of a Connection Pool SHOULD be implemented if they make sense in the driver and driver's
language.</p>
<h5 id="background-thread"><a class="header" href="#background-thread">Background Thread</a></h5>
<p>A Pool SHOULD have a background Thread that is responsible for monitoring the state of all available
<a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connections</a>. This background thread SHOULD</p>
<ul>
<li>Populate <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connections</a> to ensure that the pool always satisfies minPoolSize.</li>
<li>Remove and close perished available <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connections</a> including "in use" connections if
<code>interruptInUseConnections</code> option was set to true in the most recent pool clear.</li>
<li>Apply timeouts to connection establishment per
<a href="connection-monitoring-and-pooling/../client-side-operations-timeout/client-side-operations-timeout.html#background-connection-pooling">Client Side Operations Timeout: Background Connection Pooling</a>.</li>
</ul>
<p>A pool SHOULD allow immediate scheduling of the next background thread iteration after a clear is performed.</p>
<p>Conceptually, the aforementioned activities are organized into sequential Background Thread Runs. A Run MUST do as much
work as readily available and then end instead of waiting for more work. For example, instead of waiting for
pendingConnectionCount to become less than maxConnecting when satisfying minPoolSize, a Run MUST either proceed with the
rest of its duties, e.g., closing available perished connections, or end.</p>
<p>The duration of intervals between the end of one Run and the beginning of the next Run is not specified, but the
<a href="connection-monitoring-and-pooling/../connection-monitoring-and-pooling/tests/README.html">Test Format and Runner Specification</a> may restrict this duration,
or introduce other restrictions to facilitate testing.</p>
<h5 id="withconnection"><a class="header" href="#withconnection">withConnection</a></h5>
<p>A Pool SHOULD implement a scoped resource management mechanism idiomatic to their language to prevent
<a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connections</a> from not being checked in. Examples include
<a href="https://docs.python.org/3/whatsnew/2.6.html#pep-343-the-with-statement">Python's "with" statement</a> and
<a href="https://docs.microsoft.com/en-us/dotnet/csharp/language-reference/keywords/using-statement">C#'s "using" statement</a>. If
implemented, drivers SHOULD use this method as the default method of checking out and checking in
<a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connections</a>.</p>
<h3 id="connection-pool-monitoring-1"><a class="header" href="#connection-pool-monitoring-1">Connection Pool Monitoring</a></h3>
<p>All drivers that implement a connection pool MUST provide an API that allows users to subscribe to events emitted from
the pool. If a user subscribes to Connection Monitoring events, these events MUST be emitted when specified in
"Connection Pool Behaviors". Events SHOULD be created and subscribed to in a manner idiomatic to their language and
driver.</p>
<p><span id="events"></span></p>
<h4 id="events-1"><a class="header" href="#events-1">Events</a></h4>
<p>See the <a href="connection-monitoring-and-pooling/../load-balancers/load-balancers.html#events">Load Balancer Specification</a> for details on the <code>serviceId</code> field.</p>
<pre><code class="language-typescript">/**
 *  Emitted when a Connection Pool is created
 */
interface PoolCreatedEvent {
  /**
   *  The ServerAddress of the Endpoint the pool is attempting to connect to.
   */
  address: string;

  /**
   *  Any non-default pool options that were set on this Connection Pool.
   */
  options: {...}
}

/**
 *  Emitted when a Connection Pool is marked as ready.
 */
interface PoolReadyEvent {
  /**
   *  The ServerAddress of the Endpoint the pool is attempting to connect to.
   */
  address: string;
}

/**
 *  Emitted when a Connection Pool is cleared
 */
interface PoolClearedEvent {
  /**
   *  The ServerAddress of the Endpoint the pool is attempting to connect to.
   */
  address: string;

  /**
   * The service id for which the pool was cleared for in load balancing mode.
   * See load balancer specification for more information about this field.
   */
  serviceId: Optional&lt;ObjectId&gt;;

  /**
   * A flag whether the pool forced interrupting "in use" connections as part of the clear.
  */
  interruptInUseConnections: Optional&lt;Boolean&gt;;
}

/**
 *  Emitted when a Connection Pool is closed
 */
interface PoolClosedEvent {
  /**
   *  The ServerAddress of the Endpoint the pool is attempting to connect to.
   */
  address: string;
}

/**
 *  Emitted when a Connection Pool creates a Connection object.
 *  NOTE: This does not mean that the Connection is ready for use.
 */
interface ConnectionCreatedEvent { 
  /**
   *  The ServerAddress of the Endpoint the pool is attempting to connect to.
   */
  address: string;

  /**
   *  The ID of the Connection
   */
  connectionId: int64;
}

/**
 *  Emitted when a Connection has finished its setup, and is now ready to use
 */
interface ConnectionReadyEvent {
  /**
   *  The ServerAddress of the Endpoint the pool is attempting to connect to.
   */
  address: string;

  /**
   *  The ID of the Connection
   */
  connectionId: int64;

  /**
   * The time it took to establish the connection.
   * In accordance with the definition of establishment of a connection
   * specified by `ConnectionPoolOptions.maxConnecting`,
   * it is the time elapsed between emitting a `ConnectionCreatedEvent`
   * and emitting this event as part of the same checking out.
   *
   * Naturally, when establishing a connection is part of checking out,
   * this duration is not greater than
   * `ConnectionCheckedOutEvent`/`ConnectionCheckOutFailedEvent.duration`.
   *
   * A driver MAY choose the type idiomatic to the driver.
   * If the type chosen does not convey units, e.g., `int64`,
   * then the driver MAY include units in the name, e.g., `durationMS`.
   */
  duration: Duration;
}

/**
 *  Emitted when a Connection Pool closes a Connection
 */
interface ConnectionClosedEvent {
  /**
   *  The ServerAddress of the Endpoint the pool is attempting to connect to.
   */
  address: string;

  /**
   *  The ID of the Connection
   */
  connectionId: int64;

  /**
   * A reason explaining why this Connection was closed.
   * Can be implemented as a string or enum.
   * Current valid values are:
   *   - "stale":           The pool was cleared, making the Connection no longer valid
   *   - "idle":            The Connection became stale by being available for too long
   *   - "error":           The Connection experienced an error, making it no longer valid
   *   - "poolClosed":      The pool was closed, making the Connection no longer valid
   */
  reason: string|Enum;
}

/**
 *  Emitted when the driver starts attempting to check out a Connection
 */
interface ConnectionCheckOutStartedEvent {
  /**
   * The ServerAddress of the Endpoint the pool is attempting
   * to connect to.
   */
  address: string;
}

/**
 *  Emitted when the driver's attempt to check out a Connection fails
 */
interface ConnectionCheckOutFailedEvent {
  /**
   *  The ServerAddress of the Endpoint the pool is attempting to connect to.
   */
  address: string;

  /**
   *  A reason explaining why Connection check out failed.
   *  Can be implemented as a string or enum.
   *  Current valid values are:
   *   - "poolClosed":      The pool was previously closed, and cannot provide new Connections
   *   - "timeout":         The Connection check out attempt exceeded the specified timeout
   *   - "connectionError": The Connection check out attempt experienced an error while setting up a new Connection
   */
  reason: string|Enum;

  /**
   * See `ConnectionCheckedOutEvent.duration`.
   */
  duration: Duration;
}

/**
 *  Emitted when the driver successfully checks out a Connection
 */
interface ConnectionCheckedOutEvent {
  /**
   *  The ServerAddress of the Endpoint the pool is attempting to connect to.
   */
  address: string;

  /**
   *  The ID of the Connection
   */
  connectionId: int64;

  /**
   * The time it took to check out the connection.
   * More specifically, the time elapsed between
   * emitting a `ConnectionCheckOutStartedEvent`
   * and emitting this event as part of the same checking out.
   *
   * Naturally, if a new connection was not created (`ConnectionCreatedEvent`)
   * and established (`ConnectionReadyEvent`) as part of checking out,
   * this duration is usually
   * not greater than `ConnectionPoolOptions.waitQueueTimeoutMS`,
   * but MAY occasionally be greater than that,
   * because a driver does not provide hard real-time guarantees.
   *
   * A driver MAY choose the type idiomatic to the driver.
   * If the type chosen does not convey units, e.g., `int64`,
   * then the driver MAY include units in the name, e.g., `durationMS`.
   */
  duration: Duration;
}

/**
 *  Emitted when the driver checks in a Connection back to the Connection Pool
 */
interface ConnectionCheckedInEvent {
  /**
   * The ServerAddress of the Endpoint the pool is attempting to connect to.
   */
  address: string;

  /**
   *  The ID of the Connection
   */
  connectionId: int64;
}
</code></pre>
<h3 id="connection-pool-logging"><a class="header" href="#connection-pool-logging">Connection Pool Logging</a></h3>
<p>Please refer to the <a href="connection-monitoring-and-pooling/../logging/logging.html">logging specification</a> for details on logging implementations in general,
including log levels, log components, handling of null values in log messages, and structured versus unstructured
logging.</p>
<p>Drivers MUST support logging of connection pool information via the following types of log messages. These messages MUST
be logged at <code>Debug</code> level and use the <code>connection</code> log component. These messages MUST be emitted when specified in
"Connection Pool Behaviors".</p>
<p>The log messages are intended to match the information contained in the events above. Drivers MAY implement connection
logging support via an event subscriber if it is convenient to do so.</p>
<p>The types used in the structured message definitions below are demonstrative, and drivers MAY use similar types instead
so long as the information is present (e.g. a double instead of an integer, or a string instead of an integer if the
structured logging framework does not support numeric types).</p>
<h4 id="common-fields"><a class="header" href="#common-fields">Common Fields</a></h4>
<p>All connection log messages MUST contain the following key-value pairs:</p>
<div class="table-wrapper"><table><thead><tr><th>Key</th><th>Suggested Type</th><th>Value</th></tr></thead><tbody>
<tr><td>serverHost</td><td>String</td><td>the hostname, IP address, or Unix domain socket path for the endpoint the pool is for.</td></tr>
<tr><td>serverPort</td><td>Int</td><td>The port for the endpoint the pool is for. Optional; not present for Unix domain sockets. When the user does not specify a port and the default (27017) is used, the driver SHOULD include it here.</td></tr>
</tbody></table>
</div>
<h4 id="pool-created-message"><a class="header" href="#pool-created-message">Pool Created Message</a></h4>
<p>In addition to the common fields defined above, this message MUST contain the following key-value pairs:</p>
<div class="table-wrapper"><table><thead><tr><th>Key</th><th>Suggested Type</th><th>Value</th></tr></thead><tbody>
<tr><td>message</td><td>String</td><td>"Connection pool created"</td></tr>
<tr><td>maxIdleTimeMS</td><td>Int</td><td>The maxIdleTimeMS value for this pool. Optional; only required to include if the user specified a value.</td></tr>
<tr><td>minPoolSize</td><td>Int</td><td>The minPoolSize value for this pool. Optional; only required to include if the user specified a value.</td></tr>
<tr><td>maxPoolSize</td><td>Int</td><td>The maxPoolSize value for this pool. Optional; only required to include if the user specified a value.</td></tr>
<tr><td>maxConnecting</td><td>Int</td><td>The maxConnecting value for this pool. Optional; only required to include if the driver supports this option and the user specified a value.</td></tr>
<tr><td>waitQueueTimeoutMS</td><td>Int</td><td>The waitQueueTimeoutMS value for this pool. Optional; only required to include if the driver supports this option and the user specified a value.</td></tr>
<tr><td>waitQueueSize</td><td>Int</td><td>The waitQueueSize value for this pool. Optional; only required to include if the driver supports this option and the user specified a value.</td></tr>
<tr><td>waitQueueMultiple</td><td>Int</td><td>The waitQueueMultiple value for this pool. Optional; only required to include if the driver supports this option and the user specified a value.</td></tr>
</tbody></table>
</div>
<p>The unstructured form SHOULD be as follows, using the values defined in the structured format above to fill in
placeholders as appropriate:</p>
<blockquote>
<p>Connection pool created for {{serverHost}}:{{serverPort}} using options maxIdleTimeMS={{maxIdleTimeMS}},
minPoolSize={{minPoolSize}}, maxPoolSize={{maxPoolSize}}, maxConnecting={{maxConnecting}},
waitQueueTimeoutMS={{waitQueueTimeoutMS}}, waitQueueSize={{waitQueueSize}}, waitQueueMultiple={{waitQueueMultiple}}</p>
</blockquote>
<h4 id="pool-ready-message"><a class="header" href="#pool-ready-message">Pool Ready Message</a></h4>
<p>In addition to the common fields defined above, this message MUST contain the following key-value pairs:</p>
<div class="table-wrapper"><table><thead><tr><th>Key</th><th>Suggested Type</th><th>Value</th></tr></thead><tbody>
<tr><td>message</td><td>String</td><td>"Connection pool ready"</td></tr>
</tbody></table>
</div>
<p>The unstructured form SHOULD be as follows, using the values defined in the structured format above to fill in
placeholders as appropriate:</p>
<blockquote>
<p>Connection pool ready for {{serverHost}}:{{serverPort}}</p>
</blockquote>
<h4 id="pool-cleared-message"><a class="header" href="#pool-cleared-message">Pool Cleared Message</a></h4>
<p>In addition to the common fields defined above, this message MUST contain the following key-value pairs:</p>
<div class="table-wrapper"><table><thead><tr><th>Key</th><th>Suggested Type</th><th>Value</th></tr></thead><tbody>
<tr><td>message</td><td>String</td><td>"Connection pool cleared"</td></tr>
<tr><td>serviceId</td><td>String</td><td>The hex string representation of the service ID which the pool was cleared for. Optional; only present in load balanced mode.</td></tr>
</tbody></table>
</div>
<p>The unstructured form SHOULD be as follows, using the values defined in the structured format above to fill in
placeholders as appropriate:</p>
<blockquote>
<p>Connection pool for {{serverHost}}:{{serverPort}} cleared for serviceId {{serviceId}}</p>
</blockquote>
<h4 id="pool-closed-message"><a class="header" href="#pool-closed-message">Pool Closed Message</a></h4>
<p>In addition to the common fields defined above, this message MUST contain the following key-value pairs:</p>
<div class="table-wrapper"><table><thead><tr><th>Key</th><th>Suggested Type</th><th>Value</th></tr></thead><tbody>
<tr><td>message</td><td>String</td><td>"Connection pool closed"</td></tr>
</tbody></table>
</div>
<p>The unstructured form SHOULD be as follows, using the values defined in the structured format above to fill in
placeholders as appropriate:</p>
<blockquote>
<p>Connection pool closed for {{serverHost}}:{{serverPort}}</p>
</blockquote>
<h4 id="connection-created-message"><a class="header" href="#connection-created-message">Connection Created Message</a></h4>
<p>In addition to the common fields defined above, this message MUST contain the following key-value pairs:</p>
<div class="table-wrapper"><table><thead><tr><th>Key</th><th>Suggested Type</th><th>Value</th></tr></thead><tbody>
<tr><td>message</td><td>String</td><td>"Connection created"</td></tr>
<tr><td>driverConnectionId</td><td>Int64</td><td>The driver-generated ID for the connection as defined in <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connection</a>.</td></tr>
</tbody></table>
</div>
<p>The unstructured form SHOULD be as follows, using the values defined in the structured format above to fill in
placeholders as appropriate:</p>
<blockquote>
<p>Connection created: address={{serverHost}}:{{serverPort}}, driver-generated ID={{driverConnectionId}}</p>
</blockquote>
<h4 id="connection-ready-message"><a class="header" href="#connection-ready-message">Connection Ready Message</a></h4>
<p>In addition to the common fields defined above, this message MUST contain the following key-value pairs:</p>
<div class="table-wrapper"><table><thead><tr><th>Key</th><th>Suggested Type</th><th>Value</th></tr></thead><tbody>
<tr><td>message</td><td>String</td><td>"Connection ready"</td></tr>
<tr><td>driverConnectionId</td><td>Int64</td><td>The driver-generated ID for the connection as defined in <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connection</a>.</td></tr>
<tr><td>durationMS</td><td>Int64</td><td><code>ConnectionReadyEvent.duration</code> converted to milliseconds.</td></tr>
</tbody></table>
</div>
<p>The unstructured form SHOULD be as follows, using the values defined in the structured format above to fill in
placeholders as appropriate:</p>
<blockquote>
<p>Connection ready: address={{serverHost}}:{{serverPort}}, driver-generated ID={{driverConnectionId}}, established
in={{durationMS}} ms</p>
</blockquote>
<h4 id="connection-closed-message"><a class="header" href="#connection-closed-message">Connection Closed Message</a></h4>
<p>In addition to the common fields defined above, this message MUST contain the following key-value pairs:</p>
<div class="table-wrapper"><table><thead><tr><th>Key</th><th>Suggested Type</th><th>Value</th></tr></thead><tbody>
<tr><td>message</td><td>String</td><td>"Connection closed"</td></tr>
<tr><td>driverConnectionId</td><td>Int64</td><td>The driver-generated ID for the connection as defined in a <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connection</a>.</td></tr>
<tr><td>reason</td><td>String</td><td>A string describing the reason the connection was closed. The following strings MUST be used for each possible reason as defined in <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#events">Events</a> above:<br>- Stale: "Connection became stale because the pool was cleared<br>- Idle: "Connection has been available but unused for longer than the configured max idle time"<br>- Error: "An error occurred while using the connection"<br>- Pool closed: "Connection pool was closed"</td></tr>
<tr><td>error</td><td>Flexible</td><td>If <code>reason</code> is <code>Error</code>, the associated error.<br>The type and format of this value is flexible; see the <a href="connection-monitoring-and-pooling/../logging/logging.html#representing-errors-in-log-messages">logging specification</a> for details on representing errors in log messages.</td></tr>
</tbody></table>
</div>
<p>The unstructured form SHOULD be as follows, using the values defined in the structured format above to fill in
placeholders as appropriate:</p>
<blockquote>
<p>Connection closed: address={{serverHost}}:{{serverPort}}, driver-generated ID={{driverConnectionId}}. Reason:
{{reason}}. Error: {{error}}</p>
</blockquote>
<h4 id="connection-checkout-started-message"><a class="header" href="#connection-checkout-started-message">Connection Checkout Started Message</a></h4>
<p>In addition to the common fields defined above, this message MUST contain the following key-value pairs:</p>
<div class="table-wrapper"><table><thead><tr><th>Key</th><th>Suggested Type</th><th>Value</th></tr></thead><tbody>
<tr><td>message</td><td>String</td><td>"Connection checkout started"</td></tr>
</tbody></table>
</div>
<p>The unstructured form SHOULD be as follows, using the values defined in the structured format above to fill in
placeholders as appropriate:</p>
<blockquote>
<p>Checkout started for connection to {{serverHost}}:{{serverPort}}</p>
</blockquote>
<h4 id="connection-checkout-failed-message"><a class="header" href="#connection-checkout-failed-message">Connection Checkout Failed Message</a></h4>
<p>In addition to the common fields defined above, this message MUST contain the following key-value pairs:</p>
<div class="table-wrapper"><table><thead><tr><th>Key</th><th>Suggested Type</th><th>Value</th></tr></thead><tbody>
<tr><td>message</td><td>String</td><td>"Connection checkout failed"</td></tr>
<tr><td>reason</td><td>String</td><td>A string describing the reason checkout. The following strings MUST be used for each possible reason as defined in <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#events">Events</a> above:<br>- Timeout: "Wait queue timeout elapsed without a connection becoming available"<br>- ConnectionError: "An error occurred while trying to establish a new connection"<br>- Pool closed: "Connection pool was closed"</td></tr>
<tr><td>error</td><td>Flexible</td><td>If <code>reason</code> is <code>ConnectionError</code>, the associated error. The type and format of this value is flexible; see the <a href="connection-monitoring-and-pooling/../logging/logging.html#representing-errors-in-log-messages">logging specification</a> for details on representing errors in log messages.</td></tr>
<tr><td>durationMS</td><td>Int64</td><td><code>ConnectionCheckOutFailedEvent.duration</code> converted to milliseconds.</td></tr>
</tbody></table>
</div>
<p>The unstructured form SHOULD be as follows, using the values defined in the structured format above to fill in
placeholders as appropriate:</p>
<blockquote>
<p>Checkout failed for connection to {{serverHost}}:{{serverPort}}. Reason: {{reason}}. Error: {{error}}. Duration:
{{durationMS}} ms</p>
</blockquote>
<h4 id="connection-checked-out"><a class="header" href="#connection-checked-out">Connection Checked Out</a></h4>
<p>In addition to the common fields defined above, this message MUST contain the following key-value pairs:</p>
<div class="table-wrapper"><table><thead><tr><th>Key</th><th>Suggested Type</th><th>Value</th></tr></thead><tbody>
<tr><td>message</td><td>String</td><td>"Connection checked out"</td></tr>
<tr><td>driverConnectionId</td><td>Int64</td><td>The driver-generated ID for the connection as defined in <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connection</a>.</td></tr>
<tr><td>durationMS</td><td>Int64</td><td><code>ConnectionCheckedOutEvent.duration</code> converted to milliseconds.</td></tr>
</tbody></table>
</div>
<p>The unstructured form SHOULD be as follows, using the values defined in the structured format above to fill in
placeholders as appropriate:</p>
<blockquote>
<p>Connection checked out: address={serverHost}}:{{serverPort}}, driver-generated ID={{driverConnectionId}},
duration={{durationMS}} ms</p>
</blockquote>
<h4 id="connection-checked-in"><a class="header" href="#connection-checked-in">Connection Checked In</a></h4>
<p>In addition to the common fields defined above, this message MUST contain the following key-value pairs:</p>
<div class="table-wrapper"><table><thead><tr><th>Key</th><th>Suggested Type</th><th>Value</th></tr></thead><tbody>
<tr><td>message</td><td>String</td><td>"Connection checked in"</td></tr>
<tr><td>driverConnectionId</td><td>Int64</td><td>The driver-generated ID for the connection as defined in <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connection</a>.</td></tr>
</tbody></table>
</div>
<p>The unstructured form SHOULD be as follows, using the values defined in the structured format above to fill in
placeholders as appropriate:</p>
<blockquote>
<p>Connection checked in: address={{serverHost}}:{{serverPort}}, driver-generated ID={{driverConnectionId}}</p>
</blockquote>
<h3 id="connection-pool-errors"><a class="header" href="#connection-pool-errors">Connection Pool Errors</a></h3>
<p>A connection pool throws errors in specific circumstances. These Errors MUST be emitted by the pool. Errors SHOULD be
created and dispatched in a manner idiomatic to the Driver and Language.</p>
<pre><code class="language-typescript">/**
 *  Thrown when the driver attempts to check out a
 *  Connection from a closed Connection Pool
 */
interface PoolClosedError {
  message: 'Attempted to check out a Connection from closed connection pool';
  address: &lt;pool address&gt;;
}

/**
 *  Thrown when the driver attempts to check out a
 *  Connection from a paused Connection Pool
 */
interface PoolClearedError extends RetryableError {
  message: 'Connection pool for &lt;pool address&gt; was cleared because another operation failed with: &lt;original error which cleared the pool&gt;';
  address: &lt;pool address&gt;;
}

/**
 *  Thrown when a driver times out when attempting to check out
 *  a Connection from a Pool
 */
interface WaitQueueTimeoutError {
  message: 'Timed out while checking out a Connection from connection pool';
  address: &lt;pool address&gt;;
}
</code></pre>
<h2 id="test-plan-11"><a class="header" href="#test-plan-11">Test Plan</a></h2>
<p>See <a href="connection-monitoring-and-pooling/tests/README.html">tests/README</a></p>
<h2 id="design-rationale-10"><a class="header" href="#design-rationale-10">Design Rationale</a></h2>
<h3 id="why-do-we-set-minpoolsize-across-all-members-of-a-replicaset-when-most-traffic-will-be-against-a-primary"><a class="header" href="#why-do-we-set-minpoolsize-across-all-members-of-a-replicaset-when-most-traffic-will-be-against-a-primary">Why do we set minPoolSize across all members of a replicaSet, when most traffic will be against a Primary?</a></h3>
<p>Currently, we are attempting to codify our current pooling behavior with minimal changes, and minPoolSize is currently
uniform across all members of a replicaSet. This has the benefit of offsetting connection swarming during a Primary
Step-Down, which will be further addressed in our <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#advanced-pooling-behaviors">Advanced Pooling Behaviors</a>.</p>
<h3 id="why-do-we-have-separate-connectioncreated-and-connectionready-events-but-only-one-connectionclosed-event"><a class="header" href="#why-do-we-have-separate-connectioncreated-and-connectionready-events-but-only-one-connectionclosed-event">Why do we have separate ConnectionCreated and ConnectionReady events, but only one ConnectionClosed event?</a></h3>
<p>ConnectionCreated and ConnectionReady each involve different state changes in the pool.</p>
<ul>
<li>ConnectionCreated adds a new "pending" <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connection</a>, meaning the totalConnectionCount and
pendingConnectionCount increase by one</li>
<li>ConnectionReady establishes that the <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connection</a> is ready for use, meaning the availableConnectionCount
increases by one</li>
</ul>
<p>ConnectionClosed indicates that the <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connection</a> is no longer a member of the pool, decrementing
totalConnectionCount and potentially availableConnectionCount. After this point, the <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connection</a> is no
longer a part of the pool. Further hypothetical events would not indicate a change to the state of the pool, so they are
not specified here.</p>
<h3 id="why-are-waitqueuesize-and-waitqueuemultiple-deprecated"><a class="header" href="#why-are-waitqueuesize-and-waitqueuemultiple-deprecated">Why are waitQueueSize and waitQueueMultiple deprecated?</a></h3>
<p>These options were originally only implemented in three drivers (Java, C#, and Python), and provided little value. While
these fields would allow for faster diagnosis of issues in the connection pool, they would not actually prevent an error
from occurring.</p>
<p>Additionally, these options have the effect of prioritizing older requests over newer requests, which is not necessarily
the behavior that users want. They can also result in cases where queue access oscillates back and forth between full
and not full. If a driver has a full waitQueue, then all requests for <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connections</a> will be rejected. If
the client is continually spammed with requests, you could wind up with a scenario where as soon as the waitQueue is no
longer full, it is immediately filled. It is not a favorable situation to be in, partially b/c it violates the fairness
guarantee that the waitQueue normally provides.</p>
<p>Because of these issues, it does not make sense to
<a href="connection-monitoring-and-pooling/../driver-mantras.html#">go against driver mantras and provide an additional knob</a>. We may eventually pursue an
alternative configuration to address wait queue size in <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#advanced-pooling-behaviors">Advanced Pooling Behaviors</a>.</p>
<p>Users that wish to have this functionality can achieve similar results by utilizing other methods to limit concurrency.
Examples include implementing either a thread pool or an operation queue with a capped size in the user application.
Drivers that need to deprecate <code>waitQueueSize</code> and/or <code>waitQueueMultiple</code> SHOULD refer users to these examples.</p>
<h3 id="why-is-waitqueuetimeoutms-optional-for-some-drivers"><a class="header" href="#why-is-waitqueuetimeoutms-optional-for-some-drivers">Why is waitQueueTimeoutMS optional for some drivers?</a></h3>
<p>We are anticipating eventually introducing a single client-side timeout mechanism, making us hesitant to introduce
another granular timeout control. Therefore, if a driver/language already has an idiomatic way to implement their
timeouts, they should leverage that mechanism over implementing waitQueueTimeoutMS.</p>
<h3 id="why-must-populating-the-pool-require-the-use-of-a-background-thread-or-async-io"><a class="header" href="#why-must-populating-the-pool-require-the-use-of-a-background-thread-or-async-io">Why must populating the pool require the use of a background thread or async I/O?</a></h3>
<p>Without the use of a background thread, the pool is
<a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#populating-the-pool-with-a-connection-internal-implementation">populated</a> with enough connections to satisfy
minPoolSize during checkOut. <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connections</a> are established as part of populating the pool though, so if
<a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connection</a> establishment were done in a blocking fashion, the first operations after a clearing of the
pool would experience unacceptably high latency, especially for larger values of minPoolSize. Thus, populating the pool
must occur on a background thread (which is acceptable to block) or via the usage of non-blocking (async) I/O.</p>
<h3 id="why-should-closing-a-connection-be-non-blocking"><a class="header" href="#why-should-closing-a-connection-be-non-blocking">Why should closing a connection be non-blocking?</a></h3>
<p>Because idle and perished <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connections</a> are cleaned up as part of checkOut, performing blocking I/O while
closing such <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connections</a> would block application threads, introducing unnecessary latency. Once a
<a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connection</a> is marked as "closed", it will not be checked out again, so ensuring the socket is torn down
does not need to happen immediately and can happen at a later time, either via async I/O or a background thread.</p>
<h3 id="why-can-the-pool-be-paused"><a class="header" href="#why-can-the-pool-be-paused">Why can the pool be paused?</a></h3>
<p>The distinction between the "paused" state and the "ready" state allows the pool to determine whether or not the
endpoint it is associated with is available or not. This enables the following behaviors:</p>
<ol>
<li>The pool can halt the creation of background connection establishments until the endpoint becomes available again.
Without the "paused" state, the pool would have no way of determining when to begin establishing background
connections again, so it would just continually attempt, and often fail, to create connections until minPoolSize was
satisfied, even after repeated failures. This could unnecessarily waste resources both server and driver side.</li>
<li>The pool can evict requests that enter the WaitQueue after the pool was cleared but before the server was in a known
state again. Such requests can occur when a server is selected at the same time as it becomes marked as Unknown in
highly concurrent workloads. Without the "paused" state, the pool would attempt to service these requests, since it
would assume they were routed to the pool because its endpoint was available, not because of a race between SDAM and
Server Selection. These requests would then likely fail with potentially high latency, again wasting resources both
server and driver side.</li>
</ol>
<h3 id="why-not-emit-poolcleared-events-and-log-messages-when-clearing-a-paused-pool"><a class="header" href="#why-not-emit-poolcleared-events-and-log-messages-when-clearing-a-paused-pool">Why not emit PoolCleared events and log messages when clearing a paused pool?</a></h3>
<p>If a pool is already paused when it is cleared, that means it was previously cleared and no new connections have been
created since then. Thus, clearing the pool in this case is essentially a no-op, so there is no need to notify any
listeners that it has occurred. The generation is still incremented, however, to ensure future errors that caused the
duplicate clear will stop attempting to clear the pool again. This situation is possible if the pool is cleared by the
background thread after it encounters an error establishing a connection, but the ServerDescription for the endpoint was
not updated accordingly yet.</p>
<h3 id="why-does-the-pool-need-to-support-interrupting-in-use-connections-as-part-of-its-clear-logic"><a class="header" href="#why-does-the-pool-need-to-support-interrupting-in-use-connections-as-part-of-its-clear-logic">Why does the pool need to support interrupting in use connections as part of its clear logic?</a></h3>
<p>If a SDAM monitor has observed a network timeout, we assume that all connections including "in use" connections are no
longer healthy. In some cases connections will fail to detect the network timeout fast enough. For example, a server
request can hang at the OS level in TCP retry loop up for 17 minutes before failing. Therefore these connections MUST be
proactively interrupted in the case of a server monitor network timeout. Requesting an immediate background thread run
will speed up this process.</p>
<h3 id="why-dont-we-configure-tcp_user_timeout"><a class="header" href="#why-dont-we-configure-tcp_user_timeout">Why don't we configure TCP_USER_TIMEOUT?</a></h3>
<p>Ideally, a reasonable TCP_USER_TIMEOUT can help with detecting stale connections as an alternative to
<code>interruptInUseConnections</code> in Clear. Unfortunately this approach is platform dependent and not each driver allows
easily configuring it. For example, C# driver can configure this socket option on linux only with target frameworks
higher or equal to .net 5.0. On macOS, there is no straight equivalent for this option, it's possible that we can find
some equivalent configuration, but this configuration will also require target frameworks higher than or equal to .net
5.0. The advantage of using Background Thread to manage perished connections is that it will work regardless of
environment setup.</p>
<h2 id="backwards-compatibility-9"><a class="header" href="#backwards-compatibility-9">Backwards Compatibility</a></h2>
<p>As mentioned in <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#deprecated-options">Deprecated Options</a>, some drivers currently implement the options <code>waitQueueSize</code>
and/or <code>waitQueueMultiple</code>. These options will need to be deprecated and phased out of the drivers that have implemented
them.</p>
<h2 id="reference-implementations-3"><a class="header" href="#reference-implementations-3">Reference Implementations</a></h2>
<ul>
<li>JAVA (JAVA-3079)</li>
<li>RUBY (RUBY-1560)</li>
</ul>
<h2 id="future-development"><a class="header" href="#future-development">Future Development</a></h2>
<h3 id="sdam"><a class="header" href="#sdam">SDAM</a></h3>
<p>This specification does not dictate how SDAM Monitoring connections are managed. SDAM specifies that "A monitor SHOULD
NOT use the client's regular Connection pool". Some possible solutions for this include:</p>
<ul>
<li>Having each Endpoint representation in the driver create and manage a separate dedicated <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connection</a> for
monitoring purposes</li>
<li>Having each Endpoint representation in the driver maintain a separate pool of maxPoolSize 1 for monitoring purposes.</li>
<li>Having each Pool maintain a dedicated <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connection</a> for monitoring purposes, with an API to expose that
Connection.</li>
</ul>
<h3 id="advanced-pooling-behaviors"><a class="header" href="#advanced-pooling-behaviors">Advanced Pooling Behaviors</a></h3>
<p>This spec does not address all advanced pooling behaviors like predictive pooling or aggressive
<a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connection</a> creation. Future work may address this.</p>
<h3 id="add-support-for-op_msg-exhaustallowed"><a class="header" href="#add-support-for-op_msg-exhaustallowed">Add support for OP_MSG exhaustAllowed</a></h3>
<p>Exhaust Cursors may require changes to how we close <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connections</a> in the future, specifically to add a way
to close and remove from its pool a <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connection</a> which has unread exhaust messages.</p>
<h2 id="changelog-15"><a class="header" href="#changelog-15">Changelog</a></h2>
<ul>
<li>
<p>2024-01-23: Migrated from reStructuredText to Markdown.</p>
</li>
<li>
<p>2019-06-06: Add "connectionError" as a valid reason for ConnectionCheckOutFailedEvent</p>
</li>
<li>
<p>2020-09-03: Clarify Connection states and definition. Require the use of a background thread and/or async I/O. Add
tests to ensure ConnectionReadyEvents are fired after ConnectionCreatedEvents.</p>
</li>
<li>
<p>2020-09-24: Introduce maxConnecting requirement</p>
</li>
<li>
<p>2020-12-17: Introduce "paused" and "ready" states. Clear WaitQueue on pool clear.</p>
</li>
<li>
<p>2021-01-12: Clarify "clear" method behavior in load balancer mode.</p>
</li>
<li>
<p>2021-01-19: Require that timeouts be applied per the client-side operations timeout specification.</p>
</li>
<li>
<p>2021-04-12: Adding in behaviour for load balancer mode.</p>
</li>
<li>
<p>2021-06-02: Formalize the behavior of a <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#background-thread">Background Thread</a>.</p>
</li>
<li>
<p>2021-11-08: Make maxConnecting configurable.</p>
</li>
<li>
<p>2022-04-05: Preemptively cancel in progress operations when SDAM heartbeats timeout.</p>
</li>
<li>
<p>2022-10-05: Remove spec front matter and reformat changelog.</p>
</li>
<li>
<p>2022-10-14: Add connection pool log messages and associated tests.</p>
</li>
<li>
<p>2023-04-17: Fix duplicate logging test description.</p>
</li>
<li>
<p>2023-08-04: Add durations to connection pool events.</p>
</li>
<li>
<p>2023-10-04: Commit to the currently specified requirements regarding durations in events.</p>
</li>
</ul>
<hr />
<div style="break-before: page; page-break-before: always;"></div><h1 id="load-balancer-support"><a class="header" href="#load-balancer-support">Load Balancer Support</a></h1>
<ul>
<li>Status: Accepted</li>
<li>Minimum Server Version: 5.0</li>
</ul>
<hr />
<h2 id="abstract-16"><a class="header" href="#abstract-16">Abstract</a></h2>
<p>This specification defines driver behaviour when connected to MongoDB services through a load balancer.</p>
<h2 id="meta-16"><a class="header" href="#meta-16">META</a></h2>
<p>The keywords "MUST", "MUST NOT", "REQUIRED", "SHALL", "SHALL NOT", "SHOULD", "SHOULD NOT", "RECOMMENDED", "MAY", and
"OPTIONAL" in this document are to be interpreted as described in <a href="https://www.ietf.org/rfc/rfc2119.txt">RFC 2119</a>.</p>
<h2 id="specification-14"><a class="header" href="#specification-14">Specification</a></h2>
<h3 id="terms-7"><a class="header" href="#terms-7">Terms</a></h3>
<h4 id="sdam-1"><a class="header" href="#sdam-1">SDAM</a></h4>
<p>An abbreviated form of "Server Discovery and Monitoring", specification defined in
<a href="load-balancers/../server-discovery-and-monitoring/server-discovery-and-monitoring.html">Server Discovery and Monitoring Specification</a>.</p>
<h4 id="service"><a class="header" href="#service">Service</a></h4>
<p>Any MongoDB service that can run behind a load balancer.</p>
<h3 id="mongoclient-configuration-3"><a class="header" href="#mongoclient-configuration-3">MongoClient Configuration</a></h3>
<h4 id="loadbalanced"><a class="header" href="#loadbalanced">loadBalanced</a></h4>
<p>To specify to the driver to operate in load balancing mode, a connection string option of <code>loadBalanced=true</code> MUST be
added to the connection string. This boolean option specifies whether or not the driver is connecting to a MongoDB
cluster through a load balancer. The default value MUST be false. This option MUST only be configurable at the level of
a <code>MongoClient</code>.</p>
<h4 id="uri-validation-1"><a class="header" href="#uri-validation-1">URI Validation</a></h4>
<p>When <code>loadBalanced=true</code> is provided in the connection string, the driver MUST throw an exception in the following
cases:</p>
<ul>
<li>The connection string contains more than one host/port.</li>
<li>The connection string contains a <code>replicaSet</code> option.</li>
<li>The connection string contains a <code>directConnection</code> option with a value of <code>true</code>.</li>
<li>The connection string contains an <code>srvMaxHosts</code> option with a positive integer value.</li>
</ul>
<p>If a URI is provided with the <code>mongodb+srv</code> scheme, the driver MUST first do the SRV and TXT lookup and then perform the
validation. For drivers that do SRV lookup asynchronously this may result in a <code>MongoClient</code> being instantiated but
erroring later during operation execution.</p>
<h4 id="dns-seedlist-discovery"><a class="header" href="#dns-seedlist-discovery">DNS Seedlist Discovery</a></h4>
<p>The connection string option for <code>loadBalanced=true</code> MUST be valid in a TXT record and when present MUST be validated as
defined in the URI Validation section.</p>
<p>When a MongoClient is configured with an SRV URI and <code>loadBalanced=true</code>, the driver MUST NOT poll for changes in the
SRV record as is done for non-load balanced sharded clusters.</p>
<h3 id="server-discovery-logging-and-monitoring"><a class="header" href="#server-discovery-logging-and-monitoring">Server Discovery Logging and Monitoring</a></h3>
<p><span id="monitoring"></span></p>
<h4 id="monitoring-1"><a class="header" href="#monitoring-1">Monitoring</a></h4>
<p>When <code>loadBalanced=true</code> is specified in the URI the topology MUST start in type <code>LoadBalanced</code> and MUST remain as
<code>LoadBalanced</code> indefinitely. The topology MUST contain 1 <code>ServerDescription</code> with a <code>ServerType</code> of -
Code:<code>LoadBalancer</code>. The "address" field of the <code>ServerDescription</code> MUST be set to the address field of the load
balancer. All other fields in the - Code:<code>ServerDescription</code> MUST remain unset. In this mode the driver MUST NOT start a
monitoring connection. The <code>TopologyDescription</code>'s <code>compatible</code> field MUST always be <code>true</code>.</p>
<p>Although there is no monitoring connection in load balanced mode, drivers MUST emit the following series of SDAM events:</p>
<ul>
<li><code>TopologyOpeningEvent</code> when the topology is created.</li>
<li><code>TopologyDescriptionChangedEvent</code>. The <code>previousDescription</code> field MUST have <code>TopologyType</code> <code>Unknown</code> and no servers.
The <code>newDescription</code> MUST have <code>TopologyType</code> <code>LoadBalanced</code> and one server with <code>ServerType</code> <code>Unknown</code>.</li>
<li><code>ServerOpeningEvent</code> when the server representing the load balancer is created.</li>
<li><code>ServerDescriptionChangedEvent</code>. The <code>previousDescription</code> MUST have <code>ServerType</code> <code>Unknown</code>. The <code>newDescription</code> MUST
have <code>ServerType</code> <code>LoadBalancer</code>.</li>
<li><code>TopologyDescriptionChangedEvent</code>. The <code>newDescription</code> MUST have <code>TopologyType</code> <code>LoadBalanced</code> and one server with
<code>ServerType</code> <code>LoadBalancer</code>.</li>
</ul>
<p>Drivers MUST also emit a <code>ServerClosedEvent</code> followed by a <code>TopologyDescriptionChangedEvent</code> that transitions the
<code>Topology</code> to the <code>UNKNOWN</code> state and a <code>TopologyClosedEvent</code> when the topology is closed and MUST NOT emit any other
events when operating in this mode.</p>
<h4 id="log-messages"><a class="header" href="#log-messages">Log Messages</a></h4>
<p>SDAM events details described in <a href="load-balancers/load-balancers.html#monitoring">Monitoring</a> apply to corresponding log messages. Please refer to the
<a href="load-balancers/../server-discovery-and-monitoring/server-discovery-and-monitoring-logging-and-monitoring.html#log-messages">SDAM logging specification</a>
for details on SDAM logging. Drivers MUST emit the relevant SDAM log messages, such as:</p>
<ul>
<li><a href="load-balancers/../server-discovery-and-monitoring/server-discovery-and-monitoring-logging-and-monitoring.html#starting-topology-monitoring-log-message">Starting Topology Monitoring</a></li>
<li><a href="load-balancers/../server-discovery-and-monitoring/server-discovery-and-monitoring-logging-and-monitoring.html#stopped-topology-monitoring-log-message">Stopped Topology Mmonitoring</a></li>
<li><a href="load-balancers/../server-discovery-and-monitoring/server-discovery-and-monitoring-logging-and-monitoring.html#starting-server-monitoring-log-message">Starting Server Monitoring</a></li>
<li><a href="load-balancers/../server-discovery-and-monitoring/server-discovery-and-monitoring-logging-and-monitoring.html#stopped-server-monitoring-log-message">Stopped Server Monitoring</a></li>
<li><a href="load-balancers/../server-discovery-and-monitoring/server-discovery-and-monitoring-logging-and-monitoring.html#topology-description-changed-log-message">Topology Description Changed</a></li>
</ul>
<h3 id="driver-sessions-2"><a class="header" href="#driver-sessions-2">Driver Sessions</a></h3>
<h4 id="session-support"><a class="header" href="#session-support">Session Support</a></h4>
<p>When the <code>TopologyType</code> is <code>LoadBalanced</code>, sessions are always supported.</p>
<h4 id="session-expiration"><a class="header" href="#session-expiration">Session Expiration</a></h4>
<p>When in load balancer mode, drivers MUST ignore <code>logicalSessionTimeoutMinutes</code> and MUST NOT prune client sessions from
the session pool when implemented by the driver.</p>
<h4 id="data-bearing-server-type-1"><a class="header" href="#data-bearing-server-type-1">Data-Bearing Server Type</a></h4>
<p>A <code>ServerType</code> of <code>LoadBalancer</code> MUST be considered a data-bearing server.</p>
<h3 id="server-selection-1"><a class="header" href="#server-selection-1">Server Selection</a></h3>
<p>A deployment of topology type Load Balanced contains one server of type <code>LoadBalancer</code>.</p>
<p>For read and write operations, the single server in the topology MUST always be selected.</p>
<p>During command construction, the LoadBalancer server MUST be treated like a mongos and drivers MUST add a
<code>$readPreference</code> field to the command when required by
<a href="load-balancers/../server-selection/server-selection.html#passing-read-preference-to-mongos-and-load-balancers">Passing read preference to mongos and load balancers</a>.</p>
<h3 id="connection-pooling-1"><a class="header" href="#connection-pooling-1">Connection Pooling</a></h3>
<h4 id="connection-establishment-1"><a class="header" href="#connection-establishment-1">Connection Establishment</a></h4>
<p>In the case of the driver having the <code>loadBalanced=true</code> connection string option specified, every pooled connection
MUST add a <code>loadBalanced</code> field to the - Code:<code>hello</code> command in its
<a href="load-balancers/../mongodb-handshake/handshake.html#connection-handshake">handshake</a>. The value of the field MUST be <code>true</code>. If
<code>loadBalanced=true</code> is specified then the <code>OP_MSG</code> protocol MUST be used for all steps of the connection handshake.</p>
<p>Example:</p>
<p>Driver connection string contains <code>loadBalanced=true</code>:</p>
<pre><code class="language-typescript">{ hello: 1, loadBalanced: true }
</code></pre>
<p>Driver connection string contains <code>loadBalanced=false</code> or no - Code:<code>loadBalanced</code> option:</p>
<pre><code class="language-typescript">{ hello: 1 }
</code></pre>
<p>When the server's hello response does not contain a <code>serviceId</code> field, the driver MUST throw an exception with the
message "Driver attempted to initialize in load balancing mode, but the server does not support this mode."</p>
<p>For single threaded drivers that do not use a connection pool, the driver MUST have only 1 socket connection to the load
balancer in load balancing mode.</p>
<h4 id="connection-pinning"><a class="header" href="#connection-pinning">Connection Pinning</a></h4>
<p>Some features in MongoDB such as cursors and transactions require sending multiple commands to the same mongos in a
sharded cluster. In load balanced mode, it is not possible to target the same mongos behind a load balancer when pooling
connections. To account for this, drivers MUST pin to a single connection for these features. When using a pinned
connection, the driver MUST emit only 1 - Code:<code>ConnectionCheckOutStartedEvent</code>, and only 1 <code>ConnectionCheckedOutEvent</code>
or <code>ConnectionCheckOutFailedEvent</code>. Similarly, the driver MUST only publish 1 - Code:<code>ConnectionCheckedInEvent</code>.</p>
<h4 id="behaviour-with-cursors"><a class="header" href="#behaviour-with-cursors">Behaviour With Cursors</a></h4>
<p>When the driver is in load balancing mode and executing any cursor-initiating command, the driver MUST NOT check the
connection back into the pool unless the command fails or the server returns a cursor ID of <code>0</code> (i.e. all documents are
returned in a single batch). Otherwise, the driver MUST continue to use the same connection for all subsequent -
Code:<code>getMore</code> commands for the cursor. The driver MUST check the connection back into the pool if the server returns a
cursor ID of <code>0</code> in a <code>getMore</code> response (i.e. the cursor is drained). When the cursor's <code>close</code> method is invoked,
either explicitly or via an implicit resource cleanup mechanism, the driver MUST use the same connection to execute a
<code>killCursors</code> command if necessary and then check the connection back into the pool regardless of the result.</p>
<p>For multi-threaded drivers, cursors with pinned connections MUST either document to the user that calling <code>next()</code> and
<code>close()</code> operations on the cursor concurrently is not permitted, or explicitly prevent cursors from executing those
operations simultaneously.</p>
<p>If a <code>getMore</code> fails with a network error, drivers MUST leave the connection pinned to the cursor. When the cursor's
<code>close</code> method is invoked, drivers MUST NOT execute a <code>killCursors</code> command because the pinned connection is no longer
valid and MUST return the connection back to the pool.</p>
<h4 id="behaviour-with-transactions"><a class="header" href="#behaviour-with-transactions">Behaviour With Transactions</a></h4>
<p>When executing a transaction in load balancing mode, drivers MUST follow the rules outlined in
<a href="load-balancers/../transactions/transactions.html#sharded-transactions">Sharded Transactions</a> with one exception: drivers MUST use the
same connection for all commands in the transaction (excluding retries of commitTranscation and abortTransaction in some
cases). Pinning to a single connection ensures that all commands in the transaction target the same service behind the
load balancer. The rules for pinning to a connection and releasing a pinned connection are the same as those for server
pinning in non-load balanced sharded transactions as described in
<a href="load-balancers/../transactions/transactions.html#when-to-unpin">When to unpin</a>. Drivers MUST NOT use the same connection for two
concurrent transactions run under different sessions from the same client.</p>
<h4 id="connection-tracking"><a class="header" href="#connection-tracking">Connection Tracking</a></h4>
<p>The driver connection pool MUST track the purpose for which connections are checked out in the following 3 categories:</p>
<ul>
<li>Connections checked out for cursors</li>
<li>Connections checked out for transactions</li>
<li>Connections checked out for operations not falling under the previous 2 categories</li>
</ul>
<p>When the connection pool's <code>maxPoolSize</code> is reached and the pool times out waiting for a new connection the
<code>WaitQueueTimeoutError</code> MUST include a new detailed message, "Timeout waiting for connection from the connection pool.
maxPoolSize: n, connections in use by cursors: n, connections in use by transactions: n, connections in use by other
operations: n".</p>
<h3 id="error-handling-1"><a class="header" href="#error-handling-1">Error Handling</a></h3>
<h4 id="initial-handshake-errors"><a class="header" href="#initial-handshake-errors">Initial Handshake Errors</a></h4>
<p>When establishing a new connection in load balanced mode, drivers MUST NOT perform SDAM error handling for any errors
that occur before the MongoDB Handshake (i.e. <code>hello</code> command) is complete. Errors during the MongoDB Handshake MUST
also be ignored for SDAM error handling purposes. Once the initial handshake is complete, the connection MUST determine
its generation number based on the <code>serviceId</code> field in the handshake response. Any errors that occur during the rest of
connection establishment (e.g. errors during authentication commands) MUST go through the SDAM error handling flow but
MUST NOT mark the server as - Code:<code>Unknown</code> and when requiring the connection pool to be cleared, MUST only clear
connections for the <code>serviceId</code>.</p>
<h4 id="post-handshake-errors"><a class="header" href="#post-handshake-errors">Post-Handshake Errors</a></h4>
<p>When the driver is operating in load balanced mode and an application operation receives a state change error, the
driver MUST NOT make any changes to the <code>TopologyDescription</code> or the <code>ServerDescription</code> of the load balancer (i.e. it
MUST NOT mark the load balancer as <code>Unknown</code>). If the error requires the connection pool to be cleared, the driver MUST
only clear connections with the same <code>serviceId</code> as the connection which errored.</p>
<h3 id="events-2"><a class="header" href="#events-2">Events</a></h3>
<p>When in load balancer mode the driver MUST now include the <code>serviceId</code> in the - Code:<code>CommandStartedEvent</code>,
<code>CommandSucceededEvent</code>, and - Code:<code>CommandFailedEvent</code>. The driver MAY decide how to expose this information. Drivers
that have a <code>ConnectionId</code> object for example, MAY choose to provide a - Code:<code>serviceId</code> in that object. The
<code>serviceId</code> field is only present when in load balancer mode and connected to a service that is behind a load balancer.</p>
<p>Additionally the <code>PoolClearedEvent</code> MUST also contain a <code>serviceId</code> field.</p>
<h3 id="downstream-visible-behavioral-changes"><a class="header" href="#downstream-visible-behavioral-changes">Downstream Visible Behavioral Changes</a></h3>
<p>Services MAY add a command line option or other configuration parameter, that tells the service it is running behind a
load balancer. Services MAY also dynamically determine whether they are behind a load balancer.</p>
<p>All services which terminate TLS MUST be configured to return a TLS certificate for a hostname which matches the
hostname the client is connecting to.</p>
<p>All services behind a load balancer that have been started with the aforementioned option MUST add a top level
<code>serviceId</code> field to their response to the <code>hello</code> command. This field MUST be a BSON <code>ObjectId</code> and SHOULD NOT change
while the service is running. When a driver is configured to not be in load balanced mode and the service is configured
behind a load balancer, the service MAY return an error from the driver's <code>hello</code> command that the driver is not
configured to use it properly.</p>
<p>All services that have the behaviour of reaping idle cursors after a specified period of time MAY also close the
connection associated with the cursor when the cursor is reaped. Conversely, those services MAY reap a cursor when the
connection associated with the cursor is closed.</p>
<p>All services that have the behaviour of reaping idle transactions after a specified period of time MAY also close the
connection associated with the transaction when the transaction is reaped. Conversely, those services must abort a
transaction when the connection associated with the transaction is closed.</p>
<p>Any applications that connect directly to services and not through the load balancer MUST connect via the regular
service port as they normally would and not the port specified by the <code>loadBalancerPort</code> option. The <code>loadBalanced=true</code>
URI option MUST be omitted in this case.</p>
<h3 id="qa-6"><a class="header" href="#qa-6">Q&amp;A</a></h3>
<h4 id="why-use-a-connection-string-option-instead-of-a-new-uri-scheme"><a class="header" href="#why-use-a-connection-string-option-instead-of-a-new-uri-scheme">Why use a connection string option instead of a new URI scheme?</a></h4>
<p>Use of a connection string option would allow the driver to continue to use SRV records that pointed at a load balancer
instead of a replica set without needing to change the URI provided to the <code>MongoClient</code>. The SRV records could also
provide the default <code>loadBalanced=true</code> in the TXT records.</p>
<h4 id="why-explicitly-opt-in-to-this-behaviour-instead-of-letting-mongos-inform-the-driver-of-the-load-balancer"><a class="header" href="#why-explicitly-opt-in-to-this-behaviour-instead-of-letting-mongos-inform-the-driver-of-the-load-balancer">Why explicitly opt-in to this behaviour instead of letting mongos inform the driver of the load balancer?</a></h4>
<p>Other versions of this design proposed a scheme in which the application does not have to opt-in to load balanced mode.
Instead, the server would send a special field in <code>hello</code> command responses to indicate that it was running behind a
load balancer and the driver would change its behavior accordingly. We opted to take an approach that required code
changes instead because load balancing changes driver behavior in ways that could cause unexpected application errors,
so it made sense to have applications consciously opt-in to this mode. For example, connection pinning creates new
stresses on connection pools because we go from a total of <code>numMongosServers * maxPoolSize</code> connections to simply
maxPoolSize. Furthermore, connections get pinned to open cursors and transactions, further straining resource
availability. Due to this change, applications may also need to increase the configured <code>maxPoolSize</code> when opting into
this mode.</p>
<h4 id="why-does-this-specification-instruct-drivers-to-not-check-connections-back-into-the-connection-pool-in-some-circumstances"><a class="header" href="#why-does-this-specification-instruct-drivers-to-not-check-connections-back-into-the-connection-pool-in-some-circumstances">Why does this specification instruct drivers to not check connections back into the connection pool in some circumstances?</a></h4>
<p>In the case of a load balancer fronting multiple services, it is possible that a connection to the load balancer could
result in a connection behind the load balancer to a different service. In order to guarantee these operations execute
on the same service they need to be executed on the same socket - not checking a connection back into the pool for the
entire operation guarantees this.</p>
<h4 id="what-reason-has-a-client-side-connection-reaper-for-idle-cursors-not-been-put-into-this-specification"><a class="header" href="#what-reason-has-a-client-side-connection-reaper-for-idle-cursors-not-been-put-into-this-specification">What reason has a client side connection reaper for idle cursors not been put into this specification?</a></h4>
<p>It was discussed as a potential solution for maxed out connection pools that the drivers could potentially behave
similar to the server and close long running cursors after a specified time period and return their connections to the
pool. Due to the high complexity of that solution it was determined that better error messaging when the connection pool
was maxed out would suffice in order for users to easily debug when the pool ran out of connections and fix their
applications or adjust their pool options accordingly.</p>
<h4 id="why-are-we-requiring-mongos-servers-to-add-a-new-serviceid-field-in-hello-responses-rather-than-reusing-the-existing-topologyversionprocessid"><a class="header" href="#why-are-we-requiring-mongos-servers-to-add-a-new-serviceid-field-in-hello-responses-rather-than-reusing-the-existing-topologyversionprocessid">Why are we requiring mongos servers to add a new serviceId field in hello responses rather than reusing the existing topologyVersion.processId?</a></h4>
<p>This option was previously discussed, but we opted to add a new <code>hello</code> response field in order to not mix intentions.</p>
<h4 id="why-does-this-specification-not-address-load-balancer-restarts-or-maintenance"><a class="header" href="#why-does-this-specification-not-address-load-balancer-restarts-or-maintenance">Why does this specification not address load balancer restarts or maintenance?</a></h4>
<p>The Layer 4 load balancers that would be in use for this feature lack the ability that a layer 7 load balancer could
potentially have to be able to understand the MongoDB wire protocol and respond to monitoring requests.</p>
<h3 id="design-rationales-1"><a class="header" href="#design-rationales-1">Design Rationales</a></h3>
<p>Services cannot dynamically switch from running behind a load balancer and not running behind a load balancer. Based on
that, this design forces the application to opt-in to this behaviour and make potential changes that require restarts to
their applications. If this were to change, see alternative designs below.</p>
<h3 id="alternative-designs-1"><a class="header" href="#alternative-designs-1">Alternative Designs</a></h3>
<h4 id="service-proxy-detection"><a class="header" href="#service-proxy-detection">Service PROXY Detection</a></h4>
<p>An alternative to the driver using a connection string option to put it into load balancing mode would be for the
service the driver is connected to to inform the driver it is behind a load balancer. A possible solution for this would
be for all services to understand the PROXY protocol such as Data Lake does, and to alter their hello responses to
inform the driver they are behind a load balancer, potentially with the IP address of the load balancer itself.</p>
<p>The benefit of this solution would be that no changes would be required from the application side, and could also not
require a restart of any application. A single request to the service through the load balancer could automatically
trigger the change in the hello response and cause the driver to switch into load balancing mode pointing at the load
balancer's IP address. Also with this solution it would provide services the ability to record the original IP addresses
of the application that was connecting to it as they are provided the PROXY protocol's header bytes.</p>
<p>The additional complexity of this alternative on the driver side is that instead of starting in a single mode and
remaining there for the life of the application, the driver would need to deal with additional state changes based on
the results of the server monitors. From a service perspective, every service would need to be updated to understand the
PROXY protocol header bytes prepended to the initial connection and modify their states and hello responses accordingly.
Additionally load balancers would need to have additional configuration as noted in the reference section below, and
only load balancers that support the PROXY protocol would be supported.</p>
<h2 id="changelog-16"><a class="header" href="#changelog-16">Changelog</a></h2>
<ul>
<li>2024-04-25: Clarify that <code>TopologyDescriptionChangedEvent</code> must be emitted on topology close</li>
<li>2024-03-06: Migrated from reStructuredText to Markdown.</li>
<li>2022-10-05: Remove spec front matter and reformat changelog.</li>
<li>2022-01-18: Clarify that <code>OP_MSG</code> must be used in load balanced mode.</li>
<li>2021-12-22: Clarify that pinned connections in transactions are exclusive.</li>
<li>2021-10-14: Note that <code>loadBalanced=true</code> conflicts with <code>srvMaxHosts</code>.</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="server-monitoring"><a class="header" href="#server-monitoring">Server Monitoring</a></h1>
<ul>
<li>Status: Accepted</li>
<li>Minimum Server Version: 2.4</li>
</ul>
<hr />
<h2 id="abstract-17"><a class="header" href="#abstract-17">Abstract</a></h2>
<p>This spec defines how a driver monitors a MongoDB server. In summary, the client monitors each server in the topology.
The scope of server monitoring is to provide the topology with updated ServerDescriptions based on hello or legacy hello
command responses.</p>
<h2 id="meta-17"><a class="header" href="#meta-17">META</a></h2>
<p>The keywords "MUST", "MUST NOT", "REQUIRED", "SHALL", "SHALL NOT", "SHOULD", "SHOULD NOT", "RECOMMENDED", "MAY", and
"OPTIONAL" in this document are to be interpreted as described in <a href="https://www.ietf.org/rfc/rfc2119.txt">RFC 2119</a>.</p>
<h2 id="specification-15"><a class="header" href="#specification-15">Specification</a></h2>
<h3 id="terms-8"><a class="header" href="#terms-8">Terms</a></h3>
<p>See the terms in the <a href="server-discovery-and-monitoring/server-discovery-and-monitoring.html">main SDAM spec</a>.</p>
<h4 id="check-1"><a class="header" href="#check-1">check</a></h4>
<p>The client checks a server by attempting to call hello or legacy hello on it, and recording the outcome.</p>
<h4 id="client-1"><a class="header" href="#client-1">client</a></h4>
<p>A process that initiates a connection to a MongoDB server. This includes mongod and mongos processes in a replica set or
sharded cluster, as well as drivers, the shell, tools, etc.</p>
<h4 id="scan-1"><a class="header" href="#scan-1">scan</a></h4>
<p>The process of checking all servers in the deployment.</p>
<h4 id="suitable-1"><a class="header" href="#suitable-1">suitable</a></h4>
<p>A server is judged "suitable" for an operation if the client can use it for a particular operation. For example, a write
requires a standalone, primary, or mongos. Suitability is fully specified in the
<a href="server-discovery-and-monitoring/../server-selection/server-selection.html">Server Selection Spec</a>.</p>
<h4 id="significant-topology-change"><a class="header" href="#significant-topology-change">significant topology change</a></h4>
<p>A change in the server's state that is relevant to the client's view of the server, e.g. a change in the server's
replica set member state, or its replica set tags. In SDAM terms, a significant topology change on the server means the
client's ServerDescription is out of date. Standalones and mongos do not currently experience significant topology
changes but they may in the future.</p>
<h4 id="regular-hello-or-legacy-hello-command"><a class="header" href="#regular-hello-or-legacy-hello-command">regular hello or legacy hello command</a></h4>
<p>A default <code>{hello: 1}</code> or legacy hello command where the server responds immediately.</p>
<h4 id="streamable-hello-or-legacy-hello-command"><a class="header" href="#streamable-hello-or-legacy-hello-command">streamable hello or legacy hello command</a></h4>
<p>The hello or legacy hello command feature which allows the server to stream multiple replies back to the client.</p>
<h4 id="rtt"><a class="header" href="#rtt">RTT</a></h4>
<p>Round trip time. The client's measurement of the duration of one hello or legacy hello call. The RTT is used to support
<a href="server-discovery-and-monitoring/../server-selection/server-selection.html#localthresholdms">localThresholdMS</a> from the Server Selection spec and
<a href="server-discovery-and-monitoring/../client-side-operations-timeout/client-side-operations-timeout.html#timeoutms">timeoutMS</a> from the
<a href="server-discovery-and-monitoring/../client-side-operations-timeout/client-side-operations-timeout.html">Client Side Operations Timeout Spec</a>.</p>
<h4 id="faas-1"><a class="header" href="#faas-1">FaaS</a></h4>
<p>A Function-as-a-Service (FaaS) environment like AWS Lambda.</p>
<p><span id="servermonitoringmode"></span></p>
<h4 id="servermonitoringmode"><a class="header" href="#servermonitoringmode">serverMonitoringMode</a></h4>
<p>The serverMonitoringMode option configures which server monitoring protocol to use. Valid modes are "stream", "poll", or
"auto". The default value MUST be "auto":</p>
<ul>
<li>With "stream" mode, the client MUST use the streaming protocol when the server supports it or fall back to the polling
protocol otherwise.</li>
<li>With "poll" mode, the client MUST use the polling protocol.</li>
<li>With "auto" mode, the client MUST behave the same as "poll" mode when running on a FaaS platform or the same as
"stream" mode otherwise. The client detects that it's running on a FaaS platform via the same rules for generating the
<code>client.env</code> handshake metadata field in the <a href="server-discovery-and-monitoring/../mongodb-handshake/handshake.html#client-env">MongoDB Handshake spec</a>.</li>
</ul>
<p>Multi-threaded or asynchronous drivers MUST implement this option. See
<a href="server-discovery-and-monitoring/server-monitoring.html#why-disable-the-streaming-protocol-on-faas-platforms-like-aws-lambda">Why disable the streaming protocol on FaaS platforms like AWS Lambda?</a>
and <a href="server-discovery-and-monitoring/server-monitoring.html#why-introduce-a-knob-for-servermonitoringmode">Why introduce a knob for serverMonitoringMode?</a></p>
<h3 id="monitoring-2"><a class="header" href="#monitoring-2">Monitoring</a></h3>
<p>The client monitors servers using the hello or legacy hello commands. In MongoDB 4.4+, a monitor uses the
<a href="server-discovery-and-monitoring/server-monitoring.html#streaming-protocol">Streaming Protocol</a> to continuously stream hello or legacy hello responses from the server. In
MongoDB &lt;= 4.2, a monitor uses the <a href="server-discovery-and-monitoring/server-monitoring.html#polling-protocol">Polling Protocol</a> pausing heartbeatFrequencyMS between
<a href="server-discovery-and-monitoring/server-monitoring.html#check">checks</a>. Clients check servers sooner in response to certain events.</p>
<p>If a <a href="server-discovery-and-monitoring/../versioned-api/versioned-api.html">server API version</a> is requested, then the driver must use hello for
monitoring. If a server API version is not requested, the initial handshake using the legacy hello command must include
<code>helloOk: true</code>. If the response contains <code>helloOk: true</code>, then the driver must use the <code>hello</code> command for monitoring.
If the response does not contain <code>helloOk: true</code>, then the driver must use the legacy hello command for monitoring.</p>
<p>The socket used to check a server MUST use the same
<a href="https://www.mongodb.com/docs/manual/reference/connection-string/">connectTimeoutMS</a> as regular sockets. Multi-threaded
clients SHOULD set monitoring sockets' socketTimeoutMS to the connectTimeoutMS. (See
<a href="server-discovery-and-monitoring/server-monitoring.html#socket-timeout-for-monitoring-is-connecttimeoutms">socket timeout for monitoring is connectTimeoutMS</a>. Drivers MAY let
users configure the timeouts for monitoring sockets separately if necessary to preserve backwards compatibility.)</p>
<p>The client begins monitoring a server when:</p>
<ul>
<li>... the client is initialized and begins monitoring each seed. See
<a href="server-discovery-and-monitoring/server-discovery-and-monitoring.html#initial-servers">initial servers</a>.</li>
<li>... <a href="server-discovery-and-monitoring/server-discovery-and-monitoring.html#updateRSWithoutPrimary">updateRSWithoutPrimary</a> or
<a href="server-discovery-and-monitoring/server-discovery-and-monitoring.html#updateRSFromPrimary">updateRSFromPrimary</a> discovers new replica set members.</li>
</ul>
<p>The following subsections specify how monitoring works, first in multi-threaded or asynchronous clients, and second in
single-threaded clients. This spec provides detailed requirements for monitoring because it intends to make all drivers
behave consistently.</p>
<h4 id="multi-threaded-or-asynchronous-monitoring"><a class="header" href="#multi-threaded-or-asynchronous-monitoring">Multi-threaded or asynchronous monitoring</a></h4>
<h5 id="servers-are-monitored-in-parallel"><a class="header" href="#servers-are-monitored-in-parallel">Servers are monitored in parallel</a></h5>
<p>All servers' monitors run independently, in parallel: If some monitors block calling hello or legacy hello over slow
connections, other monitors MUST proceed unimpeded.</p>
<p>The natural implementation is a thread per server, but the decision is left to the implementer. (See
<a href="server-discovery-and-monitoring/server-monitoring.html#thread-per-server">thread per server</a>.)</p>
<h5 id="servers-are-monitored-with-dedicated-sockets"><a class="header" href="#servers-are-monitored-with-dedicated-sockets">Servers are monitored with dedicated sockets</a></h5>
<p><a href="server-discovery-and-monitoring/server-monitoring.html#a-monitor-should-not-use-the-clients-regular-connection-pool">A monitor SHOULD NOT use the client's regular connection pool</a>
to acquire a socket; it uses a dedicated socket that does not count toward the pool's maximum size.</p>
<p>Drivers MUST NOT authenticate on sockets used for monitoring nor include SCRAM mechanism negotiation (i.e.
<code>saslSupportedMechs</code>), as doing so would make monitoring checks more expensive for the server.</p>
<h5 id="servers-are-checked-periodically"><a class="header" href="#servers-are-checked-periodically">Servers are checked periodically</a></h5>
<p>Each monitor <a href="server-discovery-and-monitoring/server-monitoring.html#check">checks</a> its server and notifies the client of the outcome so the client can update the
TopologyDescription.</p>
<p>After each check, the next check SHOULD be scheduled <a href="server-discovery-and-monitoring/server-monitoring.html#heartbeatfrequencyms">heartbeatFrequencyMS</a> later; a check MUST
NOT run while a previous check is still in progress.</p>
<h5 id="requesting-an-immediate-check"><a class="header" href="#requesting-an-immediate-check">Requesting an immediate check</a></h5>
<p>At any time, the client can request that a monitor check its server immediately. (For example, after a "not writable
primary" error. See <a href="server-discovery-and-monitoring/server-discovery-and-monitoring.html#error-handling">error handling</a>.) If the monitor is sleeping
when this request arrives, it MUST wake and check as soon as possible. If a hello or legacy hello call is already in
progress, the request MUST be ignored. If the previous check ended less than
<a href="server-discovery-and-monitoring/server-monitoring.html#minheartbeatfrequencyms">minHeartbeatFrequencyMS</a> ago, the monitor MUST sleep until the minimum delay has passed, then
check the server.</p>
<h5 id="application-operations-are-unblocked-when-a-server-is-found"><a class="header" href="#application-operations-are-unblocked-when-a-server-is-found">Application operations are unblocked when a server is found</a></h5>
<p>Each time a check completes, threads waiting for a <a href="server-discovery-and-monitoring/server-monitoring.html#suitable">suitable</a> server are unblocked. Each unblocked thread
MUST proceed if the new TopologyDescription now contains a suitable server.</p>
<h5 id="clients-update-the-topology-from-each-handshake"><a class="header" href="#clients-update-the-topology-from-each-handshake">Clients update the topology from each handshake</a></h5>
<p>When a monitor check creates a new connection, the <a href="server-discovery-and-monitoring/../mongodb-handshake/handshake.html">connection handshake</a> response
MUST be used to satisfy the check and update the topology.</p>
<p>When a client successfully calls hello or legacy hello to handshake a new connection for application operations, it
SHOULD use the hello or legacy hello reply to update the ServerDescription and TopologyDescription, the same as with a
hello or legacy hello reply on a monitoring socket. If the hello or legacy hello call fails, the client SHOULD mark the
server Unknown and update its TopologyDescription, the same as a failed server check on monitoring socket.</p>
<h5 id="clients-use-the-streaming-protocol-when-supported"><a class="header" href="#clients-use-the-streaming-protocol-when-supported">Clients use the streaming protocol when supported</a></h5>
<p>When a monitor discovers that the server supports the streamable hello or legacy hello command and the client does not
have <a href="server-discovery-and-monitoring/server-monitoring.html#streaming-disabled">streaming disabled</a>, it MUST use the <a href="server-discovery-and-monitoring/server-monitoring.html#streaming-protocol">streaming protocol</a>.</p>
<h4 id="single-threaded-monitoring"><a class="header" href="#single-threaded-monitoring">Single-threaded monitoring</a></h4>
<p><span id="cooldownms"></span></p>
<h5 id="cooldownms"><a class="header" href="#cooldownms">cooldownMS</a></h5>
<p>After a single-threaded client gets a network error trying to <a href="server-discovery-and-monitoring/server-monitoring.html#check">check</a> a server, the client skips re-checking the
server until cooldownMS has passed.</p>
<p>This avoids spending connectTimeoutMS on each unavailable server during each scan.</p>
<p>This value MUST be 5000 ms, and it MUST NOT be configurable.</p>
<p><span id="scanning"></span></p>
<h5 id="scanning"><a class="header" href="#scanning">Scanning</a></h5>
<p>Single-threaded clients MUST <a href="server-discovery-and-monitoring/server-monitoring.html#scan">scan</a> all servers synchronously, inline with regular application operations. Before
each operation, the client checks if <a href="server-discovery-and-monitoring/server-monitoring.html#heartbeatfrequencyms">heartbeatFrequencyMS</a> has passed since the previous scan
ended, or if the topology is marked "stale"; if so it scans all the servers before selecting a server and performing the
operation.</p>
<p>Selection failure triggers an immediate scan. When a client that uses single-threaded monitoring fails to select a
suitable server for any operation, it <a href="server-discovery-and-monitoring/server-monitoring.html#scan">scans</a> the servers, then attempts selection again, to see if the scan
discovered suitable servers. It repeats, waiting <a href="server-discovery-and-monitoring/server-monitoring.html#minheartbeatfrequencyms">minHeartbeatFrequencyMS</a> after each scan,
until a timeout.</p>
<h5 id="scanning-order"><a class="header" href="#scanning-order">Scanning order</a></h5>
<p>If the topology is a replica set, the client attempts to contact the primary as soon as possible to get an authoritative
list of members. Otherwise, the client attempts to check all members it knows of, in order from the least-recently to
the most-recently checked.</p>
<p>When all servers have been checked the scan is complete. New servers discovered <strong>during</strong> the scan MUST be checked
before the scan is complete. Sometimes servers are removed during a scan so they are not checked, depending on the order
of events.</p>
<p>The scanning order is expressed in this pseudocode:</p>
<pre><code>scanStartTime = now()
# You'll likely need to convert units here.
beforeCoolDown = scanStartTime - cooldownMS

while true:
    serversToCheck = all servers with lastUpdateTime before scanStartTime

    remove from serversToCheck any Unknowns with lastUpdateTime &gt; beforeCoolDown

    if no serversToCheck:
        # This scan has completed.
        break

    if a server in serversToCheck is RSPrimary:
        check it
    else if there is a PossiblePrimary:
        check it
    else if any servers are not of type Unknown or RSGhost:
        check the one with the oldest lastUpdateTime
        if several servers have the same lastUpdateTime, choose one at random
    else:
        check the Unknown or RSGhost server with the oldest lastUpdateTime
        if several servers have the same lastUpdateTime, choose one at random
</code></pre>
<p>This algorithm might be better understood with an example:</p>
<ol>
<li>The client is configured with one seed and TopologyType Unknown. It begins a scan.</li>
<li>When it checks the seed, it discovers a secondary.</li>
<li>The secondary's hello or legacy hello response includes the "primary" field with the address of the server that the
secondary thinks is primary.</li>
<li>The client creates a ServerDescription with that address, type PossiblePrimary, and lastUpdateTime "infinity ago".
(See <a href="server-discovery-and-monitoring/server-discovery-and-monitoring.html#updateRSWithoutPrimary">updateRSWithoutPrimary</a>.)</li>
<li>On the next iteration, there is still no RSPrimary, so the new PossiblePrimary is the top-priority server to check.</li>
<li>The PossiblePrimary is checked and replaced with an RSPrimary. The client has now acquired an authoritative host
list. Any new hosts in the list are added to the TopologyDescription with lastUpdateTime "infinity ago". (See
<a href="server-discovery-and-monitoring/server-discovery-and-monitoring.html#updateRSFromPrimary">updateRSFromPrimary</a>.)</li>
<li>The client continues scanning until all known hosts have been checked.</li>
</ol>
<p>Another common case might be scanning a pool of mongoses. When the client first scans its seed list, they all have the
default lastUpdateTime "infinity ago", so it scans them in random order. This randomness provides some load-balancing if
many clients start at once. A client's subsequent scans of the mongoses are always in the same order, since their
lastUpdateTimes are always in the same order by the time a scan ends.</p>
<h4 id="minheartbeatfrequencyms-1"><a class="header" href="#minheartbeatfrequencyms-1">minHeartbeatFrequencyMS</a></h4>
<p>If a client frequently rechecks a server, it MUST wait at least minHeartbeatFrequencyMS milliseconds since the previous
check ended, to avoid pointless effort. This value MUST be 500 ms, and it MUST NOT be configurable (no knobs).</p>
<h4 id="heartbeatfrequencyms-1"><a class="header" href="#heartbeatfrequencyms-1">heartbeatFrequencyMS</a></h4>
<p>The interval between server <a href="server-discovery-and-monitoring/server-monitoring.html#check">checks</a>, counted from the end of the previous check until the beginning of the next
one.</p>
<p>For multi-threaded and asynchronous drivers it MUST default to 10 seconds and MUST be configurable. For single-threaded
drivers it MUST default to 60 seconds and MUST be configurable. It MUST be called heartbeatFrequencyMS unless this
breaks backwards compatibility.</p>
<p>For both multi- and single-threaded drivers, the driver MUST NOT permit users to configure it less than
minHeartbeatFrequencyMS (500ms).</p>
<p>(See <a href="server-discovery-and-monitoring/server-discovery-and-monitoring.html#heartbeatFrequencyMS">heartbeatFrequencyMS in the main SDAM spec</a>.)</p>
<h3 id="awaitable-hello-or-legacy-hello-server-specification"><a class="header" href="#awaitable-hello-or-legacy-hello-server-specification">Awaitable hello or legacy hello Server Specification</a></h3>
<p>As of MongoDB 4.4 the hello or legacy hello command can wait to reply until there is a topology change or a maximum time
has elapsed. Clients opt in to this "awaitable hello" feature by passing new parameters "topologyVersion" and
"maxAwaitTimeMS" to the hello or legacy hello commands. Exhaust support has also been added, which clients can enable in
the usual manner by setting the <a href="server-discovery-and-monitoring/../message/OP_MSG.html#exhaustAllowed">OP_MSG exhaustAllowed flag</a>.</p>
<p>Clients use the awaitable hello feature as the basis of the streaming heartbeat protocol to learn much sooner about
stepdowns, elections, reconfigs, and other events.</p>
<h4 id="topologyversion-1"><a class="header" href="#topologyversion-1">topologyVersion</a></h4>
<p>A server that supports awaitable hello or legacy hello includes a "topologyVersion" field in all hello or legacy hello
replies and State Change Error replies. The topologyVersion is a subdocument with two fields, "processId" and "counter":</p>
<pre><code class="language-typescript">{
    topologyVersion: {processId: &lt;ObjectId&gt;, counter: &lt;int64&gt;},
    ( ... other fields ...)
}
</code></pre>
<h5 id="processid"><a class="header" href="#processid">processId</a></h5>
<p>An ObjectId maintained in memory by the server. It is reinitialized by the server using the standard ObjectId logic each
time this server process starts.</p>
<h5 id="counter-1"><a class="header" href="#counter-1">counter</a></h5>
<p>An int64 State change counter, maintained in memory by the server. It begins at 0 when the server starts, and it is
incremented whenever there is a significant topology change.</p>
<h4 id="maxawaittimems"><a class="header" href="#maxawaittimems">maxAwaitTimeMS</a></h4>
<p>To enable awaitable hello or legacy hello, the client includes a new int64 field "maxAwaitTimeMS" in the hello or legacy
hello request. This field determines the maximum duration in milliseconds a server will wait for a significant topology
change before replying.</p>
<h4 id="feature-discovery"><a class="header" href="#feature-discovery">Feature Discovery</a></h4>
<p>To discover if the connected server supports awaitable hello or legacy hello, a client checks the most recent hello or
legacy hello command reply. If the reply includes "topologyVersion" then the server supports awaitable hello or legacy
hello.</p>
<h4 id="awaitable-hello-or-legacy-hello-protocol"><a class="header" href="#awaitable-hello-or-legacy-hello-protocol">Awaitable hello or legacy hello Protocol</a></h4>
<p>To initiate an awaitable hello or legacy hello command, the client includes both maxAwaitTimeMS and topologyVersion in
the request, for example:</p>
<pre><code class="language-typescript">{
    hello: 1,
    maxAwaitTimeMS: 10000,
    topologyVersion: {processId: &lt;ObjectId&gt;, counter: &lt;int64&gt;},
    ( ... other fields ...)
}
</code></pre>
<p>Clients MAY additionally set the <a href="server-discovery-and-monitoring/../message/OP_MSG.html#exhaustAllowed">OP_MSG exhaustAllowed flag</a> to enable streaming
hello or legacy hello. With streaming hello or legacy hello, the server MAY send multiple hello or legacy hello
responses without waiting for further requests.</p>
<p>A server that implements the new protocol follows these rules:</p>
<ul>
<li>Always include the server's topologyVersion in hello, legacy hello, and State Change Error replies.</li>
<li>If the request includes topologyVersion without maxAwaitTimeMS or vice versa, return an error.</li>
<li>If the request omits topologyVersion and maxAwaitTimeMS, reply immediately.</li>
<li>If the request includes topologyVersion and maxAwaitTimeMS, then reply immediately if the server's
topologyVersion.processId does not match the request's, otherwise reply when the server's topologyVersion.counter is
greater than the request's, or maxAwaitTimeMS elapses, whichever comes first.</li>
<li>Following the <a href="server-discovery-and-monitoring/../message/OP_MSG.html">OP_MSG spec</a>, if the request omits the exhaustAllowed flag, the server MUST NOT
set the moreToCome flag on the reply. If the request's exhaustAllowed flag is set, the server MAY set the moreToCome
flag on the reply. If the server sets moreToCome, it MUST continue streaming replies without awaiting further
requests. Between replies it MUST wait until the server's topologyVersion.counter is incremented or maxAwaitTimeMS
elapses, whichever comes first. If the reply includes <code>ok: 0</code> the server MUST NOT set the moreToCome flag.</li>
<li>On a topology change that changes the horizon parameters, the server will close all application connections.</li>
</ul>
<p>Example awaitable hello conversation:</p>
<div class="table-wrapper"><table><thead><tr><th>Client</th><th>Server</th></tr></thead><tbody>
<tr><td>hello handshake -&gt;</td><td></td></tr>
<tr><td></td><td>&lt;- reply with topologyVersion</td></tr>
<tr><td>hello as OP_MSG with maxAwaitTimeMS and topologyVersion -&gt;</td><td></td></tr>
<tr><td></td><td>wait for change or timeout</td></tr>
<tr><td></td><td>&lt;- OP_MSG with topologyVersion</td></tr>
<tr><td>...</td><td></td></tr>
</tbody></table>
</div>
<p>Example streaming hello conversation (awaitable hello with exhaust):</p>
<div class="table-wrapper"><table><thead><tr><th>Client</th><th>Server</th></tr></thead><tbody>
<tr><td>hello handshake -&gt;</td><td></td></tr>
<tr><td></td><td>&lt;- reply with topologyVersion</td></tr>
<tr><td>hello as OP_MSG with exhaustAllowed, maxAwaitTimeMS, and topologyVersion -&gt;</td><td></td></tr>
<tr><td></td><td>wait for change or timeout</td></tr>
<tr><td></td><td>&lt;- OP_MSG with moreToCome and topologyVersion</td></tr>
<tr><td></td><td>wait for change or timeout</td></tr>
<tr><td></td><td>&lt;- OP_MSG with moreToCome and topologyVersion</td></tr>
<tr><td></td><td>...</td></tr>
<tr><td></td><td>&lt;- OP_MSG without moreToCome</td></tr>
<tr><td>...</td><td></td></tr>
</tbody></table>
</div>
<h3 id="streaming-protocol"><a class="header" href="#streaming-protocol">Streaming Protocol</a></h3>
<p>The streaming protocol is used to monitor MongoDB 4.4+ servers and optimally reduces the time it takes for a client to
discover server state changes. Multi-threaded or asynchronous drivers MUST use the streaming protocol when connected to
a server that supports the awaitable hello or legacy hello commands. This protocol requires an extra thread and an extra
socket for each monitor to perform RTT calculations.</p>
<h4 id="streaming-disabled"><a class="header" href="#streaming-disabled">Streaming disabled</a></h4>
<p>The streaming protocol MUST be disabled when either:</p>
<ul>
<li>the client is configured with serverMonitoringMode=poll, or</li>
<li>the client is configured with serverMonitoringMode=auto and a FaaS platform is detected, or</li>
<li>the server does not support streaming (eg MongoDB &lt; 4.4).</li>
</ul>
<p>When the streaming protocol is disabled the client MUST use the <a href="server-discovery-and-monitoring/server-monitoring.html#polling-protocol">polling protocol</a> and MUST NOT start
an extra thread or connection for <a href="server-discovery-and-monitoring/server-monitoring.html#measuring-rtt">Measuring RTT</a>.</p>
<p>See
<a href="server-discovery-and-monitoring/server-monitoring.html#why-disable-the-streaming-protocol-on-faas-platforms-like-aws-lambda">Why disable the streaming protocol on FaaS platforms like AWS Lambda?</a>.</p>
<h4 id="streaming-hello-or-legacy-hello"><a class="header" href="#streaming-hello-or-legacy-hello">Streaming hello or legacy hello</a></h4>
<p>The streaming hello or legacy hello protocol uses awaitable hello or legacy hello with the OP_MSG exhaustAllowed flag to
continuously stream hello or legacy hello responses from the server. Drivers MUST set the OP_MSG exhaustAllowed flag
with the awaitable hello or legacy hello command and MUST process each hello or legacy hello response. (I.e., they MUST
process responses strictly in the order they were received.)</p>
<p>A client follows these rules when processing the hello or legacy hello exhaust response:</p>
<ul>
<li>If the response indicates a command error, or a network error or timeout occurs, the client MUST close the connection
and restart the monitoring protocol on a new connection. (See
<a href="server-discovery-and-monitoring/server-monitoring.html#network-or-command-error-during-server-check">Network or command error during server check</a>.)</li>
<li>If the response is successful (includes "ok:1") and includes the OP_MSG moreToCome flag, then the client begins
reading the next response.</li>
<li>If the response is successful (includes "ok:1") and does not include the OP_MSG moreToCome flag, then the client
initiates a new awaitable hello or legacy hello with the topologyVersion field from the previous response.</li>
</ul>
<h4 id="socket-timeout"><a class="header" href="#socket-timeout">Socket timeout</a></h4>
<p>Clients MUST use connectTimeoutMS as the timeout for the connection handshake. When connectTimeoutMS=0, the timeout is
unlimited and MUST remain unlimited for awaitable hello and legacy hello replies. Otherwise, connectTimeoutMS is
non-zero and clients MUST use connectTimeoutMS + heartbeatFrequencyMS as the timeout for awaitable hello and legacy
hello replies.</p>
<h4 id="measuring-rtt"><a class="header" href="#measuring-rtt">Measuring RTT</a></h4>
<p>When using the streaming protocol, clients MUST issue a hello or legacy hello command to each server to measure RTT
every heartbeatFrequencyMS. The RTT command MUST be run on a dedicated connection to each server. Clients MUST NOT use
dedicated connections to measure RTT when the streaming protocol is not used. (See
<a href="server-discovery-and-monitoring/server-monitoring.html#monitors-must-use-a-dedicated-connection-for-rtt-commands">Monitors MUST use a dedicated connection for RTT commands</a>.)</p>
<p>Clients MUST update the RTT from the hello or legacy hello duration of the initial connection handshake. Clients MUST
NOT update RTT based on streaming hello or legacy hello responses.</p>
<p>Clients MUST ignore the response to the hello or legacy hello command when measuring RTT. Errors encountered when
running a hello or legacy hello command MUST NOT update the topology. (See
<a href="server-discovery-and-monitoring/server-monitoring.html#why-dont-clients-mark-a-server-unknown-when-an-rtt-command-fails">Why don't clients mark a server unknown when an RTT command fails?</a>)</p>
<p>Clients MUST track the minimum RTT out of the (at most) last 10 samples. Clients MUST report the minimum RTT as 0 until
at least 2 samples have been gathered.</p>
<p>When constructing a ServerDescription from a streaming hello or legacy hello response, clients MUST set the average and
minimum round trip times from the RTT task as the "roundTripTime" and "minRoundTripTime" fields, respectively.</p>
<p>See the pseudocode in the <a href="server-discovery-and-monitoring/server-monitoring.html#rtt-thread">RTT thread</a> section for an example implementation.</p>
<h4 id="sdam-monitoring"><a class="header" href="#sdam-monitoring">SDAM Monitoring</a></h4>
<p>Clients MUST publish a ServerHeartbeatStartedEvent before attempting to read the next hello or legacy hello exhaust
response. (See
<a href="server-discovery-and-monitoring/server-monitoring.html#why-must-streaming-hello-or-legacy-hello-clients-publish-serverheartbeatstartedevents">Why must streaming hello or legacy hello clients publish ServerHeartbeatStartedEvents?</a>)</p>
<p>Clients MUST NOT publish any events when running an RTT command. (See
<a href="server-discovery-and-monitoring/server-monitoring.html#why-dont-streaming-hello-or-legacy-hello-clients-publish-events-for-rtt-commands">Why don't streaming hello or legacy hello clients publish events for RTT commands?</a>)</p>
<h4 id="heartbeat-frequency"><a class="header" href="#heartbeat-frequency">Heartbeat frequency</a></h4>
<p>In the polling protocol, a client sleeps between each hello or legacy hello check (for at least minHeartbeatFrequencyMS
and up to heartbeatFrequencyMS). In the streaming protocol, after processing an "ok:1" hello or legacy hello response,
the client MUST NOT sleep and MUST begin the next check immediately.</p>
<p>Clients MUST set <a href="server-discovery-and-monitoring/server-monitoring.html#maxawaittimems">maxAwaitTimeMS</a> to heartbeatFrequencyMS.</p>
<h4 id="hello-or-legacy-hello-cancellation"><a class="header" href="#hello-or-legacy-hello-cancellation">hello or legacy hello Cancellation</a></h4>
<p>When a client is closed, clients MUST cancel all hello and legacy hello checks; a monitor blocked waiting for the next
streaming hello or legacy hello response MUST be interrupted such that threads may exit promptly without waiting
maxAwaitTimeMS.</p>
<p>When a client marks a server Unknown from
<a href="server-discovery-and-monitoring/server-discovery-and-monitoring.html#network-error-when-reading-or-writing">Network error when reading or writing</a>,
clients MUST cancel the hello or legacy hello check on that server and close the current monitoring connection. (See
<a href="server-discovery-and-monitoring/server-monitoring.html#drivers-cancel-in-progress-monitor-checks">Drivers cancel in-progress monitor checks</a>.)</p>
<h3 id="polling-protocol"><a class="header" href="#polling-protocol">Polling Protocol</a></h3>
<p>The polling protocol is used to monitor MongoDB &lt; 4.4 servers or when streaming is disabled. The client
<a href="server-discovery-and-monitoring/server-monitoring.html#check">checks</a> a server with a hello or legacy hello command and then sleeps for heartbeatFrequencyMS before running
another check.</p>
<h3 id="marking-the-connection-pool-as-ready-cmap-only"><a class="header" href="#marking-the-connection-pool-as-ready-cmap-only">Marking the connection pool as ready (CMAP only)</a></h3>
<p>When a monitor completes a successful check against a server, it MUST mark the connection pool for that server as
"ready", and doing so MUST be synchronized with the update to the topology (e.g. by marking the pool as ready in
onServerDescriptionChanged). This is required to ensure a server does not get selected while its pool is still paused.
See the <a href="server-discovery-and-monitoring/../connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection-pool">Connection Pool</a>
definition in the CMAP specification for more details on marking the pool as "ready".</p>
<h3 id="error-handling-2"><a class="header" href="#error-handling-2">Error handling</a></h3>
<h4 id="network-or-command-error-during-server-check"><a class="header" href="#network-or-command-error-during-server-check">Network or command error during server check</a></h4>
<p>When a server <a href="server-discovery-and-monitoring/server-monitoring.html#check">check</a> fails due to a network error (including a network timeout) or a command error (<code>ok: 0</code>),
the client MUST follow these steps:</p>
<ol>
<li>Close the current monitoring connection.</li>
<li>Mark the server Unknown.</li>
<li>Clear the connection pool for the server (See
<a href="server-discovery-and-monitoring/server-monitoring.html#clear-the-connection-pool-on-both-network-and-command-errors">Clear the connection pool on both network and command errors</a>).
For CMAP compliant drivers, clearing the pool MUST be synchronized with marking the server as Unknown (see
<a href="server-discovery-and-monitoring/server-discovery-and-monitoring.html#why-synchronize-clearing-a-servers-pool-with-updating-the-topology">Why synchronize clearing a server's pool with updating the topology?</a>).
If this was a network timeout error, then the pool MUST be cleared with interruptInUseConnections = true (see
<a href="server-discovery-and-monitoring/../connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#why-does-the-pool-need-to-support-interrupting-in-use-connections-as-part-of-its-clear-logic">Why does the pool need to support closing in use connections as part of its clear logic?</a>)</li>
<li>If this was a network error and the server was in a known state before the error, the client MUST NOT sleep and MUST
begin the next check immediately. (See
<a href="server-discovery-and-monitoring/server-monitoring.html#retry-hello-or-legacy-hello-calls-once">retry hello or legacy hello calls once</a> and
<a href="https://jira.mongodb.org/browse/JAVA-1159">JAVA-1159</a>.)</li>
<li>Otherwise, wait for heartbeatFrequencyMS (or minHeartbeatFrequencyMS if a check is requested) before restarting the
monitoring protocol on a new connection.
<ul>
<li>Note that even in the streaming protocol, a monitor in this state will wait for an application operation to request
an immediate check or for the heartbeatFrequencyMS timeout to expire before beginning the next check.</li>
</ul>
</li>
</ol>
<p>See the pseudocode in the <code>Monitor thread</code> section.</p>
<p>Note that this rule applies only to server checks during monitoring. It does <em>not</em> apply when multi-threaded
<a href="server-discovery-and-monitoring/server-monitoring.html#clients-update-the-topology-from-each-handshake">clients update the topology from each handshake</a>.</p>
<h3 id="implementation-notes-3"><a class="header" href="#implementation-notes-3">Implementation notes</a></h3>
<p>This section intends to provide generous guidance to driver authors. It is complementary to the reference
implementations. Words like "should", "may", and so on are used more casually here.</p>
<h4 id="monitor-thread"><a class="header" href="#monitor-thread">Monitor thread</a></h4>
<p>Most platforms can use an event object to control the monitor thread. The event API here is assumed to be like the
standard <a href="https://docs.python.org/2/library/threading.html#event-objects">Python Event</a>.
<a href="server-discovery-and-monitoring/server-monitoring.html#heartbeatfrequencyms">heartbeatFrequencyMS</a> is configurable, <a href="server-discovery-and-monitoring/server-monitoring.html#minheartbeatfrequencyms">minHeartbeatFrequencyMS</a> is
always 500 milliseconds:</p>
<pre><code class="language-python">class Monitor(Thread):
  def __init__():
      # Monitor options:
      serverAddress = serverAddress
      connectTimeoutMS = connectTimeoutMS
      heartbeatFrequencyMS = heartbeatFrequencyMS
      minHeartbeatFrequencyMS = 500
      stableApi = stableApi
      if serverMonitoringMode == "stream":
          streamingEnabled = True
      elif serverMonitoringMode == "poll":
          streamingEnabled = False
      else:  # serverMonitoringMode == "auto"
          streamingEnabled = not isFaas()

      # Internal Monitor state:
      connection = Null
      # Server API versioning implies that the server supports hello.
      helloOk = stableApi != Null
      description = default ServerDescription
      lock = Mutex()
      rttMonitor = RttMonitor(serverAddress, stableApi)

  def run():
      while this monitor is not stopped:
          previousDescription = description
          try:
              description = checkServer(previousDescription)
          except CheckCancelledError:
              if this monitor is stopped:
                  # The client was closed.
                  return
              # The client marked this server Unknown and cancelled this
              # check during "Network error when reading or writing".
              # Wait before running the next check.
              wait()
              continue

          with client.lock:
              topology.onServerDescriptionChanged(description, connection pool for server)
              if description.error != Null:
                  # Clear the connection pool only after the server description is set to Unknown.
                  clear(interruptInUseConnections: isNetworkTimeout(description.error)) connection pool for server

          # Immediately proceed to the next check if the previous response
          # was successful and included the topologyVersion field, or the
          # previous response included the moreToCome flag, or the server
          # has just transitioned to Unknown from a network error.
          serverSupportsStreaming = description.type != Unknown and description.topologyVersion != Null
          connectionIsStreaming = connection != Null and connection.moreToCome
          transitionedWithNetworkError = isNetworkError(description.error) and previousDescription.type != Unknown
          if streamingEnabled and serverSupportsStreaming and not rttMonitor.started:
              # Start the RttMonitor.
              rttMonitor.run()
          if (streamingEnabled and (serverSupportsStreaming or connectionIsStreaming)) or transitionedWithNetworkError:
              continue

          wait()

  def setUpConnection():
      # Take the mutex to avoid a data race because this code writes to the connection field and a concurrent
      # cancelCheck call could be reading from it.
      with lock:
          # Server API versioning implies that the server supports hello.
          helloOk = stableApi != Null
          connection = new Connection(serverAddress)
          if connectTimeoutMS != 0:
              set connection timeout to connectTimeoutMS

      # Do any potentially blocking operations after releasing the mutex.
      create the socket and perform connection handshake

  def checkServer(previousDescription):
      try:
          # The connection is null if this is the first check. It's closed if there was an error during the previous
          # check or the previous check was cancelled.

          if helloOk:
              helloCommand = hello
          else
              helloCommand = legacy hello

          if not connection or connection.isClosed():
              setUpConnection()
              rttMonitor.addSample(connection.handshakeDuration)
              response = connection.handshakeResponse
          elif connection.moreToCome:
              response = read next helloCommand exhaust response
          elif streamingEnabled and previousDescription.topologyVersion:
              # Initiate streaming hello or legacy hello
              if connectTimeoutMS != 0:
                  set connection timeout to connectTimeoutMS+heartbeatFrequencyMS
              response = call {helloCommand: 1, helloOk: True, topologyVersion: previousDescription.topologyVersion, maxAwaitTimeMS: heartbeatFrequencyMS}
          else:
              # The server does not support topologyVersion or streamingEnabled=False.
              response = call {helloCommand: 1, helloOk: True}

          # If the server supports hello, then response.helloOk will be true
          # and hello will be used for subsequent monitoring commands.
          # If the server does not support hello, then response.helloOk will be undefined
          # and legacy hello will be used for subsequent monitoring commands.
          helloOk = response.helloOk

          return ServerDescription(response, rtt=rttMonitor.average(), ninetiethPercentileRtt=rttMonitor.ninetiethPercentile())
      except Exception as exc:
          close connection
          rttMonitor.reset()
          return ServerDescription(type=Unknown, error=exc)

  def wait():
      start = gettime()

      # Can be awakened by requestCheck().
      event.wait(heartbeatFrequencyMS)
      event.clear()

      waitTime = gettime() - start
      if waitTime &lt; minHeartbeatFrequencyMS:
          # Cannot be awakened.
          sleep(minHeartbeatFrequencyMS - waitTime)
</code></pre>
<p><a href="server-discovery-and-monitoring/server-monitoring.html#requesting-an-immediate-check">Requesting an immediate check</a>:</p>
<pre><code class="language-python">def requestCheck():
    event.set()
</code></pre>
<p><a href="server-discovery-and-monitoring/server-monitoring.html#hello-or-legacy-hello-cancellation">hello or legacy hello Cancellation</a>:</p>
<pre><code class="language-python">def cancelCheck():
    # Take the mutex to avoid reading the connection value while setUpConnection is writing to it.
    # Copy the connection value in the lock but do the actual cancellation outside.
    with lock:
        tempConnection = connection

    if tempConnection:
      interrupt connection read
      close tempConnection
</code></pre>
<h4 id="rtt-thread"><a class="header" href="#rtt-thread">RTT thread</a></h4>
<p>The requirements in the <a href="server-discovery-and-monitoring/server-monitoring.html#measuring-rtt">Measuring RTT</a> section can be satisfied with an additional thread that
periodically runs the hello or legacy hello command on a dedicated connection, for example:</p>
<pre><code class="language-python">class RttMonitor(Thread):
  def __init__():
      # Options:
      serverAddress = serverAddress
      connectTimeoutMS = connectTimeoutMS
      heartbeatFrequencyMS = heartbeatFrequencyMS
      stableApi = stableApi

      # Internal state:
      connection = Null
      # Server API versioning implies that the server supports hello.
      helloOk = stableApi != Null
      lock = Mutex()
      movingAverage = MovingAverage()
      # Track the min RTT seen in the most recent 10 samples.
      recentSamples = deque(maxlen=10)

  def reset():
      with lock:
          movingAverage.reset()
          recentSamples.clear()

  def addSample(rtt):
      with lock:
          movingAverage.update(rtt)
          recentSamples.append(rtt)

  def average():
      with lock:
          return movingAverage.get()

  def min():
      with lock:
          # Need at least 2 RTT samples.
          if len(recentSamples) &lt; 2:
              return 0
          return min(recentSamples)

  def run():
      while this monitor is not stopped:
          try:
              rtt = pingServer()
              addSample(rtt)
          except Exception as exc:
              # Don't call reset() here. The Monitor thread is responsible
              # for resetting the average RTT.
              close connection
              connection = Null
              helloOk = stableApi != Null

          # Can be awakened when the client is closed.
          event.wait(heartbeatFrequencyMS)
          event.clear()

  def setUpConnection():
      # Server API versioning implies that the server supports hello.
      helloOk = stableApi != Null
      connection = new Connection(serverAddress)
      if connectTimeoutMS != 0:
          set connection timeout to connectTimeoutMS
      perform connection handshake

  def pingServer():
      if helloOk:
          helloCommand = hello
      else
          helloCommand = legacy hello

      if not connection:
          setUpConnection()
          return RTT of the connection handshake

      start = time()
      response = call {helloCommand: 1, helloOk: True}
      rtt = time() - start
      helloOk = response.helloOk
      return rtt
</code></pre>
<h2 id="design-alternatives"><a class="header" href="#design-alternatives">Design Alternatives</a></h2>
<h3 id="alternating-hello-or-legacy-hello-to-check-servers-and-rtt-without-adding-an-extra-connection"><a class="header" href="#alternating-hello-or-legacy-hello-to-check-servers-and-rtt-without-adding-an-extra-connection">Alternating hello or legacy hello to check servers and RTT without adding an extra connection</a></h3>
<p>The streaming hello or legacy hello protocol is optimal in terms of latency; clients are always blocked waiting for the
server to stream updated hello or legacy hello information, they learn of server state changes as soon as possible.
However, streaming hello or legacy hello has two downsides:</p>
<ol>
<li>Streaming hello or legacy hello requires a new connection to each server to calculate the RTT.</li>
<li>Streaming hello or legacy hello requires a new thread (or threads) to calculate the RTT of each server.</li>
</ol>
<p>To address these concerns we designed the alternating hello or legacy hello protocol. This protocol would have
alternated between awaitable hello or legacy hello and regular hello or legacy hello. The awaitable hello or legacy
hello replaces the polling protocol's client side sleep and allows the client to receive updated hello or legacy hello
responses sooner. The regular hello or legacy hello allows the client to maintain accurate RTT calculations without
requiring any extra threads or sockets.</p>
<p>We reject this design because streaming hello or legacy hello is strictly better at reducing the client's
time-to-recovery. We determined that one extra connection per server per MongoClient is reasonable for all drivers.
Applications that upgrade may see a modest increase in connections and memory usage on the server. We don't expect this
increase to be problematic; however, we have several projects planned for future MongoDB releases to make the streaming
hello or legacy hello protocol cheaper server-side which should mitigate the cost of the extra monitoring connections.</p>
<h3 id="use-tcp-smoothed-round-trip-time-instead-of-measuring-rtt-explicitly"><a class="header" href="#use-tcp-smoothed-round-trip-time-instead-of-measuring-rtt-explicitly">Use TCP smoothed round-trip time instead of measuring RTT explicitly</a></h3>
<p>TCP sockets internally maintain a "smoothed round-trip time" or SRTT. Drivers could use this SRTT instead of measuring
RTT explicitly via hello or legacy hello commands. The server could even include this value on all hello or legacy hello
responses. We reject this idea for a few reasons:</p>
<ul>
<li>Not all programming languages have an API to access the TCP socket's RTT.</li>
<li>On Windows, RTT access requires Admin privileges.</li>
<li>TCP's SRTT would likely differ substantially from RTT measurements in the current protocol. For example, the SRTT can
be reset on <a href="https://tools.ietf.org/html/rfc2988#section-5">retransmission timeouts</a>.</li>
</ul>
<h2 id="rationale-1"><a class="header" href="#rationale-1">Rationale</a></h2>
<h3 id="thread-per-server"><a class="header" href="#thread-per-server">Thread per server</a></h3>
<p>Mongos uses a monitor thread per replica set, rather than a thread per server. A thread per server is impractical if
mongos is monitoring a large number of replica sets. But a driver only monitors one.</p>
<p>In mongos, threads trying to do reads and writes join the effort to scan the replica set. Such threads are more likely
to be abundant in mongos than in drivers, so mongos can rely on them to help with monitoring.</p>
<p>In short: mongos has different scaling concerns than a multi-threaded or asynchronous driver, so it allocates threads
differently.</p>
<h3 id="socket-timeout-for-monitoring-is-connecttimeoutms"><a class="header" href="#socket-timeout-for-monitoring-is-connecttimeoutms">Socket timeout for monitoring is connectTimeoutMS</a></h3>
<p>When a client waits for a server to respond to a connection, the client does not know if the server will respond
eventually or if it is down. Users can help the client guess correctly by supplying a reasonable connectTimeoutMS for
their network: on some networks a server is probably down if it hasn't responded in 10 ms, on others a server might
still be up even if it hasn't responded in 10 seconds.</p>
<p>The socketTimeoutMS, on the other hand, must account for both network latency and the operation's duration on the
server. Applications should typically set a very long or infinite socketTimeoutMS so they can wait for long-running
MongoDB operations.</p>
<p>Multi-threaded clients use distinct sockets for monitoring and for application operations. A socket used for monitoring
does two things: it connects and calls hello or legacy hello. Both operations are fast on the server, so only network
latency matters. Thus both operations SHOULD use connectTimeoutMS, since that is the value users supply to help the
client guess if a server is down, based on users' knowledge of expected latencies on their networks.</p>
<h3 id="a-monitor-should-not-use-the-clients-regular-connection-pool"><a class="header" href="#a-monitor-should-not-use-the-clients-regular-connection-pool">A monitor SHOULD NOT use the client's regular connection pool</a></h3>
<p>If a multi-threaded driver's connection pool enforces a maximum size and monitors use sockets from the pool, there are
two bad options: either monitors compete with the application for sockets, or monitors have the exceptional ability to
create sockets even when the pool has reached its maximum size. The former risks starving the monitor. The latter is
more complex than it is worth. (A lesson learned from PyMongo 2.6's pool, which implemented this option.)</p>
<p>Since this rule is justified for drivers that enforce a maximum pool size, this spec recommends that all drivers follow
the same rule for the sake of consistency.</p>
<h3 id="monitors-must-use-a-dedicated-connection-for-rtt-commands"><a class="header" href="#monitors-must-use-a-dedicated-connection-for-rtt-commands">Monitors MUST use a dedicated connection for RTT commands</a></h3>
<p>When using the streaming protocol, a monitor needs to maintain an extra dedicated connection to periodically update its
average round trip time in order to support <a href="server-discovery-and-monitoring/../server-selection/server-selection.html#localthresholdms">localThresholdMS</a>
from the Server Selection spec.</p>
<p>It could pop a connection from its regular pool, but we rejected this option for a few reasons:</p>
<ul>
<li>Under contention the RTT task may block application operations from completing in a timely manner.</li>
<li>Under contention the application may block the RTT task from completing in a timely manner.</li>
<li>Under contention the RTT task may often result in an extra connection anyway because the pool creates new connections
under contention up to maxPoolSize.</li>
<li>This would be inconsistent with the rule that a monitor SHOULD NOT use the client's regular connection pool.</li>
</ul>
<p>The client could open and close a new connection for each RTT check. We rejected this design, because if we ping every
heartbeatFrequencyMS (default 10 seconds) then the cost to the client and the server of creating and destroying the
connection might exceed the cost of keeping a dedicated connection open.</p>
<p>Instead, the client must use a dedicated connection reserved for RTT commands. Despite the cost of the additional
connection per server, we chose this option as the safest and least likely to result in surprising behavior under load.</p>
<h3 id="monitors-must-use-the-hello-or-legacy-hello-command-to-measure-rtt"><a class="header" href="#monitors-must-use-the-hello-or-legacy-hello-command-to-measure-rtt">Monitors MUST use the hello or legacy hello command to measure RTT</a></h3>
<p>In the streaming protocol, clients could use the "ping", "hello", or legacy hello commands to measure RTT. This spec
chooses "hello" or legacy hello for consistency with the polling protocol as well as consistency with the initial RTT
provided the connection handshake which also uses the hello or legacy hello commands. Additionally, mongocryptd does not
allow the ping command but does allow hello or legacy hello.</p>
<h3 id="why-not-use-awaitedtimems-in-the-server-response-to-calculate-rtt-in-the-streaming-protocol"><a class="header" href="#why-not-use-awaitedtimems-in-the-server-response-to-calculate-rtt-in-the-streaming-protocol">Why not use <code>awaitedTimeMS</code> in the server response to calculate RTT in the streaming protocol?</a></h3>
<p>One approach to calculating RTT in the streaming protocol would be to have the server return an <code>awaitedTimeMS</code> in its
<code>hello</code> or legacy hello response. A driver could then determine the RTT by calculating the difference between the
initial request, or last response, and the <code>awaitedTimeMS</code>.</p>
<p>We rejected this design because of a number of issue with the unreliability of clocks in distributed systems. Clocks
skew between local and remote system clocks. This approach mixes two notions of time: the local clock times the whole
operation while the remote clock times the wait. This means that if these clocks tick at different rates, or there are
anomalies like clock changes, you will get bad results. To make matters worse, you will be comparing times from multiple
servers that could each have clocks ticking at different rates. This approach will bias toward servers with the fastest
ticking clock, since it will seem like it spends the least time on the wire.</p>
<p>Additionally, systems using NTP will experience clock "slew". ntpd "slews" time by up to 500 parts-per-million to have
the local time gradually approach the "true" time without big jumps - over a 10 second window that means a 5ms
difference. If both sides are slewing in opposite directions, that can result in an effective difference of 10ms. Both
of these times are close enough to <a href="server-discovery-and-monitoring/../server-selection/server-selection.html#localthresholdms">localThresholdMS</a> to
significantly affect which servers are viable in NEAREST calculations.</p>
<p>Ensuring that all measurements use the same clock obviates the need for a more complicated solution, and mitigates the
above mentioned concerns.</p>
<h3 id="why-dont-clients-mark-a-server-unknown-when-an-rtt-command-fails"><a class="header" href="#why-dont-clients-mark-a-server-unknown-when-an-rtt-command-fails">Why don't clients mark a server unknown when an RTT command fails?</a></h3>
<p>In the streaming protocol, clients use the hello or legacy hello command on a dedicated connection to measure a server's
RTT. However, errors encountered when running the RTT command MUST NOT mark a server Unknown. We reached this decision
because the dedicated RTT connection does not come from a connection pool and thus does not have a generation number
associated with it. Without a generation number we cannot handle errors from the RTT command without introducing race
conditions. Introducing such a generation number would add complexity to this design without much benefit. It is safe to
ignore these errors because the Monitor will soon discover the server's state regardless (either through an updated
streaming response, an error on the streaming connection, or by handling an error on an application connection).</p>
<h3 id="drivers-cancel-in-progress-monitor-checks"><a class="header" href="#drivers-cancel-in-progress-monitor-checks">Drivers cancel in-progress monitor checks</a></h3>
<p>When an application operation fails with a non-timeout network error, drivers cancel that monitor's in-progress check.</p>
<p>We assume that a non-timeout network error on one application connection implies that all other connections to that
server are also bad. This means that it is redundant to continue reading on the current monitoring connection. Instead,
we cancel the current monitor check, close the monitoring connection, and start a new check soon. Note that we rely on
the connection/pool generation number checking to avoid races and ensure that the monitoring connection is only closed
once.</p>
<p>This approach also handles the rare case where the client sees a network error on an application connection but the
monitoring connection is still healthy. If we did not cancel the monitor check in this scenario, then the server would
remain in the Unknown state until the next hello or legacy hello response (up to maxAwaitTimeMS). A potential real world
example of this behavior is when Azure closes an idle connection in the application pool.</p>
<h3 id="retry-hello-or-legacy-hello-calls-once"><a class="header" href="#retry-hello-or-legacy-hello-calls-once">Retry hello or legacy hello calls once</a></h3>
<p>A monitor's connection to a server is long-lived and used only for hello or legacy hello calls. So if a server has
responded in the past, a network error on the monitor's connection means that there was a network glitch, or a server
restart since the last check, or that the server is truly down. To handle the case that the server is truly down, the
monitor makes the server unselectable by marking it Unknown. To handle the case of a transient network glitch or
restart, the monitor immediately runs the next check without waiting.</p>
<h3 id="clear-the-connection-pool-on-both-network-and-command-errors"><a class="header" href="#clear-the-connection-pool-on-both-network-and-command-errors">Clear the connection pool on both network and command errors</a></h3>
<p>A monitor clears the connection pool when a server check fails with a network or command error
(<a href="server-discovery-and-monitoring/server-monitoring.html#network-or-command-error-during-server-check">Network or command error during server check</a>). When the check fails
with a network error it is likely that all connections to that server are also closed. (See
<a href="https://jira.mongodb.org/browse/JAVA-1252">JAVA-1252</a>). When the check fails with a network timeout error, a monitor
MUST set interruptInUseConnections to true. See,
<a href="server-discovery-and-monitoring/../connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#why-does-the-pool-need-to-support-interrupting-in-use-connections-as-part-of-its-clear-logic">Why does the pool need to support closing in use connections as part of its clear logic?</a>.</p>
<p>When the server is shutting down, it may respond to hello or legacy hello commands with ShutdownInProgress errors before
closing connections. In this case, the monitor clears the connection pool because all connections will be closed soon.
Other command errors are unexpected but are handled identically.</p>
<h3 id="why-must-streaming-hello-or-legacy-hello-clients-publish-serverheartbeatstartedevents"><a class="header" href="#why-must-streaming-hello-or-legacy-hello-clients-publish-serverheartbeatstartedevents">Why must streaming hello or legacy hello clients publish ServerHeartbeatStartedEvents?</a></h3>
<p>The <a href="server-discovery-and-monitoring/server-discovery-and-monitoring-logging-and-monitoring.html#heartbeats">SDAM Monitoring spec</a> guarantees that every
ServerHeartbeatStartedEvent has either a correlating ServerHeartbeatSucceededEvent or ServerHeartbeatFailedEvent. This
is consistent with Command Monitoring on exhaust cursors where the driver publishes a fake CommandStartedEvent before
reading the next getMore response.</p>
<h3 id="why-dont-streaming-hello-or-legacy-hello-clients-publish-events-for-rtt-commands"><a class="header" href="#why-dont-streaming-hello-or-legacy-hello-clients-publish-events-for-rtt-commands">Why don't streaming hello or legacy hello clients publish events for RTT commands?</a></h3>
<p>In the streaming protocol, clients MUST NOT publish any events (server, topology, command, CMAP, etc..) when running an
RTT command. We considered introducing new RTT events (ServerRTTStartedEvent, ServerRTTSucceededEvent,
ServerRTTFailedEvent) but it's not clear that there is a demand for this. Applications can still monitor changes to a
server's RTT by listening to TopologyDescriptionChangedEvents.</p>
<h3 id="what-is-the-purpose-of-the-awaited-field-on-server-heartbeat-events"><a class="header" href="#what-is-the-purpose-of-the-awaited-field-on-server-heartbeat-events">What is the purpose of the "awaited" field on server heartbeat events?</a></h3>
<p>ServerHeartbeatSucceededEvents published from awaitable hello or legacy hello responses will regularly have 10 second
durations. The spec introduces the "awaited" field on server heartbeat events so that applications can differentiate a
slow heartbeat in the polling protocol from a normal awaitable hello or legacy hello heartbeat in the new protocol.</p>
<h3 id="why-disable-the-streaming-protocol-on-faas-platforms-like-aws-lambda"><a class="header" href="#why-disable-the-streaming-protocol-on-faas-platforms-like-aws-lambda">Why disable the streaming protocol on FaaS platforms like AWS Lambda?</a></h3>
<p>The streaming protocol relies on the assumption that the client can read the server's heartbeat responses in a timely
manner, otherwise the client will be acting on stale information. In many FaaS platforms, like AWS Lambda, host
applications will be suspended and resumed many minutes later. This behavior causes a build up of heartbeat responses
and the client can end up spending a long time in a catch up phase processing outdated responses. This problem was
discovered in <a href="https://jira.mongodb.org/browse/DRIVERS-2246">DRIVERS-2246</a>.</p>
<p>Additionally, the streaming protocol requires an extra connection and thread per monitored server which is expensive on
platforms like AWS Lambda. The extra connection is particularly inefficient when thousands of AWS instances and thus
thousands of clients are used.</p>
<p>We decided to make polling the default behavior when running on FaaS platforms like AWS Lambda to improve scalability,
performance, and reliability.</p>
<h3 id="why-introduce-a-knob-for-servermonitoringmode"><a class="header" href="#why-introduce-a-knob-for-servermonitoringmode">Why introduce a knob for serverMonitoringMode?</a></h3>
<p>The serverMonitoringMode knob provides a workaround in cases where the polling protocol would be a better choice but the
driver is not running on a FaaS platform. It also provides a workaround in case the FaaS detection logic becomes
outdated or inaccurate.</p>
<h2 id="changelog-17"><a class="header" href="#changelog-17">Changelog</a></h2>
<ul>
<li>
<p>2024-05-02: Migrated from reStructuredText to Markdown.</p>
</li>
<li>
<p>2020-02-20: Extracted server monitoring from SDAM into this new spec.</p>
</li>
<li>
<p>2020-03-09: A monitor check that creates a new connection MUST use the connection's handshake to update the topology.</p>
</li>
<li>
<p>2020-04-20: Add streaming heartbeat protocol.</p>
</li>
<li>
<p>2020-05-20: Include rationale for why we don't use <code>awaitedTimeMS</code></p>
</li>
<li>
<p>2020-06-11: Support connectTimeoutMS=0 in streaming heartbeat protocol.</p>
</li>
<li>
<p>2020-12-17: Mark the pool for a server as "ready" after performing a successful check. Synchronize pool clearing with
SDAM updates.</p>
</li>
<li>
<p>2021-06-21: Added support for hello/helloOk to handshake and monitoring.</p>
</li>
<li>
<p>2021-06-24: Remove optimization mention that no longer applies</p>
</li>
<li>
<p>2022-01-19: Add 90th percentile RTT tracking.</p>
</li>
<li>
<p>2022-02-24: Rename Versioned API to Stable API</p>
</li>
<li>
<p>2022-04-05: Preemptively cancel in progress operations when SDAM heartbeats timeout.</p>
</li>
<li>
<p>2022-10-05: Remove spec front matter reformat changelog.</p>
</li>
<li>
<p>2022-11-17: Add minimum RTT tracking and remove 90th percentile RTT.</p>
</li>
<li>
<p>2023-10-05: Add serverMonitoringMode and default to the polling protocol on FaaS. Clients MUST NOT use dedicated
connections to measure RTT when using the polling protocol.</p>
</li>
</ul>
<hr />
<div style="break-before: page; page-break-before: always;"></div><h1 id="polling-srv-records-for-mongos-discovery"><a class="header" href="#polling-srv-records-for-mongos-discovery">Polling SRV Records for mongos Discovery</a></h1>
<ul>
<li>Status: Accepted</li>
<li>Minimum Server Version: N/A</li>
</ul>
<hr />
<h2 id="abstract-18"><a class="header" href="#abstract-18">Abstract</a></h2>
<p>Currently the <a href="polling-srv-records-for-mongos-discovery/../initial-dns-seedlist-discovery/initial-dns-seedlist-discovery.html">Initial DNS Seedlist Discovery</a>
functionality provides a static seedlist when a MongoClient is constructed. Periodically polling the DNS SRV records
would allow for the mongos proxy list to be updated without having to change client configuration.</p>
<p>This specification builds on top of the original Initial DNS Seedlist Discovery specification, and modifies the
<a href="polling-srv-records-for-mongos-discovery/../server-discovery-and-monitoring/server-discovery-and-monitoring.html">Server Discovery and Monitoring</a> specification's
definition of monitoring a set of mongos servers in a Sharded TopologyType.</p>
<h2 id="meta-18"><a class="header" href="#meta-18">META</a></h2>
<p>The keywords "MUST", "MUST NOT", "REQUIRED", "SHALL", "SHALL NOT", "SHOULD", "SHOULD NOT", "RECOMMENDED", "MAY", and
"OPTIONAL" in this document are to be interpreted as described in <a href="https://www.ietf.org/rfc/rfc2119.txt">RFC 2119</a>.</p>
<h2 id="specification-16"><a class="header" href="#specification-16">Specification</a></h2>
<h3 id="terms-9"><a class="header" href="#terms-9">Terms</a></h3>
<h4 id="rescan-rescanning"><a class="header" href="#rescan-rescanning">rescan, rescanning</a></h4>
<p>A rescan is the periodic scan of all DNS SRV records to discover a new set of mongos hosts.</p>
<h4 id="rescansrvintervalms"><a class="header" href="#rescansrvintervalms">rescanSRVIntervalMS</a></h4>
<p>An internal value representing how often the DNS SRV records should be queried for.</p>
<h3 id="implementation"><a class="header" href="#implementation">Implementation</a></h3>
<p>If the initial topology was created through a <code>mongodb+srv://</code> URI, then drivers MUST implement this specification by
periodically rescanning the SRV DNS records. There MUST NOT be an option to turn this behaviour off.</p>
<p>Drivers MUST NOT implement this specification if they do not adhere fully to the
<a href="polling-srv-records-for-mongos-discovery/../initial-dns-seedlist-discovery/initial-dns-seedlist-discovery.html">Initial DNS Seedlist Discovery</a> specification.</p>
<p>This feature is only available when the Server Discovery has determined that the TopologyType is Sharded, or Unknown.
Drivers MUST NOT rescan SRV DNS records when the Topology is not Sharded (i.e. Single, ReplicaSetNoPrimary, or
ReplicaSetWithPrimary).</p>
<p>The discovery of a set of mongos servers is explained in the
<a href="polling-srv-records-for-mongos-discovery/../initial-dns-seedlist-discovery/initial-dns-seedlist-discovery.html#seedlist-discovery">seedlist</a> discovery section of
the original specification. The behaviour of the periodic rescan is similar, but not identical to the behaviour of
initial seedlist discovery. Periodic scan MUST follow these rules:</p>
<ul>
<li>The driver will query the DNS server for SRV records on <code>{hostname}.{domainname}</code>, prefixed with the SRV service name
and protocol. The SRV service name is provided in the
<a href="polling-srv-records-for-mongos-discovery/../initial-dns-seedlist-discovery/initial-dns-seedlist-discovery.html#srvservicename">srvServiceName</a> URI option and
defaults to <code>mongodb</code>. The protocol is always <code>tcp</code>. After prefixing, the URI should look like:
<code>_{srvServiceName}._tcp.{hostname}.{domainname}</code>.</li>
<li>A driver MUST verify that the host names returned through SRV records have the same parent <code>{domainname}</code>. When this
verification fails, a driver:
<ul>
<li>MUST NOT add such a non-compliant host name to the topology</li>
<li>MUST NOT raise an error</li>
<li>SHOULD log the non-compliance, including the host name</li>
<li>MUST NOT initiate a connection to any such host</li>
</ul>
</li>
<li>If the DNS request returns no verified hosts in SRV records, no SRV records at all, or a DNS error happens, the
driver:
<ul>
<li>MUST NOT change the topology</li>
<li>MUST NOT raise an error</li>
<li>SHOULD log this situation, including the reason why the DNS records could not be found, if possible</li>
<li>MUST temporarily set <em>rescanSRVIntervalMS</em> to <em>heartbeatFrequencyMS</em> until at least one verified SRV record is
obtained.</li>
</ul>
</li>
<li>For all verified host names, as returned through the DNS SRV query, the driver:
<ul>
<li>MUST remove all hosts that are part of the topology, but are no longer in the returned set of valid hosts</li>
<li>MUST NOT remove all hosts, and then re-add the ones that were returned. Hosts that have not changed, MUST be left
alone and unchanged.</li>
<li>If <a href="polling-srv-records-for-mongos-discovery/../initial-dns-seedlist-discovery/initial-dns-seedlist-discovery.html#srvmaxhosts">srvMaxHosts</a> is zero or greater
than or equal to the number of valid hosts, each valid new host MUST be added to the topology as Unknown.</li>
<li>If <a href="polling-srv-records-for-mongos-discovery/../initial-dns-seedlist-discovery/initial-dns-seedlist-discovery.html#srvmaxhosts">srvMaxHosts</a> is greater than
zero and less than the number of valid hosts, valid new hosts MUST be randomly selected and added to the topology as
Unknown until the topology has <code>srvMaxHosts</code> hosts. Drivers MUST use the same randomization algorithm as they do for
<a href="polling-srv-records-for-mongos-discovery/../initial-dns-seedlist-discovery/initial-dns-seedlist-discovery.html#querying-dns">initial selection</a>.</li>
</ul>
</li>
<li>Priorities and weights in SRV records MUST continue to be ignored, and MUST NOT dictate which mongos server is used
for new connections.</li>
</ul>
<p>The rescan needs to happen periodically. As SRV records contain a TTL value, this value can be used to indicate when a
rescan needs to happen. Different SRV records can have different TTL values. The <em>rescanSRVIntervalMS</em> value MUST be set
to the lowest of the individual TTL values associated with the different SRV records in the most recent rescan, but MUST
NOT be lower than <em>60 seconds</em>. If a driver is unable to access the TTL values of SRV records, it MUST rescan every 60
seconds.</p>
<p>Drivers SHOULD endeavour to rescan and obtain a new list of mongos servers every <em>rescanSRVIntervalMS</em> value. The
<em>rescanSRVIntervalMS</em> period SHOULD be calculated from the <strong>end</strong> of the previous rescan (or the <strong>end</strong> of the initial
DNS seedlist discovery scan).</p>
<h3 id="multi-threaded-drivers"><a class="header" href="#multi-threaded-drivers">Multi-Threaded Drivers</a></h3>
<p>A threaded driver MUST use a separate monitoring thread for scanning the DNS records so that DNS lookups don't block
other operations.</p>
<h3 id="single-threaded-drivers"><a class="header" href="#single-threaded-drivers">Single-Threaded Drivers</a></h3>
<p>The rescan MUST happen <strong>before</strong> scanning all servers as part of the normal
<a href="polling-srv-records-for-mongos-discovery/../server-discovery-and-monitoring/server-monitoring.html#scanning">scanning</a> functionality, but only if
<em>rescanSRVIntervalMS</em> has passed.</p>
<h2 id="test-plan-12"><a class="header" href="#test-plan-12">Test Plan</a></h2>
<p>See README.md in the accompanying <a href="polling-srv-records-for-mongos-discovery/tests/README.html">test directory</a>.</p>
<h2 id="motivation-for-change-8"><a class="header" href="#motivation-for-change-8">Motivation for Change</a></h2>
<p>The original <a href="polling-srv-records-for-mongos-discovery/../initial-dns-seedlist-discovery/initial-dns-seedlist-discovery.html">Initial DNS Seedlist Discovery</a>
specification only regulates the initial list of mongos hosts to be used instead of a single hostname from a connection
URI. Although this makes the initial configuration of a set of mongos servers a lot easier, it does not provide a method
for updating the list of mongos servers in the topology.</p>
<p>Since the introduction of the <code>mongodb+srv://</code> schema to provide an initial seedlist, some users have requested
additional functionality to be able to update the configured list of mongos hosts that make up the initially seeded
topology:</p>
<ul>
<li><a href="https://jira.mongodb.org/browse/JAVA-2927">https://jira.mongodb.org/browse/JAVA-2927</a></li>
</ul>
<h2 id="design-rationale-11"><a class="header" href="#design-rationale-11">Design Rationale</a></h2>
<h3 id="from-the-scope-document"><a class="header" href="#from-the-scope-document">From the scope document</a></h3>
<h4 id="should-dns-polling-use-heartbeatfrequencyms-or-dns-cache-ttls"><a class="header" href="#should-dns-polling-use-heartbeatfrequencyms-or-dns-cache-ttls">Should DNS polling use heartbeatFrequencyMS or DNS cache TTLs?</a></h4>
<p>We have selected to use lowest TTLs among all DNS SRV records, with a caveat that the rescan frequency is not lower than
60 seconds.</p>
<h4 id="should-dns-polling-also-have-a-fast-polling-mode-when-no-servers-are-available"><a class="header" href="#should-dns-polling-also-have-a-fast-polling-mode-when-no-servers-are-available">Should DNS polling also have a "fast polling" mode when no servers are available?</a></h4>
<p>We have not opted to have a "fast polling" mode, but we did include a provision that a rescan needs to happen when DNS
records are not available. In that case, a rescan would happen every <em>heartbeatFrequencyMS</em>. The rationale being that
polling DNS really often really fast does not make a lot of sense due to DNS caching, which often uses the TTL already
anyway, but when we have no TTL records to reference we still need a fallback frequency.</p>
<h3 id="for-the-design"><a class="header" href="#for-the-design">For the design</a></h3>
<h4 id="no-option-to-turn-off-periodic-rescanning"><a class="header" href="#no-option-to-turn-off-periodic-rescanning">No option to turn off periodic rescanning</a></h4>
<p>The design does not allow for an option to turn off the periodic rescanning of SRV records on the basis that we try to
have as few options as possible: the "no knobs" philosophy.</p>
<h2 id="backwards-compatibility-10"><a class="header" href="#backwards-compatibility-10">Backwards Compatibility</a></h2>
<p>This specification changes the behaviour of server monitoring by introducing a repeating DNS lookup of the SRV records.
Although this is an improvement in the <code>mongodb+srv://</code> scheme it can nonetheless break expectations with users that
were familiar with the old behaviour. We do not expect this to negatively impact users.</p>
<h2 id="reference-implementation-8"><a class="header" href="#reference-implementation-8">Reference Implementation</a></h2>
<p>Reference implementations are made for the following drivers:</p>
<ul>
<li>Perl</li>
<li>C#</li>
</ul>
<h2 id="security-implication-1"><a class="header" href="#security-implication-1">Security Implication</a></h2>
<p>This specification has no security implications beyond the ones associated with the original
<a href="polling-srv-records-for-mongos-discovery/../initial-dns-seedlist-discovery/initial-dns-seedlist-discovery.html">Initial DNS Seedlist Discovery</a> specification.</p>
<h2 id="future-work-7"><a class="header" href="#future-work-7">Future work</a></h2>
<p>No future work is expected.</p>
<h2 id="changelog-18"><a class="header" href="#changelog-18">Changelog</a></h2>
<ul>
<li>
<p>2024-08-22: Migrated from reStructuredText to Markdown.</p>
</li>
<li>
<p>2022-10-05: Revise spec front matter and reformat changelog.</p>
</li>
<li>
<p>2021-10-14: Specify behavior for <code>srvMaxHosts</code> MongoClient option.</p>
</li>
<li>
<p>2021-09-15: Clarify that service name only defaults to <code>mongodb</code>, and should be defined by the <code>srvServiceName</code> URI
option.</p>
</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="server-selection-2"><a class="header" href="#server-selection-2">Server Selection</a></h1>
<ul>
<li>Status: Accepted</li>
<li>Minimum Server Version: 2.4</li>
</ul>
<h2 id="abstract-19"><a class="header" href="#abstract-19">Abstract</a></h2>
<p>MongoDB deployments may offer more than one server that can service an operation. This specification describes how
MongoDB drivers and mongos shall select a server for either read or write operations. It includes the definition of a
"read preference" document, configuration options, and algorithms for selecting a server for different deployment
topologies.</p>
<h2 id="meta-19"><a class="header" href="#meta-19">Meta</a></h2>
<p>The key words "MUST", "MUST NOT", "REQUIRED", "SHALL", "SHALL NOT", "SHOULD", "SHOULD NOT", "RECOMMENDED", "MAY", and
"OPTIONAL" in this document are to be interpreted as described in <a href="https://www.ietf.org/rfc/rfc2119.txt">RFC 2119</a>.</p>
<h2 id="motivation-for-change-9"><a class="header" href="#motivation-for-change-9">Motivation for Change</a></h2>
<p>This specification builds upon the prior "Driver Read Preference" specification, which had a number of omissions, flaws
or other deficiencies:</p>
<ol>
<li>Mandating features that implied monotonicity for situations where monotonicity is not guaranteed</li>
<li>Mandating features that are not supported by mongos</li>
<li>Neglecting to specify a single, standard way to calculate average latency times</li>
<li>Specifying complex command-helper rules</li>
<li>Omitting rules for applying read preferences to a single server or to select among multiple mongos servers</li>
<li>Omitting test cases for verification of spec compliance</li>
</ol>
<p>This revision addresses these problems as well as improving structure and specificity.</p>
<p>Additionally, it adds specifications for server selection more broadly:</p>
<ul>
<li>Selection of a server for write operations</li>
<li>Server selection retry and timeout</li>
</ul>
<h2 id="specification-17"><a class="header" href="#specification-17">Specification</a></h2>
<h3 id="scope-and-general-requirements"><a class="header" href="#scope-and-general-requirements">Scope and general requirements</a></h3>
<p>This specification describes how MongoDB drivers and mongos select a server for read and write operations, including
commands, OP_QUERY, OP_INSERT, OP_UPDATE, and OP_DELETE. For read operations, it describes how drivers and mongos shall
interpret a read preference document.</p>
<p>This specification does not apply to OP_GET_MORE or OP_KILL_CURSORS operations on cursors, which need to go to the same
server that received an OP_QUERY and returned a cursor ID.</p>
<p>For operations that are part of a sharded transaction this specification only applies to the initial operation which
starts the transaction on a mongos. This specification does not apply to subsequent operations that are part of the
sharded transaction because all operations in a sharded transaction need to go to the same mongos server.</p>
<p>Drivers and mongos MUST conform to the semantics of this document, but SHOULD use language-appropriate data models or
variable names.</p>
<p>This specification does not apply to commands issued for server monitoring or authentication.</p>
<h3 id="terms-10"><a class="header" href="#terms-10">Terms</a></h3>
<p><strong>Available</strong></p>
<p>Describes a server that is believed to be reachable over the network and able to respond to requests. A server of type
Unknown or PossiblePrimary is not available; other types are available.</p>
<p><strong>Client</strong></p>
<p>Software that communicates with a MongoDB deployment. This includes both drivers and mongos.</p>
<p><strong>Candidate</strong></p>
<p>Describes servers in a deployment that enter the selection process, determined by the read preference <code>mode</code> parameter
and the servers' type. Depending on the <code>mode</code>, candidate servers might only include secondaries or might apply to all
servers in the deployment.</p>
<p><strong>Deployment</strong></p>
<p>One or more servers that collectively provide access to a single logical set of MongoDB databases.</p>
<p><strong>Command</strong></p>
<p>An OP_QUERY operation targeting the '$cmd' collection namespace.</p>
<p><strong>Direct connection</strong></p>
<p>A driver connection mode that sends all database operations to a single server without regard for type.</p>
<p><span id="eligible"></span></p>
<p><strong>Eligible</strong></p>
<p>Describes candidate servers that also meet the criteria specified by the <code>tag_sets</code> and <code>maxStalenessSeconds</code> read
preference parameters.</p>
<p><strong>Hedged Read</strong></p>
<p>A server mode in which the same query is dispatched in parallel to multiple replica set members.</p>
<p><strong>Immediate topology check</strong></p>
<p>For a multi-threaded or asynchronous client, this means waking all server monitors for an immediate check. For a
single-threaded client, this means a (blocking) scan of all servers.</p>
<p><strong>Latency window</strong></p>
<p>When choosing between several suitable servers, the latency window is the range of acceptable RTTs from the shortest RTT
to the shortest RTT plus the local threshold. E.g. if the shortest RTT is 15ms and the local threshold is 200ms, then
the latency window ranges from 15ms - 215ms.</p>
<p><strong>Local threshold</strong></p>
<p>The maximum acceptable difference in milliseconds between the shortest RTT and the longest RTT of servers suitable to be
selected.</p>
<p><strong>Mode</strong></p>
<p>One of several enumerated values used as part of a read preference, defining which server types are candidates for reads
and the semantics for choosing a specific one.</p>
<p><strong>Primary</strong></p>
<p>Describes a server of type RSPrimary.</p>
<p><strong>Query</strong></p>
<p>An OP_QUERY operation targeting a regular (non '$cmd') collection namespace.</p>
<p><strong>Read preference</strong></p>
<p>The parameters describing which servers in a deployment can receive read operations, including <code>mode</code>, <code>tag_sets</code>,
<code>maxStalenessSeconds</code>, and <code>hedge</code>.</p>
<p><strong>RS</strong></p>
<p>Abbreviation for "replica set".</p>
<p><strong>RTT</strong></p>
<p>Abbreviation for "round trip time".</p>
<p><strong>Round trip time</strong></p>
<p>The time in milliseconds to execute a <code>hello</code> or legacy hello command and receive a response for a given server. This
spec differentiates between the RTT of a single <code>hello</code> or legacy hello command and a server's <em>average</em> RTT over
several such commands.</p>
<p><strong>Secondary</strong></p>
<p>A server of type RSSecondary.</p>
<p><strong>Staleness</strong></p>
<p>A worst-case estimate of how far a secondary's replication lags behind the primary's last write.</p>
<p><strong>Server</strong></p>
<p>A mongod or mongos process.</p>
<p><strong>Server selection</strong></p>
<p>The process by which a server is chosen for a database operation out of all potential servers in a deployment.</p>
<p><strong>Server type</strong></p>
<p>An enumerated type indicating whether a server is up or down, whether it is a mongod or mongos, whether it belongs to a
replica set and, if so, what role it serves in the replica set. See the
<a href="server-selection/../server-discovery-and-monitoring/server-discovery-and-monitoring.html">Server Discovery and Monitoring</a> spec for more
details.</p>
<p><strong>Suitable</strong></p>
<p>Describes a server that meets all specified criteria for a read or write operation.</p>
<p><strong>Tag</strong></p>
<p>A single key/value pair describing either (1) a user-specified characteristic of a replica set member or (2) a desired
characteristic for the target of a read operation. The key and value have no semantic meaning to the driver; they are
arbitrary user choices.</p>
<p><strong>Tag set</strong></p>
<p>A document of zero or more tags. Each member of a replica set can be configured with zero or one tag set.</p>
<p><strong>Tag set list</strong></p>
<p>A list of zero or more tag sets. A read preference might have a tag set list used for selecting servers.</p>
<p><strong>Topology</strong></p>
<p>The state of a deployment, including its type, which servers are members, and the server types of members.</p>
<p><strong>Topology type</strong></p>
<p>An enumerated type indicating the semantics for monitoring servers and selecting servers for database operations. See
the <a href="server-selection/../server-discovery-and-monitoring/server-discovery-and-monitoring.html">Server Discovery and Monitoring</a> spec for
more details.</p>
<h3 id="assumptions"><a class="header" href="#assumptions">Assumptions</a></h3>
<ol>
<li>Unless they explicitly override these priorities, we assume our users prefer their applications to be, in order:
<ul>
<li>Predictable: the behavior of the application should not change based on the deployment type, whether single mongod,
replica set or sharded cluster.</li>
<li>Resilient: applications will adapt to topology changes, if possible, without raising errors or requiring manual
reconfiguration.</li>
<li>Low-latency: all else being equal, faster responses to queries and writes are preferable.</li>
</ul>
</li>
<li>Clients know the state of a deployment based on some form of ongoing monitoring, following the rules defined in the
<a href="server-selection/../server-discovery-and-monitoring/server-discovery-and-monitoring.html">Server Discovery and Monitoring</a> spec.
<ul>
<li>They know which members are up or down, what their tag sets are, and their types.</li>
<li>They know average round trip times to each available member.</li>
<li>They detect reconfiguration and the addition or removal of members.</li>
</ul>
</li>
<li>The state of a deployment could change at any time, in between any network interaction.
<ul>
<li>Servers might or might not be reachable; they can change type at any time, whether due to partitions, elections, or
misconfiguration.</li>
<li>Data rollbacks could occur at any time.</li>
</ul>
</li>
</ol>
<h3 id="mongoclient-configuration-4"><a class="header" href="#mongoclient-configuration-4">MongoClient Configuration</a></h3>
<p>Selecting a server requires the following client-level configuration options:</p>
<h4 id="localthresholdms"><a class="header" href="#localthresholdms">localThresholdMS</a></h4>
<p>This defines the size of the latency window for selecting among multiple suitable servers. The default is 15
(milliseconds). It MUST be configurable at the client level. It MUST NOT be configurable at the level of a database
object, collection object, or at the level of an individual query.</p>
<p>In the prior read preference specification, <code>localThresholdMS</code> was called <code>secondaryAcceptableLatencyMS</code> by drivers.
Drivers MUST support the new name for consistency, but MAY continue to support the legacy name to avoid a
backward-breaking change.</p>
<p>mongos currently uses <code>localThreshold</code> and MAY continue to do so.</p>
<h4 id="serverselectiontimeoutms"><a class="header" href="#serverselectiontimeoutms">serverSelectionTimeoutMS</a></h4>
<p>This defines the maximum time to block for server selection before throwing an exception. The default is 30,000
(milliseconds). It MUST be configurable at the client level. It MUST NOT be configurable at the level of a database
object, collection object, or at the level of an individual query.</p>
<p>The actual timeout for server selection can be less than <code>serverSelectionTimeoutMS</code>. See <a href="server-selection/server-selection.html#timeouts">Timeouts</a> for rules
to compute the exact value.</p>
<p>This default value was chosen to be sufficient for a typical server primary election to complete. As the server improves
the speed of elections, this number may be revised downward.</p>
<p>Users that can tolerate long delays for server selection when the topology is in flux can set this higher. Users that
want to "fail fast" when the topology is in flux can set this to a small number.</p>
<p>A serverSelectionTimeoutMS of zero MAY have special meaning in some drivers; zero's meaning is not defined in this spec,
but all drivers SHOULD document the meaning of zero.</p>
<h4 id="serverselectiontryonce"><a class="header" href="#serverselectiontryonce">serverSelectionTryOnce</a></h4>
<p>Single-threaded drivers MUST provide a "serverSelectionTryOnce" mode, in which the driver scans the topology exactly
once after server selection fails, then either selects a server or raises an error.</p>
<p>The serverSelectionTryOnce option MUST be true by default. If it is set false, then the driver repeatedly searches for
an appropriate server until the selection process times out (pausing
<a href="server-selection/../server-discovery-and-monitoring/server-discovery-and-monitoring.html#minheartbeatfrequencyms">minHeartbeatFrequencyMS</a>
between attempts, as required by the
<a href="server-selection/../server-discovery-and-monitoring/server-discovery-and-monitoring.html">Server Discovery and Monitoring</a> spec).</p>
<p>Users of single-threaded drivers MUST be able to control this mode in one or both of these ways:</p>
<ul>
<li>In code, pass true or false for an option called serverSelectionTryOnce, spelled idiomatically for the language, to
the MongoClient constructor.</li>
<li>Include "serverSelectionTryOnce=true" or "serverSelectionTryOnce=false" in the URI. The URI option is spelled the same
for all drivers.</li>
</ul>
<p>Conflicting usages of the URI option and the symbol is an error.</p>
<p>Multi-threaded drivers MUST NOT provide this mode. (See
<a href="server-selection/server-selection.html#single-threaded-server-selection-implementation">single-threaded server selection implementation</a> and the rationale
for a <a href="server-selection/server-selection.html#try-once-mode">"try once" mode</a>.)</p>
<h4 id="heartbeatfrequencyms-2"><a class="header" href="#heartbeatfrequencyms-2">heartbeatFrequencyMS</a></h4>
<p>This controls when topology updates are scheduled. See
<a href="server-selection/../server-discovery-and-monitoring/server-discovery-and-monitoring.html#heartbeatfrequencyms">heartbeatFrequencyMS</a> in
the <a href="server-selection/../server-discovery-and-monitoring/server-discovery-and-monitoring.html">Server Discovery and Monitoring</a> spec for
details.</p>
<h4 id="socketcheckintervalms"><a class="header" href="#socketcheckintervalms">socketCheckIntervalMS</a></h4>
<p>Only for single-threaded drivers.</p>
<p>The default socketCheckIntervalMS MUST be 5000 (5 seconds), and it MAY be configurable. If socket has been idle for at
least this long, it must be checked before being used again.</p>
<p>See <a href="server-selection/server-selection.html#checking-an-idle-socket-after-socketcheckintervalms">checking an idle socket after socketCheckIntervalMS</a> and
<a href="server-selection/server-selection.html#what-is-the-purpose-of-socketcheckintervalms">what is the purpose of socketCheckIntervalMS?</a>.</p>
<h4 id="idlewriteperiodms"><a class="header" href="#idlewriteperiodms">idleWritePeriodMS</a></h4>
<p>A constant, how often an idle primary writes a no-op to the oplog. See
<a href="server-selection/../max-staleness/max-staleness.html#idlewriteperiodms">idleWritePeriodMS</a> in the
<a href="server-selection/../max-staleness/max-staleness.html">Max Staleness</a> spec for details.</p>
<h4 id="smallestmaxstalenessseconds"><a class="header" href="#smallestmaxstalenessseconds">smallestMaxStalenessSeconds</a></h4>
<p>A constant, 90 seconds. See "Smallest allowed value for maxStalenessSeconds" in the Max Staleness Spec.</p>
<h4 id="serverselector"><a class="header" href="#serverselector">serverSelector</a></h4>
<p>Implementations MAY allow configuration of an optional, application-provided function that augments the server selection
rules. The function takes as a parameter a list of server descriptions representing the suitable servers for the read or
write operation, and returns a list of server descriptions that should still be considered suitable.</p>
<h3 id="read-preference"><a class="header" href="#read-preference">Read Preference</a></h3>
<p>A read preference determines which servers are considered suitable for read operations. Read preferences are interpreted
differently based on topology type. See topology-type-specific server selection rules for details.</p>
<p>When no servers are suitable, the selection might be retried or will eventually fail following the rules described in
the <a href="server-selection/server-selection.html#rules-for-server-selection">Rules for server selection</a> section.</p>
<h4 id="components-of-a-read-preference"><a class="header" href="#components-of-a-read-preference">Components of a read preference</a></h4>
<p>A read preference consists of a <code>mode</code> and optional <code>tag_sets</code>, <code>maxStalenessSeconds</code>, and <code>hedge</code>. The <code>mode</code>
prioritizes between primaries and secondaries to produce either a single suitable server or a list of candidate servers.
If <code>tag_sets</code> and <code>maxStalenessSeconds</code> are set, they determine which candidate servers are eligible for selection. If
<code>hedge</code> is set, it configures how server hedged reads are used.</p>
<p>The default <code>mode</code> is 'primary'. The default <code>tag_sets</code> is a list with an empty tag set: <code>[{}]</code>. The default
<code>maxStalenessSeconds</code> is -1 or null, depending on the language. The default <code>hedge</code> is unset.</p>
<p>Each is explained in greater detail below.</p>
<h5 id="mode"><a class="header" href="#mode">mode</a></h5>
<p>For a deployment with topology type ReplicaSetWithPrimary or ReplicaSetNoPrimary, the <code>mode</code> parameter controls whether
primaries or secondaries are deemed suitable. Topology types Single and Sharded have different selection criteria and
are described elsewhere.</p>
<p>Clients MUST support these modes:</p>
<p><strong>primary</strong></p>
<p>Only an available primary is suitable.</p>
<p><strong>secondary</strong></p>
<p>All secondaries (and <em>only</em> secondaries) are candidates, but only <a href="server-selection/server-selection.html#eligible">eligible</a> candidates (i.e. after applying
<code>tag_sets</code> and <code>maxStalenessSeconds</code>) are suitable.</p>
<p><strong>primaryPreferred</strong></p>
<p>If a primary is available, only the primary is suitable. Otherwise, all secondaries are candidates, but only eligible
secondaries are suitable.</p>
<p><strong>secondaryPreferred</strong></p>
<p>All secondaries are candidates. If there is at least one eligible secondary, only eligible secondaries are suitable.
Otherwise, when there are no eligible secondaries, the primary is suitable.</p>
<p><strong>nearest</strong></p>
<p>The primary and all secondaries are candidates, but only eligible candidates are suitable.</p>
<p><em>Note on other server types</em>: The
<a href="server-selection/../server-discovery-and-monitoring/server-discovery-and-monitoring.html">Server Discovery and Monitoring</a> spec defines
several other server types that could appear in a replica set. Such types are never candidates, eligible or suitable.</p>
<p><span id="algorithm-for-filtering-by-staleness"></span></p>
<h5 id="maxstalenessseconds"><a class="header" href="#maxstalenessseconds">maxStalenessSeconds</a></h5>
<p>The maximum replication lag, in wall clock time, that a secondary can suffer and still be eligible.</p>
<p>The default is no maximum staleness.</p>
<p>A <code>maxStalenessSeconds</code> of -1 MUST mean "no maximum". Drivers are also free to use None, null, or other representations
of "no value" to represent "no max staleness".</p>
<p>Drivers MUST raise an error if <code>maxStalenessSeconds</code> is a positive number and the <code>mode</code> field is 'primary'.</p>
<p>A driver MUST raise an error if the TopologyType is ReplicaSetWithPrimary or ReplicaSetNoPrimary and either of these
conditions is false:</p>
<pre><code>maxStalenessSeconds * 1000 &gt;= heartbeatFrequencyMS + idleWritePeriodMS
maxStalenessSeconds &gt;= smallestMaxStalenessSeconds
</code></pre>
<p><code>heartbeatFrequencyMS</code> is defined in the
<a href="server-selection/../server-discovery-and-monitoring/server-discovery-and-monitoring.html">Server Discovery and Monitoring</a> spec, and
<code>idleWritePeriodMS</code> is defined to be 10 seconds in the <a href="server-selection/../max-staleness/max-staleness.html">Max Staleness</a> spec.</p>
<p>See "Smallest allowed value for maxStalenessSeconds" in the Max Staleness Spec.</p>
<p>mongos MUST reject a read with <code>maxStalenessSeconds</code> provided and a <code>mode</code> of 'primary'.</p>
<p>mongos MUST reject a read with <code>maxStalenessSeconds</code> that is not a positive integer.</p>
<p>mongos MUST reject a read if <code>maxStalenessSeconds</code> is less than smallestMaxStalenessSeconds, with error code 160
(SERVER-24421).</p>
<p>During server selection, drivers (but not mongos) with <code>minWireVersion</code> &lt; 5 MUST raise an error if
<code>maxStalenessSeconds</code> is a positive number, and any available server's <code>maxWireVersion</code> is less than 5.<sup class="footnote-reference"><a href="#1">1</a></sup></p>
<p>After filtering servers according to <code>mode</code>, and before filtering with <code>tag_sets</code>, eligibility MUST be determined from
<code>maxStalenessSeconds</code> as follows:</p>
<ul>
<li>
<p>If <code>maxStalenessSeconds</code> is not a positive number, then all servers are eligible.</p>
</li>
<li>
<p>Otherwise, calculate staleness. Non-secondary servers (including Mongos servers) have zero staleness. If TopologyType
is ReplicaSetWithPrimary, a secondary's staleness is calculated using its ServerDescription "S" and the primary's
ServerDescription "P":</p>
<pre><code>(S.lastUpdateTime - S.lastWriteDate) - (P.lastUpdateTime - P.lastWriteDate) + heartbeatFrequencyMS
</code></pre>
<p>(All datetime units are in milliseconds.)</p>
<p>If TopologyType is ReplicaSetNoPrimary, a secondary's staleness is calculated using its ServerDescription "S" and the
ServerDescription of the secondary with the greatest lastWriteDate, "SMax":</p>
<pre><code>SMax.lastWriteDate - S.lastWriteDate + heartbeatFrequencyMS
</code></pre>
<p>Servers with staleness less than or equal to <code>maxStalenessSeconds</code> are eligible.</p>
</li>
</ul>
<p>See the Max Staleness Spec for overall description and justification of this feature.</p>
<p><span id="algorithm-for-filtering-by-tag_sets"></span></p>
<h5 id="tag_sets"><a class="header" href="#tag_sets">tag_sets</a></h5>
<p>The read preference <code>tag_sets</code> parameter is an ordered list of tag sets used to restrict the eligibility of servers,
such as for data center awareness.</p>
<p>Clients MUST raise an error if a non-empty tag set is given in <code>tag_sets</code> and the <code>mode</code> field is 'primary'.</p>
<p>A read preference tag set (<code>T</code>) matches a server tag set (<code>S</code>) – or equivalently a server tag set (<code>S</code>) matches a read
preference tag set (<code>T</code>) — if <code>T</code> is a subset of <code>S</code> (i.e. <code>T ⊆ S</code>).</p>
<p>For example, the read preference tag set "{ dc: 'ny', rack: '2' }" matches a secondary server with tag set "{ dc: 'ny',
rack: '2', size: 'large' }".</p>
<p>A tag set that is an empty document matches any server, because the empty tag set is a subset of any tag set. This means
the default <code>tag_sets</code> parameter (<code>[{}]</code>) matches all servers.</p>
<p>Tag sets are applied after filtering servers by <code>mode</code> and <code>maxStalenessSeconds</code>, and before selecting one server within
the latency window.</p>
<p>Eligibility MUST be determined from <code>tag_sets</code> as follows:</p>
<ul>
<li>If the <code>tag_sets</code> list is empty then all candidate servers are eligible servers. (Note, the default of <code>[{}]</code> means an
empty list probably won't often be seen, but if the client does not forbid an empty list, this rule MUST be
implemented to handle that case.)</li>
<li>If the <code>tag_sets</code> list is not empty, then tag sets are tried in order until a tag set matches at least one candidate
server. All candidate servers matching that tag set are eligible servers. Subsequent tag sets in the list are ignored.</li>
<li>If the <code>tag_sets</code> list is not empty and no tag set in the list matches any candidate server, no servers are eligible
servers.</li>
</ul>
<h5 id="hedge"><a class="header" href="#hedge">hedge</a></h5>
<p>The read preference <code>hedge</code> parameter is a document that configures how the server will perform hedged reads. It
consists of the following keys:</p>
<ul>
<li><code>enabled</code>: Enables or disables hedging</li>
</ul>
<p>Hedged reads are automatically enabled in MongoDB 4.4+ when using a <code>nearest</code> read preference. To explicitly enable
hedging, the <code>hedge</code> document must be passed. An empty document uses server defaults to control hedging, but the
<code>enabled</code> key may be set to <code>true</code> or <code>false</code> to explicitly enable or disable hedged reads.</p>
<p>Drivers MAY allow users to specify an empty hedge document if they accept documents for read preference options. Any
driver that exposes a builder API for read preference objects MUST NOT allow an empty <code>hedge</code> document to be
constructed. In this case, the user MUST specify a value for <code>enabled</code>, which MUST default to <code>true</code>. If the user does
not call a <code>hedge</code> API method, drivers MUST NOT send a <code>hedge</code> option to the server.</p>
<h4 id="read-preference-configuration"><a class="header" href="#read-preference-configuration">Read preference configuration</a></h4>
<p>Drivers MUST allow users to configure a default read preference on a <code>MongoClient</code> object. Drivers MAY allow users to
configure a default read preference on a <code>Database</code> or <code>Collection</code> object.</p>
<p>A read preference MAY be specified as an object, document or individual <code>mode</code>, <code>tag_sets</code>, and <code>maxStalenessSeconds</code>
parameters, depending on what is most idiomatic for the language.</p>
<p>If more than one object has a default read preference, the default of the most specific object takes precedence. I.e.
<code>Collection</code> is preferred over <code>Database</code>, which is preferred over <code>MongoClient</code>.</p>
<p>Drivers MAY allow users to set a read preference on queries on a per-operation basis similar to how <code>hint</code> or
<code>batchSize</code> are set. E.g., in Python:</p>
<pre><code class="language-python">db.collection.find({}, read_preference=ReadPreference.SECONDARY)
db.collection.find(
    {},
    read_preference=ReadPreference.NEAREST,
    tag_sets=[{'dc': 'ny'}],
    maxStalenessSeconds=120,
    hedge={'enabled': true})
</code></pre>
<p><span id="passing-read-preference-to-mongos"></span></p>
<h4 id="passing-read-preference-to-mongos-and-load-balancers"><a class="header" href="#passing-read-preference-to-mongos-and-load-balancers">Passing read preference to mongos and load balancers</a></h4>
<p>If a server of type Mongos or LoadBalancer is selected for a read operation, the read preference is passed to the
selected mongos through the use of <code>$readPreference</code> (as a
<a href="server-selection/../message/OP_MSG.html#global-command-arguments">Global Command Argument</a> for OP_MSG or a query modifier for OP_QUERY)
and, for OP_QUERY only, the <code>SecondaryOk</code> wire protocol flag, according to the following rules.</p>
<h5 id="for-op_msg"><a class="header" href="#for-op_msg">For OP_MSG:</a></h5>
<ul>
<li>For mode 'primary', drivers MUST NOT set <code>$readPreference</code></li>
<li>For all other read preference modes (i.e. 'secondary', 'primaryPreferred', ...), drivers MUST set <code>$readPreference</code></li>
</ul>
<h5 id="for-op_query"><a class="header" href="#for-op_query">For OP_QUERY:</a></h5>
<p>If the read preference contains <strong>only</strong> a <code>mode</code> parameter and the mode is 'primary' or 'secondaryPreferred', for
maximum backwards compatibility with older versions of mongos, drivers MUST only use the value of the <code>SecondaryOk</code> wire
protocol flag (i.e. set or unset) to indicate the desired read preference and MUST NOT use a <code>$readPreference</code> query
modifier.</p>
<p>Therefore, when sending queries to a mongos or load balancer, the following rules apply:</p>
<ul>
<li>For mode 'primary', drivers MUST NOT set the <code>SecondaryOk</code> wire protocol flag and MUST NOT use <code>$readPreference</code></li>
<li>For mode 'secondary', drivers MUST set the <code>SecondaryOk</code> wire protocol flag and MUST also use <code>$readPreference</code></li>
<li>For mode 'primaryPreferred', drivers MUST set the <code>SecondaryOk</code> wire protocol flag and MUST also use <code>$readPreference</code></li>
<li>For mode 'secondaryPreferred', drivers MUST set the <code>SecondaryOk</code> wire protocol flag. If the read preference contains
a non-empty <code>tag_sets</code> parameter, <code>maxStalenessSeconds</code> is a positive integer, or the <code>hedge</code> parameter is non-empty,
drivers MUST use <code>$readPreference</code>; otherwise, drivers MUST NOT use <code>$readPreference</code></li>
<li>For mode 'nearest', drivers MUST set the <code>SecondaryOk</code> wire protocol flag and MUST also use <code>$readPreference</code></li>
</ul>
<p>The <code>$readPreference</code> query modifier sends the read preference as part of the query. The read preference fields
<code>tag_sets</code> is represented in a <code>$readPreference</code> document using the field name <code>tags</code>.</p>
<p>When sending a read operation via OP_QUERY and any <code>$</code> modifier is used, including the <code>$readPreference</code> modifier, the
query MUST be provided using the <code>$query</code> modifier like so:</p>
<pre><code class="language-javascript">{
    $query: {
        field1: 'query_value',
        field2: 'another_query_value'
    },
    $readPreference: {
        mode: 'secondary',
        tags: [ { 'dc': 'ny' } ],
        maxStalenessSeconds: 120,
        hedge: { enabled: true }
    }
}
</code></pre>
<h5 id="document-structure"><a class="header" href="#document-structure">Document structure</a></h5>
<p>A valid <code>$readPreference</code> document for mongos or load balancer has the following requirements:</p>
<ol>
<li>
<p>The <code>mode</code> field MUST be present exactly once with the mode represented in camel case:</p>
<ul>
<li>'primary'</li>
<li>'secondary'</li>
<li>'primaryPreferred'</li>
<li>'secondaryPreferred'</li>
<li>'nearest'</li>
</ul>
</li>
<li>
<p>If the <code>mode</code> field is "primary", the <code>tags</code>, <code>maxStalenessSeconds</code>, and <code>hedge</code> fields MUST be absent.</p>
<p>Otherwise, for other <code>mode</code> values, the <code>tags</code> field MUST either be absent or be present exactly once and have an
array value containing at least one document. It MUST contain only documents, no other type.</p>
<p>The <code>maxStalenessSeconds</code> field MUST be either be absent or be present exactly once with an integer value.</p>
<p>The <code>hedge</code> field MUST be either absent or be a document.</p>
</li>
</ol>
<p>Mongos or service receiving a query with <code>$readPreference</code> SHOULD validate the <code>mode</code>, <code>tags</code>, <code>maxStalenessSeconds</code>,
and <code>hedge</code> fields according to rules 1 and 2 above, but SHOULD ignore unrecognized fields for forward-compatibility
rather than throwing an error.</p>
<h4 id="use-of-read-preferences-with-commands"><a class="header" href="#use-of-read-preferences-with-commands">Use of read preferences with commands</a></h4>
<p>Because some commands are used for writes, deployment-changes or other state-changing side-effects, the use of read
preference by a driver depends on the command and how it is invoked:</p>
<ol>
<li>
<p>Write commands: <code>insert</code>, <code>update</code>, <code>delete</code>, <code>findAndModify</code></p>
<p>Write commands are considered write operations and MUST follow the corresponding
<a href="server-selection/server-selection.html#rules-for-server-selection">Rules for server selection</a> for each topology type.</p>
</li>
<li>
<p>Generic command method: typically <code>command</code> or <code>runCommand</code></p>
<p>The generic command method MUST act as a read operation for the purposes of server selection.</p>
<p>The generic command method has a default read preference of <code>mode</code> 'primary'. The generic command method MUST ignore
any default read preference from client, database or collection configuration. The generic command method SHOULD
allow an optional read preference argument.</p>
<p>If an explicit read preference argument is provided as part of the generic command method call, it MUST be used for
server selection, regardless of the name of the command. It is up to the user to use an appropriate read preference,
e.g. not calling <code>renameCollection</code> with a <code>mode</code> of 'secondary'.</p>
<p>N.B.: "used for server selection" does not supersede rules for server selection on "Standalone" topologies, which
ignore any requested read preference.</p>
</li>
<li>
<p>Command-specific helper: methods that wrap database commands, like <code>count</code>, <code>distinct</code>, <code>listCollections</code> or
<code>renameCollection</code>.</p>
<p>Command-specific helpers MUST act as read operations for the purposes of server selection, with read preference rules
defined by the following three categories of commands:</p>
<ul>
<li>
<p>"must-use-primary": these commands have state-modifying effects and will only succeed on a primary. An example is
<code>renameCollection</code>.</p>
<p>These command-specific helpers MUST use a read preference <code>mode</code> of 'primary', MUST NOT take a read preference
argument and MUST ignore any default read preference from client, database or collection configuration. Languages
with dynamic argument lists MUST throw an error if a read preference is provided as an argument.</p>
<p>Clients SHOULD rely on the server to return a "not writable primary" or other error if the command is
"must-use-primary". Clients MAY raise an exception before sending the command if the topology type is Single and
the server type is not "Standalone", "RSPrimary" or "Mongos", but the identification of the set of
'must-use-primary' commands is out of scope for this specification.</p>
</li>
<li>
<p>"should-use-primary": these commands are intended to be run on a primary, but would succeed -- albeit with possibly
stale data -- when run against a secondary. An example is <code>listCollections</code>.</p>
<p>These command-specific helpers MUST use a read preference <code>mode</code> of 'primary', MUST NOT take a read preference
argument and MUST ignore any default read preference from client, database or collection configuration. Languages
with dynamic argument lists MUST throw an error if a read preference is provided as an argument.</p>
<p>Clients MUST NOT raise an exception if the topology type is Single.</p>
</li>
<li>
<p>"may-use-secondary": these commands run against primaries or secondaries, according to users' read preferences.
They are sometimes called "query-like" commands.</p>
<p>The current list of "may-use-secondary" commands includes:</p>
<ul>
<li>aggregate without a write stage (e.g. <code>$out</code>, <code>$merge</code>)</li>
<li>collStats</li>
<li>count</li>
<li>dbStats</li>
<li>distinct</li>
<li>find</li>
<li>geoNear</li>
<li>geoSearch</li>
<li>group</li>
<li>mapReduce where the <code>out</code> option is <code>{ inline: 1 }</code></li>
<li>parallelCollectionScan</li>
</ul>
<p>Associated command-specific helpers SHOULD take a read preference argument and otherwise MUST use the default read
preference from client, database, or collection configuration.</p>
<p>For pre-5.0 servers, an aggregate command is "must-use-primary" if its pipeline contains a write stage (e.g.
<code>$out</code>, <code>$merge</code>); otherwise, it is "may-use-secondary". For 5.0+ servers, secondaries can execute an aggregate
command with a write stage and all aggregate commands are "may-use-secondary". This is discussed in more detail in
<a href="server-selection/../crud/crud.html#read-preferences-and-server-selection">Read preferences and server selection</a> in the CRUD spec.</p>
<p>If a client provides a specific helper for inline mapReduce, then it is "may-use-secondary" and the <em>regular</em>
mapReduce helper is "must-use-primary". Otherwise, the mapReduce helper is "may-use-secondary" and it is the user's
responsibility to specify <code>{inline: 1}</code> when running mapReduce on a secondary.</p>
</li>
</ul>
<p>New command-specific helpers implemented in the future will be considered "must-use-primary", "should-use-primary" or
"may-use-secondary" according to the specifications for those future commands. Command helper specifications SHOULD
use those terms for clarity.</p>
</li>
</ol>
<h3 id="rules-for-server-selection"><a class="header" href="#rules-for-server-selection">Rules for server selection</a></h3>
<p>Server selection is a process which takes an operation type (read or write), a ClusterDescription, and optionally a read
preference and, on success, returns a ServerDescription for an operation of the given type.</p>
<p>Server selection varies depending on whether a client is multi-threaded/asynchronous or single-threaded because a
single-threaded client cannot rely on the topology state being updated in the background.</p>
<h4 id="timeouts"><a class="header" href="#timeouts">Timeouts</a></h4>
<p>Multi-threaded drivers and single-threaded drivers with <code>serverSelectionTryOnce</code> set to false MUST enforce a timeout for
the server selection process. The timeout MUST be computed as described in
<a href="server-selection/../client-side-operations-timeout/client-side-operations-timeout.html#server-selection">Client Side Operations Timeout: Server Selection</a>.</p>
<h4 id="multi-threaded-or-asynchronous-server-selection-1"><a class="header" href="#multi-threaded-or-asynchronous-server-selection-1">Multi-threaded or asynchronous server selection</a></h4>
<p>A driver that uses multi-threaded or asynchronous monitoring MUST unblock waiting operations as soon as server selection
completes, even if not all servers have been checked by a monitor. Put differently, the client MUST NOT block server
selection while waiting for server discovery to finish.</p>
<p>For example, if the client is discovering a replica set and the application attempts a read operation with mode
'primaryPreferred', the operation MUST proceed immediately if a suitable secondary is found, rather than blocking until
the client has checked all members and possibly discovered a primary.</p>
<p>The number of threads allowed to wait for server selection SHOULD be either (a) the same as the number of threads
allowed to wait for a connection from a pool; or (b) governed by a global or client-wide limit on number of waiting
threads, depending on how resource limits are implemented by a driver.</p>
<h5 id="operationcount"><a class="header" href="#operationcount">operationCount</a></h5>
<p>Multi-threaded or async drivers MUST keep track of the number of operations that a given server is currently executing
(the server's <code>operationCount</code>). This value MUST be incremented once a server is selected for an operation and MUST be
decremented once that operation has completed, regardless of its outcome. Where this value is stored is left as a
implementation detail of the driver; some example locations include the <code>Server</code> type that also owns the connection pool
for the server (if there exists such a type in the driver's implementation) or on the pool itself. Incrementing or
decrementing a server's <code>operationCount</code> MUST NOT wake up any threads that are waiting for a topology update as part of
server selection. See
<a href="server-selection/server-selection.html#operationcount-based-selection-within-the-latency-window-multi-threaded-or-async">operationCount-based selection within the latency window (multi-threaded or async)</a>
for the rationale behind the way this value is used.</p>
<h5 id="server-selection-algorithm"><a class="header" href="#server-selection-algorithm">Server Selection Algorithm</a></h5>
<p>For multi-threaded clients, the server selection algorithm is as follows:</p>
<ol>
<li>Record the server selection start time and log a
<a href="server-selection/server-selection.html#server-selection-started-message">"Server selection started" message</a>.</li>
<li>If the topology wire version is invalid, raise an error and log a
<a href="server-selection/server-selection.html#server-selection-failed-message">"Server selection failed" message</a>.</li>
<li>Find suitable servers by topology type and operation type. If a list of deprioritized servers is provided, and the
topology is a sharded cluster, these servers should be selected only if there are no other suitable servers. The
server selection algorithm MUST ignore the deprioritized servers if the topology is not a sharded cluster.</li>
<li>Filter the suitable servers by calling the optional, application-provided server selector.</li>
<li>If there are any suitable servers, filter them according to
<a href="server-selection/server-selection.html#filtering-suitable-servers-based-on-the-latency-window">Filtering suitable servers based on the latency window</a>
and continue to the next step; otherwise, log a
<a href="server-selection/server-selection.html#waiting-for-suitable-server-to-become-available-message">"Waiting for suitable server to become available" message</a>
if one has not already been logged for this operation, and goto Step #9.</li>
<li>Choose two servers at random from the set of suitable servers in the latency window. If there is only 1 server in
the latency window, just select that server and goto Step #8.</li>
<li>Of the two randomly chosen servers, select the one with the lower <code>operationCount</code>. If both servers have the same
<code>operationCount</code>, select arbitrarily between the two of them.</li>
<li>Increment the <code>operationCount</code> of the selected server and return it. Log a
<a href="server-selection/server-selection.html#server-selection-succeeded-message">"Server selection succeeded" message</a>. Do not go onto later steps.</li>
<li>Request an immediate topology check, then block the server selection thread until the topology changes or until the
server selection timeout has elapsed</li>
<li>If server selection has timed out, raise a <a href="server-selection/server-selection.html#server-selection-errors">server selection error</a> and log a
<a href="server-selection/server-selection.html#server-selection-failed-message">"Server selection failed" message</a>.</li>
<li>Goto Step #2</li>
</ol>
<h4 id="single-threaded-server-selection-1"><a class="header" href="#single-threaded-server-selection-1">Single-threaded server selection</a></h4>
<p>Single-threaded drivers do not monitor the topology in the background. Instead, they MUST periodically update the
topology during server selection as described below.</p>
<p>When <code>serverSelectionTryOnce</code> is true, server selection timeouts have no effect; a single immediate topology check will
be done if the topology starts stale or if the first selection attempt fails.</p>
<p>When <code>serverSelectionTryOnce</code> is false, then the server selection loops until a server is successfully selected or until
the selection timeout is exceeded.</p>
<p>Therefore, for single-threaded clients, the server selection algorithm is as follows:</p>
<ol>
<li>Record the server selection start time and log a
<a href="server-selection/server-selection.html#server-selection-started-message">"Server selection started" message</a>.</li>
<li>Record the maximum time as start time plus the computed timeout</li>
<li>If the topology has not been scanned in <code>heartbeatFrequencyMS</code> milliseconds, mark the topology stale</li>
<li>If the topology is stale, proceed as follows:
<ul>
<li>record the target scan time as last scan time plus <code>minHeartBeatFrequencyMS</code></li>
<li>if <a href="server-selection/server-selection.html#serverselectiontryonce">serverSelectionTryOnce</a> is false and the target scan time would exceed the maximum
time, raise a <a href="server-selection/server-selection.html#server-selection-errors">server selection error</a> and log a
<a href="server-selection/server-selection.html#server-selection-failed-message">"Server selection failed" message</a>.</li>
<li>if the current time is less than the target scan time, sleep until the target scan time</li>
<li>do a blocking immediate topology check (which must also update the last scan time and mark the topology as no
longer stale)</li>
</ul>
</li>
<li>If the topology wire version is invalid, raise an error and log a
<a href="server-selection/server-selection.html#server-selection-failed-message">"Server selection failed" message</a>.</li>
<li>Find suitable servers by topology type and operation type. If a list of deprioritized servers is provided, and the
topology is a sharded cluster, these servers should be selected only if there are no other suitable servers. The
server selection algorithm MUST ignore the deprioritized servers if the topology is not a sharded cluster.</li>
<li>Filter the suitable servers by calling the optional, application-provided server selector.</li>
<li>If there are any suitable servers, filter them according to
<a href="server-selection/server-selection.html#filtering-suitable-servers-based-on-the-latency-window">Filtering suitable servers based on the latency window</a>
and return one at random from the filtered servers, and log a
<a href="server-selection/server-selection.html#server-selection-succeeded-message">"Server selection succeeded" message</a>.; otherwise, mark the topology stale and
continue to step #9.</li>
<li>If <a href="server-selection/server-selection.html#serverselectiontryonce">serverSelectionTryOnce</a> is true and the last scan time is newer than the selection
start time, raise a <a href="server-selection/server-selection.html#server-selection-errors">server selection error</a> and log a
<a href="server-selection/server-selection.html#server-selection-failed-message">"Server selection failed" message</a>; otherwise, log a
<a href="server-selection/server-selection.html#waiting-for-suitable-server-to-become-available-message">"Waiting for suitable server to become available" message</a>
if one has not already been logged for this operation, and goto Step #4</li>
<li>If the current time exceeds the maximum time, raise a <a href="server-selection/server-selection.html#server-selection-errors">server selection error</a> and log a
<a href="server-selection/server-selection.html#server-selection-failed-message">"Server selection failed" message</a>.</li>
<li>Goto Step #4</li>
</ol>
<p>Before using a socket to the selected server, drivers MUST check whether the socket has been used in
<a href="server-selection/server-selection.html#socketcheckintervalms">socketCheckIntervalMS</a> milliseconds. If the socket has been idle for longer, the driver MUST
update the ServerDescription for the selected server. After updating, if the server is no longer suitable, the driver
MUST repeat the server selection algorithm and select a new server.</p>
<p>Because single-threaded selection can do a blocking immediate check, the server selection timeout is not a hard
deadline. The actual maximum server selection time for any given request can vary from the timeout minus
<code>minHeartbeatFrequencyMS</code> to the timeout plus the time required for a blocking scan.</p>
<p>Single-threaded drivers MUST document that when <code>serverSelectionTryOne</code> is true, selection may take up to the time
required for a blocking scan, and when <code>serverSelectionTryOne</code> is false, selection may take up to the timeout plus the
time required for a blocking scan.</p>
<h4 id="topology-type-unknown"><a class="header" href="#topology-type-unknown">Topology type: Unknown</a></h4>
<p>When a deployment has topology type "Unknown", no servers are suitable for read or write operations.</p>
<h4 id="topology-type-single"><a class="header" href="#topology-type-single">Topology type: Single</a></h4>
<p>A deployment of topology type Single contains only a single server of any type. Topology type Single signifies a direct
connection intended to receive all read and write operations.</p>
<p>Therefore, read preference is ignored during server selection with topology type Single. The single server is always
suitable for reads if it is available. Depending on server type, the read preference is communicated to the server
differently:</p>
<ul>
<li>Type Mongos: the read preference is sent to the server using the rules for
<a href="server-selection/server-selection.html#passing-read-preference-to-mongos-and-load-balancers">Passing read preference to mongos and load balancers</a>.</li>
<li>Type Standalone: clients MUST NOT send the read preference to the server</li>
<li>For all other types, using OP_QUERY: clients MUST always set the <code>SecondaryOk</code> wire protocol flag on reads to ensure
that any server type can handle the request.</li>
<li>For all other types, using OP_MSG: If no read preference is configured by the application, or if the application read
preference is Primary, then $readPreference MUST be set to <code>{ "mode": "primaryPreferred" }</code> to ensure that any server
type can handle the request. If the application read preference is set otherwise, $readPreference MUST be set
following <a href="server-selection/server-selection.html#document-structure">Document structure</a>.</li>
</ul>
<p>The single server is always suitable for write operations if it is available.</p>
<h4 id="topology-type-loadbalanced"><a class="header" href="#topology-type-loadbalanced">Topology type: LoadBalanced</a></h4>
<p>During command construction, drivers MUST add a $readPreference field to the command when required by
<a href="server-selection/server-selection.html#passing-read-preference-to-mongos-and-load-balancers">Passing read preference to mongos and load balancers</a>; see the
<a href="server-selection/../load-balancers/load-balancers.html#server-selection">Load Balancer Specification</a> for details.</p>
<h4 id="topology-types-replicasetwithprimary-or-replicasetnoprimary"><a class="header" href="#topology-types-replicasetwithprimary-or-replicasetnoprimary">Topology types: ReplicaSetWithPrimary or ReplicaSetNoPrimary</a></h4>
<p>A deployment with topology type ReplicaSetWithPrimary or ReplicaSetNoPrimary can have a mix of server types: RSPrimary
(only in ReplicaSetWithPrimary), RSSecondary, RSArbiter, RSOther, RSGhost, Unknown or PossiblePrimary.</p>
<h5 id="read-operations"><a class="header" href="#read-operations">Read operations</a></h5>
<p>For the purpose of selecting a server for read operations, the same rules apply to both ReplicaSetWithPrimary and
ReplicaSetNoPrimary.</p>
<p>To select from the topology a server that matches the user's Read Preference:</p>
<p>If <code>mode</code> is 'primary', select the primary server.</p>
<p>If <code>mode</code> is 'secondary' or 'nearest':</p>
<blockquote>
<ol>
<li>Select all secondaries if <code>mode</code> is 'secondary', or all secondaries and the primary if <code>mode</code> is 'nearest'.</li>
<li>From these, filter out servers staler than <code>maxStalenessSeconds</code> if it is a positive number.</li>
<li>From the remaining servers, select servers matching the <code>tag_sets</code>.</li>
<li>From these, select one server within the latency window.</li>
</ol>
</blockquote>
<p>(See <a href="server-selection/server-selection.html#algorithm-for-filtering-by-staleness">algorithm for filtering by staleness</a>,
<a href="server-selection/server-selection.html#algorithm-for-filtering-by-tag_sets">algorithm for filtering by tag_sets</a>, and
<a href="server-selection/server-selection.html#filtering-suitable-servers-based-on-the-latency-window">filtering suitable servers based on the latency window</a> for
details on each step, and
<a href="server-selection/server-selection.html#why-is-maxstalenessseconds-applied-before-tag_sets">why is maxStalenessSeconds applied before tag_sets?</a>.)</p>
<p>If <code>mode</code> is 'secondaryPreferred', attempt the selection algorithm with <code>mode</code> 'secondary' and the user's
<code>maxStalenessSeconds</code> and <code>tag_sets</code>. If no server matches, select the primary.</p>
<p>If <code>mode</code> is 'primaryPreferred', select the primary if it is known, otherwise attempt the selection algorithm with
<code>mode</code> 'secondary' and the user's <code>maxStalenessSeconds</code> and <code>tag_sets</code>.</p>
<p>For all read preferences modes except 'primary', clients MUST set the <code>SecondaryOk</code> wire protocol flag (OP_QUERY) or
<code>$readPreference</code> global command argument (OP_MSG) to ensure that any suitable server can handle the request. If the
read preference mode is 'primary', clients MUST NOT set the <code>SecondaryOk</code> wire protocol flag (OP_QUERY) or
<code>$readPreference</code> global command argument (OP_MSG).</p>
<h5 id="write-operations"><a class="header" href="#write-operations">Write operations</a></h5>
<p>If the topology type is ReplicaSetWithPrimary, only an available primary is suitable for write operations.</p>
<p>If the topology type is ReplicaSetNoPrimary, no servers are suitable for write operations.</p>
<h4 id="topology-type-sharded"><a class="header" href="#topology-type-sharded">Topology type: Sharded</a></h4>
<p>A deployment of topology type Sharded contains one or more servers of type Mongos or Unknown.</p>
<p>For read operations, all servers of type Mongos are suitable; the <code>mode</code>, <code>tag_sets</code>, and <code>maxStalenessSeconds</code> read
preference parameters are ignored for selecting a server, but are passed through to mongos. See
<a href="server-selection/server-selection.html#passing-read-preference-to-mongos-and-load-balancers">Passing read preference to mongos and load balancers</a>.</p>
<p>For write operations, all servers of type Mongos are suitable.</p>
<p>If more than one mongos is suitable, drivers MUST select a suitable server within the latency window (see
<a href="server-selection/server-selection.html#filtering-suitable-servers-based-on-the-latency-window">Filtering suitable servers based on the latency window</a>).</p>
<h3 id="round-trip-times-and-the-latency-window"><a class="header" href="#round-trip-times-and-the-latency-window">Round Trip Times and the Latency Window</a></h3>
<h4 id="calculation-of-average-round-trip-times"><a class="header" href="#calculation-of-average-round-trip-times">Calculation of Average Round Trip Times</a></h4>
<p>For every available server, clients MUST track the average RTT of server monitoring <code>hello</code> or legacy hello commands.</p>
<p>An Unknown server has no average RTT. When a server becomes unavailable, its average RTT MUST be cleared. Clients MAY
implement this idiomatically (e.g nil, -1, etc.).</p>
<p>When there is no average RTT for a server, the average RTT MUST be set equal to the first RTT measurement (i.e. the
first <code>hello</code> or legacy hello command after the server becomes available).</p>
<p>After the first measurement, average RTT MUST be computed using an exponentially-weighted moving average formula, with a
weighting factor (<code>alpha</code>) of 0.2. If the prior average is denoted <code>old_rtt</code>, then the new average (<code>new_rtt</code>) is
computed from a new RTT measurement (<code>x</code>) using the following formula:</p>
<pre><code class="language-javascript">    alpha = 0.2
    new_rtt = alpha * x + (1 - alpha) * old_rtt
</code></pre>
<p>A weighting factor of 0.2 was chosen to put about 85% of the weight of the average RTT on the 9 most recent
observations.</p>
<h4 id="filtering-suitable-servers-based-on-the-latency-window"><a class="header" href="#filtering-suitable-servers-based-on-the-latency-window">Filtering suitable servers based on the latency window</a></h4>
<p>Server selection results in a set of zero or more suitable servers. If more than one server is suitable, a server MUST
be selected from among those within the latency window.</p>
<p>The <code>localThresholdMS</code> configuration parameter controls the size of the latency window used to select a suitable server.</p>
<p>The shortest average round trip time (RTT) from among suitable servers anchors one end of the latency window (<code>A</code>). The
other end is determined by adding <code>localThresholdMS</code> (<code>B = A + localThresholdMS</code>).</p>
<p>A server MUST be selected from among suitable servers that have an average RTT (<code>RTT</code>) within the latency window (i.e.
<code>A ≤ RTT ≤ B</code>). In other words, the suitable server with the shortest average RTT is <strong>always</strong> a possible choice. Other
servers could be chosen if their average RTTs are no more than <code>localThresholdMS</code> more than the shortest average RTT.</p>
<p>See either <a href="server-selection/server-selection.html#single-threaded-server-selection">Single-threaded server selection</a> or
<a href="server-selection/server-selection.html#multi-threaded-or-asynchronous-server-selection">Multi-threaded or asynchronous server selection</a> for information on
how to select a server from among those within the latency window.</p>
<h3 id="checking-an-idle-socket-after-socketcheckintervalms"><a class="header" href="#checking-an-idle-socket-after-socketcheckintervalms">Checking an Idle Socket After socketCheckIntervalMS</a></h3>
<p>Only for single-threaded drivers.</p>
<p>If a server is selected that has an existing connection that has been idle for socketCheckIntervalMS, the driver MUST
check the connection with the "ping" command. If the ping succeeds, use the selected connection. If not, set the
server's type to Unknown and update the Topology Description according to the Server Discovery and Monitoring Spec, and
attempt <strong>once</strong> more to select a server.</p>
<p>The logic is expressed in this pseudocode. The algorithm for the "getServer" function is suggested below, in
<a href="server-selection/server-selection.html#single-threaded-server-selection-implementation">Single-threaded server selection implementation</a>:</p>
<pre><code class="language-python">    def getConnection(criteria):
        # Get a server for writes, or a server matching read prefs, by
        # running the server selection algorithm.
        server = getServer(criteria)
        if not server:
            throw server selection error

        connection = server.connection
        if connection is NULL:
            # connect to server and return connection
        else if connection has been idle &lt; socketCheckIntervalMS:
            return connection
        else:
            try:
                use connection for "ping" command
                return connection
            except network error:
                close connection
                mark server Unknown and update Topology Description

                # Attempt *once* more to select.
                server = getServer(criteria)
                if not server:
                    throw server selection error

                # connect to server and return connection
</code></pre>
<p>See <a href="server-selection/server-selection.html#what-is-the-purpose-of-socketcheckintervalms">What is the purpose of socketCheckIntervalMS?</a>.</p>
<h3 id="requests-and-pinning-deprecated"><a class="header" href="#requests-and-pinning-deprecated">Requests and Pinning Deprecated</a></h3>
<p>The prior read preference specification included the concept of a "request", which pinned a server to a thread for
subsequent, related reads. Requests and pinning are now <strong>deprecated</strong>. See
<a href="server-selection/server-selection.html#what-happened-to-pinning">What happened to pinning?</a> for the rationale for this change.</p>
<p>Drivers with an existing request API MAY continue to provide it for backwards compatibility, but MUST document that
pinning for the request does not guarantee monotonic reads.</p>
<p>Drivers MUST NOT automatically pin the client or a thread to a particular server without an explicit <code>start_request</code> (or
comparable) method call.</p>
<p>Outside a legacy "request" API, drivers MUST use server selection for each individual read operation.</p>
<h3 id="logging"><a class="header" href="#logging">Logging</a></h3>
<p>Please refer to the <a href="server-selection/../logging/logging.html">logging specification</a> for details on logging implementations in general,
including log levels, log components, and structured versus unstructured logging.</p>
<p>Drivers MUST support logging of server selection information via the following log messages. These messages MUST use the
<code>serverSelection</code> log component.</p>
<p>The types used in the structured message definitions below are demonstrative, and drivers MAY use similar types instead
so long as the information is present (e.g. a double instead of an integer, or a string instead of an integer if the
structured logging framework does not support numeric types.)</p>
<h4 id="common-fields-1"><a class="header" href="#common-fields-1">Common Fields</a></h4>
<p>The following key-value pairs MUST be included in all server selection log messages:</p>
<div class="table-wrapper"><table><thead><tr><th>Key</th><th>Suggested Type</th><th>Value</th></tr></thead><tbody>
<tr><td>selector</td><td>String</td><td>String representation of the selector being used to select the server. This can be a read preference or an application-provided custom selector. The exact content of is flexible depending on what the driver is able to log. At minimum, when the selector is a read preference this string MUST contain all components of the read preference, and when it is an application-provided custom selector the string MUST somehow indicate that it is a custom selector.</td></tr>
<tr><td>operationId</td><td>Int</td><td>The driver-generated operation ID. Optional; only present if the driver generates operation IDs and this command has one.</td></tr>
<tr><td>operation</td><td>String</td><td>The name of the operation for which a server is being selected. When server selection is being performed to select a server for a command, this MUST be the command name.</td></tr>
<tr><td>topologyDescription</td><td>String</td><td>String representation of the current topology description. The format of is flexible and could be e.g. the <code>toString()</code> implementation for a driver's topology type, or an extended JSON representation of the topology object.</td></tr>
</tbody></table>
</div>
<h4 id="server-selection-started-message"><a class="header" href="#server-selection-started-message">"Server selection started" message</a></h4>
<p>This message MUST be logged at <code>debug</code> level. It MUST be emitted on the occasions specified either in
<a href="server-selection/server-selection.html#multi-threaded-or-asynchronous-server-selection">Multi-threaded or asynchronous server selection</a> or
<a href="server-selection/server-selection.html#single-threaded-server-selection">Single-threaded server selection</a>, depending on which algorithm the driver
implements.</p>
<p>This message MUST contain the following key-value pairs:</p>
<div class="table-wrapper"><table><thead><tr><th>Key</th><th>Suggested Type</th><th>Value</th></tr></thead><tbody>
<tr><td>message</td><td>String</td><td>"Server selection started"</td></tr>
</tbody></table>
</div>
<p>The unstructured form SHOULD be as follows, using the values defined in the structured format above to fill in
placeholders as appropriate:</p>
<blockquote>
<p>Server selection started for operation {{operation}} with ID {{operationId}}. Selector: {{selector}}, topology
description: {{topologyDescription}}</p>
</blockquote>
<h4 id="server-selection-succeeded-message"><a class="header" href="#server-selection-succeeded-message">"Server selection succeeded" message</a></h4>
<p>This message MUST be logged at <code>debug</code> level. It MUST be emitted on the occasions specified either in
<a href="server-selection/server-selection.html#multi-threaded-or-asynchronous-server-selection">Multi-threaded or asynchronous server selection</a> or
<a href="server-selection/server-selection.html#single-threaded-server-selection">Single-threaded server selection</a>, depending on which algorithm the driver
implements.</p>
<p>This message MUST contain the following key-value pairs:</p>
<div class="table-wrapper"><table><thead><tr><th>Key</th><th>Suggested Type</th><th>Value</th></tr></thead><tbody>
<tr><td>message</td><td>String</td><td>"Server selection succeeded"</td></tr>
<tr><td>serverHost</td><td>String</td><td>The hostname, IP address, or Unix domain socket path for the selected server.</td></tr>
<tr><td>serverPort</td><td>Int</td><td>The port for the selected server. Optional; not present for Unix domain sockets. When the user does not specify a port and the default (27017) is used, the driver SHOULD include it here.</td></tr>
</tbody></table>
</div>
<p>The unstructured form SHOULD be as follows, using the values defined in the structured format above to fill in
placeholders as appropriate:</p>
<blockquote>
<p>Server selection succeeded for operation {{operation}} with ID {{operationId}}. Selected server:
{{serverHost}}:{{serverPort}}. Selector: {{selector}}, topology description: {{topologyDescription}}</p>
</blockquote>
<h4 id="server-selection-failed-message"><a class="header" href="#server-selection-failed-message">"Server selection failed" message</a></h4>
<p>This message MUST be logged at <code>debug</code> level. It MUST be emitted on the occasions specified either in
<a href="server-selection/server-selection.html#multi-threaded-or-asynchronous-server-selection">Multi-threaded or asynchronous server selection</a> or
<a href="server-selection/server-selection.html#single-threaded-server-selection">Single-threaded server selection</a>, depending on which algorithm the driver
implements.</p>
<p>This message MUST contain the following key-value pairs:</p>
<div class="table-wrapper"><table><thead><tr><th>Key</th><th>Suggested Type</th><th>Value</th></tr></thead><tbody>
<tr><td>message</td><td>String</td><td>"Server selection failed"</td></tr>
<tr><td>failure</td><td>Flexible</td><td>Representation of the error the driver will throw regarding server selection failing. The type and format of this value is flexible; see the <a href="server-selection/../logging/logging.html#representing-errors-in-log-messages">logging specification</a> for details on representing errors in log messages. Drivers MUST take care to not include any information in this field that is already included in the log message; e.g. the topology description should not be duplicated within this field.</td></tr>
</tbody></table>
</div>
<p>The unstructured form SHOULD be as follows, using the values defined in the structured format above to fill in
placeholders as appropriate:</p>
<blockquote>
<p>Server selection failed for operation {{operationName}} with ID {{operationId}}. Failure: {{failure}}. Selector:
{{selector}}, topology description: {{topologyDescription}}</p>
</blockquote>
<h4 id="waiting-for-suitable-server-to-become-available-message"><a class="header" href="#waiting-for-suitable-server-to-become-available-message">"Waiting for suitable server to become available" message</a></h4>
<p>This message MUST be logged at <code>info</code> level. It MUST be emitted on the occasions specified either in
<a href="server-selection/server-selection.html#multi-threaded-or-asynchronous-server-selection">Multi-threaded or asynchronous server selection</a> or
<a href="server-selection/server-selection.html#single-threaded-server-selection">Single-threaded server selection</a>, depending on which algorithm the driver
implements.</p>
<p>In order to avoid generating redundant log messages, the driver MUST take care to only emit this message once per
operation. We only log the message once because the only values that can change over time are:</p>
<ul>
<li>The remaining time: given the initial message's timestamp and the initial timestamp, the time remaining can always be
inferred from the original message.</li>
<li>The topology description: rather than logging these changes on a per-operation basis, users should observe them with a
single set of messages for the entire client via SDAM log messages.</li>
</ul>
<p>This message MUST contain the following key-value pairs:</p>
<div class="table-wrapper"><table><thead><tr><th>Key</th><th>Suggested Type</th><th>Value</th></tr></thead><tbody>
<tr><td>message</td><td>String</td><td>"Waiting for suitable server to become available"</td></tr>
<tr><td>remainingTimeMS</td><td>Int</td><td>The remaining time left until server selection will time out. This MAY be omitted if the driver supports disabling server selection timeout altogether.</td></tr>
</tbody></table>
</div>
<p>The unstructured form SHOULD be as follows, using the values defined in the structured format above to fill in
placeholders as appropriate:</p>
<blockquote>
<p>Waiting for server to become available for operation {{operationName}} with ID {{operationId}}. Remaining time:
{{remainingTimeMS}} ms. Selector: {{selector}}, topology description: {{topologyDescription}}.</p>
</blockquote>
<h2 id="implementation-notes-4"><a class="header" href="#implementation-notes-4">Implementation Notes</a></h2>
<p>These are suggestions. As always, driver authors should balance cross-language standardization with backwards
compatibility and the idioms of their language.</p>
<h3 id="modes"><a class="header" href="#modes">Modes</a></h3>
<p>Modes ('primary', 'secondary', ...) are constants declared in whatever way is idiomatic for the programming language.
The constant values may be ints, strings, or whatever. However, when attaching modes to <code>$readPreference</code> camel case
must be used as described above in
<a href="server-selection/server-selection.html#passing-read-preference-to-mongos-and-load-balancers">Passing read preference to mongos and load balancers</a>.</p>
<h4 id="primarypreferred-and-secondarypreferred"><a class="header" href="#primarypreferred-and-secondarypreferred">primaryPreferred and secondaryPreferred</a></h4>
<p>'primaryPreferred' is equivalent to selecting a server with read preference mode 'primary' (without <code>tag_sets</code> or
<code>maxStalenessSeconds</code>), or, if that fails, falling back to selecting with read preference mode 'secondary' (with
<code>tag_sets</code> and <code>maxStalenessSeconds</code>, if provided).</p>
<p>'secondaryPreferred' is the inverse: selecting with mode 'secondary' (with <code>tag_sets</code> and <code>maxStalenessSeconds</code>) and
falling back to selecting with mode 'primary' (without <code>tag_sets</code> or <code>maxStalenessSeconds</code>).</p>
<p>Depending on the implementation, this may result in cleaner code.</p>
<h4 id="nearest"><a class="header" href="#nearest">nearest</a></h4>
<p>The term 'nearest' is unfortunate, as it implies a choice based on geographic locality or absolute lowest latency,
neither of which are true.</p>
<p>Instead, and unlike the other read preference modes, 'nearest' does not favor either primaries or secondaries; instead
all servers are candidates and are filtered by <code>tag_sets</code> and <code>maxStalenessSeconds</code>.</p>
<p>To always select the server with the lowest RTT, users should use mode 'nearest' without <code>tag_sets</code> or
<code>maxStalenessSeconds</code> and set <code>localThresholdMS</code> to zero.</p>
<p>To distribute reads across all members evenly regardless of RTT, users should use mode 'nearest' without <code>tag_sets</code> or
<code>maxStalenessSeconds</code> and set <code>localThresholdMS</code> very high so that all servers fall within the latency window.</p>
<p>In both cases, <code>tag_sets</code> and <code>maxStalenessSeconds</code> could be used to further restrict the set of eligible servers, if
desired.</p>
<h3 id="tag-set-lists"><a class="header" href="#tag-set-lists">Tag set lists</a></h3>
<p>Tag set lists can be configured in the driver in whatever way is natural for the language.</p>
<h3 id="multi-threaded-server-selection-implementation"><a class="header" href="#multi-threaded-server-selection-implementation">Multi-threaded server selection implementation</a></h3>
<p>The following example uses a single lock for clarity. Drivers are free to implement whatever concurrency model best
suits their design.</p>
<p>The following is pseudocode for
<a href="server-selection/server-selection.html#multi-threaded-or-asynchronous-server-selection">multi-threaded or asynchronous server selection</a>:</p>
<pre><code class="language-python">    def getServer(criteria):
        client.lock.acquire()

        now = gettime()
        endTime = now + computed server selection timeout

        log a "server selection started" message
        while true:
            # The topologyDescription keeps track of whether any server has an
            # an invalid wire version range
            if not topologyDescription.compatible:
                client.lock.release()
                log a "server selection failed" message
                throw invalid wire protocol range error with details

            if maxStalenessSeconds is set:
                if client minWireVersion &lt; 5 and "&lt;any available server's maxWireVersion &lt; 5"&gt;:
                    client.lock.release()
                    throw error

                if topologyDescription.type in (ReplicaSetWithPrimary, ReplicaSetNoPrimary):
                    if (maxStalenessSeconds * 1000 &lt; heartbeatFrequencyMS + idleWritePeriodMS or
                        maxStalenessSeconds &lt; smallestMaxStalenessSeconds):
                    client.lock.release()
                    throw error

            servers = all servers in topologyDescription matching criteria

            if serverSelector is not null:
                servers = serverSelector(servers)

            if servers is not empty:
                in_window = servers within the latency window
                if len(in_window) == 1:
                    selected = in_window[0]
                else:
                    server1, server2 = random two entries from in_window
                    if server1.operation_count &lt;= server2.operation_count:
                        selected = server1
                    else:
                        selected = server2
                selected.operation_count += 1
                client.lock.release()
                return selected

            request that all monitors check immediately
            if the message was not logged already for this operation: 
                log a "waiting for suitable server to become available" message

            # Wait for a new TopologyDescription. condition.wait() releases
            # client.lock while waiting and reacquires it before returning.
            # While a thread is waiting on client.condition, it is awakened
            # early whenever a server check completes.
            timeout_left = endTime - gettime()
            client.condition.wait(timeout_left)

            if now after endTime:
                client.lock.release()
                throw server selection error
</code></pre>
<h3 id="single-threaded-server-selection-implementation"><a class="header" href="#single-threaded-server-selection-implementation">Single-threaded server selection implementation</a></h3>
<p>The following is pseudocode for <a href="server-selection/server-selection.html#single-threaded-server-selection">single-threaded server selection</a>:</p>
<pre><code class="language-python">    def getServer(criteria):
        startTime = gettime()
        loopEndTime = startTime
        maxTime = startTime + computed server selection timeout
        nextUpdateTime = topologyDescription.lastUpdateTime
                       + heartbeatFrequencyMS/1000:

        if nextUpdateTime &lt; startTime:
            topologyDescription.stale = true

        while true:

            if topologyDescription.stale:
                scanReadyTime = topologyDescription.lastUpdateTime
                              + minHeartbeatFrequencyMS/1000

                if ((not serverSelectionTryOnce) &amp;&amp; (scanReadyTime &gt; maxTime)):
                    throw server selection error with details

                # using loopEndTime below is a proxy for "now" but avoids
                # the overhead of another gettime() call
                sleepTime = scanReadyTime - loopEndTime

                if sleepTime &gt; 0:
                    sleep sleepTime

                rescan all servers
                topologyDescription.lastupdateTime = gettime()
                topologyDescription.stale = false

            # topologyDescription keeps a record of whether any
            # server has an incompatible wire version range
            if not topologyDescription.compatible:
                topologyDescription.stale = true
                # throw invalid wire version range error with details

            if maxStalenessSeconds is set:
                if client minWireVersion &lt; 5 and "&lt;any available server's maxWireVersion &lt; 5&gt;":
                    # throw error

                if topologyDescription.type in (ReplicaSetWithPrimary, ReplicaSetNoPrimary):
                    if (maxStalenessSeconds * 1000 &lt; heartbeatFrequencyMS + idleWritePeriodMS or
                        maxStalenessSeconds &lt; smallestMaxStalenessSeconds):
                    # throw error

            servers = all servers in topologyDescription matching criteria

            if serverSelector is not null:
                servers = serverSelector(servers)

            if servers is not empty:
                in_window = servers within the latency window
                return random entry from in_window
            else:
                topologyDescription.stale = true

            loopEndTime = gettime()

            if serverSelectionTryOnce:
                if topologyDescription.lastUpdateTime &gt; startTime:
                    throw server selection error with details
            else if loopEndTime &gt; maxTime:
                throw server selection error with details

            if the message was not logged already: 
                log a "waiting for suitable server to become available" message
</code></pre>
<h3 id="server-selection-errors"><a class="header" href="#server-selection-errors">Server Selection Errors</a></h3>
<p>Drivers should use server descriptions and their error attributes (if set) to return useful error messages.</p>
<p>For example, when there are no members matching the ReadPreference:</p>
<ul>
<li>"No server available for query with ReadPreference primary"</li>
<li>"No server available for query with ReadPreference secondary"</li>
<li>"No server available for query with ReadPreference " + mode + ", tag set list " + tag_sets + ", and
<code>maxStalenessSeconds</code> " + maxStalenessSeconds</li>
</ul>
<p>Or, if authentication failed:</p>
<ul>
<li>"Authentication failed: <code>[specific error message]</code>"</li>
</ul>
<p>Here is a sketch of some pseudocode for handling error reporting when errors could be different across servers:</p>
<pre><code class="language-python">    if there are any available servers:
        error_message = "No servers are suitable for " + criteria
    else if all ServerDescriptions' errors are the same:
        error_message = a ServerDescription.error value
    else:
        error_message = ', '.join(all ServerDescriptions' errors)
</code></pre>
<h3 id="cursors"><a class="header" href="#cursors">Cursors</a></h3>
<p>Cursor operations OP_GET_MORE and OP_KILL_CURSOR do not go through the server selection process. Cursor operations must
be sent to the original server that received the query and sent the OP_REPLY. For exhaust cursors, the same socket must
be used for OP_GET_MORE until the cursor is exhausted.</p>
<h3 id="sharded-transactions"><a class="header" href="#sharded-transactions">Sharded Transactions</a></h3>
<p>Operations that are part of a sharded transaction (after the initial command) do not go through the server selection
process. Sharded transaction operations MUST be sent to the original mongos server on which the transaction was started.</p>
<h3 id="the-text-command-and-mongos"><a class="header" href="#the-text-command-and-mongos">The 'text' command and mongos</a></h3>
<p><em>Note</em>: As of MongoDB 2.6, mongos doesn't distribute the "text" command to secondaries, see
<a href="https://jira.mongodb.org/browse/SERVER-10947">SERVER-10947</a>.</p>
<p>However, the "text" command is deprecated in 2.6, so this command-specific helper may become deprecated before this is
fixed.</p>
<h2 id="test-plan-13"><a class="header" href="#test-plan-13">Test Plan</a></h2>
<p>The server selection test plan is given in a separate document that describes the tests and supporting data files:
<a href="server-selection/./server-selection-tests.html">Server Selection Tests</a></p>
<h2 id="design-rationale-12"><a class="header" href="#design-rationale-12">Design Rationale</a></h2>
<h3 id="use-of-topology-types"><a class="header" href="#use-of-topology-types">Use of topology types</a></h3>
<p>The prior version of the read preference spec had only a loose definition of server or topology types. The
<a href="server-selection/../server-discovery-and-monitoring/server-discovery-and-monitoring.html">Server Discovery and Monitoring</a> spec defines
these terms explicitly and they are used here for consistency and clarity.</p>
<h3 id="consistency-with-mongos"><a class="header" href="#consistency-with-mongos">Consistency with mongos</a></h3>
<p>In order to ensure that behavior is consistent regardless of topology type, read preference behaviors are limited to
those that mongos can proxy.</p>
<p>For example, mongos ignores read preference 'secondary' when a shard consists of a single server. Therefore, this spec
calls for topology type Single to ignore read preferences for consistency.</p>
<p>The spec has been written with the intention that it can apply to both drivers and mongos and the term "client" has been
used when behaviors should apply to both. Behaviors that are specific to drivers are largely limited to those for
communicating with a mongos.</p>
<h3 id="new-localthresholdms-configuration-option-name"><a class="header" href="#new-localthresholdms-configuration-option-name">New localThresholdMS configuration option name</a></h3>
<p>Because this does not apply <strong>only</strong> to secondaries and does not limit absolute latency, the name
<code>secondaryAcceptableLatencyMS</code> is misleading.</p>
<p>The mongos name <code>localThreshold</code> misleads because it has nothing to do with locality. It also doesn't include the <code>MS</code>
units suffix for consistency with other time-related configuration options.</p>
<p>However, given a choice between the two, <code>localThreshold</code> is a more general term. For drivers, we add the <code>MS</code> suffix
for clarity about units and consistency with other configuration options.</p>
<h3 id="random-selection-within-the-latency-window-single-threaded"><a class="header" href="#random-selection-within-the-latency-window-single-threaded">Random selection within the latency window (single-threaded)</a></h3>
<p>When more than one server is judged to be suitable, the spec calls for random selection to ensure a fair distribution of
work among servers within the latency window.</p>
<p>It would be hard to ensure a fair round-robin approach given the potential for servers to come and go. Making newly
available servers either first or last could lead to unbalanced work. Random selection has a better fairness guarantee
and keeps the design simpler.</p>
<h3 id="operationcount-based-selection-within-the-latency-window-multi-threaded-or-async"><a class="header" href="#operationcount-based-selection-within-the-latency-window-multi-threaded-or-async">operationCount-based selection within the latency window (multi-threaded or async)</a></h3>
<p>As operation execution slows down on a node (e.g. due to degraded server-side performance or increased network latency),
checked-out pooled connections to that node will begin to remain checked out for longer periods of time. Assuming at
least constant incoming operation load, more connections will then need to be opened against the node to service new
operations that it gets selected for, further straining it and slowing it down. This can lead to runaway connection
creation scenarios that can cripple a deployment ("connection storms"). As part of DRIVERS-781, the random choice
portion of multi-threaded server selection was changed to more evenly spread out the workload among suitable servers in
order to prevent any single node from being overloaded. The new steps achieve this by approximating an individual
server's load via the number of concurrent operations that node is processing (operationCount) and then routing
operations to servers with less load. This should reduce the number of new operations routed towards nodes that are
busier and thus increase the number routed towards nodes that are servicing operations faster or are simply less busy.
The previous random selection mechanism did not take load into account and could assign work to nodes that were under
too much stress already.</p>
<p>As an added benefit, the new approach gives preference to nodes that have recently been discovered and are thus are more
likely to be alive (e.g. during a rolling restart). The narrowing to two random choices first ensures new servers aren't
overly preferred however, preventing a "thundering herd" situation. Additionally, the
<a href="server-selection/../connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection-pool">maxConnecting</a> provisions
included in the CMAP specification prevent drivers from crippling new nodes with connection storms.</p>
<p>This approach is based on the
<a href="https://web.archive.org/web/20191212194243/https://www.nginx.com/blog/nginx-power-of-two-choices-load-balancing-algorithm/">"Power of Two Random Choices with Least Connections"</a>
load balancing algorithm.</p>
<p>An alternative approach to this would be to prefer selecting servers that already have available connections. While that
approach could help reduce latency, it does not achieve the benefits of routing operations away from slow servers or of
preferring newly introduced servers. Additionally, that approach could lead to the same node being selected repeatedly
rather than spreading the load out among all suitable servers.</p>
<h3 id="the-secondaryok-wire-protocol-flag"><a class="header" href="#the-secondaryok-wire-protocol-flag">The SecondaryOk wire protocol flag</a></h3>
<p>In server selection, there is a race condition that could exist between what a selected server type is believed to be
and what it actually is.</p>
<p>The <code>SecondaryOk</code> wire protocol flag solves the race problem by communicating to the server whether a secondary is
acceptable. The server knows its type and can return a "not writable primary" error if <code>SecondaryOk</code> is false and the
server is a secondary.</p>
<p>However, because topology type Single is used for direct connections, we want read operations to succeed even against a
secondary, so the <code>SecondaryOk</code> wire protocol flag must be sent to mongods with topology type Single.</p>
<p>(If the server type is Mongos, follow the rules for
<a href="server-selection/server-selection.html#passing-read-preference-to-mongos-and-load-balancers">Passing read preference to mongos and load balancers</a>, even for
topology type Single.)</p>
<h3 id="general-command-method-going-to-primary"><a class="header" href="#general-command-method-going-to-primary">General command method going to primary</a></h3>
<p>The list of commands that can go to secondaries changes over time and depends not just on the command but on parameters.
For example, the <code>mapReduce</code> command may or may not be able to be run on secondaries depending on the value of the <code>out</code>
parameter.</p>
<p>It significantly simplifies implementation for the general command method always to go to the primary unless a explicit
read preference is set and rely on users of the general command method to provide a read preference appropriate to the
command.</p>
<p>The command-specific helpers will need to implement a check of read preferences against the semantics of the command and
its parameters, but keeping this logic close to the command rather than in a generic method is a better design than
either delegating this check to the generic method, duplicating the logic in the generic method, or coupling both to
another validation method.</p>
<h3 id="average-round-trip-time-calculation"><a class="header" href="#average-round-trip-time-calculation">Average round trip time calculation</a></h3>
<p>Using an exponentially-weighted moving average avoids having to store and rotate an arbitrary number of RTT
observations. All observations count towards the average. The weighting makes recent observations count more heavily
while smoothing volatility.</p>
<h3 id="verbose-errors"><a class="header" href="#verbose-errors">Verbose errors</a></h3>
<p>Error messages should be sufficiently verbose to allow users and/or support engineers to determine the reasons for
server selection failures from log or other error messages.</p>
<h3 id="try-once-mode"><a class="header" href="#try-once-mode">"Try once" mode</a></h3>
<p>Single-threaded drivers in languages like PHP and Perl are typically deployed as many processes per application server.
Each process must independently discover and monitor the MongoDB deployment.</p>
<p>When no suitable server is available (due to a partition or misconfiguration), it is better for each request to fail as
soon as its process detects a problem, instead of waiting and retrying to see if the deployment recovers.</p>
<p>Minimizing response latency is important for maximizing request-handling capacity and for user experience (e.g. a quick
fail message instead of a slow web page).</p>
<p>However, when a request arrives and the topology information is already stale, or no suitable server is known, making a
single attempt to update the topology to service the request is acceptable.</p>
<p>A user of a single-threaded driver who prefers resilience in the face of topology problems, rather than short response
times, can turn the "try once" mode off. Then driver rescans the topology every minHeartbeatFrequencyMS until a suitable
server is found or the timeout expires.</p>
<h3 id="what-is-the-purpose-of-socketcheckintervalms"><a class="header" href="#what-is-the-purpose-of-socketcheckintervalms">What is the purpose of socketCheckIntervalMS?</a></h3>
<p>Single-threaded clients need to make a compromise: if they check servers too frequently it slows down regular
operations, but if they check too rarely they cannot proactively avoid errors.</p>
<p>Errors are more disruptive for single-threaded clients than for multi-threaded. If one thread in a multi-threaded
process encounters an error, it warns the other threads not to use the disconnected server. But single-threaded clients
are deployed as many independent processes per application server, and each process must throw an error until all have
discovered that a server is down.</p>
<p>The compromise specified here balances the cost of frequent checks against the disruption of many errors. The client
preemptively checks individual sockets that have not been used in the last
<a href="server-selection/server-selection.html#socketcheckintervalms">socketCheckIntervalMS</a>, which is more frequent by default than <code>heartbeatFrequencyMS</code> defined
in the Server Discovery and Monitoring Spec.</p>
<p>The client checks the socket with a "ping" command, rather than "hello" or legacy hello, because it is not checking the
server's full state as in the Server Discovery and Monitoring Spec, it is only verifying that the connection is still
open. We might also consider a <code>select</code> or <code>poll</code> call to check if the socket layer considers the socket closed, without
requiring a round-trip to the server. However, this technique usually will not detect an uncleanly shutdown server or a
network outage.</p>
<h2 id="backwards-compatibility-11"><a class="header" href="#backwards-compatibility-11">Backwards Compatibility</a></h2>
<p>In general, backwards breaking changes have been made in the name of consistency with mongos and avoiding misleading
users about monotonicity.</p>
<ul>
<li>
<p>Features removed:</p>
<blockquote>
<ul>
<li>Automatic pinning (see <a href="server-selection/server-selection.html#what-happened-to-pinning">What happened to pinning?</a>)</li>
<li>Auto retry (replaced by the general server selection algorithm)</li>
<li>mongos "high availability" mode (effectively, mongos pinning)</li>
</ul>
</blockquote>
</li>
<li>
<p>Other features and behaviors have changed explicitly</p>
<blockquote>
<ul>
<li>Ignoring read preferences for topology type Single</li>
<li>Default read preference for the generic command method</li>
</ul>
</blockquote>
</li>
<li>
<p>Changes with grandfather clauses</p>
<blockquote>
<ul>
<li>Alternate names for <code>localThresholdMS</code></li>
<li>Pinning for legacy request APIs</li>
</ul>
</blockquote>
</li>
<li>
<p>Internal changes with little user-visibility</p>
<blockquote>
<ul>
<li>Clarifying calculation of average RTT</li>
</ul>
</blockquote>
</li>
</ul>
<h2 id="questions-and-answers-1"><a class="header" href="#questions-and-answers-1">Questions and Answers</a></h2>
<h3 id="what-happened-to-pinning"><a class="header" href="#what-happened-to-pinning">What happened to pinning?</a></h3>
<p>The prior read preference spec, which was implemented in the versions of the drivers and mongos released concomitantly
with MongoDB 2.2, stated that a thread / client should remain pinned to an RS member as long as that member matched the
current mode, tags, and acceptable latency. This increased the odds that reads would be monotonic (assuming no
rollback), but had the following surprising consequence:</p>
<ol>
<li>Thread / client reads with mode 'secondary' or 'secondaryPreferred', gets pinned to a secondary</li>
<li>Thread / client reads with mode 'primaryPreferred', driver / mongos sees that the pinned member (a secondary) matches
the mode (which <em>allows</em> for a secondary) and reads from secondary, even though the primary is available and
preferable</li>
</ol>
<p>The old spec also had the swapped problem, reading from the primary with 'secondaryPreferred', except for mongos which
was changed at the last minute before release with <a href="https://jira.mongodb.org/browse/SERVER-6565">SERVER-6565</a>.</p>
<p>This left application developers with two problems:</p>
<ol>
<li>'primaryPreferred' and 'secondaryPreferred' acted surprisingly and unpredictably within requests</li>
<li>There was no way to specify a common need: read from a secondary if possible with 'secondaryPreferred', then from
primary if possible with 'primaryPreferred', all within a request. Instead an application developer would have to do
the second read with 'primary', which would unpin the thread but risk unavailability if only secondaries were up.</li>
</ol>
<p>Additionally, mongos 2.4 introduced the releaseConnectionsAfterResponse option (RCAR), mongos 2.6 made it the default
and mongos 2.8 will remove the ability to turn it off. This means that pinning to a mongos offers no guarantee that
connections to shards are pinned. Since we can't provide the same guarantees for replica sets and sharded clusters, we
removed automatic pinning entirely and deprecated "requests". See
<a href="https://jira.mongodb.org/browse/SERVER-11956">SERVER-11956</a> and
<a href="https://jira.mongodb.org/browse/SERVER-12273">SERVER-12273</a>.</p>
<p>Regardless, even for replica sets, pinning offers no monotonicity because of the ever-present possibility of rollbacks.
Through MongoDB 2.6, secondaries did not close sockets on rollback, so a rollback could happen between any two queries
without any indication to the driver.</p>
<p>Therefore, an inconsistent feature that doesn't actually do what people think it does has no place in the spec and has
been removed. Should the server eventually implement some form of "sessions", this spec will need to be revised
accordingly.</p>
<h3 id="why-change-from-mongos-high-availability-ha-to-random-selection"><a class="header" href="#why-change-from-mongos-high-availability-ha-to-random-selection">Why change from mongos High Availability (HA) to random selection?</a></h3>
<p>Mongos HA has similar problems with pinning, in that one can wind up pinned to a high-latency mongos even if a
lower-latency mongos later becomes available.</p>
<p>Selection within the latency window avoids this problem and makes server selection exactly analogous to having multiple
suitable servers from a replica set. This is easier to explain and implement.</p>
<h3 id="what-happened-to-auto-retry"><a class="header" href="#what-happened-to-auto-retry">What happened to auto-retry?</a></h3>
<p>The old auto-retry mechanism was closely connected to server pinning, which has been removed. It also mandated exactly
three attempts to carry out a query on different servers, with no way to disable or adjust that value, and only for the
first query within a request.</p>
<p>To the extent that auto-retry was trying to compensate for unavailable servers, the Server Discovery and Monitoring spec
and new server selection algorithm provide a more robust and configurable way to direct <em>all</em> queries to available
servers.</p>
<p>After a server is selected, several error conditions could still occur that make the selected server unsuitable for
sending the operation, such as:</p>
<blockquote>
<ul>
<li>the server could have shutdown the socket (e.g. a primary stepping down),</li>
<li>a connection pool could be empty, requiring new connections; those connections could fail to connect or could fail
the server handshake</li>
</ul>
</blockquote>
<p>Once an operation is sent over the wire, several additional error conditions could occur, such as:</p>
<blockquote>
<ul>
<li>a socket timeout could occur before the server responds</li>
<li>the server might send an RST packet, indicating the socket was already closed</li>
<li>for write operations, the server might return a "not writable primary" error</li>
</ul>
</blockquote>
<p>This specification does not require nor prohibit drivers from attempting automatic recovery for various cases where it
might be considered reasonable to do so, such as:</p>
<blockquote>
<ul>
<li>repeating server selection if, after selection, a socket is determined to be unsuitable before a message is sent on
it</li>
<li>for a read operation, after a socket error, selecting a new server meeting the read preference and resending the
query</li>
<li>for a write operation, after a "not writable primary" error, selecting a new server (to locate the primary) and
resending the write operation</li>
</ul>
</blockquote>
<p>Driver-common rules for retrying operations (and configuring such retries) could be the topic of a different, future
specification.</p>
<h3 id="why-is-maxstalenessseconds-applied-before-tag_sets"><a class="header" href="#why-is-maxstalenessseconds-applied-before-tag_sets">Why is maxStalenessSeconds applied before tag_sets?</a></h3>
<p>The intention of read preference's list of tag sets is to allow a user to prefer the first tag set but fall back to
members matching later tag sets. In order to know whether to fall back or not, we must first filter by all other
criteria.</p>
<p>Say you have two secondaries:</p>
<blockquote>
<ul>
<li>Node 1, tagged <code>{'tag': 'value1'}</code>, estimated staleness 5 minutes</li>
<li>Node 2, tagged <code>{'tag': 'value2'}</code>, estimated staleness 1 minute</li>
</ul>
</blockquote>
<p>And a read preference:</p>
<blockquote>
<ul>
<li>mode: "secondary"</li>
<li>maxStalenessSeconds: 120 (2 minutes)</li>
<li>tag_sets: <code>[{'tag': 'value1'}, {'tag': 'value2'}]</code></li>
</ul>
</blockquote>
<p>If tag sets were applied before maxStalenessSeconds, we would select Node 1 since it matches the first tag set, then
filter it out because it is too stale, and be left with no eligible servers.</p>
<p>The user's intent in specifying two tag sets was to fall back to the second set if needed, so we filter by
maxStalenessSeconds first, then tag_sets, and select Node 2.</p>
<h2 id="references"><a class="header" href="#references">References</a></h2>
<ul>
<li><a href="server-selection/../server-discovery-and-monitoring/server-discovery-and-monitoring.html">Server Discovery and Monitoring</a> specification</li>
<li><a href="server-selection/../auth/auth.html">Driver Authentication</a> specification</li>
<li><a href="server-selection/../connection-monitoring-and-pooling/connection-monitoring-and-pooling.html">Connection Monitoring and Pooling</a>
specification</li>
</ul>
<h2 id="changelog-19"><a class="header" href="#changelog-19">Changelog</a></h2>
<ul>
<li>
<p>2015-06-26: Updated single-threaded selection logic with "stale" and serverSelectionTryOnce.</p>
</li>
<li>
<p>2015-08-10: Updated single-threaded selection logic to ensure a scan always happens at least once under
serverSelectionTryOnce if selection fails. Removed the general selection algorithm and put full algorithms for each of
the single- and multi-threaded sections. Added a requirement that single-threaded drivers document selection time
expectations.</p>
</li>
<li>
<p>2016-07-21: Updated for Max Staleness support.</p>
</li>
<li>
<p>2016-08-03: Clarify selection algorithm, in particular that maxStalenessMS comes before tag_sets.</p>
</li>
<li>
<p>2016-10-24: Rename option from "maxStalenessMS" to "maxStalenessSeconds".</p>
</li>
<li>
<p>2016-10-25: Change minimum maxStalenessSeconds value from 2 * heartbeatFrequencyMS to heartbeatFrequencyMS +
idleWritePeriodMS (with proper conversions of course).</p>
</li>
<li>
<p>2016-11-01: Update formula for secondary staleness estimate with the equivalent, and clearer, expression of this
formula from the Max Staleness Spec</p>
</li>
<li>
<p>2016-11-21: Revert changes that would allow idleWritePeriodMS to change in the future, require maxStalenessSeconds to
be at least 90.</p>
</li>
<li>
<p>2017-06-07: Clarify socketCheckIntervalMS behavior, single-threaded drivers must retry selection after checking an
idle socket and discovering it is broken.</p>
</li>
<li>
<p>2017-11-10: Added application-configurated server selector.</p>
</li>
<li>
<p>2017-11-12: Specify read preferences for OP_MSG with direct connection, and delete obsolete comment direct connections
to secondaries getting "not writable primary" errors by design.</p>
</li>
<li>
<p>2018-01-22: Clarify that $query wrapping is only for OP_QUERY</p>
</li>
<li>
<p>2018-01-22: Clarify that $out on aggregate follows the "$out Aggregation Pipeline Operator" spec and warns if read
preference is not primary.</p>
</li>
<li>
<p>2018-01-29: Remove reference to '$out Aggregation spec'. Clarify runCommand selection rules.</p>
</li>
<li>
<p>2018-12-13: Update tag_set example to use only String values</p>
</li>
<li>
<p>2019-05-20: Added rule to not send read preferene to standalone servers</p>
</li>
<li>
<p>2019-06-07: Clarify language for aggregate and mapReduce commands that write</p>
</li>
<li>
<p>2020-03-17: Specify read preferences with support for server hedged reads</p>
</li>
<li>
<p>2020-10-10: Consider server load when selecting servers within the latency window.</p>
</li>
<li>
<p>2021-04-07: Adding in behaviour for load balancer mode.</p>
</li>
<li>
<p>2021-05-12: Removed deprecated URI option in favour of readPreference=secondaryPreferred.</p>
</li>
<li>
<p>2021-05-13: Updated to use modern terminology.</p>
</li>
<li>
<p>2021-08-05: Updated $readPreference logic to describe OP_MSG behavior.</p>
</li>
<li>
<p>2021-09-03: Clarify that wire version check only applies to available servers.</p>
</li>
<li>
<p>2021-09-28: Note that 5.0+ secondaries support aggregate with write stages (e.g. <code>$out</code> and <code>$merge</code>). Clarify setting
<code>SecondaryOk</code> wire protocol flag or <code>$readPreference</code> global command argument for replica set topology.</p>
</li>
<li>
<p>2022-01-19: Require that timeouts be applied per the client-side operations timeout spec</p>
</li>
<li>
<p>2022-10-05: Remove spec front matter, move footnote, and reformat changelog.</p>
</li>
<li>
<p>2022-11-09: Add log messages and tests.</p>
</li>
<li>
<p>2023-08-26: Add list of deprioritized servers for sharded cluster topology.</p>
</li>
<li>
<p>2024-02-07: Migrated from reStructuredText to Markdown.</p>
</li>
</ul>
<div class="footnote-definition" id="1"><sup class="footnote-definition-label">1</sup>
<p>mongos 3.4 refuses to connect to mongods with maxWireVersion &lt; 5, so it does no additional wire version checks
related to maxStalenessSeconds.</p>
</div>
<div style="break-before: page; page-break-before: always;"></div><h1 id="max-staleness"><a class="header" href="#max-staleness">Max Staleness</a></h1>
<ul>
<li>Status: Accepted</li>
<li>Minimum Server Version: 3.4</li>
</ul>
<h2 id="abstract-20"><a class="header" href="#abstract-20">Abstract</a></h2>
<p>Read preference gains a new option, "maxStalenessSeconds".</p>
<p>A client (driver or mongos) MUST estimate the staleness of each secondary, based on lastWriteDate values provided in
server hello responses, and select only those secondaries whose staleness is less than or equal to maxStalenessSeconds.</p>
<p>Most of the implementation of the maxStalenessSeconds option is specified in the Server Discovery And Monitoring Spec
and the Server Selection Spec. This document supplements those specs by collecting information specifically about
maxStalenessSeconds.</p>
<h2 id="meta-20"><a class="header" href="#meta-20">Meta</a></h2>
<p>The key words "MUST", "MUST NOT", "REQUIRED", "SHALL", "SHALL NOT", "SHOULD", "SHOULD NOT", "RECOMMENDED", "MAY", and
"OPTIONAL" in this document are to be interpreted as described in <a href="https://www.ietf.org/rfc/rfc2119.txt">RFC 2119</a>.</p>
<h2 id="motivation-for-change-10"><a class="header" href="#motivation-for-change-10">Motivation for Change</a></h2>
<p>Users have often asked for ways to avoid reading from stale secondaries. An application with a geographically
distributed replica set may want to prefer nearby members to minimize latency, while at the same time avoiding extremely
laggy secondaries to mitigate the risk of very stale reads.</p>
<h3 id="goals"><a class="header" href="#goals">Goals</a></h3>
<ul>
<li>Provide an approximate means of limiting the staleness of secondary reads.</li>
<li>Provide a client-side knob to adjust the tradeoff between network-local reads and data recency.</li>
<li>Be robust in the face of clock skew between the client and servers, and skew between the primary and secondaries.</li>
<li>Avoid "inadvertent primary read preference": prevent a maxStalenessSeconds setting so small it forces all reads to the
primary regardless of actual replication lag.</li>
<li>Specify how mongos routers and shards track the opTimes of Config Servers as Replica Sets ("CSRS").</li>
</ul>
<h3 id="non-goals"><a class="header" href="#non-goals">Non-Goals</a></h3>
<ul>
<li>Provide a global server-side configuration of max acceptable staleness (see <a href="max-staleness/max-staleness.html#rejected-ideas">rejected ideas</a>).</li>
<li>Support small values for max staleness.</li>
<li>Make a consistency guarantee resembling readConcern "afterOpTime".</li>
<li>Specify how maxStalenessSeconds interacts with readConcern "afterOpTime" in drivers (distinct from the goal for
routers and shards).</li>
<li>Compensate for the duration of server checks in staleness estimations.</li>
</ul>
<h2 id="specification-18"><a class="header" href="#specification-18">Specification</a></h2>
<h3 id="api"><a class="header" href="#api">API</a></h3>
<p>"maxStalenessSeconds" is a new read preference option, with a positive integer value. It MUST be configurable similar to
other read preference options like "readPreference" and "tag_sets". Clients MUST also recognize it in the connection
string:</p>
<pre><code>mongodb://host/?readPreference=secondary&amp;maxStalenessSeconds=120
</code></pre>
<p>Clients MUST consider "maxStalenessSeconds=-1" in the connection string to mean "no maximum staleness".</p>
<p>A connection string combining a positive maxStalenessSeconds with read preference mode "primary" MUST be considered
invalid; this includes connection strings with no explicit read preference mode.</p>
<p>By default there is no maximum staleness.</p>
<p>A driver connected to a replica set requires that maxStalenessSeconds be absent, or be at least
smallestMaxStalenessSeconds (90 seconds) and at least heartbeatFrequencyMS + idleWritePeriodMS. The exact mechanism for
enforcement is defined in the Server Selection Spec.</p>
<p>Besides configuring maxStalenessSeconds in the connection string, the API for configuring it in code is not specified;
drivers are free to use None, null, -1, or other representations of "no value" to represent "no max staleness".</p>
<h3 id="replica-sets"><a class="header" href="#replica-sets">Replica Sets</a></h3>
<p>Replica set primaries and secondaries implement the following features to support maxStalenessSeconds.</p>
<h4 id="idlewriteperiodms-1"><a class="header" href="#idlewriteperiodms-1">idleWritePeriodMS</a></h4>
<p>An idle primary writes a no-op to the oplog every 10 seconds to refresh secondaries' lastWriteDate values (see
SERVER-23892 and <a href="max-staleness/max-staleness.html#primary-must-write-periodic-no-ops">primary must write periodic no-ops</a>). This spec refers to this
period as <code>idleWritePeriodMS</code> with constant value 10,000.</p>
<h4 id="lastwrite"><a class="header" href="#lastwrite">lastWrite</a></h4>
<p>A primary's or secondary's hello response contains a "lastWrite" subdocument with these fields (SERVER-8858):</p>
<ul>
<li>lastWriteDate: a BSON UTC datetime, the wall-clock time of the <strong>primary</strong> when it most recently recorded a write to
the oplog.</li>
<li>opTime: an opaque value representing the position in the oplog of the most recently seen write. Needed for sharding,
not used for the maxStalenessSeconds read preference option.</li>
</ul>
<h3 id="wire-version"><a class="header" href="#wire-version">Wire Version</a></h3>
<p>The maxWireVersion MUST be incremented to 5 to indicate that the server includes maxStalenessSeconds features
(SERVER-23893).</p>
<h3 id="client-2"><a class="header" href="#client-2">Client</a></h3>
<p>A client (driver or mongos) MUST estimate the staleness of each secondary, based on lastWriteDate values provided in
server hello responses, and select for reads only those secondaries whose estimated staleness is less than or equal to
maxStalenessSeconds.</p>
<p>If any server's maxWireVersion is less than 5 and maxStalenessSeconds is a positive number, every attempt at server
selection throws an error.</p>
<p>When there is a known primary, a secondary S's staleness is estimated with this formula:</p>
<pre><code>(S.lastUpdateTime - S.lastWriteDate) - (P.lastUpdateTime - P.lastWriteDate) + heartbeatFrequencyMS
</code></pre>
<p>Where "P" and "S" are the primary's and secondary's ServerDescriptions. All datetimes are in milliseconds. The staleness
estimate could be temporarily negative.</p>
<p>When there is no known primary, a secondary S's staleness is estimated with this formula:</p>
<pre><code>SMax.lastWriteDate - S.lastWriteDate + heartbeatFrequencyMS
</code></pre>
<p>Where "SMax" is the secondary with the greatest lastWriteDate.</p>
<h4 id="explanation-of-staleness-estimate-with-primary"><a class="header" href="#explanation-of-staleness-estimate-with-primary">Explanation of Staleness Estimate With Primary</a></h4>
<ol>
<li>When the client checks the primary, it gets the delta between the primary's lastWriteDate and the client clock. Call
this "Client_to_Primary".</li>
<li>When the client checks a secondary, it gets the delta between the secondary's lastWriteDate and the client clock.
Call this "Client_to_Secondary".</li>
<li>The difference of these two is an estimate of the delta between the primary's and secondary's lastWriteDate.</li>
</ol>
<p>Thus:</p>
<pre><code>staleness = Client_to_Secondary - Client_to_Primary
= (S.lastUpdateTime - S.lastWriteDate) - (P.lastUpdateTime - P.lastWriteDate)
</code></pre>
<p>Finally, add heartbeatFrequencyMS:</p>
<pre><code>(S.lastUpdateTime - S.lastWriteDate) - (P.lastUpdateTime - P.lastWriteDate) + heartbeatFrequencyMS
</code></pre>
<p>This adjusts for the pessimistic assumption that S stops replicating right after S.lastUpdateTime, so it will be
heartbeatFrequencyMS <em>more</em> stale by the time it is checked again. This means S must be fresh enough at S.lastUpdateTime
to be eligible for reads from now until the next check, even if it stops replicating.</p>
<p>See the Server Discovery and Monitoring Spec and Server Selection Spec for details of client implementation.</p>
<h3 id="routers-and-shards"><a class="header" href="#routers-and-shards">Routers and shards</a></h3>
<p>Background: Shard servers and mongos servers in a sharded cluster with CSRS use readConcern "afterOptime" for
consistency guarantees when querying the shard config.</p>
<p>Besides tracking lastWriteDate, routers and shards additionally track the opTime of CSRS members if they have
maxWireVersion 5 or greater. (See Server Discovery and Monitoring Spec for details.)</p>
<p>When a router or shard selects a CSRS member to read from with readConcern like:</p>
<pre><code>readConcern: { afterOpTime: OPTIME }
</code></pre>
<p>... then it follows this selection logic:</p>
<ol>
<li>Make a list of known CSRS data members.</li>
<li>Filter out those whose last known opTime is older than OPTIME.</li>
<li>If no servers remain, select the primary.</li>
<li>Otherwise, select randomly one of the CSRS members whose roundTripTime is within localThresholdMS of the member with
the fastest roundTripTime.</li>
</ol>
<p>Step 4 is the standard localThresholdMS logic from the Server Selection Spec.</p>
<p>This algorithm helps routers and shards select a secondary that is likely to satisfy readConcern "afterOpTime" without
blocking.</p>
<p>This feature is only for routers and shards, not drivers. See <a href="max-staleness/max-staleness.html#future-work">Future Work</a>.</p>
<h2 id="reference-implementation-9"><a class="header" href="#reference-implementation-9">Reference Implementation</a></h2>
<p>The C Driver (CDRIVER-1363) and Perl Driver (PERL-626).</p>
<h2 id="estimating-staleness-example-with-a-primary-and-continuous-writes"><a class="header" href="#estimating-staleness-example-with-a-primary-and-continuous-writes">Estimating Staleness: Example With a Primary and Continuous Writes</a></h2>
<p>Consider a primary P and a secondary S, and a client with heartbeatFrequencyMS set to 10 seconds. Say that the primary's
clock is 50 seconds skewed ahead of the client's.</p>
<p>The client checks P and S at time 60 (meaning 60 seconds past midnight) by the client's clock. The primary reports its
lastWriteDate is 10.</p>
<p>Then, S reports its lastWriteDate is 0. The client estimates S's staleness as:</p>
<pre><code>(S.lastUpdateTime - S.lastWriteDate) - (P.lastUpdateTime - P.lastWriteDate) + heartbeatFrequencyMS
= (60 - 0) - (60 - 10) + 10
= 20 seconds
</code></pre>
<p>(Values converted from milliseconds to seconds for the sake of discussion.)</p>
<p>Note that the secondary appears only 10 seconds stale at this moment, but the client adds heartbeatFrequencyMS,
pessimistically assuming that the secondary will not replicate at all between now and the next check. If the current
staleness plus heartbeatFrequencyMS is still less than maxStalenessSeconds, then we can safely read from the secondary
from now until the next check.</p>
<p>The client re-checks P and S 10 seconds later, at time 70 by the client's clock. S responds first with a lastWriteDate
of 5: it has fallen 5 seconds further behind. The client updates S's lastWriteDate and lastUpdateTime. The client now
estimates S's staleness as:</p>
<pre><code>(S.lastUpdateTime - S.lastWriteDate) - (P.lastUpdateTime - P.lastWriteDate) + heartbeatFrequencyMS
= (70 - 5) - (60 - 10) + 10
= 25 seconds
</code></pre>
<p>Say that P's response arrives 10 seconds later, at client time 80, and reports its lastWriteDate is 30. S's staleness is
still 25 seconds:</p>
<pre><code>(S.lastUpdateTime - S.lastWriteDate) - (P.lastUpdateTime - P.lastWriteDate) + heartbeatFrequencyMS
= (70 - 5) - (80 - 30) + 10
= 25 seconds
</code></pre>
<p>The same story as a table:</p>
<div class="table-wrapper"><table><thead><tr><th>Client clock</th><th>Primary clock</th><th>Event</th><th>S.lastUpdateTime</th><th>S.lastWriteDate</th><th>P.lastUpdateTime</th><th>P.lastWriteDate</th><th>S staleness</th></tr></thead><tbody>
<tr><td>60</td><td>10</td><td>P and S respond</td><td>60</td><td>0</td><td>60</td><td>10</td><td>20 seconds</td></tr>
<tr><td>70</td><td>20</td><td>S responds</td><td>70</td><td>5</td><td>60</td><td>10</td><td>25 seconds</td></tr>
<tr><td>80</td><td>30</td><td>P responds</td><td>70</td><td>5</td><td>80</td><td>30</td><td>25 seconds</td></tr>
</tbody></table>
</div>
<h2 id="estimating-staleness-example-with-no-primary"><a class="header" href="#estimating-staleness-example-with-no-primary">Estimating Staleness: Example With No Primary</a></h2>
<p>Consider a replica set with secondaries S1 and S2, and no primary. S2 lags 15 seconds <em>farther</em> behind S1 and has not
yet caught up. The client has heartbeatFrequencyMS set to 10 seconds.</p>
<p>When the client checks the two secondaries, S1's lastWriteDate is 20 and S2's lastWriteDate is 5.</p>
<p>Because S1 is the secondary with the maximum lastWriteDate, "SMax", its staleness estimate equals heartbeatFrequencyMS:</p>
<blockquote>
<p>SMax.lastWriteDate - S.lastWriteDate + heartbeatFrequencyMS = 20 - 20 + 10 = 10</p>
</blockquote>
<p>(Since max staleness must be at least heartbeatFrequencyMS + idleWritePeriodMS, S1 is eligible for reads no matter
what.)</p>
<p>S2's staleness estimate is:</p>
<pre><code>SMax.lastWriteDate - S.lastWriteDate + heartbeatFrequencyMS
= 20 - 5 + 10
= 25
</code></pre>
<h2 id="estimating-staleness-example-of-worst-case-accuracy-with-idle-replica-set"><a class="header" href="#estimating-staleness-example-of-worst-case-accuracy-with-idle-replica-set">Estimating Staleness: Example of Worst-Case Accuracy With Idle Replica Set</a></h2>
<p>Consider a primary P and a secondary S, and a client with heartbeatFrequencyMS set to 500 ms. There is no clock skew.
(Previous examples show that skew has no effect.)</p>
<p>The primary has been idle for 10 seconds and writes a no-op to the oplog at time 50 (meaning 50 seconds past midnight),
and again at time 60.</p>
<p>Before the secondary can replicate the no-op at time 60, the client checks both servers. The primary reports its
lastWriteDate is 60, the secondary reports 50.</p>
<p>The client estimates S's staleness as:</p>
<pre><code>(S.lastUpdateTime - S.lastWriteDate) - (P.lastUpdateTime - P.lastWriteDate) + heartbeatFrequencyMS
= (60 - 50) - (60 - 60) + 0.5
= 10.5
</code></pre>
<p>The same story as a table:</p>
<div class="table-wrapper"><table><thead><tr><th>Clock</th><th>Event</th><th>S.lastUpdateTime</th><th>S.lastWriteDate</th><th>P.lastUpdateTime</th><th>P.lastWriteDate</th><th>S staleness</th></tr></thead><tbody>
<tr><td>50</td><td>Idle write</td><td>50</td><td></td><td>50</td><td></td><td></td></tr>
<tr><td>60</td><td>Idle write begins</td><td>60</td><td></td><td>50</td><td></td><td></td></tr>
<tr><td>60</td><td>Client checks P and S</td><td>60</td><td>60</td><td>50</td><td>60</td><td>10.5</td></tr>
<tr><td>60</td><td>Idle write completes</td><td>60</td><td></td><td>60</td><td></td><td></td></tr>
</tbody></table>
</div>
<p>In this scenario the actual secondary lag is between 0 and 10 seconds. But the staleness estimate can be as large as:</p>
<pre><code>staleness = idleWritePeriodMS + heartbeatFrequencyMS
</code></pre>
<p>To ensure the secondary is always eligible for reads in an idle replica set, we require:</p>
<pre><code>maxStalenessSeconds * 1000 &gt;= heartbeatFrequencyMS + idleWritePeriodMS
</code></pre>
<h2 id="supplemental"><a class="header" href="#supplemental">Supplemental</a></h2>
<p>Python scripts in this document's source directory:</p>
<ul>
<li><code>test_max_staleness_spo.py</code>: Uses <code>scipy.optimize</code> to determine worst-case accuracy of the staleness estimate in an
idle replica set.</li>
<li><code>test_staleness_estimate.py</code>: Tests whether a client would correctly select a secondary from an idle replica set,
given a random distribution of values for maxStalenessSeconds, heartbeatFrequencyMS, lastWriteDate, and
lastUpdateTime.</li>
</ul>
<h2 id="test-plan-14"><a class="header" href="#test-plan-14">Test Plan</a></h2>
<p>See <code>max-staleness-tests.md</code>, and the YAML and JSON tests in the tests directory.</p>
<h2 id="design-rationale-13"><a class="header" href="#design-rationale-13">Design Rationale</a></h2>
<h3 id="specify-max-staleness-in-seconds"><a class="header" href="#specify-max-staleness-in-seconds">Specify max staleness in seconds</a></h3>
<p>Other driver options that are timespans are in milliseconds, for example serverSelectionTimeoutMS. The max staleness
option is specified in seconds, however, to make it obvious to users that clients can only enforce large, imprecise max
staleness values.</p>
<h3 id="maxstalenessseconds-is-part-of-read-preferences"><a class="header" href="#maxstalenessseconds-is-part-of-read-preferences">maxStalenessSeconds is part of Read Preferences</a></h3>
<p>maxStalenessSeconds MAY be configurable at the client, database, and collection level, and per operation, the same as
other read preference fields are, because users expressed that their tolerance for stale reads varies per operation.</p>
<h3 id="primary-must-write-periodic-no-ops"><a class="header" href="#primary-must-write-periodic-no-ops">Primary must write periodic no-ops</a></h3>
<p>Consider a scenario in which the primary does <em>not</em>:</p>
<ol>
<li>There are no writes for an hour.</li>
<li>A client performs a heavy read-only workload with read preference mode "nearest" and maxStalenessSeconds of 90
seconds.</li>
<li>The primary receives a write.</li>
<li>In the brief time before any secondary replicates the write, the client re-checks all servers.</li>
<li>Since the primary's lastWriteDate is an hour ahead of all secondaries', the client only queries the primary.</li>
<li>After heartbeatFrequencyMS, the client re-checks all servers and finds that the secondaries aren't lagging after all,
and resumes querying them.</li>
</ol>
<p>This apparent "replication lag spike" is just a measurement error, but it causes exactly the behavior the user wanted to
avoid: a small replication lag makes the client route all queries from the secondaries to the primary.</p>
<p>Therefore an idle primary must execute a no-op every 10 seconds (idleWritePeriodMS) to keep secondaries' lastWriteDate
values close to the primary's clock. The no-op also keeps opTimes close to the primary's, which helps mongos choose an
up-to-date secondary to read from in a CSRS.</p>
<p>Monitoring software like MongoDB Cloud Manager that charts replication lag will also benefit when spurious lag spikes
are solved.</p>
<p>See
<a href="max-staleness/max-staleness.html#estimating-staleness-example-of-worst-case-accuracy-with-idle-replica-set">Estimating Staleness: Example of Worst-Case Accuracy With Idle Replica Set</a>.
and <a href="https://jira.mongodb.org/browse/SERVER-23892">SERVER-23892</a>.</p>
<h3 id="smallest-allowed-value-for-maxstalenessseconds"><a class="header" href="#smallest-allowed-value-for-maxstalenessseconds">Smallest allowed value for maxStalenessSeconds</a></h3>
<p>If maxStalenessSeconds is a positive number, it must be at least smallestMaxStalenessSeconds (90 seconds) and at least
heartbeatFrequencyMS + idleWritePeriodMS. The exact mechanism for enforcement is defined in the Server Selection Spec.</p>
<p>The justification for heartbeatFrequencyMS + idleWritePeriodMS is technical: If maxStalenessSeconds is set to exactly
heartbeatFrequencyMS (converted to seconds), then so long as a secondary lags even a millisecond it is ineligible.
Despite the user's read preference mode, the client will always read from the primary.</p>
<p>This is an example of "inadvertent primary read preference": a maxStalenessSeconds setting so small it forces all reads
to the primary regardless of actual replication lag. We want to prohibit this effect (see <a href="max-staleness/max-staleness.html#goals">goals</a>).</p>
<p>We also want to ensure that a secondary in an idle replica set is always considered eligible for reads with
maxStalenessSeconds. See
<a href="max-staleness/max-staleness.html#estimating-staleness-example-of-worst-case-accuracy-with-idle-replica-set">Estimating Staleness: Example of Worst-Case Accuracy With Idle Replica Set</a>.</p>
<p>Requiring maxStalenessSeconds to be at least 90 seconds is a design choice. If the only requirement were that
maxStalenessSeconds be at least heartbeatFrequencyMS + idleWritePeriodMS, then the smallest value would be 20 seconds
for multi-threaded drivers (10 second idleWritePeriodMS plus multi-threaded drivers' default 10 second
heartbeatFrequencyMS), 70 seconds for single-threaded drivers (whose default heartbeatFrequencyMS is 60 seconds), and 40
seconds for mongos (whose replica set monitor checks servers every 30 seconds).</p>
<p>The smallest configurable value for heartbeatFrequencyMS is 0.5 seconds, so maxStalenessSeconds could be as small as
10.5 when using a driver connected to a replica set, but mongos provides no such flexibility.</p>
<p>Therefore, this spec <em>also</em> requires that maxStalenessSeconds is at least 90:</p>
<ul>
<li>To provide a minimum for all languages and topologies that is easy to document and explain</li>
<li>To avoid application breakage when moving from replica set to sharded cluster, or when using the same URI with
different drivers</li>
<li>To emphasize that maxStalenessSeconds is a low-precision heuristic</li>
<li>To avoid the arbitrary-seeming minimum of 70 seconds imposed by single-threaded drivers</li>
</ul>
<h3 id="all-servers-must-have-wire-version-5-to-support-maxstalenessseconds"><a class="header" href="#all-servers-must-have-wire-version-5-to-support-maxstalenessseconds">All servers must have wire version 5 to support maxStalenessSeconds</a></h3>
<p>Clients with minWireVersion &lt; 5 MUST throw an error if maxStalenessSeconds is set, and any available server in the
topology has maxWireVersion less than 5.</p>
<p>An available server is defined in the <a href="max-staleness/../server-selection/server-selection.html#terms">Server Selection</a> specification.</p>
<p>Servers began reporting lastWriteDate in wire protocol version 5, and clients require some or all servers' lastWriteDate
in order to estimate any servers' staleness. The exact requirements of the formula vary according to TopologyType, so
this spec makes a simple ruling: if any server is running an outdated version, maxStalenessSeconds cannot be supported.</p>
<h3 id="rejected-ideas"><a class="header" href="#rejected-ideas">Rejected ideas</a></h3>
<h4 id="add-all-secondaries-optimes-to-primarys-hello-response"><a class="header" href="#add-all-secondaries-optimes-to-primarys-hello-response">Add all secondaries' opTimes to primary's hello response</a></h4>
<p>Not needed; each secondary's self-report of its opTime is just as good as the primary's.</p>
<h4 id="use-optimes-from-command-responses-besides-hello"><a class="header" href="#use-optimes-from-command-responses-besides-hello">Use opTimes from command responses besides hello</a></h4>
<p>An idea was to add opTime to command responses that don't already include it (e.g., "find"), and use these opTimes to
update ServerDescriptions more frequently than the periodic hello calls.</p>
<p>But while a server is not being used (e.g., while it is too stale, or while it does not match some other part of the
Read Preference), only its periodic hello responses can update its opTime. Therefore, heartbeatFrequencyMS sets a lower
bound on maxStalenessSeconds, so there is no benefit in recording each server's opTime more frequently. On the other
hand there would be costs: effort adding opTime to all command responses, lock contention getting the opTime on the
server and recording it on the client, complexity in the spec and the client code.</p>
<h4 id="use-current-time-in-staleness-estimate"><a class="header" href="#use-current-time-in-staleness-estimate">Use current time in staleness estimate</a></h4>
<p>A proposed staleness formula estimated the secondary's worst possible staleness:</p>
<pre><code>P.lastWriteDate + (now - P.lastUpdateTime) - S.lastWriteDate
</code></pre>
<p>In this proposed formula, the place occupied by "S.lastUpdateTime" in the actual formula is replaced with "now", at the
moment in the server selection process when staleness is being estimated.</p>
<p>This formula attempted a worst-case estimate right now: it assumed the primary kept writing after the client checked it,
and that the secondary replicated nothing since the client last checked the secondary. The formula was rejected because
it would slosh load to and from the secondary during the interval between checks.</p>
<p>For example: Say heartbeatFrequencyMS is 10 seconds and maxStalenessSeconds is set to 25 seconds, and immediately after
a secondary is checked its staleness is estimated at 20 seconds. It is eligible for reads until 5 seconds after the
check, then it becomes ineligible, causing all queries to be directed to the primary until the next check, 5 seconds
later.</p>
<h4 id="server-side-configuration"><a class="header" href="#server-side-configuration">Server-side Configuration</a></h4>
<p>We considered a deployment-wide "max staleness" setting that servers communicate to clients in hello, e.g., "120 seconds
is the max staleness." The read preference config is simplified: "maxStalenessSeconds" is gone, instead we have
"staleOk: true" (the default?) and "staleOk: false".</p>
<p>Based on Customer Advisory Board feedback, configuring staleness per-operation on the client side is more useful. We
should merely avoid closing the door on a future server-side configuration feature.</p>
<h2 id="references-1"><a class="header" href="#references-1">References</a></h2>
<p>Complaints about stale reads, and proposed solutions:</p>
<ul>
<li><a href="https://jira.mongodb.org/browse/SERVER-3346">SERVER-3346</a></li>
<li><a href="https://jira.mongodb.org/browse/SERVER-4935">SERVER-4935</a></li>
<li><a href="https://jira.mongodb.org/browse/SERVER-4936">SERVER-4936</a></li>
<li><a href="https://jira.mongodb.org/browse/SERVER-8476">SERVER-8476</a></li>
<li><a href="https://jira.mongodb.org/browse/SERVER-12861">SERVER-12861</a></li>
</ul>
<h2 id="future-work-8"><a class="header" href="#future-work-8">Future Work</a></h2>
<h3 id="future-feature-to-support-readconcern-afteroptime"><a class="header" href="#future-feature-to-support-readconcern-afteroptime">Future feature to support readConcern "afterOpTime"</a></h3>
<p>If a future spec allows applications to use readConcern "afterOptime", clients should prefer secondaries that have
already replicated to that opTime, so reads do not block. This is an extension of the mongos logic for CSRS to
applications.</p>
<h3 id="future-feature-to-support-server-side-configuration"><a class="header" href="#future-feature-to-support-server-side-configuration">Future feature to support server-side configuration</a></h3>
<p>For this spec, we chose to control maxStalenessSeconds in client code. A future spec could allow database administrators
to configure from the server side how much replication lag makes a secondary too stale to read from. (See
<a href="max-staleness/max-staleness.html#server-side-configuration">Server-side Configuration</a> above.) This could be implemented atop the current feature: if a
server communicates is staleness configuration in its hello response like:</p>
<pre><code>{ hello: true, maxStalenessSeconds: 30 }
</code></pre>
<p>... then a future client can use the value from the server as its default maxStalenessSeconds when there is no
client-side setting.</p>
<h2 id="changelog-20"><a class="header" href="#changelog-20">Changelog</a></h2>
<ul>
<li>
<p>2024-08-09: Updated wire versions in tests to 4.0+.</p>
</li>
<li>
<p>2024-04-30: Migrated from reStructuredText to Markdown.</p>
</li>
<li>
<p>2022-10-05: Remove spec front matter and revise changelog.</p>
</li>
<li>
<p>2021-09-08: Updated tests to support driver removal of support for server versions older than 3.6.</p>
</li>
<li>
<p>2021-09-03: Clarify that wire version check only applies to available servers.</p>
</li>
<li>
<p>2021-04-06: Updated to use hello command.</p>
</li>
<li>
<p>2016-09-29: Specify "no max staleness" in the URI with "maxStalenessMS=-1" instead of "maxStalenessMS=0".</p>
</li>
<li>
<p>2016-10-24: Rename option from "maxStalenessMS" to "maxStalenessSeconds".</p>
</li>
<li>
<p>2016-10-25: Change minimum maxStalenessSeconds value from 2 * heartbeatFrequencyMS to heartbeatFrequencyMS +
idleWritePeriodMS (with proper conversions of course).</p>
</li>
<li>
<p>2016-11-21: Revert changes that would allow idleWritePeriodMS to change in the future, require maxStalenessSeconds to
be at least 90.</p>
</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="retryable-reads"><a class="header" href="#retryable-reads">Retryable Reads</a></h1>
<ul>
<li>Status: Accepted</li>
<li>Minimum Server Version: 3.6</li>
</ul>
<hr />
<h2 id="abstract-21"><a class="header" href="#abstract-21">Abstract</a></h2>
<p>This specification is about the ability for drivers to automatically retry any read operation that has not yet received
any results—due to a transient network error, a "not writable primary" error after a replica set failover, etc.</p>
<p>This specification will</p>
<ul>
<li>outline how an API for retryable read operations will be implemented in drivers</li>
<li>define an option to enable retryable reads for an application.</li>
</ul>
<h2 id="meta-21"><a class="header" href="#meta-21">META</a></h2>
<p>The keywords "MUST", "MUST NOT", "REQUIRED", "SHALL", "SHALL NOT", "SHOULD", "SHOULD NOT", "RECOMMENDED", "MAY", and
"OPTIONAL" in this document are to be interpreted as described in <a href="https://www.ietf.org/rfc/rfc2119.txt">RFC 2119</a>.</p>
<h2 id="specification-19"><a class="header" href="#specification-19">Specification</a></h2>
<h3 id="terms-11"><a class="header" href="#terms-11">Terms</a></h3>
<h4 id="retryable-error"><a class="header" href="#retryable-error">Retryable Error</a></h4>
<p>An error is considered retryable if it meets any of the criteria defined under
<a href="retryable-reads/../retryable-writes/retryable-writes.html#terms">Retryable Writes: Terms: Retryable Error</a>, minus the final criterion
about write concern errors. For convenience, the relevant criteria have been adapted to retryable reads and reproduced
below.</p>
<p>An error is considered retryable if it meets any of the following criteria:</p>
<ul>
<li>any network exception (e.g. socket timeout or error)</li>
<li>a server error response with any the following codes:</li>
</ul>
<div class="table-wrapper"><table><thead><tr><th><strong>Error Name</strong></th><th><strong>Error Code</strong></th></tr></thead><tbody>
<tr><td>ExceededTimeLimit</td><td>262</td></tr>
<tr><td>InterruptedAtShutdown</td><td>11600</td></tr>
<tr><td>InterruptedDueToReplStateChange</td><td>11602</td></tr>
<tr><td>NotWritablePrimary</td><td>10107</td></tr>
<tr><td>NotPrimaryNoSecondaryOk</td><td>13435</td></tr>
<tr><td>NotPrimaryOrSecondary</td><td>13436</td></tr>
<tr><td>PrimarySteppedDown</td><td>189</td></tr>
<tr><td>ReadConcernMajorityNotAvailableYet</td><td>134</td></tr>
<tr><td>ShutdownInProgress</td><td>91</td></tr>
<tr><td>HostNotFound</td><td>7</td></tr>
<tr><td>HostUnreachable</td><td>6</td></tr>
<tr><td>NetworkTimeout</td><td>89</td></tr>
<tr><td>SocketException</td><td>9001</td></tr>
</tbody></table>
</div>
<ul>
<li>a <a href="retryable-reads/../connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection-pool-errors">PoolClearedError</a></li>
<li>Any of the above retryable errors that occur during a connection handshake (including the authentication step). For
example, a network error or ShutdownInProgress error encountered when running the hello or saslContinue commands.</li>
</ul>
<h3 id="mongoclient-configuration-5"><a class="header" href="#mongoclient-configuration-5">MongoClient Configuration</a></h3>
<p>This specification introduces the following client-level configuration option.</p>
<h4 id="retryreads"><a class="header" href="#retryreads">retryReads</a></h4>
<p>This boolean option determines whether retryable behavior will be applied to all read operations executed within the
MongoClient. This option MUST default to true.
<a href="retryable-reads/../retryable-writes/retryable-writes.html#retrywrites">As with retryable writes</a>, this option MUST NOT be configurable at
the level of an individual read operation, collection object, or database object. Drivers that expose a "high" and
"core" API (e.g. Java and C# driver) MUST NOT expose a configurable option at the level of an individual read operation,
collection object, or database object in "high", but MAY expose the option in "core."</p>
<h5 id="naming-deviations-2"><a class="header" href="#naming-deviations-2">Naming Deviations</a></h5>
<p><a href="retryable-reads/../retryable-writes/retryable-writes.html#retrywrites">As with retryable writes</a>, drivers MUST use the defined name of
<code>retryReads</code> for the connection string parameter to ensure portability of connection strings across applications and
drivers. If drivers solicit MongoClient options through another mechanism (e.g. an options dictionary provided to the
MongoClient constructor), drivers SHOULD use the defined name but MAY deviate to comply with their existing conventions.
For example, a driver may use <code>retry_reads</code> instead of <code>retryReads</code>. For any other names in the spec, drivers SHOULD use
the defined name but MAY deviate to comply with their existing conventions.</p>
<h3 id="requirements-for-retryable-reads"><a class="header" href="#requirements-for-retryable-reads">Requirements for Retryable Reads</a></h3>
<h4 id="supported-server-versions"><a class="header" href="#supported-server-versions">Supported Server Versions</a></h4>
<p>Drivers MUST verify server eligibility by ensuring that <code>maxWireVersion</code> is at least 6 because retryable reads require a
MongoDB 3.6 standalone, replica set or shard cluster, MongoDB 3.6 server wire version is 6 as defined in the
<a href="retryable-reads/../wireversion-featurelist/wireversion-featurelist.html">Server Wire version and Feature List specification</a>.</p>
<p>The minimum server version is 3.6 because</p>
<ol>
<li>It gives us version parity with retryable writes.</li>
<li>It forces the retry attempt(s) to use the same implicit session, which would make it it easier to track operations
and kill any errant longer running operation.</li>
<li>It limits the scope of the implementation (<code>OP_QUERY</code> will not need to be supported).</li>
</ol>
<h4 id="supported-read-operations"><a class="header" href="#supported-read-operations">Supported Read Operations</a></h4>
<p>Drivers MUST support retryability for the following operations:</p>
<ul>
<li>
<p>All read operations defined in the CRUD specification i.e.</p>
<ul>
<li>
<p><code>Collection.find()</code></p>
<ul>
<li>This includes the <code>find</code> operations backing the GridFS API.</li>
</ul>
</li>
<li>
<p><code>Collection.aggregate()</code></p>
<ul>
<li>Only if the pipeline does not include a write stage (e.g. <code>$out</code>, <code>$merge</code>)</li>
</ul>
</li>
<li>
<p><code>Collection.distinct()</code></p>
</li>
<li>
<p><code>Collection.count()</code></p>
<ul>
<li>Only required if the driver already provides <code>count()</code></li>
</ul>
</li>
<li>
<p><code>Collection.estimatedDocumentCount()</code></p>
</li>
<li>
<p><code>Collection.countDocuments()</code></p>
</li>
</ul>
</li>
<li>
<p>All read operation helpers in the change streams specification i.e.</p>
<ul>
<li><code>Collection.watch()</code></li>
<li><code>Database.watch()</code></li>
<li><code>MongoClient.watch()</code></li>
</ul>
</li>
<li>
<p>All enumeration commands e.g.</p>
<ul>
<li><code>MongoClient.listDatabases()</code></li>
<li><code>Database.listCollections()</code></li>
<li><code>Collection.listIndexes()</code></li>
</ul>
</li>
<li>
<p>Any read operations not defined in the aforementioned specifications:</p>
<ul>
<li>Any read operation helpers e.g. <code>Collection.findOne()</code></li>
</ul>
</li>
</ul>
<p>Drivers SHOULD support retryability for the following operations:</p>
<ul>
<li>Any driver that provides generic command runners for read commands (with logic to inherit a client-level read
concerns) SHOULD implement retryability for the read-only command runner.</li>
</ul>
<p>Most of the above methods are defined in the following specifications:</p>
<ul>
<li><a href="retryable-reads/../change-streams/change-streams.html">Change Streams</a></li>
<li><a href="retryable-reads/../crud/crud.html">CRUD</a></li>
<li><a href="retryable-reads/../enumerate-collections/enumerate-collections.html">Enumerating Collections</a></li>
<li><a href="retryable-reads/../index-management/index-management.html#enumerate-indexes">Enumerating Indexes</a></li>
<li><a href="retryable-reads/../enumerate-databases/enumerate-databases.html">Enumerating Databases</a></li>
<li><a href="retryable-reads/../gridfs/gridfs-spec.html">GridFS Spec</a></li>
</ul>
<h4 id="unsupported-read-operations"><a class="header" href="#unsupported-read-operations">Unsupported Read Operations</a></h4>
<p>Drivers MUST NOT retry the following operations:</p>
<ul>
<li><code>Collection.mapReduce()</code>
<ul>
<li>This is due to the "Early Failure on Socket Disconnect" feature not supporting <code>mapReduce</code>.</li>
<li>N.B. If <code>mapReduce</code> is executed via a generic command runner for read commands, drivers SHOULD NOT inspect the
command to prevent <code>mapReduce</code> from retrying.</li>
</ul>
</li>
<li>Cursor.getMore()
<ul>
<li>See <a href="retryable-reads/retryable-reads.html#why-is-retrying-cursorgetmore-not-supported">Why is retrying Cursor.getMore() not supported?</a></li>
</ul>
</li>
<li>The generic runCommand helper, even if it is passed a read command.
<ul>
<li>N.B.: This applies only to a generic command runner, which is agnostic about the read/write nature of the command.</li>
</ul>
</li>
</ul>
<h3 id="implementing-retryable-reads"><a class="header" href="#implementing-retryable-reads">Implementing Retryable Reads</a></h3>
<h4 id="executing-retryable-read-commands"><a class="header" href="#executing-retryable-read-commands">Executing Retryable Read Commands</a></h4>
<p>Executing retryable read commands is extremely similar to
<a href="retryable-reads/../retryable-writes/retryable-writes.html#executing-retryable-write-commands">executing retryable write commands</a>. The
following explanation for executing retryable read commands has been adapted from the explanation for executing
retryable write commands.</p>
<h5 id="1-selecting-the-initial-server"><a class="header" href="#1-selecting-the-initial-server">1. Selecting the initial server</a></h5>
<p>The driver selects the initial server for the command as usual. When selecting a server for the first attempt of a
retryable read command, drivers MUST allow a server selection error to propagate. In this case, the caller is able to
infer that no attempt was made.</p>
<h5 id="2-determining-whether-retry-should-be-allowed"><a class="header" href="#2-determining-whether-retry-should-be-allowed">2. Determining whether retry should be allowed</a></h5>
<p>A driver then determines if it should attempt to retry next.</p>
<h6 id="2a-when-not-to-allow-retry"><a class="header" href="#2a-when-not-to-allow-retry">2a. When not to allow retry</a></h6>
<p>Drivers MUST attempt to execute the read command exactly once and allow any errors to propagate under any of the the
following conditions:</p>
<ul>
<li>if retryable reads is not enabled <strong>or</strong></li>
<li>if the selected server does not support retryable reads <strong>or</strong></li>
<li>if the session in a transaction</li>
</ul>
<p>By allowing the error to propagate, the caller is able to infer that one attempt was made.</p>
<h6 id="2b-when-to-allow-retry"><a class="header" href="#2b-when-to-allow-retry">2b. When to allow retry</a></h6>
<p>Drivers MUST only attempt to retry a read command if</p>
<ul>
<li>retryable reads are enabled <strong>and</strong></li>
<li>the selected server supports retryable reads <strong>and</strong></li>
<li>the previous attempt yields a retryable error</li>
</ul>
<h5 id="3-deciding-to-allow-retry-encountering-the-initial-retryable-error-and-selecting-a-server"><a class="header" href="#3-deciding-to-allow-retry-encountering-the-initial-retryable-error-and-selecting-a-server">3. Deciding to allow retry, encountering the initial retryable error, and selecting a server</a></h5>
<p>If the driver decides to allow retry and the previous attempt of a retryable read command encounters a retryable error,
the driver MUST update its topology according to the Server Discovery and Monitoring spec (see
<a href="retryable-reads/../server-discovery-and-monitoring/server-discovery-and-monitoring.html#error-handling">SDAM: Error Handling</a>) and
capture this original retryable error. Drivers should then proceed with selecting a server for a retry attempt.</p>
<h6 id="3a-selecting-the-server-for-retry"><a class="header" href="#3a-selecting-the-server-for-retry">3a. Selecting the server for retry</a></h6>
<p>In a sharded cluster, the server on which the operation failed MUST be provided to the server selection mechanism as a
deprioritized server.</p>
<p>If the driver cannot select a server for a retry attempt or the newly selected server does not support retryable reads,
retrying is not possible and drivers MUST raise the previous retryable error. In both cases, the caller is able to infer
that an attempt was made.</p>
<h6 id="3b-sending-an-equivalent-command-for-a-retry-attempt"><a class="header" href="#3b-sending-an-equivalent-command-for-a-retry-attempt">3b. Sending an equivalent command for a retry attempt</a></h6>
<p>After server selection, a driver MUST send a valid command to the newly selected server that is equivalent<sup class="footnote-reference"><a href="#1">1</a></sup> to the
initial command sent to the first server. If the driver determines that the newly selected server may not be able to
support a command equivalent to the initial command, drivers MUST NOT retry and MUST raise the previous retryable error</p>
<p>The above requirement can be fulfilled in one of two ways:</p>
<ol>
<li>
<p>During a retry attempt, the driver SHOULD recreate the command while adhering to that operation's specification's
server/wire version requirements. If an error occurs while recreating the command, then the driver MUST raise the
original retryable error.</p>
<p>For example, if the wire version dips from <em>W</em><sub>0</sub> to <em>W</em><sub>1</sub> after server selection, and the spec
for operation <em>O</em> notes that for wire version <em>W</em><sub>1</sub>, that field <em>F</em> should be omitted, then field <em>F</em>
should be omitted. If the spec for operation <em>O</em> requires the driver to error out if field <em>F</em> is defined when
talking to a server with wire version <em>W</em><sub>1</sub>, then the driver must error out and raise the original
retryable error.</p>
</li>
<li>
<p>Alternatively, if a driver chooses not to recreate the command as described above, then a driver MUST NOT retry if
the server/wire version dips after server selection and MUST raise the original retryable error.</p>
<p>For example, if the wire version dips after server selection, the driver can choose to not retry and simply raise the
original retryable error because there is no guarantee that the lower versioned server can support the original
command.</p>
</li>
</ol>
<h6 id="3c-if-a-retry-attempt-fails"><a class="header" href="#3c-if-a-retry-attempt-fails">3c. If a retry attempt fails</a></h6>
<p>If a retry attempt also fails and
<a href="retryable-reads/../client-side-operations-timeout/client-side-operations-timeout.html">Client Side Operations Timeout</a> (CSOT) is enabled
and the timeout has not yet expired, then the Driver MUST jump back to step 2b above in order to allow multiple retry
attempts.</p>
<p>Otherwise, drivers MUST update their topology according to the SDAM spec (see
<a href="retryable-reads/../server-discovery-and-monitoring/server-discovery-and-monitoring.html#error-handling">SDAM: Error Handling</a>). If an
error would not allow the caller to infer that an attempt was made (e.g. connection pool exception originating from the
driver), the previous error should be raised. If a retry failed due to another retryable error or some other error
originating from the server, that error should be raised instead as the caller can infer that an attempt was made and
the second error is likely more relevant (with respect to the current topology state).</p>
<p>If a driver associates server information (e.g. the server address or description) with an error, the driver MUST ensure
that the reported server information corresponds to the server that originated the error.</p>
<h5 id="4-implementation-constraints"><a class="header" href="#4-implementation-constraints">4. Implementation constraints</a></h5>
<p>When retrying a read command, drivers MUST NOT resend the original wire protocol message (see:
<a href="retryable-reads/retryable-reads.html#can-drivers-resend-the-same-wire-protocol-message-on-retry-attempts">Can drivers resend the same wire protocol message on retry attempts?</a>).</p>
<h4 id="pseudocode"><a class="header" href="#pseudocode">Pseudocode</a></h4>
<p>The following pseudocode for executing retryable read commands has been adapted from
<a href="retryable-reads/../retryable-writes/retryable-writes.html#executing-retryable-write-commands">the pseudocode for executing retryable write commands</a>
and reflects the flow described above.</p>
<pre><code class="language-typescript">/**
 * Checks if a connection supports retryable reads.
 */
function isRetryableReadsSupported(connection) {
  return connection.MaxWireVersion &gt;= RETRYABLE_READS_MIN_WIRE_VERSION);
}

/**
 * Executes a read command in the context of a MongoClient where a retryable
 * read have been enabled. The session parameter may be an implicit or
 * explicit client session (depending on how the CRUD method was invoked).
 */
function executeRetryableRead(command, session) {
  Exception previousError = null;
  retrying = false;
  Server previousServer = null;
  while true {
    if (previousError != null) {
      retrying = true;
    }
    try {
      if (previousServer == null) {
        server = selectServer();
      } else {
        // If a previous attempt was made, deprioritize the previous server
        // where the command failed.
        deprioritizedServers = [ previousServer ];
        server = selectServer(deprioritizedServers);
      }
    } catch (ServerSelectionException exception) {
      if (previousError == null) {
        // If this is the first attempt, propagate the exception.
        throw exception;
      }
      // For retries, propagate the previous error.
      throw previousError;
    }

    try {
      connection = server.getConnection();
    } catch (PoolClearedException poolClearedError) {
      /* PoolClearedException indicates the operation did not even attempt to
       * create a connection, let alone execute the operation. This means we
       * are always safe to attempt a retry. We do not need to update SDAM,
       * since whatever error caused the pool to be cleared will do so itself. */
      if (previousError == null) {
        previousError = poolClearedError;
      }
      /* CSOT is enabled and the operation has timed out. */
      if (timeoutMS != null &amp;&amp; isExpired(timeoutMS) {
        throw previousError;
      }
      continue;
    }

    if ( !isRetryableReadsSupported(connection) || session.inTransaction()) {
      /* If this is the first loop iteration and we determine that retryable
       * reads are not supported, execute the command once and allow any
       * errors to propagate */

      if (previousError == null) {
        return executeCommand(connection, command);
      }

      /* If the server selected for retrying is too old, throw the previous error.
       * The caller can then infer that an attempt was made and failed. This case
       * is very rare, and likely means that the cluster is in the midst of a
       * downgrade. */
      throw previousError;
    }

    /* NetworkException and NotWritablePrimaryException are both retryable errors. If
     * caught, remember the exception, update SDAM accordingly, and proceed with
     * retrying the operation.
     *
     * Exceptions that originate from the driver (e.g. no socket available
     * from the connection pool) are treated as fatal. Any such exception
     * that occurs on the previous attempt is propagated as-is. On retries,
     * the error from the previous attempt is raised as it will be more
     * relevant for the user. */
    try {
      return executeCommand(connection, retryableCommand);
    } catch (NetworkException networkError) {
      updateTopologyDescriptionForNetworkError(server, networkError);
      previousError = networkError;
      previousServer = server;
    } catch (NotWritablePrimaryException notPrimaryError) {
      updateTopologyDescriptionForNotWritablePrimaryError(server, notPrimaryError);
      previousError = notPrimaryError;
      previousServer = server;
    } catch (DriverException error) {
      if ( previousError != null ) {
        throw previousError;
      }
      throw error;
    }

    if (timeoutMS == null) {
      /* If CSOT is not enabled, allow any retryable error from the second
       * attempt to propagate to our caller, as it will be just as relevant
       * (if not more relevant) than the original error. */
      if (retrying) {
        throw previousError;
      }
    } else if (isExpired(timeoutMS)) {
      /* CSOT is enabled and the operation has timed out. */
      throw previousError;
    }
  }
}
</code></pre>
<h3 id="logging-retry-attempts"><a class="header" href="#logging-retry-attempts">Logging Retry Attempts</a></h3>
<p><a href="retryable-reads/../retryable-writes/retryable-writes.html#logging-retry-attempts">As with retryable writes</a>, drivers MAY choose to log
retry attempts for read operations. This specification does not define a format for such log messages.</p>
<h3 id="command-monitoring"><a class="header" href="#command-monitoring">Command Monitoring</a></h3>
<p><a href="retryable-reads/../retryable-writes/retryable-writes.html#command-monitoring">As with retryable writes</a>, in accordance with the
<a href="retryable-reads/../command-logging-and-monitoring/command-logging-and-monitoring.html">Command Logging and Monitoring</a> specification,
drivers MUST guarantee that each <code>CommandStartedEvent</code> has either a correlating <code>CommandSucceededEvent</code> or
<code>CommandFailedEvent</code> and that every "command started" log message has either a correlating "command succeeded" log
message or "command failed" log message. If the first attempt of a retryable read operation encounters a retryable
error, drivers MUST fire a <code>CommandFailedEvent</code> and emit a "command failed" log message for the retryable error and fire
a separate <code>CommandStartedEvent</code> and emit a separate "command started" log message when executing the subsequent retry
attempt. Note that the second <code>CommandStartedEvent</code> and "command started" log message may have a different
<code>connectionId</code>, since a server is reselected for a retry attempt.</p>
<h3 id="documentation-1"><a class="header" href="#documentation-1">Documentation</a></h3>
<ol>
<li>Drivers MUST document all read operations that support retryable behavior.</li>
<li>Drivers MUST document that the operations in <a href="retryable-reads/retryable-reads.html#unsupported-read-operations">Unsupported Read Operations</a> do not
support retryable behavior.</li>
<li>Driver release notes MUST make it clear to users that they may need to adjust custom retry logic to prevent an
application from inadvertently retrying for too long (see <a href="retryable-reads/retryable-reads.html#backwards-compatibility">Backwards Compatibility</a> for
details).</li>
<li>Drivers implementing retryability for their generic command runner for read commands MUST document that <code>mapReduce</code>
will be retried if it is passed as a command to the command runner. These drivers also MUST document the potential
for degraded performance given that "Early Failure on Socket Disconnect" feature does not support <code>mapReduce</code>.</li>
</ol>
<h2 id="test-plan-15"><a class="header" href="#test-plan-15">Test Plan</a></h2>
<p>See the <a href="retryable-reads/./tests/README.html">README</a> for tests.</p>
<p>At a high level, the test plan will cover executing supported read operations within a MongoClient where retryable reads
have been enabled, ensuring that reads are retried.</p>
<h2 id="motivation-for-change-11"><a class="header" href="#motivation-for-change-11">Motivation for Change</a></h2>
<p>Drivers currently have an API for the retryability of write operations but not for read operations. The driver API needs
to be extended to include support for retryable behavior for read operations.</p>
<h2 id="design-rationale-14"><a class="header" href="#design-rationale-14">Design Rationale</a></h2>
<p>The design of this specification is based off the
<a href="retryable-reads/../retryable-writes/retryable-writes.html#design-rationale">Retryable Writes specification</a>. It modifies the driver API
as little as possible to introduce the concept retryable behavior for read operations.</p>
<p>Alternative retry strategies (e.g. exponential back-off, incremental intervals, regular intervals, immediate retry,
randomization) were considered, but the behavior of a single, immediate retry attempt was chosen in the interests of
simplicity as well as consistency with the design for retryable writes.</p>
<p>See the <a href="retryable-reads/retryable-reads.html#future-work">future work</a> section for potential upcoming changes to retry mechanics.</p>
<h2 id="backwards-compatibility-12"><a class="header" href="#backwards-compatibility-12">Backwards Compatibility</a></h2>
<p>The API changes to support retryable reads extend the existing API but do not introduce any backward breaking changes.
Existing programs that do not make use of retryable reads will continue to compile and run correctly.</p>
<p>N.B.: Applications with custom retry logic that choose to enable retryable reads may need to redo their custom retry
logic to ensure that the reads are retried as desired. e.g. if an application has custom logic that retries reads n
times and enables retryable reads, then the application could end up retrying reads up to 2n times.</p>
<p>The note above will also apply if an application upgrades to a version of the driver where that defaults to enabling
retryable reads.</p>
<h3 id="rejected-designs"><a class="header" href="#rejected-designs">Rejected Designs</a></h3>
<ol>
<li>To improve performance on servers without "Early Failure on Socket Disconnect", we considered using <code>killSessions</code> to
automatically kill the previous attempt before running a retry. We decided against this because after killing the
session, parts of it still may be running if there are any errors. Additionally, killing sessions takes time because
a kill has to talk to every non-config <code>mongod</code> in the cluster (i.e. all the primaries and secondaries of each
shard). In addition, in order to protect the system against getting overloaded with these requests, every server
allows no more than one killsession operation at a time. Operations that attempt to <code>killsessions</code> while a
killsession is running are batched together and run simultaneously after the current one finishes.</li>
</ol>
<h2 id="reference-implementation-10"><a class="header" href="#reference-implementation-10">Reference Implementation</a></h2>
<p>The C# and Python drivers will provide the reference implementations. See
<a href="https://jira.mongodb.org/browse/CSHARP-2429">CSHARP-2429</a> and
<a href="https://jira.mongodb.org/browse/PYTHON-1674">PYTHON-1674</a>.</p>
<h2 id="security-implications-1"><a class="header" href="#security-implications-1">Security Implications</a></h2>
<p>None.</p>
<h2 id="future-work-9"><a class="header" href="#future-work-9">Future work</a></h2>
<ol>
<li>A later specification may allow operations (including read) to be retried any number of times during a singular
timeout period.</li>
<li>Any future changes to the the applicable parts of
<a href="retryable-reads/../retryable-writes/retryable-writes.html">retryable writes specification</a> may also need to be reflected in the
retryable reads specification, and vice versa.</li>
<li>We may revisit the decision not retry <code>Cursor.getMore()</code> (see <a href="retryable-reads/retryable-reads.html#qa">Q&amp;A</a>).</li>
<li>Once <a href="https://jira.mongodb.org/browse/DRIVERS-560">DRIVERS-560</a> is resolved, tests will be added to allow testing
Retryable Reads on MongoDB 3.6. See the <a href="retryable-reads/./tests/README.html">test plan</a> for additional information.</li>
</ol>
<h2 id="qa-7"><a class="header" href="#qa-7">Q&amp;A</a></h2>
<h3 id="why-is-retrying-cursorgetmore-not-supported"><a class="header" href="#why-is-retrying-cursorgetmore-not-supported">Why is retrying <code>Cursor.getMore()</code> not supported?</a></h3>
<p><code>Cursor.getMore()</code> cannot be retried because of the inability for the client to discern if the cursor was advanced. In
other words, since the driver does not know if the original <code>getMore()</code> succeeded or not, the driver cannot reliably
know if results might be inadvertently skipped.</p>
<p>For example, if a transient network error occurs as a driver requests the second batch of results via a getMore() and
the driver were to silently retry the <code>getMore()</code>, it is possible that the server had actually received the initial
<code>getMore()</code>. In such a case, the server will advance the cursor once more and return the third batch instead of the
desired second batch.</p>
<p>Furthermore, even if the driver could detect such a scenario, it is impossible to return previously iterated data from a
cursor because the server currently only allows forward iteration.</p>
<p>It is worth noting that the "Cursors survive primary stepdown" feature avoids this issue in certain common
circumstances, so that we may revisit this decision to disallow trying <code>getMore()</code> in the future.</p>
<h3 id="why-are-read-operations-only-retried-once-by-default"><a class="header" href="#why-are-read-operations-only-retried-once-by-default">Why are read operations only retried once by default?</a></h3>
<p><a href="retryable-reads/../retryable-writes/retryable-writes.html#why-are-write-operations-only-retried-once-by-default">Read operations are only retried once for the same reasons that writes are also only retried once.</a>
For convenience's sake, that reasoning has been adapted for reads and reproduced below:</p>
<p>The spec concerns itself with retrying read operations that encounter a retryable error (i.e. no response due to network
error or a response indicating that the node is no longer a primary). A retryable error may be classified as either a
transient error (e.g. dropped connection, replica set failover) or persistent outage. If a transient error results in
the server being marked as "unknown", a subsequent retry attempt will allow the driver to rediscover the primary within
the designated server selection timeout period (30 seconds by default). If server selection times out during this retry
attempt, we can reasonably assume that there is a persistent outage. In the case of a persistent outage, multiple retry
attempts are fruitless and would waste time. See
<a href="https://emptysqua.re/blog/how-to-write-resilient-mongodb-applications/">How To Write Resilient MongoDB Applications</a>
for additional discussion on this strategy.</p>
<p>However when <a href="retryable-reads/../client-side-operations-timeout/client-side-operations-timeout.html">Client Side Operations Timeout</a> is
enabled, the driver will retry multiple times until the operation succeeds, a non-retryable error is encountered, or the
timeout expires. Retrying multiple times provides greater resilience to cascading failures such as rolling server
restarts during planned maintenance events.</p>
<h3 id="can-drivers-resend-the-same-wire-protocol-message-on-retry-attempts"><a class="header" href="#can-drivers-resend-the-same-wire-protocol-message-on-retry-attempts">Can drivers resend the same wire protocol message on retry attempts?</a></h3>
<p>No.
<a href="retryable-reads/../retryable-writes/retryable-writes.html#can-drivers-resend-the-same-wire-protocol-message-on-retry-attempts">This is in contrast to the answer supplied in in the retryable writes specification.</a>
However, when retryable writes were implemented, no driver actually chose to resend the same wire protocol message.
Today, if a driver attempted to resend the same wire protocol message, this could violate
<a href="retryable-reads/../sessions/driver-sessions.html#gossipping-the-cluster-time">the rules for gossiping $clusterTime</a>: specifically
<a href="retryable-reads/../sessions/driver-sessions.html#sending-the-highest-seen-cluster-time">the rule that a driver must send the highest seen $clusterTime</a>.</p>
<p>Additionally, there would be a behavioral difference between a driver resending the same wire protocol message and one
that does not. For example, a driver that creates a new wire protocol message could exhibit the following
characteristics:</p>
<ol>
<li>The second attempt to send the read command could have a higher <code>$clusterTime</code>.</li>
<li>If the initial attempt failed with a server error, then the session's <code>operationTime</code> would be advanced and the next
read would include a larger <code>readConcern.afterClusterTime</code>.</li>
</ol>
<p>A driver that resends the same wire protocol message would not exhibit the above characteristics. Thus, in order to
avoid this behavioral difference and not violate the rules about gossiping <code>$clusterTime</code>, drivers MUST not resend the
same wire protocol message.</p>
<h3 id="why-isnt-mongodb-42-required"><a class="header" href="#why-isnt-mongodb-42-required">Why isn't MongoDB 4.2 required?</a></h3>
<p>MongoDB 4.2 was initially considered as a requirement for retryable reads because MongoDB 4.2 implements support for
"Early Failure on Socket Disconnect," changing the the semantics of socket disconnect to prevent ops from doing work
that no client is interested in. This prevents applications from seeing degraded performance when an expensive read is
retried. Upon further discussion, we decided that "Early Failure on Socket Disconnect" should not be required to retry
reads because the resilience benefit of retryable reads outweighs the minor risk of degraded performance. Additionally,
any customers experiencing degraded performance can simply disable <code>retryableReads</code>.</p>
<h2 id="changelog-21"><a class="header" href="#changelog-21">Changelog</a></h2>
<ul>
<li>
<p>2024-04-30: Migrated from reStructuredText to Markdown.</p>
</li>
<li>
<p>2023-12-05: Add that any server information associated with retryable exceptions MUST reflect the originating server,
even in the presence of retries.</p>
</li>
<li>
<p>2023-11-30: Add ReadConcernMajorityNotAvailableYet to the list of error codes that should be retried.</p>
</li>
<li>
<p>2023-11-28: Add ExceededTimeLimit to the list of error codes that should be retried.</p>
</li>
<li>
<p>2023-08-26: Require that in a sharded cluster the server on which the operation failed MUST be provided to the server
selection mechanism as a deprioritized server.</p>
</li>
<li>
<p>2023-08-21: Update Q&amp;A that contradicts SDAM transient error logic</p>
</li>
<li>
<p>2022-11-09: CLAM must apply both events and log messages.</p>
</li>
<li>
<p>2022-10-18: When CSOT is enabled multiple retry attempts may occur.</p>
</li>
<li>
<p>2022-10-05: Remove spec front matter, move footnote, and reformat changelog.</p>
</li>
<li>
<p>2022-01-25: Note that drivers should retry handshake network failures.</p>
</li>
<li>
<p>2021-04-26: Replaced deprecated terminology; removed requirement to parse error message text as MongoDB 3.6+ servers
will always return an error code</p>
</li>
<li>
<p>2021-03-23: Require that PoolClearedErrors are retried</p>
</li>
<li>
<p>2019-06-07: Mention $merge stage for aggregate alongside $out</p>
</li>
<li>
<p>2019-05-29: Renamed InterruptedDueToStepDown to InterruptedDueToReplStateChange</p>
</li>
</ul>
<div class="footnote-definition" id="1"><sup class="footnote-definition-label">1</sup>
<p>The first and second commands will be identical unless variations in parameters exist between wire/server versions.</p>
</div>
<div style="break-before: page; page-break-before: always;"></div><h1 id="retryable-writes"><a class="header" href="#retryable-writes">Retryable Writes</a></h1>
<ul>
<li>Status: Accepted</li>
<li>Minimum Server Version: 3.6</li>
</ul>
<hr />
<h2 id="abstract-22"><a class="header" href="#abstract-22">Abstract</a></h2>
<p>MongoDB 3.6 will implement support for server sessions, which are shared resources within a cluster identified by a
session ID. Drivers compatible with MongoDB 3.6 will also implement support for client sessions, which are always
associated with a server session and will allow for certain commands to be executed within the context of a server
session.</p>
<p>Additionally, MongoDB 3.6 will utilize server sessions to allow some write commands to specify a transaction ID to
enforce at-most-once semantics for the write operation(s) and allow for retrying the operation if the driver fails to
obtain a write result (e.g. network error or "not writable primary" error after a replica set failover). This
specification will outline how an API for retryable write operations will be implemented in drivers. The specification
will define an option to enable retryable writes for an application and describe how a transaction ID will be provided
to write commands executed therein.</p>
<h2 id="meta-22"><a class="header" href="#meta-22">META</a></h2>
<p>The keywords "MUST", "MUST NOT", "REQUIRED", "SHALL", "SHALL NOT", "SHOULD", "SHOULD NOT", "RECOMMENDED", "MAY", and
"OPTIONAL" in this document are to be interpreted as described in <a href="https://www.ietf.org/rfc/rfc2119.txt">RFC 2119</a>.</p>
<h2 id="specification-20"><a class="header" href="#specification-20">Specification</a></h2>
<h3 id="terms-12"><a class="header" href="#terms-12">Terms</a></h3>
<p><strong>Transaction ID</strong></p>
<p>The transaction ID identifies the transaction as part of which the command is running. In a write command where the
client has requested retryable behavior, it is expressed by the top-level <code>lsid</code> and <code>txnNumber</code> fields. The <code>lsid</code>
component is the corresponding server session ID. which is a BSON value defined in the
<a href="retryable-writes/../sessions/driver-sessions.html">Driver Session</a> specification. The <code>txnNumber</code> component is a monotonically increasing
(per server session), positive 64-bit integer.</p>
<p><strong>ClientSession</strong></p>
<p>Driver object representing a client session, which is defined in the <a href="retryable-writes/../sessions/driver-sessions.html">Driver Session</a>
specification. This object is always associated with a server session; however, drivers will pool server sessions so
that creating a ClientSession will not always entail creation of a new server session. The name of this object MAY vary
across drivers.</p>
<p><strong>Retryable Error</strong></p>
<p>An error is considered retryable if it has a RetryableWriteError label in its top-level "errorLabels" field. See
<a href="retryable-writes/retryable-writes.html#determining-retryable-errors">Determining Retryable Errors</a> for more information.</p>
<p>Additional terms may be defined in the <a href="retryable-writes/../sessions/driver-sessions.html">Driver Session</a> specification.</p>
<h3 id="naming-deviations-3"><a class="header" href="#naming-deviations-3">Naming Deviations</a></h3>
<p>This specification defines the name for a new MongoClient option, <code>retryWrites</code>. Drivers MUST use the defined name for
the connection string parameter to ensure portability of connection strings across applications and drivers.</p>
<p>If drivers solicit MongoClient options through another mechanism (e.g. options dictionary provided to the MongoClient
constructor), drivers SHOULD use the defined name but MAY deviate to comply with their existing conventions. For
example, a driver may use <code>retry_writes</code> instead of <code>retryWrites</code>.</p>
<p>For any other names in the spec, drivers SHOULD use the defined name but MAY deviate to comply with their existing
conventions.</p>
<h3 id="mongoclient-configuration-6"><a class="header" href="#mongoclient-configuration-6">MongoClient Configuration</a></h3>
<p>This specification introduces the following client-level configuration option.</p>
<h4 id="retrywrites"><a class="header" href="#retrywrites">retryWrites</a></h4>
<p>This boolean option determines whether retryable behavior will be applied to all supported write operations executed
within the MongoClient. This option MUST default to true.</p>
<p>This option MUST NOT be configurable at the level of a database object, collection object, or at the level of an
individual write operation.</p>
<h3 id="requirements-for-retryable-writes"><a class="header" href="#requirements-for-retryable-writes">Requirements for Retryable Writes</a></h3>
<h4 id="supported-server-versions-1"><a class="header" href="#supported-server-versions-1">Supported Server Versions</a></h4>
<p>Like sessions, retryable writes require a MongoDB 3.6 replica set or shard cluster operating with feature compatibility
version 3.6 (i.e. the <code>{setFeatureCompatibilityVersion: 3.6}</code> administrative command has been run on the cluster).
Drivers MUST verify server eligibility by ensuring that <code>maxWireVersion</code> is at least six, the
<code>logicalSessionTimeoutMinutes</code> field is present in the server's <code>hello</code> or legacy hello response, and the server type is
not standalone.</p>
<p>Retryable writes are only supported by storage engines that support document-level locking. Notably, that excludes the
MMAPv1 storage engine which is available in both MongoDB 3.6 and 4.0. Since <code>retryWrites</code> defaults to <code>true</code>, Drivers
MUST raise an actionable error message when the server returns code 20 with errmsg starting with "Transaction numbers".
The replacement error message MUST be:</p>
<pre><code>This MongoDB deployment does not support retryable writes. Please add
retryWrites=false to your connection string.
</code></pre>
<p>If the server selected for the first attempt of a retryable write operation does not support retryable writes, drivers
MUST execute the write as if retryable writes were not enabled. Drivers MUST NOT include a transaction ID in the write
command and MUST not retry the command under any circumstances.</p>
<p>In a sharded cluster, it is possible that mongos may appear to support retryable writes but one or more shards in the
cluster do not (e.g. replica set shard is configured with feature compatibility version 3.4, a standalone is added as a
new shard). In these rare cases, a write command that fans out to a shard that does not support retryable writes may
partially fail and an error may be reported in the write result from mongos (e.g. <code>writeErrors</code> array in the bulk write
result). This does not constitute a retryable error. Drivers MUST relay such errors to the user.</p>
<h4 id="supported-write-operations"><a class="header" href="#supported-write-operations">Supported Write Operations</a></h4>
<p>MongoDB 3.6 will support retryability for some, but not all, write operations.</p>
<p>Supported single-statement write operations include <code>insertOne()</code>, <code>updateOne()</code>, <code>replaceOne()</code>, <code>deleteOne()</code>,
<code>findOneAndDelete()</code>, <code>findOneAndReplace()</code>, and <code>findOneAndUpdate()</code>.</p>
<p>Supported multi-statement write operations include <code>insertMany()</code> and <code>bulkWrite()</code>. The ordered option may be <code>true</code> or
<code>false</code>. For both the collection-level and client-level <code>bulkWrite()</code> methods, a bulk write batch is only retryable if
it does not contain any <code>multi: true</code> writes (i.e. <code>UpdateMany</code> and <code>DeleteMany</code>). Drivers MUST evaluate eligibility for
each write command sent as part of the <code>bulkWrite()</code> (after order and batch splitting) individually. Drivers MUST NOT
alter existing logic for order and batch splitting in an attempt to maximize retryability for operations within a bulk
write.</p>
<p>These methods above are defined in the <a href="retryable-writes/../crud/crud.html">CRUD</a> specification.</p>
<p>Later versions of MongoDB may add support for additional write operations.</p>
<p>Drivers MUST document operations that support retryable behavior and the conditions for which retryability is determined
(see: <a href="retryable-writes/retryable-writes.html#how-will-users-know-which-operations-are-supported">How will users know which operations are supported?</a>).
Drivers are not required to exhaustively document all operations that do not support retryable behavior.</p>
<h4 id="unsupported-write-operations"><a class="header" href="#unsupported-write-operations">Unsupported Write Operations</a></h4>
<p>Write commands specifying an unacknowledged write concern (e.g. <code>{w: 0})</code>) do not support retryable behavior. Drivers
MUST NOT add a transaction ID to any write command with an unacknowledged write concern executed within a MongoClient
where retryable writes have been enabled. Drivers MUST NOT retry these commands.</p>
<p>Write commands where a single statement might affect multiple documents will not be initially supported by MongoDB 3.6,
although this may change in the future. This includes an
<a href="https://www.mongodb.com/docs/manual/reference/command/update/">update</a> command where any statement in the updates
sequence specifies a <code>multi</code> option of <code>true</code> or a
<a href="https://www.mongodb.com/docs/manual/reference/command/delete/">delete</a> command where any statement in the <code>deletes</code>
sequence specifies a <code>limit</code> option of <code>0</code>. In the context of the <a href="retryable-writes/../crud/crud.html">CRUD</a> specification, this includes
the <code>updateMany()</code> and <code>deleteMany()</code> methods and, in some cases, <code>bulkWrite()</code>. Drivers MUST NOT add a transaction ID
to any single- or multi-statement write commands that include one or more multi-document write operations. Drivers MUST
NOT retry these commands if they fail to return a response. With regard to <code>bulkWrite()</code>, drivers MUST evaluate
eligibility for each write command sent as part of the <code>bulkWrite()</code> (after order and batch splitting) individually.</p>
<p>Write commands other than <a href="https://www.mongodb.com/docs/manual/reference/command/insert/">insert</a>,
<a href="https://www.mongodb.com/docs/manual/reference/command/update/">update</a>,
<a href="https://www.mongodb.com/docs/manual/reference/command/delete/">delete</a>, or
<a href="https://www.mongodb.com/docs/manual/reference/command/findAndModify/">findAndModify</a> will not be initially supported by
MongoDB 3.6, although this may change in the future. This includes, but is not limited to, an
<a href="https://www.mongodb.com/docs/manual/reference/command/aggregate/">aggregate</a> command using a write stage (e.g. <code>$out</code>,
<code>$merge</code>). Drivers MUST NOT add a transaction ID to these commands and MUST NOT retry these commands if they fail to
return a response.</p>
<h4 id="retryable-writes-within-transactions"><a class="header" href="#retryable-writes-within-transactions">Retryable Writes Within Transactions</a></h4>
<p>In MongoDB 4.0 the only supported retryable write commands within a transaction are <code>commitTransaction</code> and
<code>abortTransaction</code>. Therefore drivers MUST NOT retry write commands within transactions even when <code>retryWrites</code> has been
set to true on the <code>MongoClient</code>. In addition, drivers MUST NOT add the <code>RetryableWriteError</code> label to any error that
occurs during a write command within a transaction (excepting <code>commitTransation</code> and <code>abortTransaction</code>), even when
<code>retryWrites</code> has been set to true on the <code>MongoClient</code>.</p>
<h3 id="implementing-retryable-writes"><a class="header" href="#implementing-retryable-writes">Implementing Retryable Writes</a></h3>
<h4 id="determining-retryable-errors"><a class="header" href="#determining-retryable-errors">Determining Retryable Errors</a></h4>
<p>When connected to a MongoDB instance that supports retryable writes (versions 3.6+), the driver MUST treat all errors
with the RetryableWriteError label as retryable. This error label can be found in the top-level "errorLabels" field of
the error.</p>
<h5 id="retryablewriteerror-labels"><a class="header" href="#retryablewriteerror-labels">RetryableWriteError Labels</a></h5>
<p>The RetryableWriteError label might be added to an error in a variety of ways:</p>
<ul>
<li>
<p>When the driver encounters a network error establishing an initial connection to a server, it MUST add a
RetryableWriteError label to that error if the MongoClient performing the operation has the retryWrites configuration
option set to true.</p>
</li>
<li>
<p>When the driver encounters a network error communicating with any server version that supports retryable writes, it
MUST add a RetryableWriteError label to that error if the MongoClient performing the operation has the retryWrites
configuration option set to true.</p>
</li>
<li>
<p>When a CMAP-compliant driver encounters a
<a href="retryable-writes/../connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection-pool-errors">PoolClearedError</a>
during connection check out, it MUST add a RetryableWriteError label to that error if the MongoClient performing the
operation has the retryWrites configuration option set to true.</p>
</li>
<li>
<p>For server versions 4.4 and newer, the server will add a RetryableWriteError label to errors or server responses that
it considers retryable before returning them to the driver. As new server versions are released, the errors that are
labeled with the RetryableWriteError label may change. Drivers MUST NOT add a RetryableWriteError label to any error
derived from a 4.4+ server response (i.e. any error that is not a network error).</p>
</li>
<li>
<p>When receiving a command result with an error from a pre-4.4 server that supports retryable writes, the driver MUST
add a RetryableWriteError label to errors that meet the following criteria if the retryWrites option is set to true on
the client performing the relevant operation:</p>
<ul>
<li>
<p>a mongod or mongos response with any the following error codes in the top-level <code>code</code> field:</p>
<div class="table-wrapper"><table><thead><tr><th>Error Name</th><th>Error Code</th></tr></thead><tbody>
<tr><td>InterruptedAtShutdown</td><td>11600</td></tr>
<tr><td>InterruptedDueToReplStateChange</td><td>11602</td></tr>
<tr><td>NotWritablePrimary</td><td>10107</td></tr>
<tr><td>NotPrimaryNoSecondaryOk</td><td>13435</td></tr>
<tr><td>NotPrimaryOrSecondary</td><td>13436</td></tr>
<tr><td>PrimarySteppedDown</td><td>189</td></tr>
<tr><td>ShutdownInProgress</td><td>91</td></tr>
<tr><td>HostNotFound</td><td>7</td></tr>
<tr><td>HostUnreachable</td><td>6</td></tr>
<tr><td>NetworkTimeout</td><td>89</td></tr>
<tr><td>SocketException</td><td>9001</td></tr>
<tr><td>ExceededTimeLimit</td><td>262</td></tr>
</tbody></table>
</div></li>
<li>
<p>a mongod response with any of the previously listed codes in the <code>writeConcernError.code</code> field.</p>
</li>
</ul>
<p>Drivers MUST NOT add a RetryableWriteError label based on the following:</p>
<ul>
<li>any <code>writeErrors[].code</code> fields in a mongod or mongos response</li>
<li>the <code>writeConcernError.code</code> field in a mongos response</li>
</ul>
<p>The criteria for retryable errors is similar to the discussion in the SDAM spec's section on
<a href="retryable-writes/../server-discovery-and-monitoring/server-discovery-and-monitoring.html#error-handling">Error Handling</a>, but includes
additional error codes. See <a href="retryable-writes/retryable-writes.html#what-do-the-additional-error-codes-mean">What do the additional error codes mean?</a> for
the reasoning behind these additional errors.</p>
</li>
</ul>
<p>To understand why the driver should only add the RetryableWriteError label to an error when the retryWrites option is
true on the MongoClient performing the operation, see
<a href="retryable-writes/retryable-writes.html#why-does-the-driver-only-add-the-retryablewriteerror-label-to-errors-that-occur-on-a-mongoclient-with-retrywrites-set-to-true">Why does the driver only add the RetryableWriteError label to errors that occur on a MongoClient with retryWrites set to true?</a></p>
<p>Note: During a retryable write operation on a sharded cluster, mongos may retry the operation internally, in which case
it will not add a RetryableWriteError label to any error that occurs after those internal retries to prevent excessive
retrying.</p>
<p>For more information about error labels, see the
<a href="retryable-writes/../transactions/transactions.html#error-labels">Transactions specification</a>.</p>
<h4 id="generating-transaction-ids"><a class="header" href="#generating-transaction-ids">Generating Transaction IDs</a></h4>
<p>The server requires each retryable write operation to provide a unique transaction ID in its command document. The
transaction ID consists of a server session ID and a monotonically increasing transaction number. The session ID is
obtained from the ClientSession object, which will have either been passed to the write operation from the application
or constructed internally for the operation. Drivers will be responsible for maintaining a monotonically increasing
transaction number for each server session used by a ClientSession object. Drivers that pool server sessions MUST
preserve the transaction number when reusing a server session from the pool with a new ClientSession (this can be
tracked as another property on the driver's object for the server session).</p>
<p>Drivers MUST ensure that each retryable write command specifies a transaction number larger than any previously used
transaction number for its session ID.</p>
<p>Since ClientSession objects are not thread safe and may only be used by one thread at a time, drivers should not need to
worry about race conditions when incrementing the transaction number.</p>
<h4 id="behavioral-changes-for-write-commands"><a class="header" href="#behavioral-changes-for-write-commands">Behavioral Changes for Write Commands</a></h4>
<p>Drivers MUST automatically add a transaction ID to all supported write commands executed via a specific
<a href="retryable-writes/../crud/crud.html">CRUD</a> method (e.g. <code>updateOne()</code>) or write command method (e.g. <code>executeWriteCommand()</code>) within a
MongoClient where retryable writes have been enabled and when the selected server supports retryable writes.</p>
<p>If your driver offers a generic command method on your database object (e.g. <code>runCommand()</code>), it MUST NOT check the
user's command document to determine if it is a supported write operation and MUST NOT automatically add a transaction
ID. The method should send the user's command document to the server as-is.</p>
<p>This specification does not affect write commands executed within a MongoClient where retryable writes have not been
enabled.</p>
<h4 id="constructing-write-commands"><a class="header" href="#constructing-write-commands">Constructing Write Commands</a></h4>
<p>When constructing a supported write command that will be executed within a MongoClient where retryable writes have been
enabled, drivers MUST increment the transaction number for the corresponding server session and include the server
session ID and transaction number in top-level <code>lsid</code> and <code>txnNumber</code> fields, respectively. <code>lsid</code> is a BSON value
(discussed in the <a href="retryable-writes/../sessions/driver-sessions.html">Driver Session</a> specification). <code>txnNumber</code> MUST be a positive 64-bit
integer (BSON type 0x12).</p>
<p>The following example illustrates a possible write command for an <code>updateOne()</code> operation:</p>
<pre><code class="language-typescript">{
  update: "coll",
  lsid: { ... },
  txnNumber: 100,
  updates: [
    { q: { x: 1 }, u: { $inc: { y: 1 } } },
  ],
  ordered: true
}
</code></pre>
<p>When constructing multiple write commands for a multi-statement write operation (i.e. <code>insertMany()</code> and <code>bulkWrite()</code>),
drivers MUST increment the transaction number for each supported write command in the batch.</p>
<h4 id="executing-retryable-write-commands"><a class="header" href="#executing-retryable-write-commands">Executing Retryable Write Commands</a></h4>
<p>When selecting a writable server for the first attempt of a retryable write command, drivers MUST allow a server
selection error to propagate. In this case, the caller is able to infer that no attempt was made.</p>
<p>If retryable writes is not enabled or the selected server does not support retryable writes, drivers MUST NOT include a
transaction ID in the command and MUST attempt to execute the write command exactly once and allow any errors to
propagate. In this case, the caller is able to infer that an attempt was made.</p>
<p>If retryable writes are enabled and the selected server supports retryable writes, drivers MUST add a transaction ID to
the command. Drivers MUST only attempt to retry a write command if the first attempt yields a retryable error. Drivers
MUST NOT attempt to retry a write command on any other error.</p>
<p>If the first attempt of a write command including a transaction ID encounters a retryable error, the driver MUST update
its topology according to the SDAM spec (see:
<a href="retryable-writes/../server-discovery-and-monitoring/server-discovery-and-monitoring.html#error-handling">Error Handling</a>) and capture this
original retryable error.</p>
<p>Drivers MUST then retry the operation as many times as necessary until any one of the following conditions is reached:</p>
<ul>
<li>the operation succeeds.</li>
<li>the operation fails with a non-retryable error.</li>
<li>CSOT is enabled and the operation times out per
<a href="retryable-writes/../client-side-operations-timeout/client-side-operations-timeout.html#retryability">Client Side Operations Timeout: Retryability</a>.</li>
<li>CSOT is not enabled and one retry was attempted.</li>
</ul>
<p>For each retry attempt, drivers MUST select a writable server. In a sharded cluster, the server on which the operation
failed MUST be provided to the server selection mechanism as a deprioritized server.</p>
<p>If the driver cannot select a server for a retry attempt or the selected server does not support retryable writes,
retrying is not possible and drivers MUST raise the retryable error from the previous attempt. In both cases, the caller
is able to infer that an attempt was made.</p>
<p>If a retry attempt also fails, drivers MUST update their topology according to the SDAM spec (see:
<a href="retryable-writes/../server-discovery-and-monitoring/server-discovery-and-monitoring.html#error-handling">Error Handling</a>). If an error
would not allow the caller to infer that an attempt was made (e.g. connection pool exception originating from the
driver) or the error is labeled "NoWritesPerformed", the error from the previous attempt should be raised. If all server
errors are labeled "NoWritesPerformed", then the first error should be raised.</p>
<p>If a driver associates server information (e.g. the server address or description) with an error, the driver MUST ensure
that the reported server information corresponds to the server that originated the error.</p>
<p>The above rules are implemented in the following pseudo-code:</p>
<pre><code class="language-typescript">/**
 * Checks if a server supports retryable writes.
 */
function isRetryableWritesSupported(server) {
  if (server.getMaxWireVersion() &lt; RETRYABLE_WIRE_VERSION) {
    return false;
  }

  if ( ! server.hasLogicalSessionTimeoutMinutes()) {
    return false;
  }

  if (server.isStandalone()) {
    return false;
  }

  return true;
}

/**
 * Executes a write command in the context of a MongoClient where retryable
 * writes have been enabled. The session parameter may be an implicit or
 * explicit client session (depending on how the CRUD method was invoked).
 */
function executeRetryableWrite(command, session) {
  /* Allow ServerSelectionException to propagate to our caller, which can then
   * assume that no attempts were made. */
  server = selectServer("writable");

  /* If the server does not support retryable writes, execute the write as if
   * retryable writes are not enabled. */
  if ( ! isRetryableWritesSupported(server)) {
    return executeCommand(server, command);
  }

  /* Incorporate lsid and txnNumber fields into the command document. These
   * values will be derived from the implicit or explicit session object. */
  retryableCommand = addTransactionIdToCommand(command, session);

  Exception previousError = null;
  retrying = false;
  while true {
    try {
      return executeCommand(server, retryableCommand);
    } catch (Exception currentError) {
      handleError(currentError);

      /* If the error has a RetryableWriteError label, remember the exception
       * and proceed with retrying the operation.
       *
       * IllegalOperation (code 20) with errmsg starting with "Transaction
       * numbers" MUST be re-raised with an actionable error message.
       */
      if (!currentError.hasErrorLabel("RetryableWriteError")) {
        if ( currentError.code == 20 &amp;&amp; previousError.errmsg.startsWith("Transaction numbers") ) {
          currentError.errmsg = "This MongoDB deployment does not support retryable...";
        }
        throw currentError;
      }

      /*
       * If the "previousError" is "null", then the "currentError" is the
       * first error encountered during the retry attempt cycle. We must
       * persist the first error in the case where all succeeding errors are
       * labeled "NoWritesPerformed", which would otherwise raise "null" as
       * the error.
       */
      if (previousError == null) {
        previousError = currentError;
      }

      /*
       * For exceptions that originate from the driver (e.g. no socket available
       * from the connection pool), we should raise the previous error if there
       * was one.
       */
      if (currentError is not DriverException &amp;&amp; ! previousError.hasErrorLabel("NoWritesPerformed")) {
        previousError = currentError;
      }
    }

    /*
     * We try to select server that is not the one that failed by passing the
     * failed server as a deprioritized server.
     * If we cannot select a writable server, do not proceed with retrying and
     * throw the previous error. The caller can then infer that an attempt was
     * made and failed. */
    try {
      deprioritizedServers = [ server ];
      server = selectServer("writable", deprioritizedServers);
    } catch (Exception ignoredError) {
      throw previousError;
    }

    /* If the server selected for retrying is too old, throw the previous error.
     * The caller can then infer that an attempt was made and failed. This case
     * is very rare, and likely means that the cluster is in the midst of a
     * downgrade. */
    if ( ! isRetryableWritesSupported(server)) {
      throw previousError;
    }

    if (timeoutMS == null) {
      /* If CSOT is not enabled, allow any retryable error from the second
       * attempt to propagate to our caller, as it will be just as relevant
       * (if not more relevant) than the original error. */
      if (retrying) {
        throw previousError;
      }
    } else if (isExpired(timeoutMS)) {
      /* CSOT is enabled and the operation has timed out. */
      throw previousError;
    }
    retrying = true;
  }
}
</code></pre>
<p><code>handleError</code> in the above pseudocode refers to the function defined in the
<a href="retryable-writes/../server-discovery-and-monitoring/server-discovery-and-monitoring.html#error-handling-pseudocode">Error handling pseudocode</a>
section of the SDAM specification.</p>
<p>When retrying a write command, drivers MUST resend the command with the same transaction ID. Drivers MUST NOT resend the
original wire protocol message if doing so would violate rules for
<a href="retryable-writes/../sessions/driver-sessions.html#gossipping-the-cluster-time">gossipping the cluster time</a> (see:
<a href="retryable-writes/retryable-writes.html#can-drivers-resend-the-same-wire-protocol-message-on-retry-attempts">Can drivers resend the same wire protocol message on retry attempts?</a>).</p>
<p>In the case of a multi-statement write operation split across multiple write commands, a failed retry attempt will also
interrupt execution of any additional write operations in the batch (regardless of the ordered option). This is no
different than if a retryable error had been encountered without retryable behavior enabled or supported by the driver.
Drivers are encouraged to provide access to an intermediary write result (e.g. BulkWriteResult, InsertManyResult)
through the BulkWriteException, in accordance with the <a href="retryable-writes/../crud/crud.html">CRUD</a> specification.</p>
<h2 id="logging-retry-attempts-1"><a class="header" href="#logging-retry-attempts-1">Logging Retry Attempts</a></h2>
<p>Drivers MAY choose to log retry attempts for write operations. This specification does not define a format for such log
messages.</p>
<h2 id="command-monitoring-1"><a class="header" href="#command-monitoring-1">Command Monitoring</a></h2>
<p>In accordance with the
<a href="retryable-writes/../command-logging-and-monitoring/command-logging-and-monitoring.html">Command Logging and Monitoring</a> specification,
drivers MUST guarantee that each <code>CommandStartedEvent</code> has either a correlating <code>CommandSucceededEvent</code> or
<code>CommandFailedEvent</code> and that every "command started" log message has either a correlating "command succeeded" log
message or "command failed" log message. If the first attempt of a retryable write operation encounters a retryable
error, drivers MUST fire a <code>CommandFailedEvent</code> and emit a "command failed" log message for the retryable error and fire
a separate <code>CommandStartedEvent</code> and "command succeeded" log message when executing the subsequent retry attempt. Note
that the second <code>CommandStartedEvent</code> and "command succeeded" log message may have a different <code>connectionId</code>, since a
writable server is reselected for the retry attempt.</p>
<p>Each attempt of a retryable write operation SHOULD report a different <code>requestId</code> so that events for each attempt can be
properly correlated with one another.</p>
<p>The <a href="retryable-writes/../command-logging-and-monitoring/command-logging-and-monitoring.html">Command Logging and Monitoring</a> specification
states that the <code>operationId</code> field is a driver-generated, 64-bit integer and may be "used to link events together such
as bulk write operations." Each attempt of a retryable write operation SHOULD report the same <code>operationId</code>; however,
drivers SHOULD NOT use the <code>operationId</code> field to relay information about a transaction ID. A bulk write operation may
consist of multiple write commands, each of which may specify a unique transaction ID.</p>
<h2 id="test-plan-16"><a class="header" href="#test-plan-16">Test Plan</a></h2>
<p>See the <a href="retryable-writes/tests/README.html">README</a> for tests.</p>
<p>At a high level, the test plan will cover the following scenarios for executing supported write operations within a
MongoClient where retryable writes have been enabled:</p>
<ul>
<li>Executing the same write operation (and transaction ID) multiple times should yield an identical write result.</li>
<li>Test at-most-once behavior by observing that subsequent executions of the same write operation do not incur further
modifications to the collection data.</li>
<li>Exercise supported single-statement write operations (i.e. deleteOne, insertOne, replaceOne, updateOne, and
findAndModify).</li>
<li>Exercise supported multi-statement insertMany and bulkWrite operations, which contain only supported single-statement
write operations. Both ordered and unordered execution should be tested.</li>
</ul>
<p>Additional prose tests for other scenarios are also included.</p>
<h2 id="motivation-for-change-12"><a class="header" href="#motivation-for-change-12">Motivation for Change</a></h2>
<p>Drivers currently have no API for specifying at-most-once semantics and retryable behavior for write operations. The
driver API needs to be extended to support this behavior.</p>
<h2 id="design-rationale-15"><a class="header" href="#design-rationale-15">Design Rationale</a></h2>
<p>The design of this specification piggy-backs that of the <a href="retryable-writes/../sessions/driver-sessions.html">Driver Session</a> specification
in that it modifies the driver API as little as possible to introduce the concept of at-most-once semantics and
retryable behavior for write operations. A transaction ID will be included in all supported write commands executed
within the scope of a MongoClient where retryable writes have been enabled.</p>
<p>Drivers expect the server to yield an error if a transaction ID is included in an unsupported write command. This
requires drivers to maintain an allow list and track which write operations support retryable behavior for a given
server version (see:
<a href="retryable-writes/retryable-writes.html#why-must-drivers-maintain-an-allow-list-of-supported-operations">Why must drivers maintain an allow list of supported operations?</a>).</p>
<p>While this approach will allow applications to take advantage of retryable write behavior with minimal code changes, it
also presents a documentation challenge. Users must understand exactly what can and will be retried (see:
<a href="retryable-writes/retryable-writes.html#how-will-users-know-which-operations-are-supported">How will users know which operations are supported?</a>).</p>
<h2 id="backwards-compatibility-13"><a class="header" href="#backwards-compatibility-13">Backwards Compatibility</a></h2>
<p>The API changes to support retryable writes extend the existing API but do not introduce any backward breaking changes.
Existing programs that do not make use of retryable writes will continue to compile and run correctly.</p>
<h2 id="reference-implementation-11"><a class="header" href="#reference-implementation-11">Reference Implementation</a></h2>
<p>The C# and C drivers will provide reference implementations. JIRA links will be added here at a later point.</p>
<h2 id="future-work-10"><a class="header" href="#future-work-10">Future Work</a></h2>
<p>Supporting at-most-once semantics and retryable behavior for updateMany and deleteMany operations may become possible
once the server implements support for multi-document transactions.</p>
<p>A separate specification for retryable read operations could complement this specification. Retrying read operations
would not require client or server sessions and could be implemented independently of retryable writes.</p>
<h2 id="q--a-3"><a class="header" href="#q--a-3">Q &amp; A</a></h2>
<h3 id="what-do-the-additional-error-codes-mean"><a class="header" href="#what-do-the-additional-error-codes-mean">What do the additional error codes mean?</a></h3>
<p>The errors <code>HostNotFound</code>, <code>HostUnreachable</code>, <code>NetworkTimeout</code>, <code>SocketException</code> may be returned from mongos during
problems routing to a shard. These may be transient, or localized to that mongos.</p>
<h3 id="why-are-write-operations-only-retried-once-by-default"><a class="header" href="#why-are-write-operations-only-retried-once-by-default">Why are write operations only retried once by default?</a></h3>
<p>The spec concerns itself with retrying write operations that encounter a retryable error (i.e. no response due to
network error or a response indicating that the node is no longer a primary). A retryable error may be classified as
either a transient error (e.g. dropped connection, replica set failover) or persistent outage. In the case of a
transient error, the driver will mark the server as "unknown" per the
<a href="retryable-writes/../server-discovery-and-monitoring/server-discovery-and-monitoring.html">SDAM</a> spec. A subsequent retry attempt will
allow the driver to rediscover the primary within the designated server selection timeout period (30 seconds by
default). If server selection times out during this retry attempt, we can reasonably assume that there is a persistent
outage. In the case of a persistent outage, multiple retry attempts are fruitless and would waste time. See
<a href="https://emptysqua.re/blog/how-to-write-resilient-mongodb-applications/">How To Write Resilient MongoDB Applications</a>
for additional discussion on this strategy.</p>
<p>However when <a href="retryable-writes/../client-side-operations-timeout/client-side-operations-timeout.html">Client Side Operations Timeout</a> is
enabled, the driver will retry multiple times until the operation succeeds, a non-retryable error is encountered, or the
timeout expires. Retrying multiple times provides greater resilience to cascading failures such as rolling server
restarts during planned maintenance events.</p>
<h3 id="what-if-the-transaction-number-overflows"><a class="header" href="#what-if-the-transaction-number-overflows">What if the transaction number overflows?</a></h3>
<p>Since server sessions are pooled and session lifetimes are configurable on the server, it is theoretically possible for
the transaction number to overflow if it reaches the limits of a signed 64-bit integer. The spec does not address this
scenario. Drivers may decide to handle this as they wish. For example, they may raise a client-side error if a
transaction number would overflow, eagerly remove sessions with sufficiently high transactions numbers from the pool in
an attempt to limit such occurrences, or simply rely on the server to raise an error when a transaction number is
reused.</p>
<h3 id="why-are-unacknowledged-write-concerns-unsupported"><a class="header" href="#why-are-unacknowledged-write-concerns-unsupported">Why are unacknowledged write concerns unsupported?</a></h3>
<p>The server does not consider the write concern when deciding if a write operation supports retryable behavior.
Technically, operations with an unacknowledged write concern can specify a transaction ID and be retried. However, the
spec elects not to support unacknowledged write concerns due to various ways that drivers may issue write operations
with unacknowledged write concerns.</p>
<p>When using <code>OP_QUERY</code> to issue a write command to the server, a command response is always returned. A write command
with an unacknowledged write concern (i.e. <code>{w: 0}</code>) will return a response of <code>{ok: 1}</code>. If a retryable error is
encountered (either a network error or "not writeable primary" response), the driver could attempt to retry the
operation by executing it again with the same transaction ID.</p>
<p>Some drivers fall back to legacy opcodes (e.g. <code>OP_INSERT</code>) to execute write operations with an unacknowledged write
concern. In the future, <code>OP_MSG</code> may allow the server to avoid returning any response for write operations sent with an
unacknowledged write concern. In both of these cases, there is no response for which the driver might encounter a
retryable error and decide to retry the operation.</p>
<p>Rather than depend on an implementation detail to determine if retryable behavior might apply, the spec has chosen to
not support retryable behavior for unacknowledged write concerns and guarantee a consistent user experience across all
drivers.</p>
<h3 id="why-must-drivers-maintain-an-allow-list-of-supported-operations"><a class="header" href="#why-must-drivers-maintain-an-allow-list-of-supported-operations">Why must drivers maintain an allow list of supported operations?</a></h3>
<p>Requiring that drivers maintain an allow list of supported write operations is unfortunate. It both adds complexity to
the driver's implementation and limits the driver's ability to immediately take advantage of new server functionality
(i.e. the driver must be upgraded to support additional write operations).</p>
<p>Several other alternatives were discussed:</p>
<ul>
<li>The server could inform drivers which write operations support retryable behavior in its <code>hello</code> or legacy hello
response. This would be a form of feature discovery, for which there is no established protocol. It would also add
complexity to the connection handshake.</li>
<li>The server could ignore a transaction ID on the first observed attempt of an unsupported write command and only yield
an error on subsequent attempts. This would require the server to create a transaction record for unsupported writes
to avoid the risk of applying a write twice and ensuring that retry attempts could be differentiated. It also poses a
significant problem for sharding if a multi-document write does not reach all shards, since those shards would not
know to create a transaction record.</li>
<li>The driver could allow more fine-grained control retryable write behavior by supporting a <code>retryWrites</code> option on the
database and collection objects. This would allow users to enable <code>retryWrites</code> on a MongoClient and disable it as
needed to execute unsupported write operations, or vice versa. Since we expect the <code>retryWrites</code> option to become less
relevant once transactions are implemented, we would prefer not to add the option throughout the driver API.</li>
</ul>
<h3 id="how-will-users-know-which-operations-are-supported"><a class="header" href="#how-will-users-know-which-operations-are-supported">How will users know which operations are supported?</a></h3>
<p>The initial list of supported operations is already quite permissive. Most <a href="retryable-writes/../crud/crud.html">CRUD</a> operations are
supported apart from <code>updateMany()</code>, <code>deleteMany()</code>, and <code>aggregate()</code> with a write stage (e.g. <code>$out</code>, <code>$merge</code>). Other
write operations (e.g. <code>renameCollection</code>) are rare.</p>
<p>That said, drivers will need to clearly document exactly which operations support retryable behavior. In the case
<code>bulkWrite()</code>, which may or may not support retryability, drivers should discuss how eligibility is determined.</p>
<h3 id="can-drivers-resend-the-same-wire-protocol-message-on-retry-attempts-1"><a class="header" href="#can-drivers-resend-the-same-wire-protocol-message-on-retry-attempts-1">Can drivers resend the same wire protocol message on retry attempts?</a></h3>
<p>Since retry attempts entail sending the same command and transaction ID to the server, drivers might consider resending
the same wire protocol message in order to avoid constructing a new message and computing its checksum. The server will
not complain if it receives two messages with the same <code>requestId</code>, as the field is only used for logging and populating
the <code>responseTo</code> field in its replies to the client. That said, re-using a wire protocol message might violate rules for
<a href="retryable-writes/../sessions/driver-sessions.html#gossipping-the-cluster-time">gossipping the cluster time</a> and might also have
implications for <a href="retryable-writes/retryable-writes.html#command-monitoring">Command Monitoring</a>, since the original write command and its retry attempt may
report the same <code>requestId</code>.</p>
<h3 id="why-cant-drivers-split-bulk-write-commands-to-maximize-retryability"><a class="header" href="#why-cant-drivers-split-bulk-write-commands-to-maximize-retryability">Why can't drivers split bulk write commands to maximize retryability?</a></h3>
<p>In <a href="retryable-writes/retryable-writes.html#supported-write-operations">Supported Write Operations</a>, the spec prohibits drivers from altering existing logic
for splits <code>bulkWrite()</code>'s <code>requests</code> parameter into write commands in an attempt to segregate unsupported,
multi-document write operations and maximize retryability for other, supported write operations. The reasoning behind
this prohibition is that such behavior would conflict with a primary goal of the bulk API in reducing the number of
command round-trips to the server.</p>
<h3 id="retrywrites-originally-defaulted-to-false-why-does-it-now-default-to-true"><a class="header" href="#retrywrites-originally-defaulted-to-false-why-does-it-now-default-to-true">retryWrites originally defaulted to false, why does it now default to true?</a></h3>
<p>Since the initial release of retryable writes in MongoDB 3.6 testing showed that the overhead for supported operations
was sufficiently small that there was no risk in changing the default. Additionally, the fact that some operations
continue to be unsupported for retryable writes (updateMany and deleteMany) does not seem to pose a problem in practice.</p>
<h3 id="why-do-drivers-have-to-parse-errmsg-to-determine-storage-engine-support"><a class="header" href="#why-do-drivers-have-to-parse-errmsg-to-determine-storage-engine-support">Why do drivers have to parse errmsg to determine storage engine support?</a></h3>
<p>There is no reliable way to determine the storage engine in use for shards in a sharded cluster, and replica sets (and
shards) can have mixed deployments using different storage engines on different members. This is especially true when a
replica set or sharded cluster is being upgraded from one storage engine to another. This could be common when upgrading
to MongoDB 4.2, where MMAPv1 is no longer supported.</p>
<p>The server returns error code 20 (IllegalOperation) when the storage engine doesn't support document-level locking and
txnNumbers. Error code 20 is used for a large number of different error cases in the server so we need some other way to
differentiate this error case from any other. The error code and errmsg are the same in MongoDB 3.6 and 4.0, and the
same from a replica set or sharded cluster (mongos just forwards the error from the shard's replica set).</p>
<h3 id="why-does-the-driver-only-add-the-retryablewriteerror-label-to-errors-that-occur-on-a-mongoclient-with-retrywrites-set-to-true"><a class="header" href="#why-does-the-driver-only-add-the-retryablewriteerror-label-to-errors-that-occur-on-a-mongoclient-with-retrywrites-set-to-true">Why does the driver only add the RetryableWriteError label to errors that occur on a MongoClient with retryWrites set to true?</a></h3>
<p>The driver does this to maintain consistency with the MongoDB server. Servers that support the RetryableWriteError label
(MongoDB version 4.4 and newer) only add the label to an error when the client has added a txnNumber to the command,
which only happens when the retryWrites option is true on the client. For the driver to add the label even if
retryWrites is not true would be inconsistent with the server and potentially confusing to developers.</p>
<h2 id="changelog-22"><a class="header" href="#changelog-22">Changelog</a></h2>
<ul>
<li>
<p>2024-05-08: Add guidance for client-level <code>bulkWrite()</code> retryability.</p>
</li>
<li>
<p>2024-05-02: Migrated from reStructuredText to Markdown.</p>
</li>
<li>
<p>2024-04-29: Fix the link to the Driver Sessions spec.</p>
</li>
<li>
<p>2024-01-16: Do not use <code>writeConcernError.code</code> in pre-4.4 mongos response to determine retryability. Do not use
<code>writeErrors[].code</code> in pre-4.4 server responses to determine retryability.</p>
</li>
<li>
<p>2023-12-06: Clarify that writes are not retried within transactions.</p>
</li>
<li>
<p>2023-12-05: Add that any server information associated with retryable exceptions MUST reflect the originating server,
even in the presence of retries.</p>
</li>
<li>
<p>2023-10-02: When CSOT is not enabled, one retry attempt occurs.</p>
</li>
<li>
<p>2023-08-26: Require that in a sharded cluster the server on which the operation failed MUST be provided to the server
selection mechanism as a deprioritized server.</p>
</li>
<li>
<p>2022-11-17: Add logic for persisting "currentError" as "previousError" on first retry attempt, avoiding raising "null"
errors.</p>
</li>
<li>
<p>2022-11-09: CLAM must apply both events and log messages.</p>
</li>
<li>
<p>2022-10-18: When CSOT is enabled multiple retry attempts may occur.</p>
</li>
<li>
<p>2022-10-05: Remove spec front matter and reformat changelog.</p>
</li>
<li>
<p>2022-01-25: Note that drivers should retry handshake network failures.</p>
</li>
<li>
<p>2021-11-02: Clarify that error labels are only specified in a top-level field of an error.</p>
</li>
<li>
<p>2021-04-26: Replaced deprecated terminology</p>
</li>
<li>
<p>2021-03-24: Require that PoolClearedErrors be retried</p>
</li>
<li>
<p>2020-09-01: State the the driver should only add the RetryableWriteError label to network errors when connected to a
4.4+ server.</p>
</li>
<li>
<p>2020-02-25: State that the driver should only add the RetryableWriteError label when retryWrites is on, and make it
clear that mongos will sometimes perform internal retries and not return the RetryableWriteError label.</p>
</li>
<li>
<p>2020-02-10: Remove redundant content in Tests section.</p>
</li>
<li>
<p>2020-01-14: Add ExceededTimeLimit to the list of error codes that should receive a RetryableWriteError label.</p>
</li>
<li>
<p>2019-10-21: Change the definition of "retryable write" to be based on the RetryableWriteError label. Stop requiring
drivers to parse errmsg to categorize retryable errors for pre-4.4 servers.</p>
</li>
<li>
<p>2019-07-30: Drivers must rewrite error messages for error code 20 when txnNumber is not supported by the storage
engine.</p>
</li>
<li>
<p>2019-06-07: Mention <code>$merge</code> stage for aggregate alongside <code>$out</code></p>
</li>
<li>
<p>2019-05-29: Renamed InterruptedDueToStepDown to InterruptedDueToReplStateChange</p>
</li>
<li>
<p>2019-03-06: retryWrites now defaults to true.</p>
</li>
<li>
<p>2019-03-05: Prohibit resending wire protocol messages if doing so would violate rules for gossipping the cluster time.</p>
</li>
<li>
<p>2018-06-07: WriteConcernFailed is not a retryable error code.</p>
</li>
<li>
<p>2018-04-25: Evaluate retryable eligibility of bulkWrite() commands individually.</p>
</li>
<li>
<p>2018-03-14: Clarify that retryable writes may fail with a FCV 3.4 shard.</p>
</li>
<li>
<p>2017-11-02: Drivers should not raise errors if selected server does not support retryable writes and instead fall back
to non-retryable behavior. In addition to wire protocol version, drivers may check for <code>logicalSessionTimeoutMinutes</code>
to determine if a server supports sessions and retryable writes.</p>
</li>
<li>
<p>2017-10-26: Errors when retrying may be raised instead of the original error provided they allow the user to infer
that an attempt was made.</p>
</li>
<li>
<p>2017-10-23: Drivers must document operations that support retryability.</p>
</li>
<li>
<p>2017-10-23: Raise the original retryable error if server selection or wire protocol checks fail during the retry
attempt. Encourage drivers to provide intermediary write results after an unrecoverable failure during a bulk write.</p>
</li>
<li>
<p>2017-10-18: Standalone servers do not support retryable writes.</p>
</li>
<li>
<p>2017-10-18: Also retry writes after a "not writable primary" error.</p>
</li>
<li>
<p>2017-10-08: Renamed <code>txnNum</code> to <code>txnNumber</code> and noted that it must be a 64-bit integer (BSON type 0x12).</p>
</li>
<li>
<p>2017-08-25: Drivers will maintain an allow list so that only supported write operations may be retried. Transaction
IDs will not be included in unsupported write commands, irrespective of the <code>retryWrites</code> option.</p>
</li>
<li>
<p>2017-08-18: <code>retryWrites</code> is now a MongoClient option.</p>
</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="client-side-operations-timeout-2"><a class="header" href="#client-side-operations-timeout-2">Client Side Operations Timeout</a></h1>
<ul>
<li>Status: Accepted</li>
<li>Minimum Server Version: 2.6</li>
</ul>
<hr />
<h2 id="abstract-23"><a class="header" href="#abstract-23">Abstract</a></h2>
<p>This specification outlines a new <code>timeoutMS</code> option to govern the amount of time that a single operation can execute
before control is returned to the user. This timeout applies to all of the work done to execute the operation, including
but not limited to server selection, connection checkout, and server-side execution.</p>
<h2 id="meta-23"><a class="header" href="#meta-23">META</a></h2>
<p>The keywords "MUST", "MUST NOT", "REQUIRED", "SHALL", "SHALL NOT", "SHOULD", "SHOULD NOT", "RECOMMENDED", "MAY", and
"OPTIONAL" in this document are to be interpreted as described in <a href="https://www.ietf.org/rfc/rfc2119.txt">RFC 2119</a>.</p>
<h2 id="specification-21"><a class="header" href="#specification-21">Specification</a></h2>
<h3 id="terms-13"><a class="header" href="#terms-13">Terms</a></h3>
<p><strong>min(a, b)</strong></p>
<p>Shorthand for "the minimum of a and b" where <code>a</code> and <code>b</code> are numeric values. For any cases where 0 means "infinite"
(e.g. <a href="client-side-operations-timeout/client-side-operations-timeout.html#timeoutms">timeoutMS</a>), <code>min(0, other)</code> MUST evaluate to <code>other</code>.</p>
<h3 id="mongoclient-configuration-7"><a class="header" href="#mongoclient-configuration-7">MongoClient Configuration</a></h3>
<p>This specification introduces a new configuration option and deprecates some existing options.</p>
<h4 id="timeoutms"><a class="header" href="#timeoutms">timeoutMS</a></h4>
<p>This 64-bit integer option specifies the per-operation timeout value in milliseconds. The default value is unset which
means this feature is not enabled, i.e. the existing timeout behavior is unchanged (including
<code>serverSelectionTimeoutMS</code>, <code>connectTimeoutMS</code>, <code>socketTimeoutMS</code> etc..). An explicit value of 0 means infinite, though
some client-side timeouts like <code>serverSelectionTimeoutMS</code> will still apply. Drivers MUST error if a negative value is
specified. This value MUST be configurable at the level of a MongoClient, MongoDatabase, MongoCollection, or of a single
operation. However, if the option is specified at any level, it cannot be later changed to unset. At each level, the
value MUST be inherited from the previous level if it is not explicitly specified. Additionally, some entities like
<code>ClientSession</code> and <code>GridFSBucket</code> either inherit <code>timeoutMS</code> from their parent entities or provide options to override
it. The behavior for these entities is described in individual sections of this specification.</p>
<p>Drivers for languages that provide an idiomatic API for expressing durations of time (e.g. <code>TimeSpan</code> in .NET) MAY
choose to leverage these APIs for the <code>timeoutMS</code> option rather than using int64. Drivers that choose to do so MUST also
follow the semantics for special values defined by those types. Such drivers MUST also ensure that there is a way to
explicitly set <code>timeoutMS</code> to <code>infinite</code> in the API.</p>
<p>See
<a href="client-side-operations-timeout/client-side-operations-timeout.html#timeoutms-cannot-be-changed-to-unset-once-its-specified">timeoutMS cannot be changed to unset once it's specified</a>.</p>
<h4 id="backwards-breaking-considerations"><a class="header" href="#backwards-breaking-considerations">Backwards Breaking Considerations</a></h4>
<p>This specification deprecates many existing timeout options and introduces a new exception type that is used to
communicate timeout expiration. If drivers need to make backwards-breaking changes to support <code>timeoutMS</code>, the backwards
breaking behavior MUST be gated behind the presence of the <code>timeoutMS</code> option. If the <code>timeoutMS</code> option is not set,
drivers MUST continue to honor existing timeouts such as <code>socketTimeoutMS</code>. Backwards breaking changes include any
changes to exception types thrown by stable API methods or changes to timeout behavior. Drivers MUST document these
changes.</p>
<p>In a subsequent major release, drivers SHOULD drop support for legacy timeout behavior and only continue to support the
timeout options that are not deprecated by this specification. Once legacy options are removed, drivers MUST make the
backwards-breaking behavioral changes described in this specification regardless of whether or not <code>timeoutMS</code> is set by
the application.</p>
<p>See the <a href="client-side-operations-timeout/client-side-operations-timeout.html#errors">Errors</a> section for explanations of the backwards-breaking changes to error reporting.</p>
<h4 id="deprecations"><a class="header" href="#deprecations">Deprecations</a></h4>
<p>The following configuration timeout options MUST be deprecated in favor of <code>timeoutMS</code>:</p>
<ul>
<li><code>socketTimeoutMS</code></li>
<li><code>waitQueueTimeoutMS</code></li>
<li><code>wTimeoutMS</code></li>
</ul>
<p>The following options for CRUD methods MUST be deprecated in favor of <code>timeoutMS</code>:</p>
<ul>
<li><code>maxTimeMS</code></li>
<li><code>maxCommitTimeMS</code></li>
</ul>
<h3 id="timeout-behavior"><a class="header" href="#timeout-behavior">Timeout Behavior</a></h3>
<p>The <code>timeoutMS</code> option specifies the best-effort maximum amount of time a single operation can take before control is
returned to the application. Drivers MUST keep track of the remaining time before the timeout expires as an operation
progresses.</p>
<h4 id="operations"><a class="header" href="#operations">Operations</a></h4>
<p>The <code>timeoutMS</code> option applies to all operations defined in the following specifications:</p>
<ul>
<li><a href="client-side-operations-timeout/../crud/crud.html">CRUD</a></li>
<li><a href="client-side-operations-timeout/../change-streams/change-streams.html">Change Streams</a></li>
<li><a href="client-side-operations-timeout/../client-side-encryption/client-side-encryption.html">Client Side Encryption</a></li>
<li><a href="client-side-operations-timeout/../enumerate-collections/enumerate-collections.html">Enumerating Collections</a></li>
<li><a href="client-side-operations-timeout/../enumerate-databases/enumerate-databases.html">Enumerating Databases</a></li>
<li><a href="client-side-operations-timeout/../gridfs/gridfs-spec.html">GridFS</a></li>
<li><a href="client-side-operations-timeout/../index-management/index-management.html">Index Management</a></li>
<li><a href="client-side-operations-timeout/../transactions/transactions.html">Transactions</a></li>
<li><a href="client-side-operations-timeout/../transactions-convenient-api/transactions-convenient-api.html">Convenient API for Transactions</a></li>
</ul>
<p>In addition, it applies to all operations on cursor objects that may perform blocking work (e.g. methods to iterate or
close a cursor, any method that reads documents from a cursor into an array, etc).</p>
<h4 id="validation-and-overrides"><a class="header" href="#validation-and-overrides">Validation and Overrides</a></h4>
<p>When executing an operation, drivers MUST ignore any deprecated timeout options if <code>timeoutMS</code> is set on the operation
or is inherited from the collection/database/client levels. In addition to being set at these levels, the timeout for an
operation can also be expressed via an explicit ClientSession (see
<a href="client-side-operations-timeout/client-side-operations-timeout.html#convenient-transactions-api">Convenient Transactions API</a>). In this case, the timeout on the session MUST be used as
the <code>timeoutMS</code> value for the operation. Drivers MUST raise a validation error if an explicit session with a timeout is
used and the <code>timeoutMS</code> option is set at the operation level for operations executed as part of a <code>withTransaction</code>
callback.</p>
<p>See <a href="client-side-operations-timeout/client-side-operations-timeout.html#timeoutms-overrides-deprecated-timeout-options">timeoutMS overrides deprecated timeout options</a>.</p>
<h4 id="errors"><a class="header" href="#errors">Errors</a></h4>
<p>If the <code>timeoutMS</code> option is not set and support for deprecated timeout options has not been dropped but a timeout is
encountered (e.g. server selection times out), drivers MUST continue to return existing errors. This ensures that
error-handling code in existing applications does not break unless the user opts into using <code>timeoutMS</code>.</p>
<p>If the <code>timeoutMS</code> option is set and the timeout expires, drivers MUST abort all blocking work and return control to the
user with an error. This error MUST be distinguished in some way (e.g. custom exception type) to make it easier for
users to detect when an operation fails due to a timeout. If the timeout expires during a blocking task, drivers MUST
expose the underlying error returned from the task from this new error type. The stringified version of the new error
type MUST include the stringified version of the underlying error as a substring. For example, if server selection
expires and returns a <code>ServerSelectionTimeoutException</code>, drivers must allow users to access that exception from this new
error type. If there is no underlying error, drivers MUST add information about when the timeout expiration was detected
to the stringified version of the timeout error.</p>
<h5 id="error-transformations"><a class="header" href="#error-transformations">Error Transformations</a></h5>
<p>When using the new timeout error type, drivers MUST transform timeout errors from external sources into the new error.
One such error is the <code>MaxTimeMSExpired</code> server error. When checking for this error, drivers MUST only check that the
error code is 50 and MUST NOT check the code name or error message. This error can be present in a top-level response
document where the <code>ok</code> value is 0, as part of an error in the <code>writeErrors</code> array, or in a nested <code>writeConcernError</code>
document. For example, all three of the following server responses would match this criteria:</p>
<pre><code class="language-javascript">{ok: 0, code: 50, codeName: "MaxTimeMSExpired", errmsg: "operation time limit exceeded"}

{ok: 1, writeErrors: [{code: 50, codeName: "MaxTimeMSExpired", errmsg: "operation time limit exceeded"}]}

{ok: 1, writeConcernError: {code: 50, codeName: "MaxTimeMSExpired"}}
</code></pre>
<p>Timeouts from other sources besides MongoDB servers MUST also be transformed into this new exception type. These include
socket read/write timeouts and HTTP request timeouts.</p>
<h4 id="blocking-sections-for-operation-execution"><a class="header" href="#blocking-sections-for-operation-execution">Blocking Sections for Operation Execution</a></h4>
<p>The following pieces of operation execution are considered blocking:</p>
<ol>
<li>Implicit session acquisition if an explicit session was not provided for the operation. This is only considered
blocking for drivers that perform server selection to determine session support when acquiring implicit sessions.</li>
<li>Server selection</li>
<li>Connection checkout - If <code>maxPoolSize</code> has already been reached for the selected server, this is the amount of time
spent waiting for a connection to be available.</li>
<li>Connection establishment - If the pool for the selected server is empty and a new connection is needed, the following
pieces of connection establishment are considered blocking:
<ol>
<li>TCP socket establishment</li>
<li>TLS handshake
<ol>
<li>All messages sent over the socket as part of the TLS handshake</li>
<li>OCSP verification - HTTP requests sent to OCSP responders.</li>
</ol>
</li>
<li>MongoDB handshake (i.e. initial connection <code>hello</code>)</li>
<li>Authentication
<ol>
<li>SCRAM-SHA-1, SCRAM-SHA-256, PLAIN: Execution of the command required for the SASL conversation.</li>
<li>GSSAPI: Execution of the commands required for the SASL conversation and requests to the KDC and TGS.</li>
<li>MONGODB-AWS: Execution of the commands required for the SASL conversation and all HTTP requests to ECS and EC2
endpoints.</li>
<li>MONGODB-X509: Execution of the commands required for the authentication conversation.</li>
</ol>
</li>
</ol>
</li>
<li>Client-side encryption
<ol>
<li>Execution of <code>listCollections</code> commands to get collection schemas.</li>
<li>Execution of <code>find</code> commands against the key vault collection to get encrypted data keys.</li>
<li>Requests to non-local key management servers (e.g. AWS KMS) to decrypt data keys.</li>
<li>Requests to mongocryptd servers.</li>
</ol>
</li>
<li>Socket write to send a command to the server</li>
<li>Socket read to receive the server’s response</li>
</ol>
<p>The <code>timeoutMS</code> option MUST apply to all blocking sections. Drivers MUST document any exceptions. For example, drivers
that do not have full control over OCSP verification might not be able to set timeouts for HTTP requests to responders
and would document that OCSP verification could result in an execution time greater than <code>timeoutMS</code>.</p>
<h4 id="server-selection-3"><a class="header" href="#server-selection-3">Server Selection</a></h4>
<p>If <code>timeoutMS</code> is set, drivers MUST use <code>min(serverSelectionTimeoutMS, remaining timeoutMS)</code>, referred to as
<code>computedServerSelectionTimeout</code> as the timeout for server selection and connection checkout. The server selection loop
MUST fail with a timeout error once the timeout expires.</p>
<p>After a server has been selected, drivers MUST use the remaining <code>computedServerSelectionTimeout</code> value as the timeout
for connection checkout. If a new connection is required,
<code>min(connectTimeoutMS, remaining computedServerSelectionTimeout)</code> MUST be used as the timeout for TCP socket
establishment. Any network requests required to create or authenticate a connection (e.g. HTTP requests to OCSP
responders) MUST use <code>min(operationTimeout, remaining computedServerSelectionTimeout)</code> as a timeout, where
<code>operationTimeout</code> is the specified default timeout for the network request. If there is no specified default, these
operations MUST use the remaining <code>computedServerSelectionTimeout</code> value. All commands sent during the connection’s
handshake MUST use the remaining <code>computedServerSelectionTimeout</code> as their <code>timeoutMS</code> value. Handshake commands MUST
also set timeouts per the <a href="client-side-operations-timeout/client-side-operations-timeout.html#command-execution">Command Execution</a> section.</p>
<p>If <code>timeoutMS</code> is not set and support for <code>waitQueueTimeoutMS</code> has not been removed, drivers MUST continue to exhibit
the existing timeout behavior by honoring <code>serverSelectionTimeoutMS</code> for server selection and <code>waitQueueTimeoutMS</code> for
connection checkout. If a new connection is required, drivers MUST use <code>connectTimeoutMS</code> as the timeout for socket
establishment and <code>socketTimeoutMS</code> as the socket timeout for all handshake commands.</p>
<p>See <a href="client-side-operations-timeout/client-side-operations-timeout.html#serverselectiontimeoutms-is-not-deprecated">serverSelectionTimeoutMS is not deprecated</a> and
<a href="client-side-operations-timeout/client-side-operations-timeout.html#connecttimeoutms-is-not-deprecated">connectTimeoutMS is not deprecated</a>.</p>
<h4 id="command-execution"><a class="header" href="#command-execution">Command Execution</a></h4>
<p>If <code>timeoutMS</code> is set, drivers MUST append a <code>maxTimeMS</code> field to commands executed against a MongoDB server using the
<code>minRoundTripTime</code> field of the selected server. Note that this value MUST be retrieved during server selection using
the <code>servers</code> field of the same
<a href="client-side-operations-timeout/../server-discovery-and-monitoring/server-discovery-and-monitoring.html#TopologyDescription">TopologyDescription</a> that
was used for selection before the selected server's description can be modified. Otherwise, drivers may be subject to a
race condition where a server is reset to the default description (e.g. due to an error in the monitoring thread) after
it has been selected but before the RTT is retrieved.</p>
<p>If the <code>minRoundTripTime</code> is less than the remaining timeoutMS, the value of this field MUST be
<code>remaining timeoutMS - minRoundTripTime</code>. If not, drivers MUST return a timeout error without attempting to send the
message to the server. This is done to ensure that an operation is not routed to the server if it will likely fail with
a socket timeout as that could cause connection churn. The <code>maxTimeMS</code> field MUST be appended after all blocking work is
complete.</p>
<p>After wire message construction, drivers MUST check for timeout before writing the message to the server. If the timeout
has expired or the amount of time remaining is less than the selected server's minimum RTT, drivers MUST return the
connection to the pool and raise a timeout exception. Otherwise, drivers MUST set the connection’s write timeout to the
remaining <code>timeoutMS</code> value before writing a message to the server. After the write is complete, drivers MUST check for
timeout expiration before reading the server’s response. If the timeout has expired, the connection MUST be closed and a
timeout exception MUST be propagated to the application. If it has not, drivers MUST set the connection’s read timeout
to the remaining <code>timeoutMS</code> value. The timeout MUST apply to the aggregate of all reads done to receive a server
response, not to individual reads. If any read or write calls on the socket fail with a timeout, drivers MUST transform
the error into the new timeout exception as described in the <a href="client-side-operations-timeout/client-side-operations-timeout.html#error-transformations">Error Transformations</a> section.</p>
<p>If <code>timeoutMS</code> is not set and support for <code>socketTimeoutMS</code> has not been removed, drivers MUST honor <code>socketTimeoutMS</code>
as the timeout for socket reads and writes.</p>
<p>See <a href="client-side-operations-timeout/client-side-operations-timeout.html#maxtimems-accounts-for-server-rtt">maxTimeMS accounts for server RTT</a>.</p>
<h4 id="batching"><a class="header" href="#batching">Batching</a></h4>
<p>If an operation must be sent to the server in multiple batches (e.g. <code>collection.bulkWrite()</code>), the <code>timeoutMS</code> option
MUST apply to the entire operation, not to each individual batch.</p>
<h4 id="retryability-1"><a class="header" href="#retryability-1">Retryability</a></h4>
<p>If an operation requires a retry per the retryable reads or writes specifications and <code>timeoutMS</code> is set, drivers MUST
retry operations as many times as possible before the timeout expires or a retry attempt returns a non-retryable error.
Once the timeout expires, a timeout error MUST be raised.</p>
<p>See
<a href="client-side-operations-timeout/client-side-operations-timeout.html#why-dont-drivers-use-backoffjitter-between-retry-attempts">Why don’t drivers use backoff/jitter between retry attempts?</a>.</p>
<h4 id="client-side-encryption"><a class="header" href="#client-side-encryption">Client Side Encryption</a></h4>
<p>If automatic client-side encryption or decryption is enabled, the remaining <code>timeoutMS</code> value MUST be used as the
<code>timeoutMS</code> when executing <code>listCollections</code> commands to retrieve collection schemas, <code>find</code> commands to get data from
the key vault, and any commands against mongocryptd. It MUST also be used as the request timeout for HTTP requests
against KMS servers to decrypt data keys. When sending a command to mongocryptd, drivers MUST NOT append a <code>maxTimeMS</code>
field. This is to ensure that a <code>maxTimeMS</code> field can be safely appended to the command after it has been marked by
mongocryptd and encrypted by libmongocrypt. To determine whether or not the server is a mongocryptd, drivers MUST check
that the <code>iscryptd</code> field in the server's description is <code>true</code>.</p>
<p>For explicit encryption and decryption, the <code>ClientEncryptionOpts</code> options type used to construct
<a href="client-side-operations-timeout/../client-side-encryption/client-side-encryption.html#clientencryption">ClientEncryption</a> instances MUST support a new
<code>timeoutMS</code> option, which specifies the timeout for all operations executed on the <code>ClientEncryption</code> object.</p>
<p>See <a href="client-side-operations-timeout/client-side-operations-timeout.html#maxtimems-is-not-added-for-mongocryptd">maxTimeMS is not added for mongocryptd</a>.</p>
<h3 id="background-connection-pooling"><a class="header" href="#background-connection-pooling">Background Connection Pooling</a></h3>
<p>Connections created as part of a connection pool’s <code>minPoolSize</code> maintenance routine MUST use <code>connectTimeoutMS</code> as the
timeout for connection establishment. After the connection is established, if <code>timeoutMS</code> is set at the MongoClient
level, it MUST be used as the timeout for all commands sent as part of the MongoDB or authentication handshakes. The
timeout MUST be refreshed after each command. These commands MUST set timeouts per the
<a href="client-side-operations-timeout/client-side-operations-timeout.html#command-execution">Command Execution</a> section. If <code>timeoutMS</code> is not set, drivers MUST continue to honor
<code>socketTimeoutMS</code> as the socket timeout for handshake and authentication commands.</p>
<h3 id="server-monitoring-1"><a class="header" href="#server-monitoring-1">Server Monitoring</a></h3>
<p>Drivers MUST NOT use <code>timeoutMS</code> for commands executed by the server monitoring and RTT calculation threads.</p>
<p>See <a href="client-side-operations-timeout/client-side-operations-timeout.html#monitoring-threads-do-not-use-timeoutms">Monitoring threads do not use timeoutMS</a>.</p>
<h3 id="cursors-1"><a class="header" href="#cursors-1">Cursors</a></h3>
<p>For operations that create cursors, <code>timeoutMS</code> can either cap the lifetime of the cursor or be applied separately to
the original operation and all <code>next</code> calls. To support both of these use cases, these operations MUST support a
<code>timeoutMode</code> option. This option is an enum with possible values <code>CURSOR_LIFETIME</code> and <code>ITERATION</code>. The default value
depends on the type of cursor being created. Drivers MUST error if <code>timeoutMode</code> is set and <code>timeoutMS</code> is not.</p>
<p>When applying the <code>timeoutMS</code> option to <code>next</code> calls on cursors, drivers MUST ensure it applies to the entire call, not
individual commands. For drivers that send <code>getMore</code> requests in a loop when iterating tailable cursors, the timeout
MUST apply to the totality of all <code>getMore</code>’s, not to each one individually. If a resume is required for a <code>next</code> call
on a change stream, the timeout MUST apply to the entirety of the initial <code>getMore</code> and all commands sent as part of the
resume attempt.</p>
<p>For <code>close</code> methods, drivers MUST allow <code>timeoutMS</code> to be overridden if doing so is possible in the language. If
explicitly set for the operation, it MUST be honored. Otherwise, if <code>timeoutMS</code> was applied to the operation that
created the cursor, it MUST be refreshed for the <code>killCursors</code> command if one is required. Note that this means
<code>timeoutMS</code> will be refreshed for the <code>close</code> call even if the cursor was created with a <code>timeoutMode</code> of
<code>CURSOR_LIFETIME</code> and the timeout associated with the cursor has expired. The calculated timeout MUST apply to explicit
<code>close</code> methods that can be invoked by users as well as implicit destructors that are automatically invoked when exiting
resource blocks.</p>
<p>See <a href="client-side-operations-timeout/client-side-operations-timeout.html#cursor-close-methods-refresh-timeoutms">Cursor close() methods refresh timeoutMS</a>.</p>
<h4 id="non-tailable-cursors"><a class="header" href="#non-tailable-cursors">Non-tailable Cursors</a></h4>
<p>For non-tailable cursors, the default value of <code>timeoutMode</code> is <code>CURSOR_LIFETIME</code>. If <code>timeoutMS</code> is set, drivers MUST
apply it to the original operation and the lifetime of the created cursor. For example, if a <code>find</code> is executed at time
<code>T</code>, the <code>find</code> and all <code>getMore</code>’s on the cursor must finish by time <code>T + timeoutMS</code>. When executing <code>next</code> calls on
the cursor, drivers MUST use the remaining timeout as the <code>timeoutMS</code> value for the operation but MUST NOT append a
<code>maxTimeMS</code> field to <code>getMore</code> commands. If there are documents remaining in a previously retrieved batch, the <code>next</code>
method MUST return them even if the timeout has expired and MUST only return a timeout error if a <code>getMore</code> is required.</p>
<p>If <code>timeoutMode</code> is set to <code>ITERATION</code>, drivers MUST raise a client-side error if the operation is an <code>aggregate</code> with a
<code>$out</code> or <code>$merge</code> pipeline stage. If the operation is not an <code>aggregate</code> with <code>$out</code> or <code>$merge</code>, drivers MUST honor
the <code>timeoutMS</code> option for the initial command but MUST NOT append a <code>maxTimeMS</code> field to the command sent to the
server. After the operation has executed, the original <code>timeoutMS</code> value MUST also be applied to each <code>next</code> call on the
created cursor. Drivers MUST NOT append a <code>maxTimeMS</code> field to <code>getMore</code> commands.</p>
<p>See <a href="client-side-operations-timeout/client-side-operations-timeout.html#non-tailable-cursor-behavior">Non-tailable cursor behavior</a>.</p>
<h4 id="tailable-cursors"><a class="header" href="#tailable-cursors">Tailable Cursors</a></h4>
<p>Tailable cursors only support the <code>ITERATION</code> value for the <code>timeoutMode</code> option. This is the default value and drivers
MUST error if the option is set to <code>CURSOR_LIFETIME</code>.</p>
<h5 id="tailable-non-awaitdata-cursors"><a class="header" href="#tailable-non-awaitdata-cursors">Tailable non-awaitData Cursors</a></h5>
<p>If <code>timeoutMS</code> is set, drivers MUST apply it separately to the original operation and to all <code>next</code> calls on the
resulting cursor but MUST NOT append a <code>maxTimeMS</code> field to any commands.</p>
<h5 id="tailable-awaitdata-cursors"><a class="header" href="#tailable-awaitdata-cursors">Tailable awaitData Cursors</a></h5>
<p>If <code>timeoutMS</code> is set, drivers MUST apply it to the original operation. Drivers MUST also apply the original <code>timeoutMS</code>
value to each <code>next</code> call on the resulting cursor but MUST NOT use it to derive a <code>maxTimeMS</code> value for <code>getMore</code>
commands. Helpers for operations that create tailable awaitData cursors MUST also support the <code>maxAwaitTimeMS</code> option.
Drivers MUST error if this option is set, <code>timeoutMS</code> is set to a non-zero value, and <code>maxAwaitTimeMS</code> is greater than
or equal to <code>timeoutMS</code>. If this option is set, drivers MUST use it as the <code>maxTimeMS</code> field on <code>getMore</code> commands.</p>
<p>See <a href="client-side-operations-timeout/client-side-operations-timeout.html#tailable-cursor-behavior">Tailable cursor behavior</a> for rationale regarding both non-awaitData and awaitData
cursors.</p>
<h4 id="change-streams"><a class="header" href="#change-streams">Change Streams</a></h4>
<p>Driver <code>watch</code> helpers MUST support both <code>timeoutMS</code> and <code>maxAwaitTimeMS</code> options. Drivers MUST error if
<code>maxAwaitTimeMS</code> is set, <code>timeoutMS</code> is set to a non-zero value, and <code>maxAwaitTimeMS</code> is greater than or equal to
<code>timeoutMS</code>. These helpers MUST NOT support the <code>timeoutMode</code> option as change streams are an abstraction around
tailable-awaitData cursors, so they implicitly use <code>ITERATION</code> mode. If set, drivers MUST apply the <code>timeoutMS</code> option
to the initial <code>aggregate</code> operation. Drivers MUST also apply the original <code>timeoutMS</code> value to each <code>next</code> call on the
change stream but MUST NOT use it to derive a <code>maxTimeMS</code> field for <code>getMore</code> commands. If the <code>maxAwaitTimeMS</code> option
is set, drivers MUST use it as the <code>maxTimeMS</code> field on <code>getMore</code> commands.</p>
<p>If a <code>next</code> call fails with a timeout error, drivers MUST NOT invalidate the change stream. The subsequent <code>next</code> call
MUST perform a resume attempt to establish a new change stream on the server. Any errors from the <code>aggregate</code> operation
done to create a new change stream MUST be propagated to the application. Drivers MUST document that users can either
call <code>next</code> again or close the existing change stream and create a new one if a previous <code>next</code> call times out. The
documentation MUST suggest closing and re-creating the stream with a higher timeout if the timeout occurs before any
events have been received because this is a signal that the server is timing out before it can finish processing the
existing oplog.</p>
<p>See <a href="client-side-operations-timeout/client-side-operations-timeout.html#change-stream-behavior">Change stream behavior</a>.</p>
<h3 id="sessions"><a class="header" href="#sessions">Sessions</a></h3>
<p>The <a href="client-side-operations-timeout/../sessions/driver-sessions.html#mongoclient-changes">SessionOptions</a> used to construct explicit
<a href="client-side-operations-timeout/../sessions/driver-sessions.html#clientsession">ClientSession</a> instances MUST accept a new <code>defaultTimeoutMS</code> option,
which specifies the <code>timeoutMS</code> value for the following operations executed on the session:</p>
<ol>
<li>commitTransaction</li>
<li>abortTransaction</li>
<li>withTransaction</li>
<li>endSession</li>
</ol>
<p>If this option is not specified for a <code>ClientSession</code>, it MUST inherit the <code>timeoutMS</code> of its parent MongoClient.</p>
<h4 id="session-checkout"><a class="header" href="#session-checkout">Session checkout</a></h4>
<p>As noted in <a href="client-side-operations-timeout/client-side-operations-timeout.html#blocking-sections-for-operation-execution">Blocking Sections for Operation Execution</a>, implicit session
checkout can be considered a blocking process for some drivers. Such drivers MUST apply the remaining <code>timeoutMS</code> value
to this process when executing an operation. For explicit session checkout, drivers MUST apply the <code>timeoutMS</code> value of
the MongoClient to the <code>startSession</code> call if set. Drivers MUST NOT allow users to override <code>timeoutMS</code> for
<code>startSession</code> operations.</p>
<p>See <a href="client-side-operations-timeout/client-side-operations-timeout.html#timeoutms-cannot-be-overridden-for-startsession-calls">timeoutMS cannot be overridden for startSession calls</a>.</p>
<h4 id="convenient-transactions-api"><a class="header" href="#convenient-transactions-api">Convenient Transactions API</a></h4>
<p>If <code>timeoutMS</code> is set, drivers MUST apply it to the entire <code>withTransaction</code> call. To propagate the timeout to the
user-supplied callback, drivers MUST store the timeout as a field on the ClientSession object. This field SHOULD be
private to ensure that a user can not modify it while a <code>withTransaction</code> call is in progress. Drivers that cannot make
this field private MUST signal that the field should not be accessed or modified by users if there is an idiomatic way
to do so in the language (e.g. underscore-prefixed variable names in Python) and MUST document that modification of the
field can cause unintended correctness issues for applications. Drivers MUST document that the remaining timeout will
not be applied to callback operations that do not use the ClientSession. Drivers MUST also document that overriding
<code>timeoutMS</code> for operations executed using the explicit session inside the provided callback will result in a client-side
error, as defined in <a href="client-side-operations-timeout/client-side-operations-timeout.html#validation-and-overrides">Validation and Overrides</a>. If the callback returns an error and the
transaction must be aborted, drivers MUST refresh the <code>timeoutMS</code> value for the <code>abortTransaction</code> operation.</p>
<p>If <code>timeoutMS</code> is not set, drivers MUST continue to exhibit the existing 120 second timeout behavior. Drivers MUST NOT
change existing implementations to use <code>timeoutMS=120000</code> for this case.</p>
<p>See
<a href="client-side-operations-timeout/client-side-operations-timeout.html#withtransaction-communicates-timeoutms-via-clientsession">withTransaction communicates timeoutMS via ClientSession</a>
and
<a href="client-side-operations-timeout/client-side-operations-timeout.html#withtransaction-refreshes-the-timeout-for-aborttransaction">withTransaction refreshes the timeout for abortTransaction</a>.</p>
<h3 id="gridfs-api"><a class="header" href="#gridfs-api">GridFS API</a></h3>
<p>GridFS buckets MUST inherit <code>timeoutMS</code> from their parent MongoDatabase instance and all methods in the GridFS Bucket
API MUST support the <code>timeoutMS</code> option. For methods that create streams (e.g. <code>open_upload_stream</code>), the option MUST
cap the lifetime of the entire stream. This MUST include the time taken by any operations executed during stream
construction, reads/writes, and close/abort calls. For example, if a stream is created at time <code>T</code>, the final <code>close</code>
call on the stream MUST finish all blocking work before time <code>T + timeoutMS</code>. Methods that interact with a user-provided
stream (e.g. <code>upload_from_stream</code>) MUST use <code>timeoutMS</code> as the timeout for the entire upload/download operation. If the
user-provided streams do not support timeouts, drivers MUST document that the timeout for these methods may be breached
if calls to interact with the stream take longer than the remaining timeout. If <code>timeoutMS</code> is set, all cursors created
for GridFS API operations MUST internally set the <code>timeoutMode</code> option to <code>CURSOR_LIFETIME</code>.</p>
<p>See <a href="client-side-operations-timeout/client-side-operations-timeout.html#gridfs-streams-behavior">GridFS streams behavior</a>.</p>
<h3 id="runcommand-1"><a class="header" href="#runcommand-1">RunCommand</a></h3>
<p>The behavior of <code>runCommand</code> is undefined if the provided command document includes a <code>maxTimeMS</code> field and the
<code>timeoutMS</code> option is set. Drivers MUST document the behavior of <code>runCommand</code> for this case and MUST NOT attempt to
check the command document for the presence of a <code>maxTimeMS</code> field.</p>
<p>See <a href="client-side-operations-timeout/client-side-operations-timeout.html#runcommand-behavior">runCommand behavior</a>.</p>
<h3 id="explain"><a class="header" href="#explain">Explain</a></h3>
<blockquote>
<p>[!NOTE]
This portion of the specification is only relevant for drivers that provide <code>explain</code> helpers.</p>
</blockquote>
<p>When <code>timeoutMS</code> is specified, drivers MUST provide a way to specify timeoutMS that results in maxTimeMS being set on
the <code>explain</code> command. For example, Node's implementation might look like:</p>
<pre><code class="language-typescript">collection.find({}).explain({ timeoutMS: 1000 });
// sends:
{ explain: { find: ... }, maxTimeMS: &lt;remaining timeoutMS - min rtt&gt;}
</code></pre>
<h2 id="test-plan-17"><a class="header" href="#test-plan-17">Test Plan</a></h2>
<p>See the <a href="client-side-operations-timeout/tests/README.html">README.md</a> in the tests directory.</p>
<h2 id="motivation-for-change-13"><a class="header" href="#motivation-for-change-13">Motivation for Change</a></h2>
<p>Users have many options to set timeouts for various parts of operation execution including, but not limited to,
<code>serverSelectionTimeoutMS</code>, <code>socketTimeoutMS</code>, <code>connectTimeoutMS</code>, <code>maxTimeMS</code>, and <code>wTimeoutMS</code>. As a result, users are
often unsure which timeout to use. Because some of these timeouts are additive, it is difficult to set a combination
which ensures control will be returned to the user after a specified amount of time. To make timeouts more intuitive,
changes are required to the drivers API to deprecate some of the existing timeouts and add a new one to specify the
maximum execution time for an entire operation from start to finish.</p>
<p>In addition, automatically retrying reads and writes that failed due to transient network blips or planned maintenance
scenarios has improved application resiliency but the original behavior of only retrying once still allowed some errors
to be propagated to applications. Supporting a timeout for an entire operation allows drivers to retry operations
multiple times while still guaranteeing that an application can get back control once the specified amount of time has
elapsed.</p>
<h2 id="design-rationale-16"><a class="header" href="#design-rationale-16">Design Rationale</a></h2>
<h3 id="timeoutms-cannot-be-changed-to-unset-once-its-specified"><a class="header" href="#timeoutms-cannot-be-changed-to-unset-once-its-specified">timeoutMS cannot be changed to unset once it's specified</a></h3>
<p>If <code>timeoutMS</code> is specified at any level, it cannot be later changed to unset at a lower level. For example, a user
cannot do:</p>
<pre><code class="language-python">client = MongoClient(uri, timeoutMS=1000)
db = client.database("foo", timeoutMS=None)
</code></pre>
<p>This is because drivers return existing exception types if <code>timeoutMS</code> is not specified, but will return new exception
types and use new timeout behaviors if it is. Once the user has opted into this behavior, we should not allow them to
opt out of it at a lower level. If a user wishes to set the timeout to infinite for a specific database, collection, or
operation, they can explicitly set <code>timeoutMS</code> to 0.</p>
<h3 id="serverselectiontimeoutms-is-not-deprecated"><a class="header" href="#serverselectiontimeoutms-is-not-deprecated">serverSelectionTimeoutMS is not deprecated</a></h3>
<p>The original goal of the project was to expose a single timeout and deprecate all others. This was not possible,
however, because executing an operation consists of two distinct parts. The first is selecting a server and checking out
a connection from its pool. This should have a default timeout because failure to do this indicates that the deployment
is not in a healthy state or that there was a configuration error which prevents the driver from successfully
connecting. The second is server-side operation execution, which cannot have a default timeout. Some operations finish
in a few milliseconds, while others can run for many hours. Adding a default would inevitably break applications. To
accomplish both of these goals, <code>serverSelectionTimeoutMS</code> was preserved and is used to timeout the client-side section
of operation execution.</p>
<h3 id="connecttimeoutms-is-not-deprecated"><a class="header" href="#connecttimeoutms-is-not-deprecated">connectTimeoutMS is not deprecated</a></h3>
<p>Similar to the reasoning for not deprecating <code>serverSelectionTimeoutMS</code>, socket establishment should have a default
timeout because failure to create a socket likely means that the target server is not healthy or there is a network
issue. To accomplish this, the <code>connectTimeoutMS</code> option is not deprecated by this specification. Drivers also use
<code>connectTimeoutMS</code> to derive a socket timeout for monitoring connections, which are not subject to timeoutMS.</p>
<h3 id="timeoutms-overrides-deprecated-timeout-options"><a class="header" href="#timeoutms-overrides-deprecated-timeout-options">timeoutMS overrides deprecated timeout options</a></h3>
<p>Applying both <code>timeoutMS</code> and a deprecated timeout option like <code>socketTimeoutMS</code> at the same time would lead to
confusing semantics that are difficult to document and understand. When first writing this specification, we considered
having drivers error in this situation to catch mismatched timeouts as early as possible. However, because <code>timeoutMS</code>
can be set at any level, this behavior could lead to unanticipated runtime errors if an application set <code>timeoutMS</code> for
a specific operation and the MongoClient used in production was configured with a deprecated timeout option. To have
clear semantics and avoid unexpected errors in applications, we decided that <code>timeoutMS</code> should override deprecated
timeout options.</p>
<h3 id="maxtimems-is-not-added-for-mongocryptd"><a class="header" href="#maxtimems-is-not-added-for-mongocryptd">maxTimeMS is not added for mongocryptd</a></h3>
<p>The mongocryptd server annotates the provided command to indicate encryption requirements and returns the marked up
result. If the command sent to mongocryptd contained <code>maxTimeMS</code>, the final command sent to MongoDB would contain two
<code>maxTimeMS</code> fields: one added by the regular MongoClient and another added by the mongocryptd client. To avoid this
complication, drivers do not add this field when sending commands to mongocryptd at all. Doing so does not sacrifice any
functionality because mongocryptd always runs on localhost and does not perform any blocking work, so execution or
network timeouts cannot occur.</p>
<h3 id="maxtimems-accounts-for-server-rtt"><a class="header" href="#maxtimems-accounts-for-server-rtt">maxTimeMS accounts for server RTT</a></h3>
<p>When constructing a command, drivers use the <code>timeoutMS</code> option to derive a value for the <code>maxTimeMS</code> command option and
the socket timeout. The full time to round trip a command is (network RTT + server-side execution time). If both
<code>maxTimeMS</code> and socket timeout were set to the same value, the server would never be able to respond with a
<code>MaxTimeMSExpired</code> error because drivers would hit the socket timeout first and close the connection. This would lead to
connection churn if the specified timeout is too low. To allow the server to gracefully error and avoid churn, drivers
must account for the network round trip in the <code>maxTimeMS</code> calculation.</p>
<h3 id="monitoring-threads-do-not-use-timeoutms"><a class="header" href="#monitoring-threads-do-not-use-timeoutms">Monitoring threads do not use timeoutMS</a></h3>
<p>Using <code>timeoutMS</code> in the monitoring and RTT calculation threads would require another special case in the code that
derives <code>maxTimeMS</code> from <code>timeoutMS</code> because the awaitable <code>hello</code> requests sent to 4.4+ servers already have a
<code>maxAwaitTimeMS</code> field. Adding <code>maxTimeMS</code> also does not help for non-awaitable <code>hello</code> commands because we expect them
to execute quickly on the server. The Server Monitoring spec already mandates that drivers set and dynamically update
the read/write timeout of the dedicated connections used in monitoring threads, so we rely on that to time out commands
rather than adding complexity to the behavior of <code>timeoutMS</code>.</p>
<h3 id="runcommand-behavior"><a class="header" href="#runcommand-behavior">runCommand behavior</a></h3>
<p>The behavior of runCommand varies across drivers. If the provided command document includes a <code>maxTimeMS</code> field and the
<code>timeoutMS</code> option is set, some drivers would overwrite the <code>maxTimeMS</code> field with the value derived from <code>timeoutMS</code>,
while others would append a second <code>maxTimeMS</code> field, which would cause a server error on versions 3.4+. To be
prescriptive, we could mandate that drivers raise a client-side error in this case, but this would require a potentially
expensive lookup in the command document. To avoid this additional cost, drivers are only required to document the
behavior and suggest that <code>timeoutMS</code> be used instead of including a manual <code>maxTimeMS</code> field.</p>
<h3 id="why-dont-drivers-use-backoffjitter-between-retry-attempts"><a class="header" href="#why-dont-drivers-use-backoffjitter-between-retry-attempts">Why don't drivers use backoff/jitter between retry attempts?</a></h3>
<p>Earlier versions of this specification proposed adding backoff and/or jitter between retry attempts to avoid connection
storming or overloading the server, but we later deemed this unnecessary. If multiple concurrent operations select the
same server for a retry and its connection pool is empty, we rely on the <code>maxConnecting</code> parameter introduced in
DRIVERS-781 to rate limit new connection attempts, which mitigates the risk of connection storms. Even if the new server
has enough connections in its pool to service the operations, recent server versions do very little resource-intensive
work until execution reaches the storage layer, which is already guarded by read/write tickets, so we don’t expect the
server to be overwhelmed. If we later decide that adding jitter would be useful, it may be easier to do so in the server
itself via a ticket-based admission system earlier in the execution stack.</p>
<h3 id="cursor-close-methods-refresh-timeoutms"><a class="header" href="#cursor-close-methods-refresh-timeoutms">Cursor close() methods refresh timeoutMS</a></h3>
<p>If a cursor times out client-side (e.g. a non-tailable cursor created with <code>timeoutMode=CURSOR_LIFETIME</code>), it’s
imperative that drivers make a good-faith effort to close the server-side cursor even though the timeout has expired
because failing to do so would leave resources open on the server for a potentially long time. It was decided that
<code>timeoutMS</code> will be refreshed for <code>close</code> operations to allow the cursor to be killed server-side.</p>
<h3 id="non-tailable-cursor-behavior"><a class="header" href="#non-tailable-cursor-behavior">Non-tailable cursor behavior</a></h3>
<p>There are two usage patterns for non-tailable cursors. The first is to read documents from a cursor into an iterable
object, either by explicitly iterating the cursor in a loop or using a language construct like Python list
comprehensions. To supply a timeout for the entire process, drivers use <code>timeoutMS</code> to cap the execution time for the
initial command and all required <code>getMore</code>’s. This use case also matches the server behavior; if <code>maxTimeMS</code> is set for
an operation that creates a non-tailable cursor, the server will use the time limit to cap the total server-side
execution time for future <code>getMore</code>’s. Because this type of usage matches the server behavior and is the more common
case, this is the default behavior.</p>
<p>The second use case is batch processing, where the user takes advantage of the lazy nature of cursors to process
documents from a large collection. In this case, the user does not want all documents from the collection to be in an
array because that would require too much memory. To accommodate this use case, drivers support a new <code>timeoutMode</code>
option. Users can set the value for this option to <code>ITERATION</code> to have <code>timeoutMS</code> apply to the original command and
then separately to each <code>next</code> call. When this option is used, drivers do not set <code>maxTimeMS</code> on the initial command to
avoid capping the cursor lifetime in the server.</p>
<h3 id="tailable-cursor-behavior"><a class="header" href="#tailable-cursor-behavior">Tailable cursor behavior</a></h3>
<p>Once a tailable cursor is created, it conceptually lives forever. Therefore, it only makes sense to support
<code>timeoutMode=ITERATION</code> for these cursors and drivers error if <code>timeoutMode=CURSOR_LIFETIME</code> is specified.</p>
<p>There are two types of tailable cursors. The first, tailable non-awaitData cursors, support <code>maxTimeMS</code> for the original
command but not for any <code>getMore</code> requests. However, setting <code>maxTimeMS</code> on the original command also incorrectly caps
the server-side execution time for future <code>getMore</code>’s (<a href="http://jira.mongodb.org/browse/SERVER-51153">SERVER-51153</a>).
This is undesirable behavior because it does not match the guarantees made by <code>timeoutMode=ITERATION</code>. To work around
this, drivers honor <code>timeoutMS</code> for both the original operation and all <code>getMore</code>’s but only use it to derive
client-side timeouts and do not append a <code>maxTimeMS</code> field to any commands. The server-side execution time is enforced
via socket timeouts.</p>
<p>The second type is tailable awaitData cursors. The server supports the <code>maxTimeMS</code> option for the original command. For
<code>getMore</code>’s, the option is supported, but instead of limiting the server-side execution time, it specifies how long the
server should wait for new data to arrive if it reaches the end of the capped collection and the batch is still empty.
If no new data arrives within that time limit, the server will respond with an empty batch. For these cursors, drivers
support both the <code>timeoutMS</code> and <code>maxAwaitTimeMS</code> options. The <code>timeoutMS</code> option is used to derive client-side
timeouts, while the <code>maxAwaitTimeMS</code> option is used as the <code>maxTimeMS</code> field for <code>getMore</code> commands. These values have
distinct meanings, so supporting both yields a more robust, albeit verbose, API. Drivers error if <code>maxAwaitTimeMS</code> is
greater than or equal to <code>timeoutMS</code> because in that case, <code>getMore</code> requests would not succeed if the batch was empty:
the server would wait for <code>maxAwaitTimeMS</code>, but the driver would close the socket after <code>timeoutMS</code>.</p>
<h3 id="change-stream-behavior"><a class="header" href="#change-stream-behavior">Change stream behavior</a></h3>
<p>Change streams internally behave as tailable awaitData cursors, so the behavior of the <code>timeoutMS</code> option is the same
for both. The main difference is that change streams are resumable and drivers automatically perform resume attempts
when they encounter transient errors. This allows change streams to be resilient to timeouts. If <code>timeoutMS</code> expires
during a next call, drivers can’t auto-resume, but they can make sure the change stream is not invalidated so the user
can call next again. In this case, the subsequent call would perform the resume without doing a <code>getMore</code> first.</p>
<h3 id="withtransaction-communicates-timeoutms-via-clientsession"><a class="header" href="#withtransaction-communicates-timeoutms-via-clientsession">withTransaction communicates timeoutMS via ClientSession</a></h3>
<p>Because the <code>withTransaction</code> API doesn’t allow drivers to plumb down the remaining timeout into the user-provided
callback, this spec requires the remaining timeout to be stored on the ClientSession. Operations in the callback that
run under that ClientSession can then extract the timeout from the session and apply it. To avoid confusing validation
semantics, operations error if there is a timeout on the session but also an overridden timeout for the operation. It’s
possible that the ability to communicate timeouts for a block of operations via a ClientSession is useful as a general
purpose API, but we’ve decided to make it private until there are other known use cases.</p>
<h3 id="withtransaction-refreshes-the-timeout-for-aborttransaction"><a class="header" href="#withtransaction-refreshes-the-timeout-for-aborttransaction">withTransaction refreshes the timeout for abortTransaction</a></h3>
<p>If the user-provided callback to <code>withTransaction</code> times out, it could leave a transaction running on the server. It’s
imperative that drivers make an effort to abort the open transaction because failing to do so could result in the
collections and databases affected by the transaction being locked for a long period of time, which could cause
applications to stall. Because <code>timeoutMS</code> has expired before drivers attempt to abort the transaction, we require
drivers to refresh it and apply the original value to the execution of the <code>abortTransaction</code> operation. This can cause
the entire <code>withTransaction</code> call to take up to <code>2*timeoutMS</code>, but it was decided that this risk is worthwhile given the
importance of transaction cleanup.</p>
<h3 id="gridfs-streams-behavior"><a class="header" href="#gridfs-streams-behavior">GridFS streams behavior</a></h3>
<p>Streams created by GridFS API operations (e.g. by <code>open_upload_stream</code> and <code>open_download_stream</code>) present a challenge
for this specification. These types of streams execute multiple operations, but there can be artificial gaps between
operations if the application does not invoke the stream functions for long periods of time. Generally, we expect users
to upload or download an entire file as quickly as possible, so we decided to have <code>timeoutMS</code> cap the lifetime of the
created stream. The other option was to apply the entire <code>timeoutMS</code> value to each operation executed by the stream, but
streams perform many hidden operations, so this approach could cause an upload/download to take much longer than
expected.</p>
<h3 id="timeoutms-cannot-be-overridden-for-startsession-calls"><a class="header" href="#timeoutms-cannot-be-overridden-for-startsession-calls">timeoutMS cannot be overridden for startSession calls</a></h3>
<p>In general, users can override <code>timeoutMS</code> at the level of a single operation. The <code>startSession</code> operation, however,
only inherits <code>timeoutMS</code> from the MongoClient and does not allow the option to be overridden. This was a conscious API
design decision because drivers are moving towards only supporting MongoDB versions 3.6 and higher, so sessions will
always be supported. Adding an override for <code>startSession</code> would introduce a new knob and increase the API surface of
drivers without providing a significant benefit.</p>
<h3 id="drivers-use-minimum-rtt-to-short-circuit-operations"><a class="header" href="#drivers-use-minimum-rtt-to-short-circuit-operations">Drivers use minimum RTT to short circuit operations</a></h3>
<p>A previous version of this spec used the 90th percentile RTT to short circuit operations that might otherwise fail with
a socket timeout. We decided to change this logic to avoid canceling operations that may have a high chance of
succeeding and also remove a dependency on t-digest. Instead, drivers use the minimum RTT from the last 10 samples, or 0
until at least 2 samples have been recorded.</p>
<h2 id="future-work-11"><a class="header" href="#future-work-11">Future work</a></h2>
<h3 id="modify-gridfs-streams-behavior-via-new-options"><a class="header" href="#modify-gridfs-streams-behavior-via-new-options">Modify GridFS streams behavior via new options</a></h3>
<p>As explained in the design rationale, drivers use <code>timeoutMS</code> to cap the entire lifetime of streams created by GridFS
operations. If we find that users are often encountering timeout errors when using these APIs due to the time spent
during non-MongoDB operations (e.g. streaming data read from a GridFS stream into another data store), we could consider
toggling GridFS behavior via an option similar to <code>timeoutMode</code> for cursors. To avoid backwards-breaking behavioral
changes, the default would continue to cap the stream lifetime but there could be another mode that refreshes the
timeout for each database operation. This would mimic using <code>timeoutMode=ITERATION</code> for cursors.</p>
<h2 id="changelog-23"><a class="header" href="#changelog-23">Changelog</a></h2>
<ul>
<li>2024-09-12: Specify that explain helpers support support timeoutMS.</li>
<li>2023-12-07: Migrated from reStructuredText to Markdown.</li>
<li>2022-11-17: Use minimum RTT for maxTimeMS calculation instead of 90th percentile RTT.</li>
<li>2022-10-05: Remove spec front matter.</li>
<li>2022-01-19: Initial version.</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="sessions-specification"><a class="header" href="#sessions-specification">Sessions Specification</a></h1>
<ul>
<li>Status: Accepted</li>
<li>Minimum Server Version: 3.6</li>
</ul>
<hr />
<h2 id="abstract-24"><a class="header" href="#abstract-24">Abstract</a></h2>
<p>Version 3.6 of the server introduces the concept of logical sessions for clients. A session is an abstract concept that
represents a set of sequential operations executed by an application that are related in some way. This specification is
limited to how applications start and end sessions. Other specifications define various ways in which sessions are used
(e.g. causally consistent reads, retryable writes, or transactions).</p>
<p>This specification also discusses how drivers participate in distributing the cluster time throughout a deployment, a
process known as "gossipping the cluster time". While gossipping the cluster time is somewhat orthogonal to sessions,
any driver that implements sessions MUST also implement gossipping the cluster time, so it is included in this
specification.</p>
<h2 id="definitions-2"><a class="header" href="#definitions-2">Definitions</a></h2>
<h3 id="meta-24"><a class="header" href="#meta-24">META</a></h3>
<p>The keywords "MUST", "MUST NOT", "REQUIRED", "SHALL", "SHALL NOT", "SHOULD", "SHOULD NOT", "RECOMMENDED", "MAY", and
"OPTIONAL" in this document are to be interpreted as described in <a href="https://www.ietf.org/rfc/rfc2119.txt">RFC 2119</a>.</p>
<h3 id="terms-14"><a class="header" href="#terms-14">Terms</a></h3>
<p><strong>ClientSession</strong></p>
<p>The driver object representing a client session and the operations that can be performed on it. Depending on the
language a driver is written in this might be an interface or a class. See also <code>ServerSession</code>.</p>
<p><strong>Deployment</strong></p>
<p>A set of servers that are all part of a single MongoDB cluster. We avoid the word "cluster" because some people
interpret "cluster" to mean "sharded cluster".</p>
<p><strong>Explicit session</strong></p>
<p>A session that was started explicitly by the application by calling <code>startSession</code> and passed as an argument to an
operation.</p>
<p><strong>MongoClient</strong></p>
<p>The root object of a driver's API. MAY be named differently in some drivers.</p>
<p><strong>Implicit session</strong></p>
<p>A session that was started implicitly by the driver because the application called an operation without providing an
explicit session.</p>
<p><strong>MongoCollection</strong></p>
<p>The driver object representing a collection and the operations that can be performed on it. MAY be named differently in
some drivers.</p>
<p><strong>MongoDatabase</strong></p>
<p>The driver object representing a database and the operations that can be performed on it. MAY be named differently in
some drivers.</p>
<p><strong>ServerSession</strong></p>
<p>The driver object representing a server session. This type is an implementation detail and does not need to be public.
See also <code>ClientSession</code>.</p>
<p><strong>Server session ID</strong></p>
<p>A server session ID is a token used to identify a particular server session. A driver can ask the server for a session
ID using the <code>startSession</code> command or it can generate one locally (see Generating a Session ID locally).</p>
<p><strong>Session</strong></p>
<p>A session is an abstract concept that represents a set of sequential operations executed by an application that are
related in some way. Other specifications define the various ways in which operations can be related, but examples
include causally consistent reads and retryable writes.</p>
<p><strong>Topology</strong></p>
<p>The current configuration and state of a deployment.</p>
<p><strong>Unacknowledged writes</strong></p>
<p>Unacknowledged writes are write operations that are sent to the server without waiting for a reply acknowledging the
write. See the "When using unacknowledged writes" section below for information on how unacknowledged writes interact
with sessions.</p>
<p><strong>Network error</strong></p>
<p>Any network exception writing to or reading from a socket (e.g. a socket timeout or error).</p>
<h2 id="specification-22"><a class="header" href="#specification-22">Specification</a></h2>
<p>Drivers currently have no concept of a session. The driver API will be expanded to provide a way for applications to
start and end sessions and to execute operations in the context of a session. The goal is to expand the API in a way
that introduces no backward breaking changes. Existing applications that don't use sessions don't need to be changed,
and new applications that don't need sessions can continue to be written using the existing API.</p>
<p>To use sessions an application will call new (or overloaded) methods that take a session parameter.</p>
<h2 id="naming-variations"><a class="header" href="#naming-variations">Naming variations</a></h2>
<p>This specification defines names for new methods and types. To the extent possible, these names SHOULD be used by
drivers. However, where a driver and/or language's naming conventions differ, those naming conventions SHOULD be used.
For example, a driver might name a method <code>StartSession</code> or <code>start_session</code> instead of <code>startSession</code>, or might name a
type <code>client_session</code> instead of <code>ClientSession</code>.</p>
<h2 id="high-level-summary-of-the-api-changes-for-sessions"><a class="header" href="#high-level-summary-of-the-api-changes-for-sessions">High level summary of the API changes for sessions</a></h2>
<p>This section is just a high level summary of the new API. Details are provided further on.</p>
<p>Applications start a new session like this:</p>
<pre><code class="language-typescript">options = new SessionOptions(/* various settings */);
session = client.startSession(options);
</code></pre>
<p>The <code>SessionOptions</code> will be individually defined in several other specifications. It is expected that the set of
<code>SessionOptions</code> will grow over time as sessions are used for new purposes.</p>
<p>Applications use a session by passing it as an argument to operation methods. For example:</p>
<pre><code class="language-typescript">collection.InsertOne(session /* etc. */)
collection.UpdateOne(session /* etc. */)
</code></pre>
<p>Applications end a session like this:</p>
<pre><code class="language-typescript">session.endSession()
</code></pre>
<p>This specification does not deal with multi-document transactions, which are covered in
<a href="sessions/../transactions/transactions.html">their own specification</a>.</p>
<h2 id="mongoclient-changes"><a class="header" href="#mongoclient-changes">MongoClient changes</a></h2>
<p><code>MongoClient</code> interface summary</p>
<pre><code class="language-java">class SessionOptions {
  // various other options as defined in other specifications
}

interface MongoClient {
  ClientSession startSession(SessionOptions options);
  // other existing members of MongoClient
}
</code></pre>
<p>Each new member is documented below.</p>
<p>While it is not part of the public API, <code>MongoClient</code> also needs a private (or internal) <code>clusterTime</code> member
(containing either a BSON document or null) to record the highest <code>clusterTime</code> observed in a deployment (as described
below in <a href="sessions/driver-sessions.html#gossipping-the-cluster-time">Gossipping the cluster time</a>).</p>
<h3 id="startsession"><a class="header" href="#startsession">startSession</a></h3>
<p>The <code>startSession</code> method starts a new <code>ClientSession</code> with the provided options.</p>
<p>It MUST NOT be possible to change the options provided to <code>startSession</code> after <code>startSession</code> has been called. This can
be accomplished by making the <code>SessionOptions</code> class immutable or using some equivalent mechanism that is idiomatic for
your language.</p>
<p>It is valid to call <code>startSession</code> with no options set. This will result in a <code>ClientSession</code> that has no effect on the
operations performed in the context of that session, other than to include a session ID in commands sent to the server.</p>
<p>The <code>SessionOptions</code> MAY be a strongly typed class in some drivers, or MAY be a loosely typed dictionary in other
drivers. Drivers MUST define <code>SessionOptions</code> in such a way that new options can be added in a backward compatible way
(it is acceptable for backward compatibility to be at the source level).</p>
<p>A <code>ClientSession</code> MUST be associated with a <code>ServerSession</code> at the time <code>startSession</code> is called. As an implementation
optimization drivers MUST reuse <code>ServerSession</code> instances across multiple <code>ClientSession</code> instances subject to the rule
that a server session MUST NOT be used by two <code>ClientSession</code> instances at the same time (see the Server Session Pool
section). Additionally, a <code>ClientSession</code> may only ever be associated with one <code>ServerSession</code> for its lifetime.</p>
<p>Drivers MUST NOT check for session support in <code>startSession</code>. Instead, if sessions are not supported, the error MUST be
reported the first time the session is used for an operation (See
<a href="sessions/driver-sessions.html#how-to-tell-whether-a-connection-supports-sessions">How to Tell Whether a Connection Supports Sessions</a>).</p>
<h3 id="explicit-vs-implicit-sessions"><a class="header" href="#explicit-vs-implicit-sessions">Explicit vs implicit sessions</a></h3>
<p>An explicit session is one started explicitly by the application by calling <code>startSession</code>. An implicit session is one
started implicitly by the driver because the application called an operation without providing an explicit session.
Internally, a driver must be able to distinguish between explicit and implicit sessions, but no public API for this is
necessary because an application will never see an implicit session.</p>
<p>The motivation for starting an implicit session for all methods that don't take an explicit session parameter is to make
sure that all commands that are sent to the server are tagged with a session ID. This improves the ability of an
operations team to monitor (and kill if necessary) long running operations. Tagging an operation with a session ID is
specially useful if a deployment wide operation needs to be killed.</p>
<h3 id="authentication-1"><a class="header" href="#authentication-1">Authentication</a></h3>
<p>When using authentication, using a session requires that only a single user be authenticated. Drivers that still support
authenticating multiple users at once MAY continue to do so, but MUST NOT allow sessions to be used under such
circumstances.</p>
<p>If <code>startSession</code> is called when multiple users are authenticated drivers MUST raise an error with the error message
"Cannot call startSession when multiple users are authenticated."</p>
<p>If a driver allows authentication to be changed on the fly (presumably few still do) the driver MUST either prevent
<code>ClientSession</code> instances from being used with a connection that doesn't have matching authentication or MUST return an
error if such use is attempted.</p>
<h2 id="clientsession"><a class="header" href="#clientsession">ClientSession</a></h2>
<p><code>ClientSession</code> instances are not thread safe or fork safe. They can only be used by one thread or process at a time.</p>
<p>Drivers MUST document the thread-safety and fork-safety limitations of sessions. Drivers MUST NOT attempt to detect
simultaneous use by multiple threads or processes (see Q&amp;A for the rationale).</p>
<p>ClientSession interface summary:</p>
<pre><code class="language-java">interface ClientSession {
    MongoClient client;
    Optional&lt;BsonDocument&gt; clusterTime;
    SessionOptions options;
    BsonDocument sessionId;

    void advanceClusterTime(BsonDocument clusterTime);
    void endSession();
}
</code></pre>
<p>While it is not part of the public API, a <code>ClientSession</code> also has a private (or internal) reference to a
<code>ServerSession</code>.</p>
<p>Each member is documented below.</p>
<h3 id="client-3"><a class="header" href="#client-3">client</a></h3>
<p>This property returns the <code>MongoClient</code> that was used to start this <code>ClientSession</code>.</p>
<h3 id="clustertime"><a class="header" href="#clustertime">clusterTime</a></h3>
<p>This property returns the most recent cluster time seen by this session. If no operations have been executed using this
session this value will be null unless <code>advanceClusterTime</code> has been called. This value will also be null when a cluster
does not report cluster times.</p>
<p>When a driver is gossiping the cluster time it should send the more recent <code>clusterTime</code> of the <code>ClientSession</code> and the
<code>MongoClient</code>.</p>
<h3 id="options"><a class="header" href="#options">options</a></h3>
<p>This property returns the <code>SessionOptions</code> that were used to start this <code>ClientSession</code>.</p>
<h3 id="sessionid"><a class="header" href="#sessionid">sessionId</a></h3>
<p>This property returns the session ID of this session. Note that since <code>ServerSessions</code> are pooled, different
<code>ClientSession</code> instances can have the same session ID, but never at the same time.</p>
<h3 id="advanceclustertime"><a class="header" href="#advanceclustertime">advanceClusterTime</a></h3>
<p>This method advances the <code>clusterTime</code> for a session. If the new <code>clusterTime</code> is greater than the session's current
<code>clusterTime</code> then the session's <code>clusterTime</code> MUST be advanced to the new <code>clusterTime</code>. If the new <code>clusterTime</code> is
less than or equal to the session's current <code>clusterTime</code> then the session's <code>clusterTime</code> MUST NOT be changed.</p>
<p>This method MUST NOT advance the <code>clusterTime</code> in <code>MongoClient</code> because we have no way of verifying that the supplied
<code>clusterTime</code> is valid. If the <code>clusterTime</code> in <code>MongoClient</code> were set to an invalid value all future operations with
this <code>MongoClient</code> would result in the server returning an error. The <code>clusterTime</code> in <code>MongoClient</code> should only be
advanced with a <code>$clusterTime</code> received directly from a server.</p>
<h3 id="endsession"><a class="header" href="#endsession">endSession</a></h3>
<p>This method ends a <code>ClientSession</code>.</p>
<p>In languages that have idiomatic ways of disposing of resources, drivers SHOULD support that in addition to or instead
of <code>endSession</code>. For example, in the .NET driver <code>ClientSession</code> would implement <code>IDisposable</code> and the application could
choose to call <code>session.Dispose</code> or put the session in a using statement instead of calling <code>session.endSession</code>. If
your language has an idiomatic way of disposing resources you MAY choose to implement that in addition to or instead of
<code>endSession</code>, whichever is more idiomatic for your language.</p>
<p>A driver MUST allow multiple calls to <code>endSession</code> (or <code>Dispose</code>). All calls after the first one are ignored.</p>
<p>Conceptually, calling <code>endSession</code> implies ending the corresponding server session (by calling the <code>endSessions</code>
command). As an implementation detail drivers SHOULD cache server sessions for reuse (see Server Session Pool).</p>
<p>Once a <code>ClientSession</code> has ended, drivers MUST report an error if any operations are attempted with that
<code>ClientSession</code>.</p>
<h2 id="serversession"><a class="header" href="#serversession">ServerSession</a></h2>
<p>A <code>ServerSession</code> is the driver object that tracks a server session. This object is an implementation detail and does
not need to be public. Drivers may store this information however they choose; this data structure is defined here
merely to describe the operation of the server session pool.</p>
<p>ServerSession interface summary</p>
<pre><code class="language-java">interface ServerSession {
  BsonDocument sessionId;
  DateTime lastUse;
}
</code></pre>
<h3 id="sessionid-1"><a class="header" href="#sessionid-1">sessionId</a></h3>
<p>This property returns the server session ID.</p>
<h3 id="lastuse"><a class="header" href="#lastuse">lastUse</a></h3>
<p>The driver MUST update the value of this property with the current DateTime every time the server session ID is sent to
the server. This allows the driver to track with reasonable accuracy the server's view of when a server session was last
used.</p>
<h3 id="creating-a-serversession"><a class="header" href="#creating-a-serversession">Creating a ServerSession</a></h3>
<p>When a driver needs to create a new <code>ServerSession</code> instance the only information it needs is the session ID to use for
the new session. It can either get the session ID from the server by running the <code>startSession</code> command, or it can
generate it locally.</p>
<p>In either case, the lastUse field of the <code>ServerSession</code> MUST be set to the current time when the <code>ServerSession</code> is
created.</p>
<h3 id="generating-a-session-id-locally"><a class="header" href="#generating-a-session-id-locally">Generating a session ID locally</a></h3>
<p>Running the <code>startSession</code> command to get a session ID for a new session requires a round trip to the server. As an
optimization the server allows drivers to generate new session IDs locally and to just start using them. When a server
sees a new session ID that it has never seen before it simply assumes that it is a new session.</p>
<p>A session ID is a <code>BsonDocument</code> that has the following form:</p>
<pre><code class="language-typescript">interface SessionId {
  id: UUID
}
</code></pre>
<p>Where the UUID is encoded as a BSON binary value of subtype 4.</p>
<p>The id field of the session ID is a version 4 UUID that must comply with the format described in RFC 4122. Section 4.4
describes an algorithm for generating correctly-versioned UUIDs from a pseudo-random number generator.</p>
<p>If a driver is unable to generate a version 4 UUID it MAY instead run the <code>startSession</code> command and let the server
generate the session ID.</p>
<h2 id="mongodatabase-changes"><a class="header" href="#mongodatabase-changes">MongoDatabase changes</a></h2>
<p>All <code>MongoDatabase</code> methods that talk to the server MUST send a session ID with the command when connected to a
deployment that supports sessions so that the server can associate the operation with a session ID.</p>
<h3 id="new-database-methods-that-take-an-explicit-session"><a class="header" href="#new-database-methods-that-take-an-explicit-session">New database methods that take an explicit session</a></h3>
<p>All <code>MongoDatabase</code> methods that talk to the server SHOULD be overloaded to take an explicit session parameter. (See
<a href="sessions/driver-sessions.html#why-is-session-an-explicit-parameter">why is session an explicit parameter?</a>.)</p>
<p>When overloading methods to take a session parameter, the session parameter SHOULD be the first parameter. If
overloading is not possible for your language, it MAY be in a different position or MAY be embedded in an options
structure.</p>
<p>Methods that have a session parameter MUST check that the session argument is not null and was created by the same
<code>MongoClient</code> that this <code>MongoDatabase</code> came from and report an error if they do not match.</p>
<h3 id="existing-database-methods-that-start-an-implicit-session"><a class="header" href="#existing-database-methods-that-start-an-implicit-session">Existing database methods that start an implicit session</a></h3>
<p>When an existing <code>MongoDatabase</code> method that does not take a session is called, the driver MUST behave as if a new
<code>ClientSession</code> was started just for this one operation and ended immediately after this operation completes. The actual
implementation will likely involve calling <code>client.startSession</code>, but that is not required by this spec. Regardless,
please consult the startSession section to replicate the required steps for creating a session. The driver MUST NOT use
the session if the checked out connection does not support sessions (see
<a href="sessions/driver-sessions.html#how-to-tell-whether-a-connection-supports-sessions">How to Tell Whether a Connection Supports Sessions</a>) and, in all
cases, MUST NOT consume a server session id until after the connection is checked out and session support is confirmed.</p>
<h2 id="mongocollection-changes"><a class="header" href="#mongocollection-changes">MongoCollection changes</a></h2>
<p>All <code>MongoCollection</code> methods that talk to the server MUST send a session ID with the command when connected to a
deployment that supports sessions so that the server can associate the operation with a session ID.</p>
<h3 id="new-collection-methods-that-take-an-explicit-session"><a class="header" href="#new-collection-methods-that-take-an-explicit-session">New collection methods that take an explicit session</a></h3>
<p>All <code>MongoCollection</code> methods that talk to the server, with the exception of <code>estimatedDocumentCount</code>, SHOULD be
overloaded to take an explicit session parameter. (See
<a href="sessions/driver-sessions.html#why-is-session-an-explicit-parameter">why is session an explicit parameter?</a>.)</p>
<p>When overloading methods to take a session parameter, the session parameter SHOULD be the first parameter. If
overloading is not possible for your language, it MAY be in a different position or MAY be embedded in an options
structure.</p>
<p>Methods that have a session parameter MUST check that the session argument is not null and was created by the same
<code>MongoClient</code> that this <code>MongoCollection</code> came from and report an error if they do not match.</p>
<p>The <code>estimatedDocumentCount</code> helper does not support an explicit session parameter. The underlying command, <code>count</code>, is
not supported in a transaction, so supporting an explicit session would likely confuse application developers. The
helper returns an estimate of the documents in a collection and causal consistency is unlikely to improve the accuracy
of the estimate.</p>
<h3 id="existing-collection-methods-that-start-an-implicit-session"><a class="header" href="#existing-collection-methods-that-start-an-implicit-session">Existing collection methods that start an implicit session</a></h3>
<p>When an existing <code>MongoCollection</code> method that does not take a session is called, the driver MUST behave as if a new
<code>ClientSession</code> was started just for this one operation and ended immediately after this operation completes. The actual
implementation will likely involve calling <code>client.startSession</code>, but that is not required by this spec. Regardless,
please consult the startSession section to replicate the required steps for creating a session. The driver MUST NOT use
the session if the checked out connection does not support sessions (see
<a href="sessions/driver-sessions.html#how-to-tell-whether-a-connection-supports-sessions">How to Tell Whether a Connection Supports Sessions</a>) and, in all
cases, MUST NOT consume a server session id until after the connection is checked out and session support is confirmed.</p>
<h2 id="sessions-and-cursors"><a class="header" href="#sessions-and-cursors">Sessions and Cursors</a></h2>
<p>When an operation using a session returns a cursor, all subsequent <code>GETMORE</code> commands for that cursor MUST be run using
the same session ID.</p>
<p>If a driver decides to run a <code>KILLCURSORS</code> command on the cursor, it also MAY be run using the same session ID. See the
Exceptions below for when it is permissible to not include a session ID in a <code>KILLCURSORS</code> command.</p>
<h2 id="sessions-and-connections"><a class="header" href="#sessions-and-connections">Sessions and Connections</a></h2>
<p>To reduce the number of <code>ServerSessions</code> created, the driver MUST only obtain an implicit session's <code>ServerSession</code>
after it successfully checks out a connection. A driver SHOULD NOT attempt to release the acquired session before
connection check in.</p>
<p>Explicit sessions MAY be changed to allocate a server session similarly.</p>
<h2 id="how-to-tell-whether-a-connection-supports-sessions"><a class="header" href="#how-to-tell-whether-a-connection-supports-sessions">How to Tell Whether a Connection Supports Sessions</a></h2>
<p>A driver can determine whether a connection supports sessions by checking whether the <code>logicalSessionTimeoutMinutes</code>
property of the establishing handshake response has a value or not. If it has a value, sessions are supported.</p>
<p>In the case of an explicit session, if sessions are not supported, the driver MUST raise an error. In the case of an
implicit session, if sessions are not supported, the driver MUST ignore the session.</p>
<h3 id="possible-race-condition-when-checking-for-session-support"><a class="header" href="#possible-race-condition-when-checking-for-session-support">Possible race condition when checking for session support</a></h3>
<p>There is a possible race condition that can happen between the time the driver checks whether sessions are supported and
subsequently sends a command to the server:</p>
<ul>
<li>The server might have supported sessions at the time the connection was first opened (and reported a value for
logicalSessionTimeoutMinutes in the initial response to the <a href="sessions/../mongodb-handshake/handshake.html">handshake</a>), but have
subsequently been downgraded to not support sessions. The server does not close the socket in this scenario, so the
driver will conclude that the server at the other end of this connection supports sessions.</li>
</ul>
<p>There is nothing that the driver can do about this race condition, and the server will just return an error in this
scenario.</p>
<h2 id="sending-the-session-id-to-the-server-on-all-commands"><a class="header" href="#sending-the-session-id-to-the-server-on-all-commands">Sending the session ID to the server on all commands</a></h2>
<p>When connected to a server that supports sessions a driver MUST append the session ID to every command it sends to the
server (with the exceptions noted in the following section). It does this by adding a top level <code>lsid</code> field to the
command sent to the server. A driver MUST do this without modifying any data supplied by the application (e.g. the
command document passed to runCommand).:</p>
<pre><code class="language-typescript">interface ExampleCommandWithLSID {
  foo: 1;
  lsid: SessionId;
}
</code></pre>
<h2 id="exceptions-to-sending-the-session-id-to-the-server-on-all-commands"><a class="header" href="#exceptions-to-sending-the-session-id-to-the-server-on-all-commands">Exceptions to sending the session ID to the server on all commands</a></h2>
<p>There are some exceptions to the rule that a driver MUST append the session ID to every command it sends to the server.</p>
<h3 id="when-opening-and-authenticating-a-connection"><a class="header" href="#when-opening-and-authenticating-a-connection">When opening and authenticating a connection</a></h3>
<p>A driver MUST NOT append a session ID to any command sent during the process of opening and authenticating a connection.</p>
<h3 id="when-monitoring-the-state-of-a-deployment"><a class="header" href="#when-monitoring-the-state-of-a-deployment">When monitoring the state of a deployment</a></h3>
<p>A driver MAY omit a session ID in hello and legacy hello commands sent solely for the purposes of monitoring the state
of a deployment.</p>
<h3 id="when-sending-a-parallelcollectionscan-command"><a class="header" href="#when-sending-a-parallelcollectionscan-command">When sending a parallelCollectionScan command</a></h3>
<p>Sessions are designed for sequential operations and <code>parallelCollectionScan</code> is designed for parallel operation. Because
these are fundamentally incompatible goals, drivers MUST NOT append session ID to the <code>parallelCollectionScan</code> command
so that the resulting cursors have no associated session ID and thus can be used in parallel.</p>
<h3 id="when-sending-a-killcursors-command"><a class="header" href="#when-sending-a-killcursors-command">When sending a killCursors command</a></h3>
<p>A driver MAY omit a session ID in <code>killCursors</code> commands for two reasons. First, <code>killCursors</code> is only ever sent to a
particular server, so operation teams wouldn't need the <code>lsid</code> for cluster-wide killOp. An admin can manually kill the
op with its operation id in the case that it is slow. Secondly, some drivers have a background cursor reaper to kill
cursors that aren't exhausted and closed. Due to GC semantics, it can't use the same <code>lsid</code> for <code>killCursors</code> as was
used for a cursor's <code>find</code> and <code>getMore</code>, so there's no point in using any <code>lsid</code> at all.</p>
<h3 id="when-multiple-users-are-authenticated-and-the-session-is-implicit"><a class="header" href="#when-multiple-users-are-authenticated-and-the-session-is-implicit">When multiple users are authenticated and the session is implicit</a></h3>
<p>The driver MUST NOT send a session ID from an implicit session when multiple users are authenticated. If possible the
driver MUST NOT start an implicit session when multiple users are authenticated. Alternatively, if the driver cannot
determine whether multiple users are authenticated at the point in time that an implicit session is started, then the
driver MUST ignore any implicit sessions that subsequently end up being used on a connection that has multiple users
authenticated.</p>
<h3 id="when-using-unacknowledged-writes"><a class="header" href="#when-using-unacknowledged-writes">When using unacknowledged writes</a></h3>
<p>A session ID MUST NOT be used simultaneously by more than one operation. Since drivers don't wait for a response for an
unacknowledged write a driver would not know when the session ID could be reused. In theory a driver could use a new
session ID for each unacknowledged write, but that would result in many orphaned sessions building up at the server.</p>
<p>Therefore drivers MUST NOT send a session ID with unacknowledged writes under any circumstances:</p>
<ul>
<li>For unacknowledged writes with an explicit session, drivers SHOULD raise an error. If a driver allows users to provide
an explicit session with an unacknowledged write (e.g. for backwards compatibility), the driver MUST NOT send the
session ID.</li>
<li>For unacknowledged writes without an explicit session, drivers SHOULD NOT use an implicit session. If a driver creates
an implicit session for unacknowledged writes without an explicit session, the driver MUST NOT send the session ID.</li>
</ul>
<p>Drivers MUST document the behavior of unacknowledged writes for both explicit and implicit sessions.</p>
<h3 id="when-wrapping-commands-in-a-query-field"><a class="header" href="#when-wrapping-commands-in-a-query-field">When wrapping commands in a <code>$query</code> field</a></h3>
<p>If the driver is wrapping the command in a <code>$query</code> field for non-OP_MSG messages in order to pass a readPreference to a
mongos (see
<a href="sessions/../find_getmore_killcursors_commands/find_getmore_killcursors_commands.html#readpreference-and-mongos">ReadPreference and Mongos</a>),
the driver SHOULD NOT add the <code>lsid</code> as a top-level field, and MUST add the <code>lsid</code> as a field of the <code>$query</code></p>
<pre><code class="language-typescript">// Wrapped command:
interface WrappedCommandExample {
  $query: {
    find: { foo: 1 }
  },
  $readPreference: {}
}

// Correct application of lsid
interface CorrectLSIDUsageExample {
  $query: {
    find: { foo: 1 },
    lsid: SessionId
  },
  $readPreference: {}
}

// Incorrect application of lsid
interface IncorrectLSIDUsageExample {
  $query: {
    find: { foo: 1 }
  },
  $readPreference: {},
  lsid: SessionId
}
</code></pre>
<h2 id="server-commands"><a class="header" href="#server-commands">Server Commands</a></h2>
<h3 id="startsession-1"><a class="header" href="#startsession-1">startSession</a></h3>
<p>The <code>startSession</code> server command has the following format:</p>
<pre><code class="language-typescript">interface StartSessionCommand {
  startSession: 1;
  $clusterTime?: ClusterTime;
}
</code></pre>
<p>The <code>$clusterTime</code> field should only be sent when gossipping the cluster time. See the section "Gossipping the cluster
time" for information on <code>$clusterTime</code>.</p>
<p>The <code>startSession</code> command MUST be sent to the <code>admin</code> database.</p>
<p>The server response has the following format:</p>
<pre><code class="language-typescript">interface StartSessionResponse {
  ok: 1;
  id: BsonDocument;
}
</code></pre>
<p>In case of an error, the server response has the following format:</p>
<pre><code class="language-typescript">interface StartSessionError {
  ok: 0;
  errmsg: string;
  code: number;
}
</code></pre>
<p>When connected to a replica set the <code>startSession</code> command MUST be sent to the primary if the primary is available. The
<code>startSession</code> command MAY be sent to a secondary if there is no primary available at the time the <code>startSession</code>
command needs to be run.</p>
<p>Drivers SHOULD generate session IDs locally if possible instead of running the <code>startSession</code> command, since running the
command requires a network round trip.</p>
<h3 id="endsessions"><a class="header" href="#endsessions">endSessions</a></h3>
<p>The <code>endSessions</code> server command has the following format:</p>
<pre><code class="language-typescript">interface EndSessionCommand {
  endSessions: Array&lt;SessionId&gt;;
  $clusterTime?: ClusterTime;
}
</code></pre>
<p>The <code>$clusterTime</code> field should only be sent when gossipping the cluster time. See the section of "Gossipping the
cluster time" for information on <code>$clusterTime</code>.</p>
<p>The <code>endSessions</code> command MUST be sent to the <code>admin</code> database.</p>
<p>The server response has the following format:</p>
<pre><code class="language-typescript">interface EndSessionResponse {
  ok: 1;
}
</code></pre>
<p>In case of an error, the server response has the following format:</p>
<pre><code class="language-typescript">interface EndSessionError {
  ok: 0;
  errmsg: string;
  code: number;
}
</code></pre>
<p>Drivers MUST ignore any errors returned by the <code>endSessions</code> command.</p>
<p>The <code>endSessions</code> command MUST be run once when the <code>MongoClient</code> instance is shut down. If the number of sessions is
very large the <code>endSessions</code> command SHOULD be run multiple times to end 10,000 sessions at a time (in order to avoid
creating excessively large commands).</p>
<p>When connected to a sharded cluster the <code>endSessions</code> command can be sent to any mongos. When connected to a replica set
the <code>endSessions</code> command MUST be sent to the primary if the primary is available, otherwise it MUST be sent to any
available secondary.</p>
<h2 id="server-session-pool"><a class="header" href="#server-session-pool">Server Session Pool</a></h2>
<p>Conceptually, each <code>ClientSession</code> can be thought of as having a new corresponding <code>ServerSession</code>. However, starting a
server session might require a round trip to the server (which can be avoided by generating the session ID locally) and
ending a session requires a separate round trip to the server. Drivers can operate more efficiently and put less load on
the server if they cache <code>ServerSession</code> instances for reuse. To this end drivers MUST implement a server session pool
containing <code>ServerSession</code> instances available for reuse. A <code>ServerSession</code> pool MUST belong to a <code>MongoClient</code> instance
and have the same lifetime as the <code>MongoClient</code> instance.</p>
<p>When a new implicit <code>ClientSession</code> is started it MUST NOT attempt to acquire a server session from the server session
pool immediately. When a new explicit <code>ClientSession</code> is started it MAY attempt to acquire a server session from the
server session pool immediately. See the algorithm below for the steps to follow when attempting to acquire a
<code>ServerSession</code> from the server session pool.</p>
<p>Note that <code>ServerSession</code> instances acquired from the server session pool might have as little as one minute left before
becoming stale and being discarded server side. Drivers MUST document that if an application waits more than one minute
after calling <code>startSession</code> to perform operations with that session it risks getting errors due to the server session
going stale before it was used.</p>
<p>A server session is considered stale by the server when it has not been used for a certain amount of time. The default
amount of time is 30 minutes, but this value is configurable on the server. Servers that support sessions will report
this value in the <code>logicalSessionTimeoutMinutes</code> field of the reply to the hello and legacy hello commands. The smallest
reported timeout is recorded in the <code>logicalSessionTimeoutMinutes</code> property of the <code>TopologyDescription</code>. See the Server
Discovery And Monitoring specification for details.</p>
<p>When a <code>ClientSession</code> is ended it MUST return the server session to the server session pool. See the algorithm below
for the steps to follow when returning a <code>ServerSession</code> instance to the server session pool.</p>
<p>The server session pool has no maximum size. The pool only shrinks when a server session is acquired for use or
discarded.</p>
<p>When a <code>MongoClient</code> instance is closed the driver MUST proactively inform the server that the pooled server sessions
will no longer be used by sending one or more <code>endSessions</code> commands to the server.</p>
<p>The server session pool is modeled as a double ended queue. The algorithms below require the ability to add and remove
<code>ServerSession</code> instances from the front of the queue and to inspect and possibly remove <code>ServerSession</code> instances from
the back of the queue. The front of the queue holds <code>ServerSession</code> instances that have been released recently and
should be the first to be reused. The back of the queue holds <code>ServerSession</code> instances that have not been used recently
and that potentially will be discarded if they are not used again before they expire.</p>
<p>An implicit session MUST be returned to the pool immediately following the completion of an operation. When an implicit
session is associated with a cursor for use with <code>getMore</code> operations, the session MUST be returned to the pool
immediately following a <code>getMore</code> operation that indicates that the cursor has been exhausted. In particular, it MUST
not wait until all documents have been iterated by the application or until the application disposes of the cursor. For
language runtimes that provide the ability to attach finalizers to objects that are run prior to garbage collection, the
cursor class SHOULD return an implicit session to the pool in the finalizer if the cursor has not already been
exhausted.</p>
<p>If a driver supports process forking, the session pool needs to be cleared on one side of the forked processes (just
like sockets need to reconnect). Drivers MUST provide a way to clear the session pool without sending <code>endSessions</code>.
Drivers MAY make this automatic when the process ID changes. If they do not, they MUST document how to clear the session
pool wherever they document fork support. After clearing the session pool in this way, drivers MUST ensure that sessions
already checked out are not returned to the new pool.</p>
<p>If a driver has a server session pool and a network error is encountered when executing any command with a
<code>ClientSession</code>, the driver MUST mark the associated <code>ServerSession</code> as dirty. Dirty server sessions are discarded when
returned to the server session pool. It is valid for a dirty session to be used for subsequent commands (e.g. an
implicit retry attempt, a later command in a bulk write, or a later operation on an explicit session), however, it MUST
remain dirty for the remainder of its lifetime regardless if later commands succeed.</p>
<h3 id="algorithm-to-acquire-a-serversession-instance-from-the-server-session-pool"><a class="header" href="#algorithm-to-acquire-a-serversession-instance-from-the-server-session-pool">Algorithm to acquire a ServerSession instance from the server session pool</a></h3>
<ol>
<li>If the server session pool is empty create a new <code>ServerSession</code> and use it</li>
<li>Otherwise remove a <code>ServerSession</code> from the front of the queue and examine it:
<ul>
<li>If the driver is in load balancer mode, use this <code>ServerSession</code>.</li>
<li>If it has at least one minute left before becoming stale use this <code>ServerSession</code></li>
<li>If it has less than one minute left before becoming stale discard it (let it be garbage collected) and return to
step 1.</li>
</ul>
</li>
</ol>
<p>See the <a href="sessions/../load-balancers/load-balancers.html#session-expiration">Load Balancer Specification</a> for details on session
expiration.</p>
<h3 id="algorithm-to-return-a-serversession-instance-to-the-server-session-pool"><a class="header" href="#algorithm-to-return-a-serversession-instance-to-the-server-session-pool">Algorithm to return a ServerSession instance to the server session pool</a></h3>
<ol>
<li>Before returning a server session to the pool a driver MUST first check the server session pool for server sessions
at the back of the queue that are about to expire (meaning they will expire in less than one minute). A driver MUST
stop checking server sessions once it encounters a server session that is not about to expire. Any server sessions
found that are about to expire are removed from the end of the queue and discarded (or allowed to be garbage
collected)</li>
<li>Then examine the server session that is being returned to the pool and:
<ul>
<li>If this session is marked dirty (i.e. it was involved in a network error) discard it (let it be garbage collected)</li>
<li>If it will expire in less than one minute discard it (let it be garbage collected)</li>
<li>If it won't expire for at least one minute add it to the front of the queue</li>
</ul>
</li>
</ol>
<h2 id="gossipping-the-cluster-time"><a class="header" href="#gossipping-the-cluster-time">Gossipping the cluster time</a></h2>
<p>Drivers MUST gossip the cluster time when connected to a deployment that uses cluster times.</p>
<p>Gossipping the cluster time is a process in which the driver participates in distributing the logical cluster time in a
deployment. Drivers learn the current cluster time (from a particular server's perspective) in responses they receive
from servers. Drivers in turn forward the highest cluster time they have seen so far to any server they subsequently
send commands to.</p>
<p>A driver detects that it MUST participate in gossipping the cluster time when it sees a <code>$clusterTime</code> in a response
received from a server.</p>
<h3 id="receiving-the-current-cluster-time"><a class="header" href="#receiving-the-current-cluster-time">Receiving the current cluster time</a></h3>
<p>Drivers MUST examine all responses from the server commands to see if they contain a top level field named
<code>$clusterTime</code> formatted as follows:</p>
<pre><code class="language-typescript">interface ClusterTime {
  clusterTime: Timestamp;
  signature: {
    hash: Binary;
    keyId: Int64;
  };
}

interface AnyServerResponse {
  // ... other properties ...
  $clusterTime: ClusterTime;
}
</code></pre>
<p>Whenever a driver receives a cluster time from a server it MUST compare it to the current highest seen cluster time for
the deployment. If the new cluster time is higher than the highest seen cluster time it MUST become the new highest seen
cluster time. Two cluster times are compared using only the BsonTimestamp value of the <code>clusterTime</code> embedded field (be
sure to include both the timestamp and the increment of the BsonTimestamp in the comparison). The signature field does
not participate in the comparison.</p>
<h3 id="sending-the-highest-seen-cluster-time"><a class="header" href="#sending-the-highest-seen-cluster-time">Sending the highest seen cluster time</a></h3>
<p>Whenever a driver sends a command to a server it MUST include the highest seen cluster time in a top level field called
<code>$clusterTime</code>, in the same format as it was received in (but see Gossipping with mixed server versions below).</p>
<h3 id="how-to-compute-the-clustertime-to-send-to-a-server"><a class="header" href="#how-to-compute-the-clustertime-to-send-to-a-server">How to compute the <code>$clusterTime</code> to send to a server</a></h3>
<p>When sending <code>$clusterTime</code> to the server the driver MUST send the greater of the <code>clusterTime</code> values from
<code>MongoClient</code> and <code>ClientSession</code>. Normally a session's <code>clusterTime</code> will be less than or equal to the <code>clusterTime</code> in
<code>MongoClient</code>, but it could be greater than the <code>clusterTime</code> in <code>MongoClient</code> if <code>advanceClusterTime</code> was called with a
<code>clusterTime</code> that came from somewhere else.</p>
<p>A driver MUST NOT use the <code>clusterTime</code> of a <code>ClientSession</code> anywhere else except when executing an operation with this
session. This rule protects the driver from the scenario where <code>advanceClusterTime</code> was called with an invalid
<code>clusterTime</code> by limiting the resulting server errors to the one session. The <code>clusterTime</code> of a <code>MongoClient</code> MUST NOT
be advanced by any <code>clusterTime</code> other than a <code>$clusterTime</code> received directly from a server.</p>
<p>The safe way to compute the <code>$clusterTime</code> to send to a server is:</p>
<ol>
<li>
<p>When the <code>ClientSession</code> is first started its <code>clusterTime</code> is set to null.</p>
</li>
<li>
<p>When the driver sends <code>$clusterTime</code> to the server it should send the greater of the <code>ClientSession</code> <code>clusterTime</code>
and the <code>MongoClient</code> <code>clusterTime</code> (either one could be null).</p>
</li>
<li>
<p>When the driver receives a <code>$clusterTime</code> from the server it should advance both the <code>ClientSession</code> and the
<code>MongoClient</code> <code>clusterTime</code>. The <code>clusterTime</code> of a <code>ClientSession</code> can also be advanced by calling
<code>advanceClusterTime</code>.</p>
</li>
</ol>
<p>This sequence ensures that if the <code>clusterTime</code> of a <code>ClientSession</code> is invalid only that one session will be affected.
The <code>MongoClient</code> <code>clusterTime</code> is only updated with <code>$clusterTime</code> values known to be valid because they were received
directly from a server.</p>
<h3 id="tracking-the-highest-seen-cluster-time-does-not-require-checking-the-deployment-topology-or-the-server-version"><a class="header" href="#tracking-the-highest-seen-cluster-time-does-not-require-checking-the-deployment-topology-or-the-server-version">Tracking the highest seen cluster time does not require checking the deployment topology or the server version</a></h3>
<p>Drivers do not need to check the deployment topology or the server version they are connected to in order to track the
highest seen <code>$clusterTime</code>. They simply need to check for the presence of the <code>$clusterTime</code> field in responses
received from servers.</p>
<h3 id="gossipping-with-mixed-server-versions"><a class="header" href="#gossipping-with-mixed-server-versions">Gossipping with mixed server versions</a></h3>
<p>Drivers MUST check that the server they are sending a command to supports <code>$clusterTime</code> before adding <code>$clusterTime</code> to
the command. A server supports <code>$clusterTime</code> when the <code>maxWireVersion</code> &gt;= 6.</p>
<p>This supports the (presumably short lived) scenario where not all servers have been upgraded to 3.6.</p>
<h2 id="test-plan-18"><a class="header" href="#test-plan-18">Test Plan</a></h2>
<p>See the <a href="sessions/tests/README.html">README</a> for tests.</p>
<h2 id="motivation-1"><a class="header" href="#motivation-1">Motivation</a></h2>
<p>Drivers currently have no concept of a session. The driver API needs to be extended to support sessions.</p>
<h2 id="design-rationale-17"><a class="header" href="#design-rationale-17">Design Rationale</a></h2>
<p>The goal is to modify the driver API in such a way that existing programs that don't use sessions continue to compile
and run correctly. This goal is met by defining new methods (or overloads) that take a session parameter. An application
does not need to be modified unless it wants to take advantage of the new features supported by sessions.</p>
<h2 id="backwards-compatibility-14"><a class="header" href="#backwards-compatibility-14">Backwards Compatibility</a></h2>
<p>The API changes to support sessions extend the existing API but do not introduce any backward breaking changes. Existing
programs that don't use sessions continue to compile and run correctly.</p>
<h2 id="reference-implementation-always-required"><a class="header" href="#reference-implementation-always-required">Reference Implementation (always required)</a></h2>
<p>A reference implementation must be completed before any spec is given status "Final", but it need not be completed
before the spec is "Accepted". While there is merit to the approach of reaching consensus on the specification and
rationale before writing code, the principle of "rough consensus and running code" is still useful when it comes to
resolving many discussions of spec details. A final reference implementation must include test code and documentation.</p>
<p>The C and C# drivers will do initial POC implementations.</p>
<h2 id="future-work-optional"><a class="header" href="#future-work-optional">Future work (optional)</a></h2>
<p>Use this section to discuss any possible work for a future spec. This could cover issues where no consensus could be
reached but that don't block this spec, changes that were rejected due to unclear use cases, etc.</p>
<h2 id="open-questions"><a class="header" href="#open-questions">Open questions</a></h2>
<h2 id="qa-8"><a class="header" href="#qa-8">Q&amp;A</a></h2>
<h3 id="why-do-we-say-drivers-must-not-attempt-to-detect-unsafe-multi-threaded-or-multi-process-use-of-clientsession"><a class="header" href="#why-do-we-say-drivers-must-not-attempt-to-detect-unsafe-multi-threaded-or-multi-process-use-of-clientsession">Why do we say drivers MUST NOT attempt to detect unsafe multi-threaded or multi-process use of <code>ClientSession</code>?</a></h3>
<p>Because doing so would provide an illusion of safety. It doesn't make these instances thread safe. And even if when
testing an application no such exceptions are encountered, that doesn't prove anything. The application might still be
using the instances in a thread-unsafe way and just didn't happen to do so during a test run. The final argument is that
checking this would require overhead that doesn't provide any clear benefit.</p>
<h3 id="why-is-session-an-explicit-parameter"><a class="header" href="#why-is-session-an-explicit-parameter">Why is session an explicit parameter?</a></h3>
<p>A previous draft proposed that ClientSession would be a MongoClient-like object added to the object hierarchy:</p>
<pre><code class="language-javascript">session = client.startSession(...)
database = session.getDatabase(...) // database is associated with session
collection = database.getCollection(...) // collection is associated with session
// operations on collection implicitly use session
collection.insertOne({})
session.endSession()
</code></pre>
<p>The central feature of this design is that a MongoCollection (or database, or perhaps a GridFS object) is associated
with a session, which is then an implied parameter to any operations executed using that MongoCollection.</p>
<p>This API was rejected, with the justification that a ClientSession does not naturally belong to the state of a
MongoCollection. MongoCollection has up to now been a stable long-lived object that could be widely shared, and in most
drivers it is thread safe. Once we associate a ClientSession with it, the MongoCollection object becomes short-lived and
is no longer thread safe. It is a bad sign that MongoCollection's thread safety and lifetime vary depending on how its
parent MongoDatabase is created.</p>
<p>Instead, we require users to pass session as a parameter to each function:</p>
<pre><code class="language-javascript">session = client.startSession(...)
database = client.getDatabase(...)
collection = database.getCollection(...)
// users must explicitly pass session to operations
collection.insertOne(session, {})
session.endSession()
</code></pre>
<h3 id="why-does-a-network-error-cause-the-serversession-to-be-discarded-from-the-pool"><a class="header" href="#why-does-a-network-error-cause-the-serversession-to-be-discarded-from-the-pool">Why does a network error cause the <code>ServerSession</code> to be discarded from the pool?</a></h3>
<p>When a network error is encountered when executing an operation with a <code>ClientSession</code>, the operation may be left
running on the server. Re-using this <code>ServerSession</code> can lead to parallel operations which violates the rule that a
session must be used sequentially. This results in multiple problems:</p>
<ol>
<li>killSessions to end an earlier operation would surprisingly also end a later operation.</li>
<li>An otherwise unrelated operation that just happens to use that same server session will potentially block waiting for
the previous operation to complete. For example, a transactional write will block a subsequent transactional write.</li>
</ol>
<h3 id="why-do-automatic-retry-attempts-re-use-a-dirty-implicit-session"><a class="header" href="#why-do-automatic-retry-attempts-re-use-a-dirty-implicit-session">Why do automatic retry attempts re-use a dirty implicit session?</a></h3>
<p>The retryable writes spec requires that both the original and retry attempt use the same server session. The server will
block the retry attempt until the initial attempt completes at which point the retry attempt will continue executing.</p>
<p>For retryable reads that use an implicit session, drivers could choose to use a new server session for the retry attempt
however this would lose the information that these two reads are related.</p>
<h3 id="why-dont-drivers-run-the-endsessions-command-to-cleanup-dirty-server-sessions"><a class="header" href="#why-dont-drivers-run-the-endsessions-command-to-cleanup-dirty-server-sessions">Why don't drivers run the endSessions command to cleanup dirty server sessions?</a></h3>
<p>Drivers do not run the endSessions command when discarding a dirty server session because disconnects should be
relatively rare and the server won't normally accumulate a large number of abandoned dirty sessions. Any abandoned
sessions will be automatically cleaned up by the server after the configured <code>logicalSessionTimeoutMinutes</code>.</p>
<h3 id="why-must-drivers-wait-to-consume-a-server-session-until-after-a-connection-is-checked-out"><a class="header" href="#why-must-drivers-wait-to-consume-a-server-session-until-after-a-connection-is-checked-out">Why must drivers wait to consume a server session until after a connection is checked out?</a></h3>
<p>The problem that may occur is when the number of concurrent application requests are larger than the number of available
connections, the driver may generate many more implicit sessions than connections. For example with maxPoolSize=1 and
100 threads, 100 implicit sessions may be created. This increases the load on the server since session state is cached
in memory. In the worst case this kind of workload can hit the session limit and trigger TooManyLogicalSessions.</p>
<p>In order to address this, drivers MUST NOT consume a server session id until after the connection is checked out. This
change will limit the number of "in use" server sessions to no greater than an application's maxPoolSize.</p>
<p>The language here is specific about obtaining a server session as opposed to creating the implicit session to permit
drivers to take an implementation approach where the implicit session creation logic largely remains unchanged. Implicit
session creation can be left as is, as long as the underlying server resource isn't allocated until it is needed and,
known it will be used, after connection checkout succeeds.</p>
<p>It is still possible that via explicit sessions or cursors, which hold on to the session they started with, a driver
could over allocate sessions. But those scenarios are extenuating and outside the scope of solving in this spec.</p>
<h3 id="why-should-drivers-not-attempt-to-release-a-serversession-before-checking-back-in-the-operations-connection"><a class="header" href="#why-should-drivers-not-attempt-to-release-a-serversession-before-checking-back-in-the-operations-connection">Why should drivers NOT attempt to release a serverSession before checking back in the operation's connection?</a></h3>
<p>There are a variety of cases, such as retryable operations or cursor creating operations, where a <code>serverSession</code> must
remain acquired by the <code>ClientSession</code> after an operation is attempted. Attempting to account for all these scenarios
has risks that do not justify the potential guaranteed <code>ServerSession</code> allocation limiting.</p>
<h2 id="changelog-24"><a class="header" href="#changelog-24">Changelog</a></h2>
<ul>
<li>2024-05-08: Migrated from reStructuredText to Markdown.</li>
<li>2017-09-13: If causalConsistency option is omitted assume true</li>
<li>2017-09-16: Omit session ID when opening and authenticating a connection</li>
<li>2017-09-18: Drivers MUST gossip the cluster time when they see a <code>$clusterTime</code>.</li>
<li>2017-09-19: How to safely use initialClusterTime</li>
<li>2017-09-29: Add an exception to the rule that <code>KILLCURSORS</code> commands always require a session id</li>
<li>2017-10-03: startSession and endSessions commands MUST be sent to the admin database</li>
<li>2017-10-03: Fix format of endSessions command</li>
<li>2017-10-04: Added advanceClusterTime</li>
<li>2017-10-06: Added descriptions of explicit and implicit sessions</li>
<li>2017-10-17: Implicit sessions MUST NOT be used when multiple users authenticated</li>
<li>2017-10-19: Possible race conditions when checking whether a deployment supports sessions</li>
<li>2017-11-21: Drivers MUST NOT send a session ID for unacknowledged writes</li>
<li>2018-01-10: Note that MongoClient must retain highest clusterTime</li>
<li>2018-01-10: Update test plan for drivers without APM</li>
<li>2018-01-11: Clarify that sessions require replica sets or sharded clusters</li>
<li>2018-02-20: Add implicit/explicit session tests</li>
<li>2018-02-20: Drivers SHOULD error if unacknowledged writes are used with sessions</li>
<li>2018-05-23: Drivers MUST not use session ID with parallelCollectionScan</li>
<li>2018-06-07: Document that estimatedDocumentCount does not support explicit sessions</li>
<li>2018-07-19: Justify why session must be an explicit parameter to each function</li>
<li>2018-10-11: Session pools must be cleared in child process after fork</li>
<li>2019-05-15: A ServerSession that is involved in a network error MUST be discarded</li>
<li>2019-10-22: Drivers may defer checking if a deployment supports sessions until the first</li>
<li>2021-04-08: Updated to use hello and legacy hello</li>
<li>2021-04-08: Adding in behaviour for load balancer mode.</li>
<li>2020-05-26: Simplify logic for determining sessions support</li>
<li>2022-01-28: Implicit sessions MUST obtain server session after connection checkout succeeds</li>
<li>2022-03-24: ServerSession Pooling is required and clarifies session acquisition bounding</li>
<li>2022-06-13: Move prose tests to test README and apply new ordering</li>
<li>2022-10-05: Remove spec front matter</li>
<li>2023-02-24: Defer checking for session support until after connection checkout</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="causal-consistency-specification"><a class="header" href="#causal-consistency-specification">Causal Consistency Specification</a></h1>
<ul>
<li>Status: Accepted</li>
<li>Minimum Server Version: 3.6</li>
</ul>
<hr />
<h2 id="abstract-25"><a class="header" href="#abstract-25">Abstract</a></h2>
<p>Version 3.6 of the server introduces support for causal consistency. This spec builds upon the Sessions Specification to
define how an application requests causal consistency and how a driver interacts with the server to implement causal
consistency.</p>
<h2 id="definitions-3"><a class="header" href="#definitions-3">Definitions</a></h2>
<h3 id="meta-25"><a class="header" href="#meta-25">META</a></h3>
<p>The keywords "MUST", "MUST NOT", "REQUIRED", "SHALL", "SHALL NOT", "SHOULD", "SHOULD NOT", "RECOMMENDED", "MAY", and
"OPTIONAL" in this document are to be interpreted as described in <a href="https://www.ietf.org/rfc/rfc2119.txt">RFC 2119</a>.</p>
<h3 id="terms-15"><a class="header" href="#terms-15">Terms</a></h3>
<p><strong>Causal consistency</strong></p>
<p>A property that guarantees that an application can read its own writes and that a later read will never observe a
version of the data that is older than an earlier read.</p>
<p><strong>ClientSession</strong></p>
<p>The driver object representing a client session and the operations that can be performed on it.</p>
<p><strong>Cluster time</strong></p>
<p>The current cluster time. The server reports its view of the current cluster time in the <code>$clusterTime</code> field in
responses from the server and the driver participates in distributing the current cluster time to all nodes (called
"gossipping the cluster time") by sending the highest <code>$clusterTime</code> it has seen so far in messages it sends to mongos
servers. The current cluster time is a logical time, but is digitally signed to prevent malicious clients from
propagating invalid cluster times. Cluster time is only used in replica sets and sharded clusters.</p>
<p><strong>Logical time</strong></p>
<p>A time-like quantity that can be used to determine the order in which events occurred. Logical time is represented as a
BsonTimestamp.</p>
<p><strong>MongoClient</strong></p>
<p>The root object of a driver's API. MAY be named differently in some drivers.</p>
<p><strong>MongoCollection</strong></p>
<p>The driver object representing a collection and the operations that can be performed on it. MAY be named differently in
some drivers.</p>
<p><strong>MongoDatabase</strong></p>
<p>The driver object representing a database and the operations that can be performed on it. MAY be named differently in
some drivers.</p>
<p><strong>Operation time</strong></p>
<p>The logical time at which an operation occurred. The server reports the operation time in the response to all commands,
including error responses. The operation time by definition is always less than or equal to the cluster time. Operation
times are tracked on a per <code>ClientSession</code> basis, so the <code>operationTime</code> of each <code>ClientSession</code> corresponds to the time
of the last operation performed in that particular <code>ClientSession</code>.</p>
<p><strong>ServerSession</strong></p>
<p>The driver object representing a server session.</p>
<p><strong>Session</strong></p>
<p>A session is an abstract concept that represents a set of sequential operations executed by an application that are
related in some way. This specification defines how sessions are used to implement causal consistency.</p>
<p><strong>Unacknowledged writes</strong></p>
<p>Unacknowledged writes are write operations that are sent to the server without waiting for a reply acknowledging the
write. See the "Unacknowledged Writes" section below for information on how unacknowledged writes interact with causal
consistency.</p>
<h2 id="specification-23"><a class="header" href="#specification-23">Specification</a></h2>
<p>An application requests causal consistency by creating a <code>ClientSession</code> with options that specify that causal
consistency is desired. An application then passes the session as an argument to methods in the <code>MongoDatabase</code> and
<code>MongoCollection</code> classes. Any operations performed against that session will then be causally consistent.</p>
<h2 id="naming-variations-1"><a class="header" href="#naming-variations-1">Naming variations</a></h2>
<p>This specification defines names for new methods and types. To the extent possible you SHOULD use these names in your
driver. However, where your driver's and/or language's naming conventions differ you SHOULD continue to use them
instead. For example, you might use <code>StartSession</code> or <code>start_session</code> instead of <code>startSession</code>.</p>
<h2 id="high-level-summary-of-the-api-changes-for-causal-consistency"><a class="header" href="#high-level-summary-of-the-api-changes-for-causal-consistency">High level summary of the API changes for causal consistency</a></h2>
<p>Causal consistency is built on top of client sessions.</p>
<p>Applications will start a new client session for causal consistency like this:</p>
<pre><code class="language-typescript">options = new SessionOptions(causalConsistency = true);
session = client.startSession(options);
</code></pre>
<p>All read operations performed using this session will now be causally consistent.</p>
<p>If no value is provided for <code>causalConsistency</code> and snapshot reads are not requested a value of true is implied. See the
<code>causalConsistency</code> section.</p>
<h2 id="mongoclient-changes-1"><a class="header" href="#mongoclient-changes-1">MongoClient changes</a></h2>
<p>There are no API changes to <code>MongoClient</code> to support causal consistency. Applications indicate whether they want causal
consistency by setting the <code>causalConsistency</code> field in the options passed to the <code>startSession</code> method.</p>
<h2 id="sessionoptions-changes"><a class="header" href="#sessionoptions-changes">SessionOptions changes</a></h2>
<p><code>SessionOptions</code> change summary</p>
<pre><code class="language-typescript">class SessionOptions {
    Optional&lt;bool&gt; causalConsistency;

    // other options defined by other specs
}
</code></pre>
<p>In order to support causal consistency a new property named <code>causalConsistency</code> is added to <code>SessionOptions</code>.
Applications set <code>causalConsistency</code> when starting a client session to indicate whether they want causal consistency.
All read operations performed using that client session are then causally consistent.</p>
<p>Each new member is documented below.</p>
<h3 id="causalconsistency"><a class="header" href="#causalconsistency">causalConsistency</a></h3>
<p>Applications set <code>causalConsistency</code> when starting a session to indicate whether they want causal consistency.</p>
<p>Note that the <code>causalConsistency</code> property is optional. For explicit sessions, the default value of this property is
<code>not supplied</code>. If no value is supplied for <code>causalConsistency</code> the value will be inherited. Currently it is inherited
from the global default which is defined to be true. In the future it <em>might</em> be inherited from client settings. For
implicit sessions, the value of this property MUST be set to <code>false</code> in order to avoid potential conflicts with an
operation's read concern level.</p>
<p>Causal consistency is provided at the session level by tracking the <code>clusterTime</code> and <code>operationTime</code> for each session.
In some cases an application may wish subsequent operations in one session to be causally consistent with operations
that were executed in a different session. In that case the application can call the <code>advanceClusterTime</code> and
<code>advanceOperationTime</code> methods in <code>ClientSession</code> to advance the <code>clusterTime</code> and <code>operationTime</code> of one session to the
<code>clusterTime</code> and <code>operationTime</code> from another session.</p>
<h2 id="clientsession-changes"><a class="header" href="#clientsession-changes">ClientSession changes</a></h2>
<p><code>ClientSession</code> changes summary</p>
<pre><code class="language-typescript">interface ClientSession {
    Optional&lt;BsonTimestamp&gt; operationTime;

    void advanceOperationTime(BsonTimestamp operationTime);

    // other members as defined in other specs
}
</code></pre>
<p>Each new member is documented below.</p>
<h3 id="operationtime"><a class="header" href="#operationtime">operationTime</a></h3>
<p>This property returns the operation time of the most recent operation performed using this session. If no operations
have been performed using this session the value will be null unless <code>advanceOperationTime</code> has been called. This value
will also be null when the cluster does not report operation times.</p>
<h3 id="advanceoperationtime"><a class="header" href="#advanceoperationtime">advanceOperationTime</a></h3>
<p>This method advances the <code>operationTime</code> for a session. If the new <code>operationTime</code> is greater than the session's current
<code>operationTime</code> then the session's <code>operationTime</code> MUST be advanced to the new <code>operationTime</code>. If the new
<code>operationTime</code> is less than or equal to the session's current <code>operationTime</code> then the session's <code>operationTime</code> MUST
NOT be changed.</p>
<p>Drivers MUST NOT attempt to validate the supplied <code>operationTime</code>. While the server requires that <code>operationTime</code> be
less than or equal to <code>clusterTime</code> we don't want to check that when <code>advanceOperationTime</code> is called. This allows an
application to call <code>advanceClusterTime</code> and <code>advanceOperationTime</code> in any order, or perhaps to not call
<code>advanceClusterTime</code> at all and let the <code>clusterTime</code> that is sent to the server be implied by the <code>clusterTime</code> in
<code>MongoClient</code>.</p>
<h2 id="mongodatabase-changes-1"><a class="header" href="#mongodatabase-changes-1">MongoDatabase changes</a></h2>
<p>There are no additional API changes to <code>MongoDatabase</code> beyond those specified in the Sessions Specification. All
<code>MongoDatabase</code> methods that talk to the server have been overloaded to take a session parameter. If that session was
started with <code>causalConsistency = true</code> then all operations using that session will be causally consistent.</p>
<h2 id="mongocollection-changes-1"><a class="header" href="#mongocollection-changes-1">MongoCollection changes</a></h2>
<p>There are no additional API changes to <code>MongoCollection</code> beyond those specified in the Sessions Specification. All
<code>MongoCollection</code> methods that talk to the server have been overloaded to take a session parameter. If that session was
started with <code>causalConsistency = true</code> then all operations using that session will be causally consistent.</p>
<h2 id="server-commands-1"><a class="header" href="#server-commands-1">Server Commands</a></h2>
<p>There are no new server commands related to causal consistency. Instead, causal consistency is implemented by:</p>
<ol>
<li>Saving the <code>operationTime</code> returned by 3.6+ servers for all operations in a property of the <code>ClientSession</code> object.
The server reports the <code>operationTime</code> whether the operation succeeded or not and drivers MUST save the
<code>operationTime</code> in the <code>ClientSession</code> whether the operation succeeded or not.</li>
<li>Passing that <code>operationTime</code> in the <code>afterClusterTime</code> field of the <code>readConcern</code> field for subsequent causally
consistent read operations (for all commands that support a <code>readConcern</code>)</li>
<li>Gossiping clusterTime (described in the Driver Session Specification)</li>
</ol>
<h2 id="server-command-responses"><a class="header" href="#server-command-responses">Server Command Responses</a></h2>
<p>To support causal consistency the server returns the <code>operationTime</code> in responses it sends to the driver (for both read
and write operations).</p>
<pre><code class="language-typescript">{
    ok : 1 or 0,
    ... // the rest of the command reply
    operationTime : &lt;BsonTimestamp&gt;
    $clusterTime : &lt;BsonDocument&gt; // only in deployments that support cluster times
}
</code></pre>
<p>The <code>operationTime</code> MUST be stored in the <code>ClientSession</code> to later be passed as the <code>afterClusterTime</code> field of the
<code>readConcern</code> field in subsequent read operations. The <code>operationTime</code> is returned whether the command succeeded or not
and MUST be stored in either case.</p>
<p>Drivers MUST examine all responses from the server for the presence of an <code>operationTime</code> field and store the value in
the <code>ClientSession</code>.</p>
<p>When connected to a standalone node command replies do not include an <code>operationTime</code> field. All operations against a
standalone node are causally consistent automatically because there is only one node.</p>
<p>When connected to a deployment that supports cluster times the command response also includes a field called
<code>$clusterTime</code> that drivers MUST use to gossip the cluster time. See the Sessions Specification for details.</p>
<h2 id="causally-consistent-read-commands"><a class="header" href="#causally-consistent-read-commands">Causally consistent read commands</a></h2>
<p>For causal consistency the driver MUST send the <code>operationTime</code> saved in the <code>ClientSession</code> as the value of the
<code>afterClusterTime</code> field of the <code>readConcern</code> field:</p>
<pre><code class="language-typescript">{
    find : &lt;string&gt;, // or other read command
    ... // the rest of the command parameters
    readConcern :
    {
        level : ..., // from the operation's read concern (only if specified)
        afterClusterTime : &lt;BsonTimestamp&gt;
    }
}
</code></pre>
<p>For the lists of commands that support causally consistent reads, see
<a href="causal-consistency/../read-write-concern/read-write-concern.html#read-concern">ReadConcern</a> spec.</p>
<p>The driver MUST merge the <code>ReadConcern</code> specified for the operation with the <code>operationTime</code> from the <code>ClientSession</code>
(which goes in the <code>afterClusterTime</code> field) to generate the combined <code>readConcern</code> to send to the server. If the level
property of the read concern for the operation is null then the driver MUST NOT include a <code>level</code> field alongside the
<code>afterClusterTime</code> of the <code>readConcern</code> value sent to the server. Drivers MUST NOT attempt to verify whether the server
supports causally consistent reads or not for a given read concern level. The server will return an error if a given
level does not support causal consistency.</p>
<p>The Read and Write Concern specification states that when a user has not specified a <code>ReadConcern</code> or has specified the
server's default <code>ReadConcern</code>, drivers MUST omit the <code>ReadConcern</code> parameter when sending the command. For causally
consistent reads this requirement is modified to state that when the <code>ReadConcern</code> parameter would normally be omitted
drivers MUST send a <code>ReadConcern</code> after all because that is how the <code>afterClusterTime</code> value is sent to the server.</p>
<p>The Read and Write Concern Specification states that drivers MUST NOT add a <code>readConcern</code> field to commands that are run
using a generic <code>runCommand</code> method. The same is true for causal consistency, so commands that are run using
<code>runCommand</code> MUST NOT have an <code>afterClusterTime</code> field added to them.</p>
<p>When executing a causally consistent read, the <code>afterClusterTime</code> field MUST be sent when connected to a deployment that
supports cluster times, and MUST NOT be sent when connected to a deployment that does not support cluster times.</p>
<h2 id="unacknowledged-writes"><a class="header" href="#unacknowledged-writes">Unacknowledged writes</a></h2>
<p>The implementation of causal consistency relies on the <code>operationTime</code> returned by the server in the acknowledgement of
a write. Since unacknowledged writes don't receive a response from the server (or don't wait for a response) the
<code>ClientSession</code>'s <code>operationTime</code> is not updated after an unacknowledged write. That means that a causally consistent
read after an unacknowledged write cannot be causally consistent with the unacknowledged write. Rather than prohibiting
unacknowledged writes in a causally consistent session we have decided to accept this limitation. Drivers MUST document
that causally consistent reads are not causally consistent with unacknowledged writes.</p>
<h2 id="test-plan-19"><a class="header" href="#test-plan-19">Test Plan</a></h2>
<p>Below is a list of test cases to write.</p>
<p>Note: some tests are only relevant to certain deployments. For the purpose of deciding which tests to run assume that
any deployment that is version 3.6 or higher and is either a replica set or a sharded cluster supports cluster times.</p>
<ol>
<li>When a <code>ClientSession</code> is first created the <code>operationTime</code> has no value.
<ul>
<li><code>session = client.startSession()</code></li>
<li>assert <code>session.operationTime</code> has no value</li>
</ul>
</li>
<li>The first read in a causally consistent session must not send <code>afterClusterTime</code> to the server (because the
<code>operationTime</code> has not yet been determined)
<ul>
<li><code>session = client.startSession(causalConsistency = true)</code></li>
<li><code>document = collection.anyReadOperation(session, ...)</code></li>
<li>capture the command sent to the server (using APM or other mechanism)</li>
<li>assert that the command does not have an <code>afterClusterTime</code></li>
</ul>
</li>
<li>The first read or write on a <code>ClientSession</code> should update the <code>operationTime</code> of the <code>ClientSession</code>, even if there
is an error.
<ul>
<li>skip this test if connected to a deployment that does not support cluster times</li>
<li><code>session = client.startSession() // with or without causal consistency</code></li>
<li><code>collection.anyReadOrWriteOperation(session, ...) // test with errors also if possible</code></li>
<li>capture the response sent from the server (using APM or other mechanism)</li>
<li>assert <code>session.operationTime</code> has the same value that is in the response from the server</li>
</ul>
</li>
<li>A <code>findOne</code> followed by any other read operation (test them all) should include the <code>operationTime</code> returned by the
server for the first operation in the <code>afterClusterTime</code> parameter of the second operation
<ul>
<li>skip this test if connected to a deployment that does not support cluster times</li>
<li><code>session = client.startSession(causalConsistency = true)</code></li>
<li><code>collection.findOne(session, {})</code></li>
<li><code>operationTime = session.operationTime</code></li>
<li><code>collection.anyReadOperation(session, ...)</code></li>
<li>capture the command sent to the server (using APM or other mechanism)</li>
<li>assert that the command has an <code>afterClusterTime</code> field with a value of <code>operationTime</code></li>
</ul>
</li>
<li>Any write operation (test them all) followed by a <code>findOne</code> operation should include the <code>operationTime</code> of the
first operation in the <code>afterClusterTime</code> parameter of the second operation, including the case where the first
operation returned an error.
<ul>
<li>skip this test if connected to a deployment that does not support cluster times</li>
<li><code>session = client.startSession(causalConsistency = true)</code></li>
<li><code>collection.anyWriteOperation(session, ...) // test with errors also where possible</code></li>
<li><code>operationTime = session.operationTime</code></li>
<li><code>collection.findOne(session, {})</code></li>
<li>capture the command sent to the server (using APM or other mechanism)</li>
<li>assert that the command has an <code>afterClusterTime</code> field with a value of <code>operationTime</code></li>
</ul>
</li>
<li>A read operation in a <code>ClientSession</code> that is not causally consistent should not include the <code>afterClusterTime</code>
parameter in the command sent to the server.
<ul>
<li>skip this test if connected to a deployment that does not support cluster times</li>
<li><code>session = client.startSession(causalConsistency = false)</code></li>
<li><code>collection.anyReadOperation(session, {})</code></li>
<li><code>operationTime = session.operationTime</code></li>
<li>capture the command sent to the server (using APM or other mechanism)</li>
<li>assert that the command does not have an <code>afterClusterTime</code> field</li>
</ul>
</li>
<li>A read operation in a causally consistent session against a deployment that does not support cluster times does not
include the <code>afterClusterTime</code> parameter in the command sent to the server.
<ul>
<li>skip this test if connected to a deployment that does support cluster times</li>
<li><code>session = client.startSession(causalConsistency = true)</code></li>
<li><code>collection.anyReadOperation(session, {})</code></li>
<li>capture the command sent to the server (using APM or other mechanism)</li>
<li>assert that the command does not have an <code>afterClusterTime</code> field</li>
</ul>
</li>
<li>When using the default server <code>ReadConcern</code> the <code>readConcern</code> parameter in the command sent to the server should not
include a <code>level</code> field.
<ul>
<li>skip this test if connected to a deployment that does not support cluster times</li>
<li><code>session = client.startSession(causalConsistency = true)</code></li>
<li>configure <code>collection</code> to use default server <code>ReadConcern</code></li>
<li><code>collection.findOne(session, {})</code></li>
<li><code>operationTime = session.operationTime</code></li>
<li><code>collection.anyReadOperation(session, ...)</code></li>
<li>capture the command sent to the server (using APM or other mechanism)</li>
<li>assert that the command does not have a <code>`level</code> field</li>
<li>assert that the command has a <code>afterClusterTime</code> field with a value of <code>operationTime</code></li>
</ul>
</li>
<li>When using a custom <code>ReadConcern</code> the <code>readConcern</code> field in the command sent to the server should be a merger of
the <code>ReadConcern</code> value and the <code>afterClusterTime</code> field.
<ul>
<li>skip this test if connected to a deployment that does not support cluster times</li>
<li><code>session = client.startSession(causalConsistency = true)</code></li>
<li>configure collection to use a custom ReadConcern</li>
<li><code>collection.findOne(session, {})</code></li>
<li><code>operationTime = session.operationTime</code></li>
<li><code>collection.anyReadOperation(session, ...)</code></li>
<li>capture the command sent to the server (using APM or other mechanism)</li>
<li>assert that the command has a <code>level</code> field with a value matching the custom readConcern</li>
<li>assert that the command has an <code>afterClusterTime</code> field with a value of <code>operationTime</code></li>
</ul>
</li>
<li><strong>Removed</strong></li>
<li>When connected to a deployment that does not support cluster times messages sent to the server should not include
<code>$clusterTime</code>.
<ul>
<li>skip this test when connected to a deployment that does support cluster times</li>
<li><code>document = collection.findOne({})</code></li>
<li>capture the command sent to the server</li>
<li>assert that the command does not include a <code>$clusterTime</code> field</li>
</ul>
</li>
<li>When connected to a deployment that does support cluster times messages sent to the server should include
<code>$clusterTime</code>.
<ul>
<li>skip this test when connected to a deployment that does not support cluster times</li>
<li><code>document = collection.findOne({})</code></li>
<li>capture the command sent to the server</li>
<li>assert that the command includes a <code>$clusterTime</code> field</li>
</ul>
</li>
</ol>
<h2 id="motivation-2"><a class="header" href="#motivation-2">Motivation</a></h2>
<p>To support causal consistency. Only supported with server version 3.6 or newer.</p>
<h2 id="design-rationale-18"><a class="header" href="#design-rationale-18">Design Rationale</a></h2>
<p>The goal is to modify the driver API as little as possible so that existing programs that don't need causal consistency
don't have to be changed. This goal is met by defining a <code>SessionOptions</code> field that applications use to start a
<code>ClientSession</code> that can be used for causal consistency. Any operations performed with such a session are then causally
consistent.</p>
<p>The <code>operationTime</code> is tracked on a per <code>ClientSession</code> basis. This allows each <code>ClientSession</code> to have an
<code>operationTime</code> that is sufficiently new to guarantee causal consistency for that session, but no newer. Using an
<code>operationTime</code> that is newer than necessary can cause reads to block longer than necessary when sent to a lagging
secondary. The goal is to block for just long enough to guarantee causal consistency and no longer.</p>
<h2 id="backwards-compatibility-15"><a class="header" href="#backwards-compatibility-15">Backwards Compatibility</a></h2>
<p>The API changes to support sessions extend the existing API but do not introduce any backward breaking changes. Existing
programs that don't use causal consistency continue to compile and run correctly.</p>
<h2 id="reference-implementation-12"><a class="header" href="#reference-implementation-12">Reference Implementation</a></h2>
<p>A reference implementation must be completed before any spec is given status "Final", but it need not be completed
before the spec is "Accepted". While there is merit to the approach of reaching consensus on the specification and
rationale before writing code, the principle of "rough consensus and running code" is still useful when it comes to
resolving many discussions of spec details. A final reference implementation must include test code and documentation.</p>
<h2 id="qa-9"><a class="header" href="#qa-9">Q&amp;A</a></h2>
<h2 id="changelog-25"><a class="header" href="#changelog-25">Changelog</a></h2>
<ul>
<li>
<p>2024-02-08: Migrated from reStructuredText to Markdown.</p>
</li>
<li>
<p>2022-11-11: Require <code>causalConsistency=false</code> for implicit sessions.</p>
</li>
<li>
<p>2022-10-05: Remove spec front matter and reformat changelog.</p>
</li>
<li>
<p>2022-01-28: Fix formatting for prose tests</p>
</li>
<li>
<p>2022-01-22: Remove outdated prose test #10</p>
</li>
<li>
<p>2021-06-26: Default value for causalConsistency is influenced by snapshot reads</p>
</li>
<li>
<p>2017-11-17: Added link to ReadConcern spec which lists commands that support readConcern</p>
</li>
<li>
<p>2017-10-06: advanceOperationTime MUST NOT validate operationTime</p>
</li>
<li>
<p>2017-10-05: How to handle default read concern</p>
</li>
<li>
<p>2017-10-04: Added advanceOperationTime</p>
</li>
<li>
<p>2017-09-28: Remove remaining references to collections being associated with sessions. Update spec to reflect that
replica sets use $clusterTime also now.</p>
</li>
<li>
<p>2017-09-13: Renamed "causally consistent reads" to "causal consistency". If no value is supplied for
<code>causallyConsistent</code> assume true.</p>
</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="snapshot-reads-specification"><a class="header" href="#snapshot-reads-specification">Snapshot Reads Specification</a></h1>
<ul>
<li>Status: Accepted</li>
<li>Minimum Server Version: 5.0</li>
</ul>
<hr />
<h2 id="abstract-26"><a class="header" href="#abstract-26">Abstract</a></h2>
<p>Version 5.0 of the server introduces support for read concern level "snapshot" (non-speculative) for read commands
outside of transactions, including on secondaries. This spec builds upon the
<a href="sessions/./driver-sessions.html">Sessions Specification</a> to define how an application requests "snapshot" level read concern and
how a driver interacts with the server to implement snapshot reads.</p>
<h2 id="definitions-4"><a class="header" href="#definitions-4">Definitions</a></h2>
<h3 id="meta-26"><a class="header" href="#meta-26">META</a></h3>
<p>The keywords "MUST", "MUST NOT", "REQUIRED", "SHALL", "SHALL NOT", "SHOULD", "SHOULD NOT", "RECOMMENDED", "MAY", and
"OPTIONAL" in this document are to be interpreted as described in <a href="https://www.ietf.org/rfc/rfc2119.txt">RFC 2119</a>.</p>
<h3 id="terms-16"><a class="header" href="#terms-16">Terms</a></h3>
<p><strong>ClientSession</strong></p>
<p>The driver object representing a client session and the operations that can be performed on it.</p>
<p><strong>MongoClient</strong></p>
<p>The root object of a driver's API. MAY be named differently in some drivers.</p>
<p><strong>MongoCollection</strong></p>
<p>The driver object representing a collection and the operations that can be performed on it. MAY be named differently in
some drivers.</p>
<p><strong>MongoDatabase</strong></p>
<p>The driver object representing a database and the operations that can be performed on it. MAY be named differently in
some drivers.</p>
<p><strong>ServerSession</strong></p>
<p>The driver object representing a server session.</p>
<p><strong>Session</strong></p>
<p>A session is an abstract concept that represents a set of sequential operations executed by an application that are
related in some way. This specification defines how sessions are used to implement snapshot reads.</p>
<p><strong>Snapshot reads</strong></p>
<p>Reads with read concern level <code>snapshot</code> that occur outside of transactions on both the primary and secondary nodes,
including in sharded clusters. Snapshots reads are majority committed reads.</p>
<p><strong>Snapshot timestamp</strong></p>
<p>Snapshot timestamp, representing timestamp of the first supported read operation (i.e. find/aggregate/distinct) in the
session. The server creates a cursor in response to a snapshot find/aggregate command and reports <code>atClusterTime</code> within
the <code>cursor</code> field in the response. For the distinct command the server adds a top-level <code>atClusterTime</code> field to the
response. The <code>atClusterTime</code> field represents the timestamp of the read and is guaranteed to be majority committed.</p>
<h2 id="specification-24"><a class="header" href="#specification-24">Specification</a></h2>
<p>An application requests snapshot reads by creating a <code>ClientSession</code> with options that specify that snapshot reads are
desired. An application then passes the session as an argument to methods in the <code>MongoDatabase</code> and <code>MongoCollection</code>
classes. Read operations (find/aggregate/distinct) performed against that session will be read from the same snapshot.</p>
<h2 id="high-level-summary-of-the-api-changes-for-snapshot-reads"><a class="header" href="#high-level-summary-of-the-api-changes-for-snapshot-reads">High level summary of the API changes for snapshot reads</a></h2>
<p>Snapshot reads are built on top of client sessions.</p>
<p>Applications will start a new client session for snapshot reads like this:</p>
<pre><code class="language-typescript">options = new SessionOptions(snapshot = true);
session = client.startSession(options);
</code></pre>
<p>All read operations performed using this session will be read from the same snapshot.</p>
<p>If no value is provided for <code>snapshot</code> a value of false is implied. There are no MongoDatabase, MongoClient, or
MongoCollection API changes.</p>
<h2 id="sessionoptions-changes-1"><a class="header" href="#sessionoptions-changes-1">SessionOptions changes</a></h2>
<p><code>SessionOptions</code> change summary</p>
<pre><code class="language-typescript">class SessionOptions {
    Optional&lt;bool&gt; snapshot;

    // other options defined by other specs
}
</code></pre>
<p>In order to support snapshot reads a new property named <code>snapshot</code> is added to <code>SessionOptions</code>. Applications set
<code>snapshot</code> when starting a client session to indicate whether they want snapshot reads. All read operations performed
using that client session will share the same snapshot.</p>
<p>Each new member is documented below.</p>
<h3 id="snapshot"><a class="header" href="#snapshot">snapshot</a></h3>
<p>Applications set <code>snapshot</code> when starting a session to indicate whether they want snapshot reads.</p>
<p>Note that the <code>snapshot</code> property is optional. The default value of this property is false.</p>
<p>Snapshot reads and causal consistency are mutually exclusive. Therefore if <code>snapshot</code> is set to true,
<code>causalConsistency</code> must be false. Client MUST throw an error if both <code>snapshot</code> and <code>causalConsistency</code> are set to
true. Snapshot reads are supported on both primaries and secondaries.</p>
<h2 id="clientsession-changes-1"><a class="header" href="#clientsession-changes-1">ClientSession changes</a></h2>
<p>Transactions are not allowed with snapshot sessions. Calling <code>session.startTransaction(options)</code> on a snapshot session
MUST raise an error.</p>
<h2 id="readconcern-changes"><a class="header" href="#readconcern-changes">ReadConcern changes</a></h2>
<p><code>snapshot</code> added to <a href="sessions/../read-write-concern/read-write-concern.html#read-concern">ReadConcernLevel enumeration</a>.</p>
<h2 id="server-commands-2"><a class="header" href="#server-commands-2">Server Commands</a></h2>
<p>There are no new server commands related to snapshot reads. Instead, snapshot reads are implemented by:</p>
<ol>
<li>Saving the <code>atClusterTime</code> returned by 5.0+ servers for the first find/aggregate/distinct operation in a private
<code>snapshotTime</code> property of the <code>ClientSession</code> object. Drivers MUST save <code>atClusterTime</code> in the <code>ClientSession</code>
object.</li>
<li>Passing that <code>snapshotTime</code> in the <code>atClusterTime</code> field of the <code>readConcern</code> field for subsequent snapshot read
operations (i.e. find/aggregate/distinct commands).</li>
</ol>
<h2 id="server-command-responses-1"><a class="header" href="#server-command-responses-1">Server Command Responses</a></h2>
<p>For find/aggregate commands the server returns <code>atClusterTime</code> within the <code>cursor</code> field of the response.</p>
<pre><code class="language-typescript">{
    ok : 1 or 0,
    ... // the rest of the command reply
    cursor : {
        ... // the rest of the cursor reply
        atClusterTime : &lt;BsonTimestamp&gt;
    }
}
</code></pre>
<p>For distinct commands the server returns <code>atClusterTime</code> as a top-level field in the response.</p>
<pre><code class="language-typescript">{
    ok : 1 or 0,
    ... // the rest of the command reply
    atClusterTime : &lt;BsonTimestamp&gt;
}
</code></pre>
<p>The <code>atClusterTime</code> timestamp MUST be stored in the <code>ClientSession</code> to later be passed as the <code>atClusterTime</code> field of
the <code>readConcern</code> with a <code>snapshot</code> level in subsequent read operations.</p>
<h2 id="server-errors"><a class="header" href="#server-errors">Server Errors</a></h2>
<ol>
<li>The server may reply to read commands with a <code>SnapshotTooOld(239)</code> error if the client's <code>atClusterTime</code> value is not
available in the server's history.</li>
<li>The server will return <code>InvalidOptions(72)</code> error if both <code>atClusterTime</code> and <code>afterClusterTime</code> options are set to
true.</li>
<li>The server will return <code>InvalidOptions(72)</code> error if the command does not support readConcern.level "snapshot".</li>
</ol>
<h2 id="snapshot-read-commands"><a class="header" href="#snapshot-read-commands">Snapshot Read Commands</a></h2>
<p>For snapshot reads the driver MUST first obtain <code>atClusterTime</code> from the server response of a find/aggregate/distinct
command, by specifying <code>readConcern</code> with <code>snapshot</code> level field, and store it as <code>snapshotTime</code> in the <code>ClientSession</code>
object.</p>
<pre><code class="language-typescript">{
    find : &lt;string&gt;, // or other read command
    ... // the rest of the command parameters
    readConcern :
    {
        level : "snapshot"
    }
}
</code></pre>
<p>For subsequent reads in the same session, the driver MUST send the <code>snapshotTime</code> saved in the <code>ClientSession</code> as the
value of the <code>atClusterTime</code> field of the <code>readConcern</code> with a <code>snapshot</code> level:</p>
<pre><code class="language-typescript">{
    find : &lt;string&gt;, // or other read command
    ... // the rest of the command parameters
    readConcern :
    {
        level : "snapshot",
        atClusterTime : &lt;BsonTimestamp&gt;
    }
}
</code></pre>
<p>Lists of commands that support snapshot reads:</p>
<ol>
<li>find</li>
<li>aggregate</li>
<li>distinct</li>
</ol>
<h2 id="sending-readconcern-to-the-server-on-all-commands"><a class="header" href="#sending-readconcern-to-the-server-on-all-commands">Sending readConcern to the server on all commands</a></h2>
<p>Drivers MUST set the readConcern <code>level</code> and <code>atClusterTime</code> fields (as outlined above) on all commands in a snapshot
session, including commands that do not accept a readConcern (e.g. insert, update). This ensures that the server will
return an error for invalid operations, such as writes, within a session configured for snapshot reads.</p>
<h2 id="requires-mongodb-50"><a class="header" href="#requires-mongodb-50">Requires MongoDB 5.0+</a></h2>
<p>Snapshot reads require MongoDB 5.0+. When the connected server's maxWireVersion is less than 13, drivers MUST throw an
exception with the message "Snapshot reads require MongoDB 5.0 or later".</p>
<h2 id="motivation-3"><a class="header" href="#motivation-3">Motivation</a></h2>
<p>To support snapshot reads. Only supported with server version 5.0+ or newer.</p>
<h2 id="design-rationale-19"><a class="header" href="#design-rationale-19">Design Rationale</a></h2>
<p>The goal is to modify the driver API as little as possible so that existing programs that don't need snapshot reads
don't have to be changed. This goal is met by defining a <code>SessionOptions</code> field that applications use to start a
<code>ClientSession</code> that can be used for snapshot reads. Alternative explicit approach of obtaining <code>atClusterTime</code> from
<code>cursor</code> object and passing it to read concern object was considered initially. A session-based approach was chosen as
it aligns better with the existing API, and requires minimal API changes. Future extensibility for snapshot reads would
be best served by a session-based approach, as no API changes will be required.</p>
<h2 id="backwards-compatibility-16"><a class="header" href="#backwards-compatibility-16">Backwards Compatibility</a></h2>
<p>The API changes to support snapshot reads extend the existing API but do not introduce any backward breaking changes.
Existing programs that don't use snapshot reads continue to compile and run correctly.</p>
<h2 id="reference-implementation-13"><a class="header" href="#reference-implementation-13">Reference Implementation</a></h2>
<p>C# driver will provide the reference implementation. The corresponding ticket is
<a href="https://jira.mongodb.org/browse/CSHARP-3668">CSHARP-3668</a>.</p>
<h2 id="qa-10"><a class="header" href="#qa-10">Q&amp;A</a></h2>
<h2 id="changelog-26"><a class="header" href="#changelog-26">Changelog</a></h2>
<ul>
<li>2024-05-08: Migrated from reStructuredText to Markdown.</li>
<li>2021-06-15: Initial version.</li>
<li>2021-06-28: Raise client side error on &lt; 5.0.</li>
<li>2021-06-29: Send readConcern with all snapshot session commands.</li>
<li>2021-07-16: Grammar revisions. Change SHOULD to MUST for startTransaction error to comply with existing tests.</li>
<li>2021-08-09: Updated client-side error spec tests to use correct syntax for <code>test.expectEvents</code></li>
<li>2022-10-05: Remove spec front matter</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="transactions-specification"><a class="header" href="#transactions-specification">Transactions Specification</a></h1>
<ul>
<li>Status: Accepted</li>
<li>Minimum Server Version: 4.0</li>
</ul>
<hr />
<h2 id="abstract-27"><a class="header" href="#abstract-27"><strong>Abstract</strong></a></h2>
<p>Version 4.0 of the server introduces multi-statement transactions. This spec builds upon the
<a href="transactions/../sessions/driver-sessions.html">Driver Sessions Specification</a> to define how an application uses transactions and how a
driver interacts with the server to implement transactions.</p>
<p>The API for transactions must be specified to ensure that all drivers and the mongo shell are consistent with each
other, and to provide a natural interface for application developers and DBAs who use multi-statement transactions.</p>
<h2 id="meta-27"><a class="header" href="#meta-27"><strong>META</strong></a></h2>
<p>The keywords "MUST", "MUST NOT", "REQUIRED", "SHALL", "SHALL NOT", "SHOULD", "SHOULD NOT", "RECOMMENDED", "MAY", and
"OPTIONAL" in this document are to be interpreted as described in <a href="https://www.ietf.org/rfc/rfc2119.txt">RFC 2119</a>.</p>
<h2 id="specification-25"><a class="header" href="#specification-25"><strong>Specification</strong></a></h2>
<h3 id="terms-17"><a class="header" href="#terms-17"><strong>Terms</strong></a></h3>
<p>This specification uses the terms defined in the <a href="transactions/../sessions/driver-sessions.html">Driver Sessions Specification</a> and
<a href="transactions/../retryable-writes/retryable-writes.html">Retryable Writes Specification</a>. Additional terms are defined below.</p>
<h4 id="resource-management-block"><a class="header" href="#resource-management-block">Resource Management Block</a></h4>
<p>Some programming languages have a concept of a code block that automatically frees resources when control exits the
block. Such a pattern is known as context managers, "using" statements, RAII, etc.. This spec refers to such a pattern
as a resource management block, regardless of the programming language.</p>
<h4 id="read-operation"><a class="header" href="#read-operation">Read operation</a></h4>
<p>Any CRUD method that uses a read preference. The listIndexes, listCollections, and listDatabases, and RunCommand helpers
are also considered read operations.</p>
<h4 id="write-operation"><a class="header" href="#write-operation">Write operation</a></h4>
<p>All operations that write and accept a ClientSession argument. All MongoClient, Database, Collection helpers that write
including (but not limited to) creating, updating, or deleting databases, collections, indexes, and users. Aggregate
(even with a write stage) is considered a read operation, see
<a href="transactions/transactions.html#aggregate-with-write-stage-is-a-read-operation">Aggregate with write stage is a read operation</a>.</p>
<h4 id="retryable-error-1"><a class="header" href="#retryable-error-1">Retryable Error</a></h4>
<p>An error considered retryable by the <a href="transactions/../retryable-writes/retryable-writes.html">Retryable Writes Specification</a>.</p>
<h4 id="command-error"><a class="header" href="#command-error">Command Error</a></h4>
<p>A server response with ok:0. A server response with ok:1 and writeConcernError or writeErrors is not considered a
command error.</p>
<h4 id="network-error-1"><a class="header" href="#network-error-1">Network Error</a></h4>
<p>Any error or timeout that occurs while selecting a server or reading from or writing to a network socket.</p>
<h4 id="error-label"><a class="header" href="#error-label">Error Label</a></h4>
<p>Starting in MongoDB 4.0, any command error may include a top level "errorLabels" field. The field contains an array of
string error labels. Drivers may also add error labels to errors that they return.</p>
<h4 id="transient-transaction-error"><a class="header" href="#transient-transaction-error">Transient Transaction Error</a></h4>
<p>Any command error that includes the "TransientTransactionError" error label in the "errorLabels" field. Any network
error encountered running any command other than commitTransaction in a transaction. If a network error occurs while
running the commitTransaction command then it is not known whether the transaction committed or not, and thus the
"TransientTransactionError" label MUST NOT be added.</p>
<h3 id="naming-variations-2"><a class="header" href="#naming-variations-2"><strong>Naming variations</strong></a></h3>
<p>This specification defines names for new methods and types. To the extent possible you SHOULD use these names in your
driver. However, where your driver's and/or language's naming conventions differ you SHOULD continue to use them
instead. For example, you might use StartTransaction or start_transaction instead of startTransaction.</p>
<p>A non-exhaustive list of acceptable naming deviations are as follows:</p>
<ul>
<li>Using "maxCommitTimeMS" as an example, .NET would use "MaxCommitTime" where it's type is a TimeSpan structure that
includes units. However, calling it "MaximumCommitTime" would not be acceptable.</li>
</ul>
<h3 id="transaction-api"><a class="header" href="#transaction-api"><strong>Transaction API</strong></a></h3>
<p>Transactions are built on top of Driver Session API. Applications can run a transaction like this:</p>
<pre><code class="language-python">with client.start_session() as s:
    s.start_transaction()
    collection_one.insert_one(doc_one, session=s)
    collection_two.insert_one(doc_two, session=s)
    s.commit_transaction()
</code></pre>
<p>This section is an overview of the public API for transactions:</p>
<pre><code class="language-typescript">class TransactionOptions {
    /**
     * The readConcern to use for this transaction.
     */
    Optional&lt;ReadConcern&gt; readConcern;

    /**
     * The writeConcern to use for this transaction.
     */
    Optional&lt;WriteConcern&gt; writeConcern;

    /**
     * The readPreference to use for this transaction.
     */
    Optional&lt;ReadPreference&gt; readPreference;

    /**
     * The maximum amount of time to allow a single commitTransaction
     * command to run.
     *
     * NOTE: This option is deprecated in favor of timeoutMS.
     */
    Optional&lt;Int64&gt; maxCommitTimeMS;
}

class SessionOptions {
    /**
     * The default TransactionOptions to use for transactions started
     * on this session.
     */
    Optional&lt;TransactionOptions&gt; defaultTransactionOptions;

    // Options defined in other specifications...
}

interface ClientSession {
    /**
     * Starts a new transaction with the given options. This session's
     * defaultTransactionOptions is used when options is omitted.
     * Raises an error if this session is already in a transaction.
     *
     * The return type MAY be non-void if necessary to participate in
     * the programming language's resource management block idiom. The
     * type of the returned object, if any, MUST NOT be named
     * Transaction, see "Why is there no Transaction object?"
     */
    void startTransaction(Optional&lt;TransactionOptions&gt; options);

    /**
     * Commits the currently active transaction in this session.
     * Raises an error if this session has no transaction.
     */
    void commitTransaction();

    /**
     * Aborts the currently active transaction in this session.
     * Raises an error if this session has no transaction.
     */
    void abortTransaction();

    /**
     * Aborts any currently active transaction and ends this session.
     * MUST NOT raise an error.
     */
    void endSession();

    // Methods defined in other specifications...
}
</code></pre>
<p>Each new member is documented below.</p>
<h3 id="transactionoptions"><a class="header" href="#transactionoptions"><strong>TransactionOptions</strong></a></h3>
<p>It is expected that the set of TransactionOptions will grow over time, TransactionOptions MUST be designed such that
future options can be added without breaking backward compatibility.</p>
<h4 id="readconcern"><a class="header" href="#readconcern">readConcern</a></h4>
<p>The readConcern to use for the first command, and only the first command, in a transaction. Server transactions are
started lazily with the first command using this session. For supported values see
<a href="transactions/transactions.html#behavior-of-the-readconcern-field">Behavior of the readConcern field</a>.</p>
<p>Note that the readConcern property is optional. The default value is NULL. If readConcern is NULL the value will be
inherited from this session’s defaultTransactionOptions. If defaultTransactionOptions itself is NULL or the readConcern
in defaultTransactionOptions is NULL, the readConcern is inherited from the MongoClient associated with this session.</p>
<p>If the user supplies an explicit readConcern via a method option, the driver MUST raise an error with the message
"Cannot set read concern after starting a transaction." See
<a href="transactions/transactions.html#users-cannot-pass-readconcern-or-writeconcern-to-operations-in-transactions">Users cannot pass readConcern or writeConcern to operations in transactions</a>.</p>
<h4 id="writeconcern"><a class="header" href="#writeconcern">writeConcern</a></h4>
<p>The writeConcern to use for the commitTransaction and abortTransaction commands. Note that the writeConcern property is
optional. The default value is NULL. If writeConcern is NULL the value will be inherited from this session’s
defaultTransactionOptions. If defaultTransactionOptions itself is NULL or the writeConcern in defaultTransactionOptions
is NULL, the writeConcern is inherited from the MongoClient associated with this session.</p>
<p>If the writeConcern is not the server default, then Drivers MUST add the writeConcern to the commitTransaction and
abortTransaction commands. Drivers MUST NOT add the transaction’s writeConcern or any writeConcern inherited from the
collection, database, or client to any preceding commands in the transaction.</p>
<p>If the user supplies an explicit writeConcern via a method option, the driver MUST raise an error with the message
"Cannot set write concern after starting a transaction." See
<a href="transactions/transactions.html#users-cannot-pass-readconcern-or-writeconcern-to-operations-in-transactions">Users cannot pass readConcern or writeConcern to operations in transactions</a>.</p>
<p>Drivers MUST raise an error if the user provides or if defaults would result in an unacknowledged writeConcern. The
Driver Sessions spec disallows using unacknowledged writes in a session. The error message MUST contain "transactions do
not support unacknowledged write concerns".</p>
<h4 id="readpreference-1"><a class="header" href="#readpreference-1">readPreference</a></h4>
<p>The read preference to use for all read operations in this transaction.</p>
<p>Note that the readPreference property is optional. The default value is NULL. If readPreference is NULL the value will
be inherited from this session’s defaultTransactionOptions. If defaultTransactionOptions itself is NULL or the
readPreference in defaultTransactionOptions is NULL, the readPreference is inherited from the MongoClient associated
with this session.</p>
<p>The transaction’s read preference MUST override all other user configurable read preferences, with the exception of
drivers that allow an operation level read preference. In this case, the driver MUST respect the read preference
specified by the user, allowing the server to report an error.</p>
<p>In MongoDB 4.0, transactions may only read from the primary. If a read is attempted and the transaction’s read
preference is not Primary drivers MUST raise an error containing the string "read preference in a transaction must be
primary". Drivers MUST NOT validate the read preference during write operations or in startTransaction. See
<a href="transactions/transactions.html#why-is-readpreference-part-of-transactionoptions">Why is readPreference part of TransactionOptions?</a>.</p>
<pre><code class="language-python">client = MongoClient("mongodb://host/?readPreference=nearest")
coll = client.db.test
with client.start_session() as s:
    with s.start_transaction():
        coll.insert_one({}, session=s)
        coll.find_one(session=s)  # Error: "read preference in a transaction must be primary"
</code></pre>
<p>In the future, we might relax this restriction and allow any read preference on a transaction.</p>
<h4 id="maxcommittimems"><a class="header" href="#maxcommittimems">maxCommitTimeMS</a></h4>
<p>NOTE: This option is deprecated in favor of
<a href="transactions/../client-side-operations-timeout/client-side-operations-timeout.html#timeoutms">timeoutMS</a>.</p>
<p>The maximum amount of time to allow a single commitTransaction command to run.</p>
<p>This option is only sent with the commitTransaction command(s) and only if the caller explicitly provides a value. The
default is to not send a value.</p>
<p>Note, this option is an alias for the <code>maxTimeMS</code> commitTransaction command option.</p>
<h3 id="sessionoptions-changes-2"><a class="header" href="#sessionoptions-changes-2"><strong>SessionOptions changes</strong></a></h3>
<h4 id="defaulttransactionoptions"><a class="header" href="#defaulttransactionoptions">defaultTransactionOptions</a></h4>
<p>The default TransactionOptions to use for transactions started on this session.</p>
<h3 id="clientsession-changes-2"><a class="header" href="#clientsession-changes-2"><strong>ClientSession changes</strong></a></h3>
<p>ClientSession is in one of five states: "no transaction", "starting transaction", "transaction in progress",
"transaction committed", and "transaction aborted". It transitions among these states according to the following
diagram:</p>
<p><img src="transactions/client-session-transaction-states.png"
style="width:6.5in;height:3.68056in" alt="states" />
(<a href="transactions/client-session-transaction-states.dot">GraphViz source</a>)</p>
<p>When a ClientSession is created it starts in the "no transaction" state. Starting, committing, and aborting a
transaction transitions the session between the "starting transaction", "transaction in progress", "transaction
committed", and "transaction aborted" states. If the session is in the "transaction aborted" or "transaction committed"
state, then any operation using the session (besides commitTransaction and abortTransaction) MUST reset the session
state to "no transaction".</p>
<p>Note that "error" is not a state, it represents throwing an error due to an invalid operation. When such errors are
thrown the session state is unchanged.</p>
<p>Client-side errors MUST NOT change transaction state. For example, if an invalid key or an excessively large document is
provided by the application to an insert when the transaction state is "starting transaction", the transaction state
MUST remain "starting transaction". If the same situation occurs when the transaction state is "transaction in
progress", the state MUST remain "transaction in progress".</p>
<h4 id="starttransaction"><a class="header" href="#starttransaction">startTransaction</a></h4>
<p>This method starts a new transaction on this session with the given TransactionOptions. When options is omitted or if
particular options are not specified, drivers will use the defaultTransactionOptions from ClientSession.options or
inherit them from the session's client, as described in the text above for each option. This session is in the "starting
transaction" state after this method returns.</p>
<p>If this session is in the "starting transaction " or "transaction in progress" state, then Drivers MUST raise an error
containing the message "Transaction already in progress" without modifying any session state.</p>
<p>startTransaction SHOULD report an error if the driver can detect that transactions are not supported by the deployment.
A deployment does not support transactions when the deployment does not support sessions, or maxWireVersion &lt; 7, or the
maxWireVersion &lt; 8 and the topology type is Sharded, see
<a href="transactions/../sessions/driver-sessions.html#how-to-tell-whether-a-connection-supports-sessions">How to Tell Whether a Connection Supports Sessions</a>.
Note that checking the maxWireVersion does not guarantee that the deployment supports transactions, for example a
MongoDB 4.0 replica set using MMAPv1 will report maxWireVersion 7 but does not support transactions. In this case,
Drivers rely on the deployment to report an error when a transaction is started.</p>
<p>Drivers MUST increment the <code>txnNumber</code> for the corresponding server session.</p>
<p>In programming languages that support resource management blocks, startTransaction MAY be used to initiate such a block:</p>
<pre><code class="language-python">with client.start_session() as s:
    with s.start_transaction():
        collection_one.insert_one(doc1, session=s)
        s.commit_transaction()
</code></pre>
<p>The exact API SHOULD match the idioms of the programming language. Depending on the conventions of the programming
language, exiting the block without calling commitTransaction MAY automatically abort the transaction, or MAY abort the
transaction when exiting due to an exception and commit it when exiting normally. The driver MUST NOT automatically
commit the transaction when exiting the block due to an exception. This means that for languages that use an RAII
pattern for resource management blocks, if object destruction can't tell if the containing scope has exited normally or
for an exception, object destruction MUST NOT automatically commit the transaction.</p>
<p>If the driver returns a type to support resource management blocks, the type MUST NOT be named "Transaction". The type
MAY be named "TransactionContext", "TransactionScopeGuard" or something similar for your language. See
<a href="transactions/transactions.html#why-is-there-no-transaction-object">Why is there no Transaction object?</a></p>
<h4 id="committransaction"><a class="header" href="#committransaction">commitTransaction</a></h4>
<p>This method commits the currently active transaction on this session. Drivers MUST run a commitTransaction command with
the writeConcern and, if configured, the maxCommitTimeMS from TransactionOptions. Drivers MUST report an error when the
command fails or the command succeeds but contains a writeConcernError. This session is in the "transaction committed"
state after this method returns — even on error.</p>
<p>If this session is in the "no transaction" state, then Drivers MUST raise an error containing the message "No
transaction started".</p>
<p>If this session is in the "transaction aborted" state, then Drivers MUST raise an error containing the message "Cannot
call commitTransaction after calling abortTransaction".</p>
<p>If this session is already in the "transaction committed" state, then Drivers MUST re-run the previous
commitTransaction.</p>
<p>It is valid to call commitTransaction when the session is in the "starting transaction" or "transaction in progress"
state. When the session is in the "starting transaction" state, meaning no operations have been performed on this
transaction, drivers MUST NOT run the commitTransaction command.</p>
<p>commitTransaction is a retryable write command. Drivers MUST retry once after commitTransaction fails with a retryable
error, including a handshake network error, according to the Retryable Writes Specification, regardless of whether
retryWrites is set on the MongoClient or not.</p>
<p>When commitTransaction is retried, either by the driver's internal retry logic or explicitly by the user calling
commitTransaction again, drivers MUST apply <code>w: majority</code> to the write concern of the commitTransaction command. If the
transaction is using a <a href="transactions/transactions.html#writeconcern">writeConcern</a> that is not the server default (i.e. specified via
TransactionOptions during the <code>startTransaction</code> call or otherwise inherited), any other write concern options (e.g.
<code>wtimeout</code>) MUST be left as-is when applying <code>w: majority</code>. Finally, if the modified write concern does not include a
<code>wtimeout</code> value, drivers MUST also apply <code>wtimeout: 10000</code> to the write concern in order to avoid waiting forever (or
until a socket timeout) if the majority write concern cannot be satisfied. See
<a href="transactions/transactions.html#majority-write-concern-is-used-when-retrying-committransaction">Majority write concern is used when retrying commitTransaction</a>.</p>
<p>Drivers MUST add error labels to certain errors when commitTransaction fails. See the
<a href="transactions/transactions.html#error-reporting-changes">Error reporting changes</a> and <a href="transactions/transactions.html#error-labels">Error Labels</a> sections for a precise
description.</p>
<h4 id="aborttransaction"><a class="header" href="#aborttransaction">abortTransaction</a></h4>
<p>This method aborts the currently active transaction on this session. Drivers MUST run an abortTransaction command with
the transaction’s writeConcern. When this method completes the session moves to the "transaction aborted" state.</p>
<p>It is only valid to call abortTransaction when the session is in the "starting transaction" or "transaction in progress"
state, otherwise drivers MUST raise an error without modifying transaction state.</p>
<p>If this session is in the "no transaction" state, then drivers MUST raise an error containing the message "No
transaction started".</p>
<p>If this session is in the "transaction committed" state, then drivers MUST raise an error containing the message "Cannot
call abortTransaction after calling commitTransaction".</p>
<p>If this session is already in the "transaction aborted" state, then drivers MUST raise an error containing the message
"Cannot call abortTransaction twice".</p>
<p>It is valid to call abortTransaction when the session is in the "starting transaction" or "transaction in progress"
state. When the session is in the "starting transaction" state, meaning, no operations have been performed on this
transaction, drivers MUST NOT run the abortTransaction command.</p>
<p>abortTransaction is a retryable write command. Drivers MUST retry after abortTransaction fails with a retryable error
according to the <a href="transactions/../retryable-writes/retryable-writes.html">Retryable Writes Specification</a>, including a handshake
network error, regardless of whether retryWrites is set on the MongoClient or not.</p>
<p>If the operation times out or fails with a non-retryable error, drivers MUST ignore all errors from the abortTransaction
command. Errors from abortTransaction are meaningless to the application because they cannot do anything to recover from
the error. The transaction will ultimately be aborted by the server anyway either upon reaching an age limit or when the
application starts a new transaction on this session, see
<a href="transactions/transactions.html#drivers-ignore-all-aborttransaction-errors">Drivers ignore all abortTransaction errors</a>.</p>
<h4 id="endsession-changes"><a class="header" href="#endsession-changes">endSession changes</a></h4>
<p>This method ends a ClientSession. Drivers MUST call abortTransaction if this session is in the "transaction in progress"
state in order to release resources on the server. Drivers MUST ignore any errors raised by abortTransaction while
ending a session.</p>
<h3 id="error-reporting-changes"><a class="header" href="#error-reporting-changes">Error reporting changes</a></h3>
<p>This spec introduces the concept of an "error label". Which labels are applied to an error may be communicated from the
server to the client, or determined client-side. Any error reported by the driver in response to a server error, server
selection error, or network error MUST have an API for determining whether it has a given label. In programming
languages that use class inheritance hierarchies for exceptions, the presence of an error label MUST NOT affect an
exception's class. Error labels MUST be expressed as a collection of text strings, and it MUST be possible for
applications to check if an error has a label that is not yet specified in MongoDB 4.0. Drivers MAY define constants for
error label strings that are known at this time.</p>
<p>Drivers MAY implement an error label API similar to the following:</p>
<pre><code class="language-python">try:
    session.commit_transaction()
except (OperationFailure, ConnectionFailure) as exc:
    if exc.has_error_label("UnknownTransactionCommitResult"):
        print("tried to commit, don't know the outcome")
</code></pre>
<p>Drivers MAY expose the list of all error labels for an exception object.</p>
<p>Drivers MUST add the error label "TransientTransactionError" to network errors thrown in a transaction except for
network errors thrown during commitTransaction.</p>
<h2 id="transactions-wire-protocol"><a class="header" href="#transactions-wire-protocol">Transactions Wire Protocol</a></h2>
<p>The server requires each operation executed within a transaction to provide an <code>lsid</code> and <code>txnNumber</code> in its command
document. Each field is obtained from the ClientSession object passed to the operation from the application. Drivers
will be responsible for maintaining a monotonically increasing transaction number for each ServerSession used by a
ClientSession object. The <code>txnNumber</code> is incremented by the call to startTransaction and remains the same for all
commands in the transaction.</p>
<p>Drivers that pool ServerSessions MUST preserve the transaction number when reusing a server session from the pool with a
new ClientSession (this can be tracked as another property on the driver's object for the server session).</p>
<p>Drivers MUST ensure that each transaction specifies a transaction number larger than any previously used transaction
number for its session ID.</p>
<h3 id="constructing-commands-within-a-transaction"><a class="header" href="#constructing-commands-within-a-transaction"><strong>Constructing commands within a transaction</strong></a></h3>
<h4 id="behavior-of-the-starttransaction-field"><a class="header" href="#behavior-of-the-starttransaction-field">Behavior of the startTransaction field</a></h4>
<p>The first command within a multi-statement transaction MUST include <code>startTransaction:true</code>. Subsequent commands MUST
NOT include the <code>startTransaction</code> field.</p>
<h4 id="behavior-of-the-autocommit-field"><a class="header" href="#behavior-of-the-autocommit-field">Behavior of the autocommit field</a></h4>
<p>All operations within a multi-statement transaction (including commitTransaction and abortTransaction) MUST include
<code>autocommit:false</code>, to distinguish them from single-statement retryable writes.</p>
<h4 id="behavior-of-the-readconcern-field"><a class="header" href="#behavior-of-the-readconcern-field">Behavior of the readConcern field</a></h4>
<p>Any command that marks the beginning of a transaction MAY include a <code>readConcern</code> argument with an optional <code>level</code> and
<code>afterClusterTime</code> fields. Read concern level 'local', 'majority', and 'snapshot' are all supported, although they will
all have the same behavior as "snapshot" in MongoDB 4.0. To support causal consistency, if <code>readConcern</code>
<code>afterClusterTime</code> is specified, then the server will ensure that the transaction’s read timestamp is after the
<code>afterClusterTime</code>.</p>
<p>All commands of a multi-statement transaction subsequent to the initial command MUST NOT specify a <code>readConcern</code>, since
the <code>readConcern</code> argument is only needed to establish the transaction’s read timestamp. If a <code>readConcern</code> argument is
specified on a subsequent (non-initial) command, the server will return an error.</p>
<p>Read concern level "snapshot" is new in MongoDB 4.0 and can only be used when starting a transaction. The server will
return an error if read concern level "snapshot" is specified on a command that is not the start of a transaction.
Drivers MUST rely on the server to report an error if read concern level snapshot is used incorrectly.</p>
<h4 id="behavior-of-the-writeconcern-field"><a class="header" href="#behavior-of-the-writeconcern-field">Behavior of the writeConcern field</a></h4>
<p>The commitTransaction and abortTransaction commands are the only commands of a multi-statement transaction that allow a
<code>writeConcern</code> argument. If a <code>writeConcern</code> argument is given on any other command of a transaction, the server will
return an error. The <code>writeConcern</code> argument of the commitTransaction and abortTransaction commands has semantics
analogous to existing write commands.</p>
<h4 id="behavior-of-the-recoverytoken-field"><a class="header" href="#behavior-of-the-recoverytoken-field">Behavior of the recoveryToken field</a></h4>
<p>Only included for sharded transactions and only when running a commitTransaction or abortTransaction command. See the
<a href="transactions/transactions.html#recoverytoken-field">recoveryToken field</a> section for more info.</p>
<h4 id="constructing-the-first-command-within-a-transaction"><a class="header" href="#constructing-the-first-command-within-a-transaction">Constructing the first command within a transaction</a></h4>
<p>When constructing the first command within a transaction, drivers MUST add the <code>lsid</code>, <code>txnNumber</code>, <code>startTransaction</code>,
and <code>autocommit</code> fields.</p>
<p>Drivers MUST include the transaction's readConcern in the first command in a transaction if and only if the readConcern
is supplied and not the server's default. The readConcern MUST NOT be inherited from the collection, database, or client
associated with the driver method that invokes the first command.</p>
<p>Drivers MUST NOT add to subsequent commands the readConcern from the transaction or any readConcern inherited from the
collection, database, or client.</p>
<p>This is an example of an insert command that begins a server transaction:</p>
<pre><code class="language-typescript">{
    insert : "test",
    documents : [{}],
    lsid : { id : &lt;UUID&gt; }
    txnNumber: NumberLong(1),
    // The "level" is optional, supported values are "local", "majority"
    // and "snapshot". "afterClusterTime" is only present in causally
    // consistent sessions.
    readConcern : {
        level : "snapshot",
        afterClusterTime : Timestamp(42,1)
    },
    startTransaction : true,
    autocommit : false
}
</code></pre>
<p>This command uses the readConcern set on the transaction's TransactionOptions during the <code>startTransaction</code> call. It is
not inherited from a client, database, or collection at the time of the first command.</p>
<p>The session transitions to the "transaction in progress" state after completing the first command within a transaction —
even on error.</p>
<h4 id="constructing-any-other-command-within-a-transaction"><a class="header" href="#constructing-any-other-command-within-a-transaction">Constructing any other command within a transaction</a></h4>
<p>When constructing any other command within a transaction, drivers MUST add the <code>lsid</code>, <code>txnNumber</code>, and <code>autocommit</code>
fields. Drivers MUST NOT automatically add the <code>writeConcern</code>, <code>readConcern</code>, or <code>startTransaction</code> fields. This is an
example of a find command within a transaction:</p>
<pre><code class="language-typescript">{
    find : "test",
    filter : {},
    lsid : { id : &lt;UUID&gt; }
    txnNumber : NumberLong(1),
    autocommit : false
}
</code></pre>
<h4 id="generic-runcommand-helper-within-a-transaction"><a class="header" href="#generic-runcommand-helper-within-a-transaction">Generic RunCommand helper within a transaction</a></h4>
<p>If your driver offers a generic RunCommand method on your database object, the driver MUST add the <code>lsid</code>, <code>autocommit</code>,
and <code>txnNumber</code> fields. If the RunCommand operation is the first operation in a transaction then the driver MUST also
add the <code>startTransaction</code> and <code>readConcern</code> fields. A driver MUST do this without modifying any data supplied by the
application (e.g. the command document passed to RunCommand). If the user supplies an explicit readConcern as an
argument to the runCommand method in a transaction, the client MUST raise an error with the message "Cannot set read
concern after starting a transaction."</p>
<p>The RunCommand method is considered a read operation and MUST use the transaction’s read preference.</p>
<p>The behavior is not defined if the command document passed to RunCommand already contains some of the transaction
fields.</p>
<h3 id="interaction-with-causal-consistency"><a class="header" href="#interaction-with-causal-consistency"><strong>Interaction with Causal Consistency</strong></a></h3>
<p>Drivers MUST add <code>readConcern.afterClusterTime</code> to the command that starts a transaction in a causally consistent
session -- even if the command is a write. Drivers MUST NOT add <code>readConcern.afterClusterTime</code> to subsequent commands in
a transaction.</p>
<h3 id="interaction-with-retryable-writes"><a class="header" href="#interaction-with-retryable-writes"><strong>Interaction with Retryable Writes</strong></a></h3>
<p>In MongoDB 4.0 the only supported retryable write commands within a transaction are commitTransaction and
abortTransaction. Therefore drivers MUST NOT retry write commands within transactions even when retryWrites has been
enabled on the MongoClient. In addition, drivers MUST NOT add the RetryableWriteError label to any error that occurs
during a write command within a transaction (excepting commitTransation and abortTransaction), even when retryWrites has
been enabled on the MongoClient.</p>
<p>Drivers MUST retry the commitTransaction and abortTransaction commands even when retryWrites has been disabled on the
MongoClient. commitTransaction and abortTransaction are retryable write commands and MUST be retried according to the
<a href="transactions/../retryable-writes/retryable-writes.html">Retryable Writes Specification</a>.</p>
<p>Retryable writes and transactions both use the <code>txnNumber</code> associated with a ServerSession. For retryable writes,
<code>txnNumber</code> would normally increment before each retryable command, whereas in a transaction, the <code>txnNumber</code> is
incremented at the start and then stays constant, even for retryable operations within the transaction. When executing
the commitTransaction and abortTransaction commands within a transaction drivers MUST use the same <code>txnNumber</code> used for
all preceding commands in the transaction.</p>
<h3 id="server-commands-3"><a class="header" href="#server-commands-3"><strong>Server Commands</strong></a></h3>
<h4 id="committransaction-1"><a class="header" href="#committransaction-1">commitTransaction</a></h4>
<p>The commitTransaction server command has the following format:</p>
<pre><code class="language-typescript">{
    commitTransaction : 1,
    lsid : { id : &lt;UUID&gt; },
    txnNumber : &lt;Int64&gt;,
    autocommit : false,
    writeConcern : {...},
    maxTimeMS: &lt;Int64&gt;,
    recoveryToken : {...}
}
</code></pre>
<h4 id="aborttransaction-1"><a class="header" href="#aborttransaction-1">abortTransaction</a></h4>
<p>The abortTransaction server command has the following format:</p>
<pre><code class="language-typescript">{
    abortTransaction : 1,
    lsid : { id : &lt;UUID&gt; },
    txnNumber : &lt;Int64&gt;,
    autocommit : false,
    writeConcern : {...},
    recoveryToken : {...}
}
</code></pre>
<p>Both commands MUST be sent to the admin database.</p>
<p>The server response has the following format:</p>
<pre><code class="language-typescript">{ ok : 1 }
</code></pre>
<p>In case of an error, the server response has the following format:</p>
<pre><code class="language-typescript">{ ok : 0, errmsg : "...", code : &lt;Number&gt;, errorLabels: ["Label"] }
</code></pre>
<p>In case of a write concern error, the server response has the following format:</p>
<pre><code class="language-typescript">{ ok : 1, writeConcernError: {code: &lt;Number&gt;, errmsg : "..."} }
</code></pre>
<h2 id="sharded-transactions-1"><a class="header" href="#sharded-transactions-1">Sharded Transactions</a></h2>
<p>MongoDB 4.2 (maxWireVersion 8) introduces support for sharded transactions. Sharded transactions support all of the same
features as single replica set transaction but introduce two new driver concepts: mongos pinning and the <code>recoveryToken</code>
field.</p>
<h3 id="mongos-pinning"><a class="header" href="#mongos-pinning">Mongos Pinning</a></h3>
<p>Drivers MUST send all commands for a single transaction to the same mongos (excluding retries of commitTransaction and
abortTransaction).</p>
<p>After the driver selects a mongos for the first command within a transaction, the driver MUST pin the ClientSession to
the selected mongos. Drivers MUST send all subsequent commands that are part of the same transaction (excluding certain
retries of commitTransaction and abortTransaction) to the same mongos.</p>
<h4 id="when-to-unpin"><a class="header" href="#when-to-unpin">When to unpin</a></h4>
<p>Drivers MUST unpin a ClientSession in the following situations:</p>
<ol>
<li>The transaction is aborted. The session MUST be unpinned regardless of whether or the <code>abortTransaction</code> command
succeeds or fails, or was executed at all. If the operation fails with a retryable error, the session MUST be
unpinned before performing server selection for the retry.</li>
<li>Any operation in the transaction, including <code>commitTransaction</code> fails with a TransientTransactionError. Transient
errors indicate that the transaction in question has already been aborted or that the pinnned mongos is
down/unavailable. Unpinning the session ensures that a subsequent <code>abortTransaction</code> (or <code>commitTransaction</code>) does
not block waiting on a server that is unreachable.</li>
<li>Any <code>commitTransaction</code> attempt fails with an <code>UnknownTransactionCommitResult</code> error label. If the error is also
considered retryable, the session MUST be unpinned before performing server selection for the retry.</li>
<li>A new transaction is started on the ClientSession after the previous transaction has been committed. The session MUST
be unpinned before performing server selection for the first operation of the new transaction.</li>
<li>A non-transactional operation is performed using the ClientSession. The session MUST be unpinned before performing
server selection for the operation.</li>
</ol>
<p>Note that committing a transaction on a pinned ClientSession MUST NOT unpin the session as <code>commitTransaction</code> may be
called multiple times.</p>
<h4 id="pinning-in-load-balancer-mode"><a class="header" href="#pinning-in-load-balancer-mode">Pinning in Load Balancer Mode</a></h4>
<p>See the <a href="transactions/../load-balancers/load-balancers.html#connection-pooling">Load Balancer Specification</a> for details.</p>
<h3 id="recoverytoken-field"><a class="header" href="#recoverytoken-field">recoveryToken field</a></h3>
<p>The <code>recoveryToken</code> field enables the driver to recover a sharded transaction's outcome on a new mongos when the
original mongos is no longer available.<sup class="footnote-reference"><a href="#1">1</a></sup></p>
<p>Every successful (<code>ok:1</code>) command response in a sharded transaction includes a <code>recoveryToken</code> field. Drivers MUST track
the most recently received <code>recoveryToken</code> field and MUST append this field to any subsequent commitTransaction or
abortTransaction commands. Tracking the most recently returned <code>recoveryToken</code> allows the server to update the
<code>recoveryToken</code> mid-transaction if needed.</p>
<p>Drivers MUST clear a session's cached <code>recoveryToken</code> when transitioning to the "no transaction" or "starting
transaction" state.</p>
<p>Drivers can safely assume that the <code>recoveryToken</code> field is always a BSON document but drivers MUST NOT modify the
contents of the document.</p>
<h2 id="error-reporting-and-retrying-transactions"><a class="header" href="#error-reporting-and-retrying-transactions">Error Reporting and Retrying Transactions</a></h2>
<h3 id="error-labels"><a class="header" href="#error-labels">Error Labels</a></h3>
<p>Starting in MongoDB 4.0, any command error may include a top level "errorLabels" field. The field contains an array of
string error labels.</p>
<h3 id="transienttransactionerror"><a class="header" href="#transienttransactionerror">TransientTransactionError</a></h3>
<p>Any command error that includes the "TransientTransactionError" error label in the "errorLabels" field. Any network
error or server selection error encountered running any command besides commitTransaction in a transaction. In the case
of command errors, the server adds the label; in the case of network errors or server selection errors where the client
receives no server reply, the client adds the label.</p>
<h4 id="retrying-transactions-that-fail-with-transienttransactionerror"><a class="header" href="#retrying-transactions-that-fail-with-transienttransactionerror">Retrying transactions that fail with TransientTransactionError</a></h4>
<p>If an exception with the "TransientTransactionError" label is thrown, an application can retry the entire transaction
from the beginning with a reasonable expectation that it will succeed. For example:</p>
<pre><code class="language-python">def run_transaction(client):
    with client.start_session() as s:
        with s.start_transaction():
            collection_one.insert_one(doc1, session=s)
            collection_two.insert_one(doc2, session=s)

while True:
    try:
        return run_transaction(client)
    except (OperationFailure, ConnectionFailure) as exc:
        if exc.has_error_label("TransientTransactionError"):
            print("Transient transaction error, retrying...")
            continue
        raise
</code></pre>
<p>In the above example, a transaction will never be committed twice. The retry loop ends when the transaction commits
successfully or the transaction fails with a non-transient error.</p>
<p>An example of a non-transient transaction error is DuplicateKeyError, which causes the server to abort the transaction.
Retrying a transaction that causes a DuplicateKeyError will again (likely) abort the transaction, therefore such an
error is not labeled "transient."</p>
<h3 id="unknowntransactioncommitresult"><a class="header" href="#unknowntransactioncommitresult">UnknownTransactionCommitResult</a></h3>
<p>The commitTransaction command is considered a retryable write. The driver will automatically retry the commitTransaction
after a retryable error. Although this adds a layer of protection, the driver’s retry attempt of a commitTransaction may
again fail with a retryable error. In that case, both the driver and the application do not know the state of the
transaction.</p>
<p>The driver MUST add the "UnknownTransactionCommitResult" error label when commitTransaction fails with a server
selection error, network error, retryable writes error, MaxTimeMSExpired error, or write concern failed / timeout. (See
<a href="transactions/transactions.html#a-server-selection-error-is-labeled-unknowntransactioncommitresult">A server selection error is labeled UnknownTransactionCommitResult</a>
for justification.) The approximate meaning of the UnknownTransactionCommitResult label is, "We don't know if your
commit has satisfied the provided write concern." The only write concern errors that are not labeled with
"UnknownTransactionCommitResult" are CannotSatisfyWriteConcern (which will be renamed to the more precise
UnsatisfiableWriteConcern in 4.2, while preserving the current error code) and UnknownReplWriteConcern. These errors
codes mean that the provided write concern is not valid and therefore a retry attempt would fail with the same error.</p>
<p>In the case that the commitTransaction fails with a retryable writes error, that error will have both an
UnknownTransactionCommitResult label and a RetryableWriteError label. This is currently the only scenario in which an
error can be assigned two error labels.</p>
<h4 id="retrying-committransaction"><a class="header" href="#retrying-committransaction">Retrying commitTransaction</a></h4>
<p>If an exception with this label is thrown, an application can safely call commitTransaction again. If this attempt
succeeds it means the transaction has committed with the provided write concern. If this attempt fails it may also have
the "UnknownTransactionCommitResult" error label. For example:</p>
<pre><code class="language-python">def run_transaction_and_retry_commit(client):
    with client.start_session() as s:
        with s.start_transaction():
            collection_one.insert_one(doc1, session=s)
            collection_two.insert_one(doc2, session=s)
            while True:
                try:
                    s.commit_transaction()
                    break
                except (OperationFailure, ConnectionFailure) as exc:
                    if exc.has_error_label("UnknownTransactionCommitResult"):
                        print("Unknown commit result, retrying...")
                        continue
                    raise

while True:
    try:
        return run_transaction_and_retry_commit(client)
    except (OperationFailure, ConnectionFailure) as exc:
        if exc.has_error_label("TransientTransactionError"):
            print("Transient transaction error, retrying...")
            continue
        raise
</code></pre>
<h2 id="handling-command-errors"><a class="header" href="#handling-command-errors">Handling command errors</a></h2>
<p>Drivers MUST document that command errors inside a transaction may abort the transaction on the server. An attempt to
commit such transaction will be rejected with <code>NoSuchTransaction</code> error.</p>
<h2 id="test-plan-20"><a class="header" href="#test-plan-20"><strong>Test Plan</strong></a></h2>
<p>See the <a href="transactions/tests/README.html">README</a> for tests.</p>
<p>The Python driver serves as a reference implementation.</p>
<h2 id="design-rationale-20"><a class="header" href="#design-rationale-20"><strong>Design Rationale</strong></a></h2>
<p>The design of this specification builds on the <a href="transactions/../sessions/driver-sessions.html">Driver Sessions Specification</a> and
modifies the driver API as little as possible.</p>
<p>Drivers will rely on the server to yield an error if an unsupported command is executed within a transaction. This will
free drivers from having to maintain a list of supported operations and also allow for forward compatibility when future
server versions begin to support transactions for additional commands.</p>
<h3 id="drivers-ignore-all-aborttransaction-errors"><a class="header" href="#drivers-ignore-all-aborttransaction-errors">Drivers ignore all abortTransaction errors</a></h3>
<p>If the driver has cleared its client-side transaction state, then the next operation it performs will be in a new
transaction or no transaction, which will cause any lingering transaction state on the server (associated with this
session) to abort. Therefore abortTransaction can be considered fail-safe, and raising an exception from it only
complicates application code. Applications would have to wrap abortTransaction in an exception-handling block, but have
no useful action to perform in response to the error.</p>
<p>abortTransaction does, however, raise an error if there is no transaction in progress. We had considered making this
situation raise no error, as well. However, we want to raise an error from abortTransaction if there is no transaction,
because it discourages an antipattern like this:</p>
<pre><code class="language-python">s.start_transaction()
try:
    coll.insert_one({}, session=s)
    s.commit_transaction()
except:
    # We don't know if it was the insert_one, the commit,
    # or some other operation that failed, so we must not
    # commit the transaction.
    s.abort_transaction()  # Raises a client-side error
</code></pre>
<p>If a user puts "commit" in the same exception handling block as the other operations in the transaction, they don't know
whether to retry the commit or the whole transaction on error. We want such code to raise an exception. One chance we
have to do that is if a commit fails with a network error and enters the exception handling block, where
abortTransaction throws "Cannot call abortTransaction after commitTransaction".</p>
<h3 id="drivers-add-the-transienttransactionerror-label-to-network-errors"><a class="header" href="#drivers-add-the-transienttransactionerror-label-to-network-errors">Drivers add the "TransientTransactionError" label to network errors</a></h3>
<p>When any non-commitTransaction command fails with a network error within a transaction Drivers add the
"TransientTransactionError" label because the client doesn't know if it has modified data in the transaction or not.
Therefore it must abort and retry the entire transaction to be certain it has executed each command in the transaction
exactly once.</p>
<p>Adding the "TransientTransactionError" label allows applications to use the the same error label API for both network
errors and command errors. This also allows applications to distinguish between a network error that occurs within a
transaction from a network error that occurs while committing a transaction.</p>
<h3 id="transactions-in-gridfs"><a class="header" href="#transactions-in-gridfs">Transactions in GridFS</a></h3>
<p>The GridFS spec has not been updated to support sessions, however some drivers have already implemented support for it
on their own. When the GridFS spec has been updated to support sessions, then drivers that implement that spec MUST also
support transactions in GridFS because all APIs that allow sessions MUST support transactions.</p>
<p>Drivers that have already implemented session support in GridFS MUST also support transactions in GridFS. Drivers that
have not implemented ClientSession support in GridFS are not required to support transactions (or sessions) in GridFS.</p>
<p>This spec does not require all drivers to implement transaction support in GridFS because transactions in GridFS are not
very useful: transactions in 4.0 are too limited in time and space to operate on large GridFS files. Additionally,
GridFS as specified already has some basic guarantees that make transactions less necessary: files are immutable and
they are created "atomically", from the primary's perspective, because the file entry is only saved after all chunks are
uploaded.</p>
<h3 id="causal-consistency-with-runcommand-helper"><a class="header" href="#causal-consistency-with-runcommand-helper">Causal Consistency with RunCommand helper</a></h3>
<p>Causal Consistency alone only applies to commands that read, and we don't want to parse the document passed to
runCommand to see if it's a command that reads. In a transaction, however, any command at all that starts a transaction
must include <code>afterClusterTime</code>, so we can add <code>afterClusterTime</code> to the document passed to runCommand without adding
per-command special logic to runCommand.</p>
<h3 id="calling-committransaction-with-the-generic-runcommand-helper-is-undefined-behavior"><a class="header" href="#calling-committransaction-with-the-generic-runcommand-helper-is-undefined-behavior">Calling commitTransaction with the generic runCommand helper is undefined behavior</a></h3>
<p>Applications should only use the ClientSession API to manage transactions. Applications should not use a generic
runCommand helper to run the commitTransaction or abortTransaction commands directly. This spec does not define the
behavior of calling such commands, consistent with other drivers specifications that do not define the behavior of
calling directly commands for which helper methods are available The purpose of the generic runCommand method is to
execute a command directly with minimum additional client-side logic.</p>
<h2 id="dependencies"><a class="header" href="#dependencies"><strong>Dependencies</strong></a></h2>
<p>This specification depends on:</p>
<ol>
<li><a href="transactions/../sessions/driver-sessions.html">Driver Sessions Specification</a></li>
<li><a href="transactions/../retryable-writes/retryable-writes.html">Retryable Writes Specification</a></li>
</ol>
<h2 id="backwards-compatibility-17"><a class="header" href="#backwards-compatibility-17"><strong>Backwards Compatibility</strong></a></h2>
<p>The API changes to support transactions extend the existing API but do not introduce any backward breaking changes.
Existing programs that do not make use of transactions will continue to compile and run correctly.</p>
<h2 id="reference-implementation-14"><a class="header" href="#reference-implementation-14"><strong>Reference Implementation</strong></a></h2>
<p>The <a href="https://github.com/mongodb/mongo-python-driver/">Python driver</a> serves as a reference implementation.</p>
<h2 id="future-work-12"><a class="header" href="#future-work-12"><strong>Future work</strong></a></h2>
<ul>
<li>
<p>Support retryable writes within a transaction.</p>
</li>
<li>
<p>Support transactions on secondaries. In this case, drivers would be required to pin a transaction to the server
selected for the initial operation. All subsequent operations in the transaction would go to the pinned server.</p>
</li>
<li>
<p>Support for transactions that read from multiple nodes in a replica set. One interesting use case would be to run a
single transaction that performs low-latency reads with readPreference "nearest" followed by some writes.</p>
</li>
<li>
<p>Support for unacknowledged transaction commits. This might be useful when data consistency is paramount but durability
is optional. Imagine a system that increments two counters in two different collections. The system may want to use
transactions to guarantee that both counters are always incremented together or not at all.</p>
</li>
</ul>
<h2 id="justifications-1"><a class="header" href="#justifications-1"><strong>Justifications</strong></a></h2>
<h3 id="why-is-there-no-transaction-object"><a class="header" href="#why-is-there-no-transaction-object">Why is there no Transaction object?</a></h3>
<p>In order to use transactions an application already has to create and manage a ClientSession object. Introducing a
Transaction object would result in another object that the application needs to manage. Moreover, a server session can
only have a single transaction in progress at a time. We chose not to introduce a public Transaction object so that
applications only need to manage a single object and to more closely mirror how transactions work on the server.</p>
<p>Some drivers' startTransaction methods will return an object as part of the language's resource management block
protocol. The object returned by startTransaction MUST NOT be named Transaction, in order to reserve that name for some
future API extension. Additionally, by avoiding the name Transaction, we prevent users from thinking they can run
multiple transactions in a session. Finally, we avoid the temptation to diverge from this spec's API by adding a
commit() or abort() method to the object returned by startTransaction. Committing and aborting a transaction is the
responsibility of the ClientSession object in all drivers.</p>
<h3 id="why-is-readpreference-part-of-transactionoptions"><a class="header" href="#why-is-readpreference-part-of-transactionoptions">Why is readPreference part of TransactionOptions?</a></h3>
<p>Providing a read preference for the entire transaction makes it easier for applications that use one or more non-primary
read preferences for non-transactional reads to run transactions under a single, primary read-preference. Applications
only need to set primary read preference on the transaction instead of changing the read preference of all operations.</p>
<p>Because primary is the only read preference allowed with transactions in MongoDB 4.0, this specification could have
omitted TransactionOptions.readPreference, or at least defaulted the read preference to primary instead of inheriting
the client's read preference. However, this would have required a breaking change circa MongoDB 4.2 when we introduce
secondary reads in transactions: TransactionOptions will inherit the client's read preference in 4.2, so for the sake of
future-compatibility, TransactionOptions inherits the client's read preference now.</p>
<p>We considered defaulting TransactionOptions.readPreference to primary in 4.0, overriding the client's read preference by
default for convenience. However, for consistency with other options-inheritance rules in our specifications,
transactions MUST inherit the client's read preference.</p>
<p>In MongoDB 4.0, the error "read preference in a transaction must be primary" is thrown whenever the application attempts
a read operation in a transaction with a non-primary read preference. We considered throwing this error from
startTransaction instead, to make the error more deterministic and reduce the performance burden of re-checking the
TransactionOptions on each operation. However, this behavior will have to change when we introduce secondary reads in
transactions. There will then be new error scenarios, such as a transaction with secondary reads followed by a write. It
won't be possible in the future for startTransaction to check that the read preference is correct for all operations the
application will perform in the transaction. Therefore, we specify now that the readPreference must be checked
per-operation. (However, we have not completely planned how read preference validation will behave in MongoDB 4.2.)</p>
<h3 id="users-cannot-pass-readconcern-or-writeconcern-to-operations-in-transactions"><a class="header" href="#users-cannot-pass-readconcern-or-writeconcern-to-operations-in-transactions">Users cannot pass readConcern or writeConcern to operations in transactions</a></h3>
<p>For drivers that allow readConcern and/or writeConcern to be passed to a particular operation, If the driver did not
prohibit the readConcern parameter to methods in a transaction, the following code would be ambiguous:</p>
<pre><code class="language-python">client = MongoClient("mongodb://localhost/?readConcernLevel=majority")
with client.start_session() as s:
    # Transaction uses readConcern majority.
    with s.start_transaction():
        # The first command in a transaction. Which readConcern?
        client.db.collection.distinct(
            readConcern={'level': 'snapshot'},
            session=s)
</code></pre>
<p>In this scenario, the driver must choose which of the two possible readConcerns to use for the <em>first</em> command in the
transaction. The server will accept either without error, so the ambiguity MUST be resolved by raising a client-side
error.</p>
<p>We <em>could</em> specify that if a user passes an explicit writeConcern to an operation in a transaction, that the driver
passes this writeConcern to the server. The server correctly returns an error in this scenario; there is not the same
ambiguity with an explicit writeConcern as there is with an explicit readConcern passed to the first operation in a
transaction. For consistency, however, we specify that an explicit writeConcern passed to an operation in a transaction
provokes a client-side error, the same as for readConcern.</p>
<p>Another alternative is to silently ignore the readConcern and/or writeConcern that the user has explicitly provided to a
particular operation in a transaction. This would be a surprising and undetectable deviation from the user's explicit
intent.</p>
<p>On the other hand, if a user configures the write concern of a client, database, or collection, and then configures the
same option on a transaction, the transaction's configuration overrides the inherited configuration:</p>
<pre><code class="language-python">client = MongoClient("mongodb://localhost/?w=majority")
with client.start_session() as s:
    with s.start_transaction(writeConcern={'w': 1}):
        # Uses w: 1.
        client.db.collection.insert_one(
           {'_id': 1},
           session=s)
</code></pre>
<p>In this case the transaction options express a more immediate user intent than the client options, so it is not
surprising to override the client options.</p>
<h3 id="aggregate-with-write-stage-is-a-read-operation"><a class="header" href="#aggregate-with-write-stage-is-a-read-operation">Aggregate with write stage is a read operation</a></h3>
<p>We intend to migrate away from designs that require drivers to inspect the contents of the aggregation pipeline and
override user read preferences for aggregate with a write stage (e.g. <code>$out</code>, <code>$merge</code>). In general, our specifications
should stop defining different behaviors based on the contents of commands.</p>
<h3 id="a-server-selection-error-is-labeled-unknowntransactioncommitresult"><a class="header" href="#a-server-selection-error-is-labeled-unknowntransactioncommitresult">A server selection error is labeled UnknownTransactionCommitResult</a></h3>
<p>Drivers add the "UnknownTransactionCommitResult" to a server selection error from commitTransaction, even if this is the
first attempt to send commitTransaction. It is true in this case that the driver knows the result: the transaction is
definitely not committed. However, the "UnknownTransactionCommitResult" label properly communicates to the application
that calling commitTransaction again may succeed.</p>
<h2 id="faq"><a class="header" href="#faq">FAQ</a></h2>
<h3 id="what-commands-can-be-run-in-a-transaction"><a class="header" href="#what-commands-can-be-run-in-a-transaction">What commands can be run in a transaction?</a></h3>
<p>The following commands are allowed inside transactions:</p>
<ol>
<li>find</li>
<li>getMore
<ul>
<li>Note that it is not possible to start a transaction with a getMore command, the cursor must have been created
within the transaction in order for the getMore to succeed.</li>
</ul>
</li>
<li>killCursors</li>
<li>insert, including into a non-existing collection that implicitly creates it</li>
<li>update</li>
<li>delete</li>
<li>findAndModify</li>
<li>aggregate (including <code>$lookup</code>)
<ul>
<li>The <code>$out</code> and <code>$merge</code> stages are prohibited.</li>
</ul>
</li>
<li>distinct</li>
<li>geoSearch</li>
<li>create</li>
<li>createIndexes on an empty collection created in the same transaction or on a non-existing collection</li>
<li>bulkWrite</li>
</ol>
<h3 id="why-dont-drivers-automatically-retry-commit-after-a-write-concern-timeout-error"><a class="header" href="#why-dont-drivers-automatically-retry-commit-after-a-write-concern-timeout-error">Why don’t drivers automatically retry commit after a write concern timeout error?</a></h3>
<p>A write concern timeout error indicates that the command succeeded but failed to meet the specified writeConcern within
the given time limit. Attempting to retry would implicitly double the application’s wtimeout value so drivers do not
automatically retry.</p>
<p>Note: this applies only to the driver's internal retry-once behavior. Write concern timeout errors will be labeled with
"UnknownTransactionCommitResult", which signals that higher-level code may retry.</p>
<h3 id="what-happens-when-a-command-object-passed-to-runcommand-already-contains-a-transaction-field-eg-lsid-txnnumber-etc"><a class="header" href="#what-happens-when-a-command-object-passed-to-runcommand-already-contains-a-transaction-field-eg-lsid-txnnumber-etc">What happens when a command object passed to RunCommand already contains a transaction field (eg. lsid, txnNumber, etc...)?</a></h3>
<p>The behavior of running such commands in a transaction are undefined. Applications should not run such commands inside a
transaction.</p>
<h3 id="majority-write-concern-is-used-when-retrying-committransaction"><a class="header" href="#majority-write-concern-is-used-when-retrying-committransaction">Majority write concern is used when retrying commitTransaction</a></h3>
<p>Drivers should apply a majority write concern when retrying commitTransaction to guard against a transaction being
applied twice.</p>
<p>Consider the following scenario:</p>
<ol>
<li>The driver is connected to a replica set where node A is primary.</li>
<li>The driver sends commitTransaction to A with <code>w:1</code>. A commits the transaction but dies before it can reply. This
constitutes a retryable error, which means the driver can retry the commitTransaction command.</li>
<li>Node B is briefly elected.</li>
<li>The driver retries commitTransaction on B with <code>w:1</code>, and B replies with a NoSuchTransaction error code and
TransientTransactionError error label. This implies that the driver may retry the entire transaction.</li>
<li>Node A revives before B has done any <code>w:majority</code> writes and is reëlected as primary.</li>
<li>The driver then retries the entire transaction on A where it commits successfully.</li>
</ol>
<p>The outcome of this scenario is that two complete executions of the transaction operations are permanently committed on
node A.</p>
<p>Drivers can avoid this scenario if they always use a majority write concern when retrying commitTransaction. Applying a
majority write concern to step four in the above scenario would lead to one of the following possible outcomes:</p>
<ul>
<li>Node B replies with failed response, which does not include a TransientTransactionError error label. This does not
constitute a retryable error. Control is returned to the user.</li>
<li>Node B replies with a successful response (e.g. <code>ok:1</code>) indicating that the retried commitTransaction has succeeded
durably and the driver can continue. Control is returned to the user.</li>
<li>Node B replies with a wtimeout error. This does not constitute a retryable error. Control is returned to the user.</li>
<li>Node B replies with a failure response that includes the TransientTransactionError label, which indicates it is safe
to retry the entire transaction. Drivers can trust that a server response will not include both a write concern error
and TransientTransactionError label (see: <a href="https://jira.mongodb.org/browse/SERVER-37179">SERVER-37179</a>).</li>
</ul>
<p>Adding a majority write concern only when retrying commitTransaction provides a good compromise of performance and
durability. Applications can use <code>w:1</code> for the initial transaction attempt for a performance advantage in the happy
path. In the event of retryable error, the driver can upgrade commitTransaction to use <code>w:majority</code> and provide
additional guarantees to the user and avoid any risk of committing the transaction twice. Note that users may still be
vulnerable to rollbacks by using <code>w:1</code> (as with any write operation).</p>
<p>While it's possible that the original write concern may provide greater guarantees than majority (e.g. <code>w:3</code> in a
three-node replica set,
<a href="https://www.mongodb.com/docs/manual/tutorial/configure-replica-set-tag-sets/#tag-sets-and-custom-write-concern-behavior">custom write concern</a>),
drivers are not in a position to make that comparison due to the possibility of hidden members or the opaque nature of
custom write concerns. Excluding the edge case where
<a href="https://www.mongodb.com/docs/manual/reference/replica-configuration/#rsconf.writeConcernMajorityJournalDefault">writeConcernMajorityJournalDefault</a>
has been disabled, drivers can readily trust that a majority write concern is durable, which achieves the primary
objective of avoiding duplicate commits.</p>
<h2 id="changelog-27"><a class="header" href="#changelog-27"><strong>Changelog</strong></a></h2>
<ul>
<li>
<p>2024-05-08: Add bulkWrite to the list of commands allowed in transactions.</p>
</li>
<li>
<p>2024-02-15: Migrated from reStructuredText to Markdown.</p>
</li>
<li>
<p>2023-11-22: Specify that non-transient transaction errors abort the transaction on the server.</p>
</li>
<li>
<p>2022-10-05: Remove spec front matter and reformat changelog</p>
</li>
<li>
<p>2022-01-25: Mention the additional case of a retryable handshake error</p>
</li>
<li>
<p>2022-01-19: Deprecate maxCommitTimeMS in favor of timeoutMS.</p>
</li>
<li>
<p>2021-04-12: Adding in behaviour for load balancer mode.</p>
</li>
<li>
<p>2020-04-07: Clarify that all abortTransaction attempts should unpin the session, even if the command is not executed.</p>
</li>
<li>
<p>2020-04-07: Specify that sessions should be unpinned once a transaction is aborted.</p>
</li>
<li>
<p>2019-10-21: Specify that a commit error can have two error labels</p>
</li>
<li>
<p>2019-07-30: Clarify when the cached recoveryToken should be cleared.</p>
</li>
<li>
<p>2019-06-10: Client-side errors must not change transaction state.</p>
</li>
<li>
<p>2019-06-07: Mention <code>$merge</code> stage for aggregate alongside <code>$out</code></p>
</li>
<li>
<p>2019-05-13: Add support for maxTimeMS on transaction commit, MaxTimeMSExpired errors on commit are labelled
UnknownTransactionCommitResult.</p>
</li>
<li>
<p>2019-02-19: Add support for sharded transaction recoveryToken.</p>
</li>
<li>
<p>2019-02-19: Clarify FAQ entry for not retrying commit on wtimeout</p>
</li>
<li>
<p>2019-01-18: Apply majority write concern when retrying commitTransaction</p>
</li>
<li>
<p>2018-11-13: Add mongos pinning to support sharded transaction.</p>
</li>
<li>
<p>2018-06-18: Explicit readConcern and/or writeConcern are prohibited within transactions, with a client-side error.</p>
</li>
<li>
<p>2018-06-07: The count command is not supported within transactions.</p>
</li>
<li>
<p>2018-06-14: Any retryable writes error raised by commitTransaction must be labelled "UnknownTransactionCommitResult".</p>
</li>
</ul>
<div class="footnote-definition" id="1"><sup class="footnote-definition-label">1</sup>
<p>In 4.2, a new mongos waits for the <em>outcome</em> of the transaction but will never itself cause the transaction to be
committed. If the initial commit on the original mongos itself failed to initiate the transaction's commit sequence,
then a retry attempt on a new mongos will block until the transaction is automatically timed out by the cluster. In
this case, the new mongos will return a transient error indicating that the transaction was aborted.</p>
</div>
<div style="break-before: page; page-break-before: always;"></div><h1 id="convenient-api-for-transactions"><a class="header" href="#convenient-api-for-transactions">Convenient API for Transactions</a></h1>
<ul>
<li>Status: Accepted</li>
<li>Minimum Server Version: 4.0</li>
</ul>
<hr />
<h2 id="abstract-28"><a class="header" href="#abstract-28">Abstract</a></h2>
<p>Reliably committing a transaction in the face of errors can be a complicated endeavor using the MongoDB 4.0 drivers API.
This specification introduces a <code>withTransaction</code> method on the ClientSession object that allows application logic to be
executed within a transaction. This method is capable of retrying either the commit operation or entire transaction as
needed (and when the error permits) to better ensure that the transaction can complete successfully.</p>
<h2 id="meta-28"><a class="header" href="#meta-28">META</a></h2>
<p>The keywords "MUST", "MUST NOT", "REQUIRED", "SHALL", "SHALL NOT", "SHOULD", "SHOULD NOT", "RECOMMENDED", "MAY", and
"OPTIONAL" in this document are to be interpreted as described in <a href="https://www.ietf.org/rfc/rfc2119.txt">RFC 2119</a>.</p>
<h2 id="specification-26"><a class="header" href="#specification-26">Specification</a></h2>
<h3 id="terms-18"><a class="header" href="#terms-18">Terms</a></h3>
<div id="callback">
<p><strong>Callback</strong></p>
<p>A user-defined function that will be passed to the helper method defined in this specification. Depending on the
implementing language, this may be a closure, function pointer, or other callable type.</p>
<p><strong>ClientSession</strong></p>
<p>Driver object representing a client session, as defined in the <a href="transactions-convenient-api/../sessions/driver-sessions.html">Driver Session</a>
specification. The name of this object MAY vary across drivers.</p>
<p><strong>MongoClient</strong></p>
<p>The root object of a driver's API. The name of this object MAY vary across drivers.</p>
<div id="TransactionOptions">
<p><strong>TransactionOptions</strong></p>
<p>Options for <code>ClientSession.startTransaction</code>, as defined in the <a href="transactions-convenient-api/../transactions/transactions.html">Transactions</a>
specification. The structure of these options MAY vary across drivers (e.g. dictionary, typed class).</p>
<h3 id="naming-deviations-4"><a class="header" href="#naming-deviations-4">Naming Deviations</a></h3>
<p>This specification defines the name for a new ClientSession method, <code>withTransaction</code>. Drivers SHOULD use the defined
name but MAY deviate to comply with their existing conventions. For example, a driver may use <code>with_transaction</code> instead
of <code>withTransaction</code>.</p>
<h3 id="callback-semantics"><a class="header" href="#callback-semantics">Callback Semantics</a></h3>
<p>The purpose of the callback is to allow the application to specify some sequence of operations to be executed within the
body of a transaction. In an ideal scenario, <code>withTransaction</code> will start a transaction, execute the callback, and
commit the transaction. In the event of error, the commit or entire transaction may need to be retried and thusly the
callback could be invoked multiple times.</p>
<p>Drivers MUST ensure that the application can access the ClientSession within the callback, since the ClientSession will
be needed to associate operations with the transaction. Drivers may elect an idiomatic approach to satisfy this
requirement (e.g. require the callback to receive the ClientSession as its first argument, expect the callback to access
the ClientSession from its lexical scope). Drivers MAY allow the callback to support additional parameters as needed
(e.g. user data parameter, error output parameter). Drivers MAY allow the callback to return a value to be propagated as
the return value of <code>withTransaction</code>.</p>
<h3 id="clientsession-changes-3"><a class="header" href="#clientsession-changes-3">ClientSession Changes</a></h3>
<p>This specification introduces a <code>withTransaction</code> method on the ClientSession class:</p>
<pre><code class="language-typescript">interface ClientSession {
    withTransaction(function&lt;any(...)&gt; callback,
                    Optional&lt;TransactionOptions&gt; options,
                    ... /* other arguments as needed */): any

    // other existing members of ClientSession
}
</code></pre>
<h4 id="clientsessionwithtransaction"><a class="header" href="#clientsessionwithtransaction">ClientSession.withTransaction</a></h4>
<p>This method is responsible for starting a transaction, invoking a callback, and committing a transaction. The callback
is expected to execute one or more operations with the transaction; however, that is not enforced. The callback is
allowed to execute other operations not associated with the transaction.</p>
<p>Since <code>withTransaction</code> includes logic to retry transactions and commits, drivers MUST apply timeouts per
<a href="transactions-convenient-api/../client-side-operations-timeout/client-side-operations-timeout.html#convenient-transactions-api">Client Side Operations Timeout: Convenient Transactions API</a>.
If <code>timeoutMS</code> is unset for a <code>withTransaction</code> call, drivers MUST enforce a 120-second timeout to limit retry behavior
and safeguard applications from long-running (or infinite) retry loops. Drivers SHOULD use a monotonic clock to
determine elapsed time.</p>
<p>If an UnknownTransactionCommitResult error is encountered for a commit, the driver MUST retry the commit if and only if
the error is not MaxTimeMSExpired and the retry timeout has not been exceeded. Otherwise, the driver MUST NOT retry the
commit and allow <code>withTransaction</code> to propagate the error to its caller.</p>
<p>If a TransientTransactionError is encountered at any point, the entire transaction may be retried. If the retry timeout
has not been exceeded, the driver MUST retry a transaction that fails with an error bearing the
"TransientTransactionError" label. Since retrying the entire transaction will entail invoking the callback again,
drivers MUST document that the callback may be invoked multiple times (i.e. one additional time per retry attempt) and
MUST document the risk of side effects from using a non-idempotent callback. If the retry timeout has been exceeded,
drivers MUST NOT retry the transaction and allow <code>withTransaction</code> to propagate the error to its caller.</p>
<p>If an error bearing neither the UnknownTransactionCommitResult nor the TransientTransactionError label is encountered at
any point, the driver MUST NOT retry and MUST allow <code>withTransaction</code> to propagate the error to its caller.</p>
<p>This method MUST receive a <a href="transactions-convenient-api/transactions-convenient-api.html#callback">callback</a> as its first parameter. An optional
<a href="transactions-convenient-api/transactions-convenient-api.html#TransactionOptions">TransactionOptions</a> MUST be provided as its second parameter (with deviations permitted as
outlined in the <a href="transactions-convenient-api/../crud/crud.html#deviations">CRUD</a> specification). Drivers MAY support other parameters or options as
needed (e.g. user data to pass as a parameter to the callback).</p>
<h5 id="sequence-of-actions"><a class="header" href="#sequence-of-actions">Sequence of Actions</a></h5>
<p>This method should perform the following sequence of actions:</p>
<ol>
<li>Record the current monotonic time, which will be used to enforce the 120-second timeout before later retry attempts.</li>
<li>Invoke <a href="transactions-convenient-api/../transactions/transactions.html#starttransaction">startTransaction</a> on the session. If TransactionOptions
were specified in the call to <code>withTransaction</code>, those MUST be used for <code>startTransaction</code>. Note that
<code>ClientSession.defaultTransactionOptions</code> will be used in the absence of any explicit TransactionOptions.</li>
<li>If <code>startTransaction</code> reported an error, propagate that error to the caller of <code>withTransaction</code> and return
immediately.</li>
<li>Invoke the callback. Drivers MUST ensure that the ClientSession can be accessed within the callback (e.g. pass
ClientSession as the first parameter, rely on lexical scoping). Drivers MAY pass additional parameters as needed
(e.g. user data solicited by withTransaction).</li>
<li>Control returns to <code>withTransaction</code>. Determine the current
<a href="transactions-convenient-api/../transactions/transactions.html#clientsession-changes">state</a> of the ClientSession and whether the callback
reported an error (e.g. thrown exception, error output parameter).</li>
<li>If the callback reported an error:
<ol>
<li>If the ClientSession is in the "starting transaction" or "transaction in progress" state, invoke
<a href="transactions-convenient-api/../transactions/transactions.html#aborttransaction">abortTransaction</a> on the session.</li>
<li>If the callback's error includes a "TransientTransactionError" label and the elapsed time of <code>withTransaction</code> is
less than 120 seconds, jump back to step two.</li>
<li>If the callback's error includes a "UnknownTransactionCommitResult" label, the callback must have manually
committed a transaction, propagate the callback's error to the caller of <code>withTransaction</code> and return
immediately.</li>
<li>Otherwise, propagate the callback's error to the caller of <code>withTransaction</code> and return immediately.</li>
</ol>
</li>
<li>If the ClientSession is in the "no transaction", "transaction aborted", or "transaction committed" state, assume the
callback intentionally aborted or committed the transaction and return immediately.</li>
<li>Invoke <a href="transactions-convenient-api/../transactions/transactions.html#committransaction">commitTransaction</a> on the session.</li>
<li>If <code>commitTransaction</code> reported an error:
<ol>
<li>If the <code>commitTransaction</code> error includes a "UnknownTransactionCommitResult" label and the error is not
MaxTimeMSExpired and the elapsed time of <code>withTransaction</code> is less than 120 seconds, jump back to step eight. We
will trust <code>commitTransaction</code> to apply a majority write concern on retry attempts (see:
<a href="transactions-convenient-api/transactions-convenient-api.html#majority-write-concern-is-used-when-retrying-committransaction">Majority write concern is used when retrying commitTransaction</a>).</li>
<li>If the <code>commitTransaction</code> error includes a "TransientTransactionError" label and the elapsed time of
<code>withTransaction</code> is less than 120 seconds, jump back to step two.</li>
<li>Otherwise, propagate the <code>commitTransaction</code> error to the caller of <code>withTransaction</code> and return immediately.</li>
</ol>
</li>
<li>The transaction was committed successfully. Return immediately.</li>
</ol>
<h5 id="pseudo-code"><a class="header" href="#pseudo-code">Pseudo-code</a></h5>
<p>This method can be expressed by the following pseudo-code:</p>
<pre><code class="language-typescript">withTransaction(callback, options) {
    // Note: drivers SHOULD use a monotonic clock to determine elapsed time
    var startTime = Date.now(); // milliseconds since Unix epoch

    retryTransaction: while (true) {
        this.startTransaction(options); // may throw on error

        try {
            callback(this);
        } catch (error) {
            if (this.transactionState == STARTING ||
                this.transactionState == IN_PROGRESS) {
                this.abortTransaction();
            }

            if (error.hasErrorLabel("TransientTransactionError") &amp;&amp;
                Date.now() - startTime &lt; 120000) {
                continue retryTransaction;
            }

            throw error;
        }

        if (this.transactionState == NO_TXN ||
            this.transactionState == COMMITTED ||
            this.transactionState == ABORTED) {
            return; // Assume callback intentionally ended the transaction
        }

        retryCommit: while (true) {
            try {
                /* We will rely on ClientSession.commitTransaction() to
                 * apply a majority write concern if commitTransaction is
                 * being retried (see: DRIVERS-601) */
                this.commitTransaction();
            } catch (error) {
                /* Note: a maxTimeMS error will have the MaxTimeMSExpired
                 * code (50) and can be reported as a top-level error or
                 * inside writeConcernError, ie:
                 * {ok:0, code: 50, codeName: "MaxTimeMSExpired"}
                 * {ok:1, writeConcernError: {code: 50, codeName: "MaxTimeMSExpired"}}
                 */
                if (!isMaxTimeMSExpiredError(error) &amp;&amp;
                    error.hasErrorLabel("UnknownTransactionCommitResult") &amp;&amp;
                    Date.now() - startTime &lt; 120000) {
                    continue retryCommit;
                }

                if (error.hasErrorLabel("TransientTransactionError") &amp;&amp;
                    Date.now() - startTime &lt; 120000) {
                    continue retryTransaction;
                }

                throw error;
            }
            break; // Commit was successful
        }
        break; // Transaction was successful
    }
}
</code></pre>
<h3 id="clientsession-must-provide-access-to-a-mongoclient"><a class="header" href="#clientsession-must-provide-access-to-a-mongoclient">ClientSession must provide access to a MongoClient</a></h3>
<p>The callback invoked by <code>withTransaction</code> is only guaranteed to receive a ClientSession parameter. Drivers MUST ensure
that it is possible to obtain a MongoClient within the callback in order to execute operations within the transaction.
Per the <a href="transactions-convenient-api/../sessions/driver-sessions.html">Driver Session</a> specification, ClientSessions should already provide access to
a client object.</p>
<h3 id="handling-errors-inside-the-callback"><a class="header" href="#handling-errors-inside-the-callback">Handling errors inside the callback</a></h3>
<p>Drivers MUST document that the callback MUST NOT silently handle command errors without allowing such errors to
propagate. Command errors may abort the transaction on the server, and an attempt to commit the transaction will be
rejected with <code>NoSuchTransaction</code> error.</p>
<p>For example, <code>DuplicateKeyError</code> is an error that aborts a transaction on the server. If the callback catches
<code>DuplicateKeyError</code> and does not re-throw it, the driver will attempt to commit the transaction. The server will reject
the commit attempt with <code>NoSuchTransaction</code> error. This error has the "TransientTransactionError" label and the driver
will retry the commit. This will result in an infinite loop.</p>
<p>Drivers MUST recommend that the callback re-throw command errors if they need to be handled inside the callback. Drivers
SHOULD also recommend using Core Transaction API if a user wants to handle errors in a custom way.</p>
<h2 id="test-plan-21"><a class="header" href="#test-plan-21">Test Plan</a></h2>
<p>See the <a href="transactions-convenient-api/tests/README.html">README</a> for tests.</p>
<h2 id="motivation-for-change-14"><a class="header" href="#motivation-for-change-14">Motivation for Change</a></h2>
<p>Reliably committing a transaction in the face of errors can be a complicated endeavor using the MongoDB 4.0 drivers API.
Providing helper method in the driver to execute a transaction (and retry when possible) will enable our users to make
better use of transactions in their applications.</p>
<h2 id="design-rationale-21"><a class="header" href="#design-rationale-21">Design Rationale</a></h2>
<p>This specification introduces a helper method on the ClientSession object that applications may optionally employ to
execute a user-defined function within a transaction. An application does not need to be modified unless it wants to
take advantage of this helper method.</p>
<h3 id="majority-write-concern-is-used-when-retrying-committransaction-1"><a class="header" href="#majority-write-concern-is-used-when-retrying-committransaction-1">Majority write concern is used when retrying commitTransaction</a></h3>
<p>Drivers should apply a majority write concern when retrying commitTransaction to guard against a transaction being
applied twice. This requirement was originally enforced in the implementation of <code>withTransaction</code>, but will now be
handled by the transaction spec itself in order to benefit applications irrespective of whether they use
<code>withTransaction</code> (see the corresponding section in the
<a href="transactions-convenient-api/../transactions/transactions.html#majority-write-concern-is-used-when-retrying-committransaction">Transactions spec Design Rationale</a>).</p>
<h3 id="the-callback-function-has-a-flexible-signature"><a class="header" href="#the-callback-function-has-a-flexible-signature">The callback function has a flexible signature</a></h3>
<p>An original design considered requiring the callback to accept a ClientSession as its first parameter. That could be
superfluous for languages where the callback might already have access to ClientSession through its lexical scope.
Instead, the spec simply requires that drivers ensure the callback will be able to access the ClientSession.</p>
<p>Similarly, the specification does not concern itself with the return type of the callback function. If drivers allow the
callback to return a value, they may also choose to propagate that value as the return value of withTransaction.</p>
<p>An earlier design also considered using the callback's return value to indicate whether control should break out of
<code>withTransaction</code> (and its retry loop) and return to the application. The design allows this to be accomplished in one
of two ways:</p>
<ul>
<li>The callback aborts the transaction directly and returns to <code>withTransaction</code>, which will then return to its caller.</li>
<li>The callback raises an error without the "TransientTransactionError" label, in which case <code>withTransaction</code> will abort
the transaction and return to its caller.</li>
</ul>
<h3 id="applications-are-responsible-for-passing-clientsession-for-operations-within-a-transaction"><a class="header" href="#applications-are-responsible-for-passing-clientsession-for-operations-within-a-transaction">Applications are responsible for passing ClientSession for operations within a transaction</a></h3>
<p>It remains the responsibility of the application to pass a ClientSession to all operations that should be included in a
transaction. With regard to <code>withTransaction</code>, applications are free to execute any operations within the callback,
irrespective of whether those operations are associated with the transaction.</p>
<h3 id="it-is-assumed-that-the-callback-will-not-start-a-new-transaction-on-the-clientsession"><a class="header" href="#it-is-assumed-that-the-callback-will-not-start-a-new-transaction-on-the-clientsession">It is assumed that the callback will not start a new transaction on the ClientSession</a></h3>
<p>Under normal circumstances, the callback should not commit the transaction nor should it start a new transaction. The
<code>withTransaction</code> method will inspect the ClientSession's transaction state after the callback returns and take the most
sensible course of action; however, it will not detect whether the callback has started a new transaction.</p>
<h3 id="the-callback-function-may-be-executed-multiple-times"><a class="header" href="#the-callback-function-may-be-executed-multiple-times">The callback function may be executed multiple times</a></h3>
<p>The callback may be executed any number of times. Drivers are free to encourage their users to design idempotent
callbacks.</p>
<h3 id="the-commit-is-retried-after-a-write-concern-timeout-ie-wtimeout-error"><a class="header" href="#the-commit-is-retried-after-a-write-concern-timeout-ie-wtimeout-error">The commit is retried after a write concern timeout (i.e. wtimeout) error</a></h3>
<p>Per the Transactions specification, drivers internally retry <code>commitTransaction</code> once if it fails due to a retryable
error (as defined in the <a href="transactions-convenient-api/../retryable-writes/retryable-writes.html#terms">Retryable Writes</a> specification). Beyond that,
applications may manually retry <code>commitTransaction</code> if it fails with any error bearing the
<a href="transactions-convenient-api/../transactions/transactions.html#unknowntransactioncommitresult">UnknownTransactionCommitResult</a> error label. This label
is applied for the the following errors:</p>
<ul>
<li>Server selection failure</li>
<li>Retryable error (as defined in the <a href="transactions-convenient-api/../retryable-writes/retryable-writes.html#terms">Retryable Writes</a> specification)</li>
<li>Write concern failure or timeout (excluding UnsatisfiableWriteConcern and UnknownReplWriteConcern)</li>
<li>MaxTimeMSExpired errors, ie <code>{ok:0, code: 50, codeName: "MaxTimeMSExpired"}</code> and
<code>{ok:1, writeConcernError: {code: 50, codeName: "MaxTimeMSExpired"}}</code>.</li>
</ul>
<p>A previous design for <code>withTransaction</code> retried for all of these errors <em>except</em> for write concern timeouts, so as not
to exceed the user's original intention for <code>wtimeout</code>. The current design of this specification no longer excludes
write concern timeouts, and simply retries <code>commitTransaction</code> within its timeout period for all errors bearing the
"UnknownTransactionCommitResult" label.</p>
<h3 id="the-commit-is-not-retried-after-a-maxtimemsexpired-error"><a class="header" href="#the-commit-is-not-retried-after-a-maxtimemsexpired-error">The commit is not retried after a MaxTimeMSExpired error</a></h3>
<p>This specification intentionally chooses not to retry commit operations after a MaxTimeMSExpired error as doing so would
exceed the user's original intention for <code>maxTimeMS</code>.</p>
<h3 id="the-transaction-and-commit-may-be-retried-any-number-of-times-within-a-timeout-period"><a class="header" href="#the-transaction-and-commit-may-be-retried-any-number-of-times-within-a-timeout-period">The transaction and commit may be retried any number of times within a timeout period</a></h3>
<p>The callback may be executed any number of times. Drivers are free to encourage their users to design idempotent
callbacks.</p>
<p>A previous design had no limits for retrying commits or entire transactions. The callback is always able indicate that
<code>withTransaction</code> should return to its caller (without future retry attempts) by aborting the transaction directly;
however, that puts the onus on avoiding very long (or infinite) retry loops on the application. We expect the most
common cause of retry loops will be due to TransientTransactionErrors caused by write conflicts, as those can occur
regularly in a healthy application, as opposed to UnknownTransactionCommitResult, which would typically be caused by an
election.</p>
<p>In order to avoid blocking the application with infinite retry loops, <code>withTransaction</code> will cease retrying invocations
of the callback or commitTransaction if it has exceeded a fixed timeout period of 120 seconds. This limit is a
non-configurable default and is intentionally twice the value of MongoDB 4.0's default for the
<a href="https://www.mongodb.com/docs/manual/reference/parameters/#param.transactionLifetimeLimitSeconds">transactionLifetimeLimitSeconds</a>
parameter (60 seconds). Applications that desire longer retry periods may call <code>withTransaction</code> additional times as
needed. Applications that desire shorter retry periods should not use this method.</p>
<h2 id="backwards-compatibility-18"><a class="header" href="#backwards-compatibility-18">Backwards Compatibility</a></h2>
<p>The specification introduces a new method on the ClientSession class and does not introduce any backward breaking
changes. Existing programs that do not make use of this new method will continue to compile and run correctly.</p>
<h2 id="reference-implementation-15"><a class="header" href="#reference-implementation-15">Reference Implementation</a></h2>
<p>The C, Java, and Ruby drivers will provide reference implementations. The corresponding tickets for those
implementations may be found via <a href="https://jira.mongodb.org/browse/DRIVERS-556">DRIVERS-556</a>.</p>
<h2 id="security-implication-2"><a class="header" href="#security-implication-2">Security Implication</a></h2>
<p>Applications that use transaction guarantees to enforce security rules will benefit from a less error-prone API. Adding
a helper method to execute a user-defined function within a transaction has few security implications, as it only
provides an implementation of a technique already described in the MongoDB 4.0 documentation
(<a href="https://jira.mongodb.org/browse/DRIVERS-488">DRIVERS-488</a>).</p>
<h2 id="changelog-28"><a class="header" href="#changelog-28">Changelog</a></h2>
<ul>
<li>
<p>2024-09-06: Migrated from reStructuredText to Markdown.</p>
</li>
<li>
<p>2023-11-22: Document error handling inside the callback.</p>
</li>
<li>
<p>2022-10-05: Remove spec front matter and reformat changelog.</p>
</li>
<li>
<p>2022-01-19: withTransaction applies timeouts per the client-side operations timeout specification.</p>
</li>
<li>
<p>2019-04-24: withTransaction does not retry when commit fails with MaxTimeMSExpired.</p>
</li>
<li>
<p>2018-02-13: withTransaction should retry commits after a wtimeout</p>
</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="enumerating-databases"><a class="header" href="#enumerating-databases">Enumerating Databases</a></h1>
<ul>
<li>Status: Accepted</li>
<li>Minimum Server Version: 3.6</li>
</ul>
<hr />
<h2 id="abstract-29"><a class="header" href="#abstract-29">Abstract</a></h2>
<p>A driver can provide functionality to enumerate all databases on a server. This specification defines several methods
for enumerating databases.</p>
<h2 id="meta-29"><a class="header" href="#meta-29">META</a></h2>
<p>The keywords "MUST", "MUST NOT", "REQUIRED", "SHALL", "SHALL NOT", "SHOULD", "SHOULD NOT", "RECOMMENDED", "MAY", and
"OPTIONAL" in this document are to be interpreted as described in <a href="https://www.ietf.org/rfc/rfc2119.txt">RFC 2119</a>.</p>
<h2 id="specification-27"><a class="header" href="#specification-27">Specification</a></h2>
<h3 id="terms-19"><a class="header" href="#terms-19">Terms</a></h3>
<p><strong>MongoClient</strong></p>
<p>Driver object representing a connection to MongoDB. This is the root object of a driver's API and MAY be named
differently in some drivers.</p>
<p><strong>MongoDatabase</strong></p>
<p>Driver object representing a database and the operations that can be performed on it. MAY be named differently in some
drivers.</p>
<p><strong>Iterable</strong></p>
<p>An object or data structure that is a sequence of elements that can be iterated over. This spec is flexible on what that
means as different drivers will have different requirements, types, and idioms.</p>
<p><strong>Document</strong></p>
<p>An object or data structure used by the driver to represent a BSON document. This spec is flexible on what that means as
different drivers will have different requirements, types, and idioms.</p>
<h3 id="naming-deviations-5"><a class="header" href="#naming-deviations-5">Naming Deviations</a></h3>
<p>This specification defines names for methods. To the extent possible, drivers SHOULD use the defined names. However,
where a driver or language's naming conventions would conflict, drivers SHOULD honor their existing conventions. For
example, a driver may use <code>list_databases</code> instead of <code>listDatabases</code>.</p>
<h3 id="filters"><a class="header" href="#filters">Filters</a></h3>
<p>Drivers SHOULD support the <code>filter</code> option when implementing the
<a href="https://www.mongodb.com/docs/manual/reference/command/listDatabases/">listDatabases</a> database command. The <code>filter</code>
option is a query predicate that determines which databases are listed in the command result. You can specify a
condition on any of the database fields returned in the command output:</p>
<ul>
<li><code>name</code></li>
<li><code>sizeOnDisk</code></li>
<li><code>empty</code></li>
<li><code>shards</code></li>
</ul>
<p>For example, to list only databases whose names begin with "foo":</p>
<pre><code class="language-javascript">db.adminCommand({listDatabases: 1, filter: {name: /^foo/}});
</code></pre>
<h3 id="authorizeddatabases"><a class="header" href="#authorizeddatabases">AuthorizedDatabases</a></h3>
<p>MongoDB 4.0.5 added an <code>authorizedDatabases</code> boolean option to the
<a href="https://www.mongodb.com/docs/manual/reference/command/listDatabases/">listDatabases</a> database command, which can be
used to limit the command result to only include databases the user is authorized to use. Drivers SHOULD support the new
<code>authorizedDatabases</code> option when implementing the
<a href="https://www.mongodb.com/docs/manual/reference/command/listDatabases/">listDatabases</a> database command.</p>
<p>The possible values for <code>authorizedDatabases</code> are:</p>
<ul>
<li>unspecified (missing entirely from the command document sent to the server)</li>
<li><code>false</code></li>
<li><code>true</code></li>
</ul>
<p>See the server's <a href="https://www.mongodb.com/docs/manual/reference/command/listDatabases/">listDatabases</a> documentation for
an explanation of what each value means.</p>
<h3 id="comment"><a class="header" href="#comment">Comment</a></h3>
<p>MongoDB 4.4 introduced a <code>comment</code> option to the <code>listDatabases</code> command. This option enables users to specify a comment
as an arbitrary BSON type to help trace the operation through the database profiler, currentOp and logs. The default is
to not send a value. If a comment is provided on pre-4.4 servers, the comment should still be attached and the driver
should rely on the server to provide an error to the user.</p>
<pre><code class="language-javascript">db.getSiblingDB("admin").runCommand({listDatabases: 1, comment: "hi there"})
</code></pre>
<h3 id="driver-methods"><a class="header" href="#driver-methods">Driver Methods</a></h3>
<p>If a driver already has a method to perform one of the listed tasks, there is no need to change it. Do not break
backwards compatibility when adding new methods.</p>
<p>All methods SHOULD be implemented on the MongoClient object.</p>
<p>All methods MUST apply timeouts per the
<a href="enumerate-databases/../client-side-operations-timeout/client-side-operations-timeout.html">Client Side Operations Timeout</a> specification.</p>
<h4 id="enumerating-full-database-information"><a class="header" href="#enumerating-full-database-information">Enumerating Full Database Information</a></h4>
<p>The <a href="https://www.mongodb.com/docs/manual/reference/command/listDatabases/">listDatabases</a> database command returns an
array of documents, each of which contains information about a database on the MongoDB server. Additionally, the command
reports the aggregate sum of all database sizes (in bytes). Consider the following example:</p>
<pre><code class="language-javascript">db.getSiblingDB("admin").runCommand({listDatabases:1})
    {
        "databases" : [
            {
                "name" : "admin",
                "sizeOnDisk" : 83886080,
                "empty" : false
            },
            {
                "name" : "local",
                "sizeOnDisk" : 83886080,
                "empty" : false
            }
        ],
        "totalSize" : 167772160,
        "ok" : 1
    }
</code></pre>
<p>Drivers SHOULD implement a MongoClient method that returns an Iterable of database specifications (e.g. model object,
document type), each of which correspond to an element in the databases array of the <code>listDatabases</code> command result.
This method SHOULD be named <code>listDatabases</code>.</p>
<p>Drivers MAY report <code>totalSize</code> (e.g. through an additional output variable on the <code>listDatabases</code> method), but this is
not necessary.</p>
<p>Drivers SHOULD support the <code>filter</code>, <code>authorizedDatabases</code> and <code>comment</code> options when implementing this method.</p>
<h4 id="enumerating-database-names"><a class="header" href="#enumerating-database-names">Enumerating Database Names</a></h4>
<p>MongoDB 3.6 introduced a <code>nameOnly</code> boolean option to the <code>listDatabases</code> database command, which limits the command
result to only include database names. Consider the following example:</p>
<pre><code>&gt; db.getSiblingDB("admin").runCommand({listDatabases:1,nameOnly:true})
{
    "databases" : [
        { "name" : "admin" },
        { "name" : "local" }
    ],
    "ok" : 1
}
</code></pre>
<p>Drivers MAY implement a MongoClient method that returns an Iterable of strings, each of which corresponds to a name in
the databases array of the <code>listDatabases</code> command result. This method SHOULD be named <code>listDatabaseNames</code>.</p>
<p>Drivers SHOULD support the <code>filter</code>, <code>authorizedDatabases</code> and <code>comment</code> options when implementing this method.</p>
<h4 id="enumerating-mongodatabase-objects"><a class="header" href="#enumerating-mongodatabase-objects">Enumerating MongoDatabase Objects</a></h4>
<p>Drivers MAY implement a MongoClient method that returns an Iterable of MongoDatabase types, each of which corresponds to
a name in the databases array of the <code>listDatabases</code> command result. This method MAY be named <code>listMongoDatabases</code>.</p>
<p>Any MongoDatabase objects returned by this method SHOULD inherit the same MongoClient options that would otherwise be
inherited by selecting an individual MongoDatabase through MongoClient (e.g. read preference, write concern).</p>
<p>Drivers SHOULD specify the <code>nameOnly</code> option when executing the <code>listDatabases</code> command for this method.</p>
<p>Drivers SHOULD support the <code>filter</code>, <code>authorizedDatabases</code> and <code>comment</code> options when implementing this method.</p>
<h3 id="replica-sets-1"><a class="header" href="#replica-sets-1">Replica Sets</a></h3>
<p>The <code>listDatabases</code> command may be run on a secondary node. Drivers MUST run the <code>listDatabases</code> command only on the
primary node in replica set topology, unless directly connected to a secondary node in Single topology.</p>
<h2 id="test-plan-22"><a class="header" href="#test-plan-22">Test Plan</a></h2>
<h3 id="test-environments"><a class="header" href="#test-environments">Test Environments</a></h3>
<p>The test plan should be executed against the following servers:</p>
<ul>
<li>Standalone</li>
<li>Replica set primary</li>
<li>Replica set secondary</li>
<li>Sharding router (i.e. mongos)</li>
</ul>
<h3 id="test-cases"><a class="header" href="#test-cases">Test Cases</a></h3>
<p>The following scenarios should be run for each test environment:</p>
<ul>
<li>Execute the method to enumerate full database information (e.g. <code>listDatabases()</code>)
<ul>
<li>Verify that the method returns an Iterable of Document types</li>
<li>Verify that all databases on the server are present in the result set</li>
<li>Verify that the result set does not contain duplicates</li>
</ul>
</li>
<li>Execute the method to enumerate database names (e.g. <code>listDatabaseNames()</code>)
<ul>
<li>Verify that the method returns an Iterable of strings</li>
<li>Verify that all databases on the server are present in the result set</li>
<li>Verify that the result set does not contain duplicates</li>
</ul>
</li>
<li>Execute the method to enumerate MongoDatabase objects (e.g. <code>listMongoDatabases()</code>)
<ul>
<li>Verify that the method returns an Iterable of MongoDatabase objects</li>
<li>Verify that all databases on the server are present in the result set</li>
<li>Verify that the result set does not contain duplicates</li>
</ul>
</li>
</ul>
<h2 id="motivation-for-change-15"><a class="header" href="#motivation-for-change-15">Motivation for Change</a></h2>
<p>Although most drivers provide a <code>listDatabases</code> command helper in their API, there was previously no spec for a database
enumeration. MongoDB 3.6 introduced a <code>nameOnly</code> option to the <code>listDatabases</code> database command. The driver API should
to be expanded to support this option.</p>
<h2 id="design-rationale-22"><a class="header" href="#design-rationale-22">Design Rationale</a></h2>
<p>The design of this specification is inspired by the
<a href="enumerate-databases/../enumerate-collections/enumerate-collections.html">Collection Enumeration</a> and
<a href="enumerate-databases/../index-management/index-management.html">Index Management</a> specifications. Since most drivers already implement a
<code>listDatabases</code> command helper in some fashion, this spec is flexible when it comes to existing APIs.</p>
<h2 id="backwards-compatibility-19"><a class="header" href="#backwards-compatibility-19">Backwards Compatibility</a></h2>
<p>There should be no backwards compatibility concerns. This specification merely deals with how to enumerate databases in
future versions of MongoDB and allows flexibility for existing driver APIs.</p>
<h2 id="reference-implementation-16"><a class="header" href="#reference-implementation-16">Reference Implementation</a></h2>
<p>TBD</p>
<h2 id="q--a-4"><a class="header" href="#q--a-4">Q &amp; A</a></h2>
<h3 id="why-is-reporting-the-total-size-of-all-databases-optional"><a class="header" href="#why-is-reporting-the-total-size-of-all-databases-optional">Why is reporting the total size of all databases optional?</a></h3>
<p>Although the <code>listDatabases</code> command provides two results, a <code>databases</code> array and <code>totalSize</code> integer, the array of
database information documents is the primary result. Returning a tuple or composite result type from a <code>listDatabases</code>
driver method would complicate the general use case, as opposed to an optional output argument (if supported by the
language). Furthermore, the <code>totalSize</code> value can be calculated client-side by summing all <code>sizeOnDisk</code> fields in the
array of database information documents.</p>
<h2 id="changelog-29"><a class="header" href="#changelog-29">Changelog</a></h2>
<ul>
<li>
<p>2024-07-26: Migrated from reStructuredText to Markdown. Removed note that applied to pre-3.6 servers.</p>
</li>
<li>
<p>2022-10-05: Remove spec front matter and reformat changelog. Also reverts the minimum server version to 3.6, which is
where <code>nameOnly</code> and <code>filter</code> options were first introduced for <code>listDatabases</code>.</p>
</li>
<li>
<p>2022-08-17: Clarify the behavior of comment on pre-4.4 servers.</p>
</li>
<li>
<p>2022-02-01: Support comment option in listDatabases command</p>
</li>
<li>
<p>2022-01-19: Require that timeouts be applied per the client-side operations timeout spec.</p>
</li>
<li>
<p>2019-11-20: Support authorizedDatabases option in listDatabases command</p>
</li>
<li>
<p>2017-10-30: Support filter option in listDatabases command</p>
</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="enumerating-collections"><a class="header" href="#enumerating-collections">Enumerating Collections</a></h1>
<ul>
<li>Status: Accepted</li>
<li>Minimum Server Version: 1.8</li>
</ul>
<hr />
<h2 id="abstract-30"><a class="header" href="#abstract-30">Abstract</a></h2>
<p>A driver can contain a feature to enumerate all collections belonging to a database. This specification defines how
collections should be enumerated.</p>
<h2 id="meta-30"><a class="header" href="#meta-30">META</a></h2>
<p>The keywords "MUST", "MUST NOT", "REQUIRED", "SHALL", "SHALL NOT", "SHOULD", "SHOULD NOT", "RECOMMENDED", "MAY", and
"OPTIONAL" in this document are to be interpreted as described in <a href="https://www.ietf.org/rfc/rfc2119.txt">RFC 2119</a>.</p>
<h2 id="specification-28"><a class="header" href="#specification-28">Specification</a></h2>
<h3 id="terms-20"><a class="header" href="#terms-20">Terms</a></h3>
<p><strong>MongoClient</strong></p>
<p>Driver object representing a connection to MongoDB. This is the root object of a driver's API and MAY be named
differently in some drivers.</p>
<p><strong>Iterable</strong></p>
<p>An object or data structure that is a sequence of elements that can be iterated over. This spec is flexible on what that
means as different drivers will have different requirements, types, and idioms.</p>
<h3 id="listcollections-database-command"><a class="header" href="#listcollections-database-command">listCollections Database Command</a></h3>
<p>The <code>listCollections</code> command returns a cursor:</p>
<pre><code class="language-javascript">db.runCommand( { listCollections: 1 } );
</code></pre>
<p>The command also accepts options.</p>
<p>The <code>filter</code> option, which acts like a query against the returned collection documents. You can i.e. use the following
to only list the collections beginning with <code>test</code>:</p>
<pre><code class="language-javascript">db.runCommand( { listCollections: 1, filter: { name: /^test/ } } );
</code></pre>
<p>Or to find all capped collections:</p>
<pre><code class="language-javascript">db.runCommand( { listCollections: 1, filter: { 'options.capped': true } } );
</code></pre>
<p>The <code>cursor.batchSize</code> option, which allows you to set how many initial collections should be returned as part of the
cursor specification document that comes back from the server. This first batch is part of the returned structure in the
<code>firstBatch</code> key (see more about return types further on).</p>
<p>The command returns a cursor definition structure:</p>
<pre><code class="language-javascript">{
    cursor: {
        id: &lt;long&gt;,
        ns: &lt;string&gt;,
        firstBatch: [&lt;object&gt;, &lt;object&gt;, ...]
    },
    ok: 1
}
</code></pre>
<p>With the <code>cursor.id</code> and <code>cursor.ns</code> fields you can retrieve further collection information structures.</p>
<p>The command also returns the field <code>ok</code> to signal whether the command was executed successfully.</p>
<p>This will return the first 25 collection descriptions as part of the returned document:</p>
<pre><code class="language-javascript">db.runCommand( { listCollections: 1, cursor : { batchSize: 25 } } );
</code></pre>
<p>MongoDB 4.4 introduced a <code>comment</code> option to the <code>listCollections</code> database command. This option enables users to
specify a comment as an arbitrary BSON type to help trace the operation through the database profiler, currentOp and
logs. The default is to not send a value. If a comment is provided on pre-4.4 servers, the comment should still be
attached and the driver should rely on the server to provide an error to the user.</p>
<p>Example of usage of the comment option:</p>
<pre><code class="language-javascript">db.runCommand({"listCollections": 1, "comment": "hi there"})
</code></pre>
<p>Any comment set on a <code>listCollections</code> command is inherited by any subsequent <code>getMore</code> commands run on the same
<code>cursor.id</code> returned from the <code>listCollections</code> command. Therefore, drivers MUST NOT attach the comment to subsequent
getMore commands on a cursor.</p>
<h4 id="return-types"><a class="header" href="#return-types">Return types</a></h4>
<p>The <code>listCollections</code> command returns a cursor description. The format that is returned is the same as for any other
command cursor:</p>
<pre><code class="language-javascript">{
    cursor: {
        id: &lt;long&gt;,
        ns: &lt;string&gt;,
        firstBatch: [&lt;object&gt;, &lt;object&gt;, ...]
    },
    ok: 1
}
</code></pre>
<p>The number of objects in the <code>firstBatch</code> field depends on the <code>cursor.batchSize</code> option.</p>
<p>Drivers MAY expose methods to return collection names as an array. If your driver already has such a method, its return
type MUST NOT be changed in order to prevent breaking backwards compatibility.</p>
<p>Drivers SHOULD expose (a) method(s) to return collection information through a cursor, where the information for each
collection is represented by a single document.</p>
<h3 id="driver-methods-1"><a class="header" href="#driver-methods-1">Driver methods</a></h3>
<p>Drivers SHOULD use the method name <code>listCollections</code> for a method that returns all collections with a cursor return
type. Drivers MAY use an idiomatic variant that fits the language the driver is for.</p>
<p>If a driver already has a method to perform one of the listed tasks, there is no need to change it. Do not break
backwards compatibility when adding new methods.</p>
<p>All methods:</p>
<ul>
<li>SHOULD be on the database object.</li>
<li>MUST allow a filter to be passed to include only requested collections.</li>
<li>MAY allow the <code>cursor.batchSize</code> option to be passed.</li>
<li>SHOULD allow the <code>comment</code> option to be passed.</li>
<li>MUST apply timeouts per the
<a href="enumerate-collections/../client-side-operations-timeout/client-side-operations-timeout.html">Client Side Operations Timeout</a> specification.</li>
</ul>
<p>All methods that return cursors MUST support the timeout options documented in
<a href="enumerate-collections/../client-side-operations-timeout/client-side-operations-timeout.html#cursors">Client Side Operations Timeout: Cursors</a>.</p>
<h4 id="getting-collection-names"><a class="header" href="#getting-collection-names">Getting Collection Names</a></h4>
<p>Drivers MAY implement a MongoClient method that returns an Iterable of strings, where each string corresponds to a
collection name. This method SHOULD be named <code>listCollectionNames</code>.</p>
<p>MongoDB 4.0 introduced a <code>nameOnly</code> boolean option to the <code>listCollections</code> database command, which limits the command
result to only include collection names. NOTE: <code>nameOnly</code> is applied before any filter is applied.</p>
<p>Example return:</p>
<pre><code class="language-javascript">[
    "me",
    "oplog.rs",
    "replset.minvalid",
    "startup_log",
    "system.indexes",
    "system.replset"
]
</code></pre>
<p>Server version between 2.7.6 (inclusive) and 4.0 (exclusive) do not support the <code>nameOnly</code> option for the
<code>listCollections</code> command and will ignore it without raising an error. Therefore, drivers MUST always specify the
<code>nameOnly</code> option when they only intend to access collection names from the <code>listCollections</code> command result, except
drivers MUST NOT set <code>nameOnly</code> if a filter specifies any keys other than <code>name</code>.</p>
<p>MongoDB 4.0 also added an <code>authorizedCollections</code> boolean option to the <code>listCollections</code> command, which can be used to
limit the command result to only include collections the user is authorized to use. Drivers MAY allow users to set the
<code>authorizedCollections</code> option on the <code>listCollectionNames</code> method.</p>
<h4 id="getting-full-collection-information"><a class="header" href="#getting-full-collection-information">Getting Full Collection Information</a></h4>
<p>Drivers MAY implement a method to return the full <code>name/options</code> pairs that are returned from both <code>listCollections</code> (in
the <code>res.cursor.firstBatch</code> field, and subsequent retrieved documents through getmore on the cursor constructed from
<code>res.cursor.ns</code> and <code>res.cursor.id</code>), and the query result for <code>system.namespaces</code>.</p>
<p>The returned result for each variant MUST be equivalent, and each collection that is returned MUST use the field names
<code>name</code> and <code>options</code>.</p>
<p>In MongoDB 4.4, the <code>ns</code> field was removed from the index specifications, so the index specification included in the
<code>idIndex</code> field of the collection information will no longer contain an <code>ns</code> field.</p>
<ul>
<li>For drivers that report those index specifications in the form of documents or dictionaries, no special handling is
necessary, but any documentation of the contents of the documents/dictionaries MUST indicate that the <code>ns</code> field will
no longer be present in MongoDB 4.4+. If the contents of the documents/dictionaries are undocumented, then no special
mention of the <code>ns</code> field is necessary.</li>
<li>For drivers that report those index specifications in the form of statically defined models, the driver MUST manually
populate the <code>ns</code> field of the models with the appropriate namespace if the server does not report it in the
<code>listCollections</code> command response. The <code>ns</code> field is not required to be a part of the models, however.</li>
</ul>
<p>Example return (a cursor which returns documents, not a simple array):</p>
<pre><code class="language-javascript">{
    "name" : "me", "options" : { "flags" : 1 }
},
{
    "name" : "oplog.rs", "options" : { "capped" : true, "size" : 10485760, "autoIndexId" : false }
},
{
    "name" : "replset.minvalid", "options" : { "flags" : 1 }
},
{
    "name" : "startup_log", "options" : { "capped" : true, "size" : 10485760 }
},
{
    "name" : "system.indexes", "options" : { }
},
{
    "name" : "system.replset", "options" : { "flags" : 1 }
}
</code></pre>
<p>When returning this information as a cursor, a driver SHOULD use the method name <code>listCollections</code> or an idiomatic
variant.</p>
<p>Drivers MAY allow the <code>nameOnly</code> and <code>authorizedCollections</code> options to be passed when executing the <code>listCollections</code>
command for this method.</p>
<h4 id="returning-a-list-of-collection-objects"><a class="header" href="#returning-a-list-of-collection-objects">Returning a List of Collection Objects</a></h4>
<p>Drivers MAY implement a method that returns a collection object for each returned collection, if the driver has such a
concept. This method MAY be named <code>listMongoCollections</code>.</p>
<p>Example return (in PHP, but abbreviated):</p>
<pre><code class="language-javascript">array(6) {
  [0] =&gt; class MongoCollection#6 { }
  [1] =&gt; class MongoCollection#7 { }
  [2] =&gt; class MongoCollection#8 { }
  [3] =&gt; class MongoCollection#9 { }
  [4] =&gt; class MongoCollection#10 { }
  [5] =&gt; class MongoCollection#11 { }
}
</code></pre>
<p>Drivers MUST specify true for the <code>nameOnly</code> option when executing the <code>listCollections</code> command for this method, except
drivers MUST NOT set <code>nameOnly</code> if a filter specifies any keys other than <code>name</code>.</p>
<p>Drivers MAY allow the <code>authorizedCollections</code> option to be passed when executing the <code>listCollections</code> command for this
method</p>
<h4 id="replica-sets-2"><a class="header" href="#replica-sets-2">Replica Sets</a></h4>
<ul>
<li><code>listCollections</code> can be run on a secondary node.</li>
<li>Querying <code>system.indexes</code> on a secondary node requires secondaryOk to be set.</li>
<li>Drivers MUST run <code>listCollections</code> on the primary node when in a replica set topology, unless directly connected to a
secondary node in Single topology.</li>
</ul>
<h2 id="test-plan-23"><a class="header" href="#test-plan-23">Test Plan</a></h2>
<h3 id="configurations"><a class="header" href="#configurations">Configurations</a></h3>
<ul>
<li>standalone node</li>
<li>replica set primary node</li>
<li>replica set secondary node</li>
<li>mongos node</li>
</ul>
<h3 id="preparation"><a class="header" href="#preparation">Preparation</a></h3>
<p>For each of the configurations:</p>
<ul>
<li>Create a (new) database</li>
<li>Create a collection and a capped collection</li>
<li>Create an index on each of the two collections</li>
<li>Insert at least one document in each of the two collections</li>
</ul>
<h3 id="tests-1"><a class="header" href="#tests-1">Tests</a></h3>
<ul>
<li>Run the driver's method that returns a list of collection names (e.g. <code>listCollectionNames()</code>):
<ul>
<li>verify that <em>all</em> collection names are represented in the result</li>
<li>verify that there are no duplicate collection names</li>
<li>there are no returned collections that do not exist</li>
<li>there are no returned collections containing an '$'</li>
</ul>
</li>
<li>Run the driver's method that returns a list of collection names (e.g. <code>listCollectionNames()</code>), pass a filter of
<code>{ 'options.capped': true }</code>, and:
<ul>
<li>verify that <em>only</em> names of capped collections are represented in the result</li>
<li>verify that there are no duplicate collection names</li>
<li>there are no returned collections that do not exist</li>
<li>there are no returned collections containing an '$'</li>
</ul>
</li>
</ul>
<h2 id="backwards-compatibility-20"><a class="header" href="#backwards-compatibility-20">Backwards Compatibility</a></h2>
<p>There should be no backwards compatibility concerns. This SPEC merely deals with how to enumerate collections in future
versions of MongoDB.</p>
<h2 id="reference-implementation-17"><a class="header" href="#reference-implementation-17">Reference Implementation</a></h2>
<p>The shell implements the first algorithm for falling back if the <code>listCollections</code> command does not exist
(<a href="https://github.com/mongodb/mongo/blob/f32ba54f971c045fb589fe4c3a37da77dc486cee/src/mongo/shell/db.js#L550">https://github.com/mongodb/mongo/blob/f32ba54f971c045fb589fe4c3a37da77dc486cee/src/mongo/shell/db.js#L550</a>).</p>
<h2 id="changelog-30"><a class="header" href="#changelog-30">Changelog</a></h2>
<ul>
<li>
<p>2024-07-26: Migrated from reStructuredText to Markdown. Drop description of behavior for MongoDB 2.x servers.</p>
</li>
<li>
<p>2022-10-05: Remove spec front matter and reformat changelog.</p>
</li>
<li>
<p>2022-09-15: Clarify the behavior of <code>comment</code> on pre-4.4 servers.</p>
</li>
<li>
<p>2022-02-01: Add <code>comment</code> option to <code>listCollections</code> command.</p>
</li>
<li>
<p>2022-01-20: Require that timeouts be applied per the client-side operations timeout spec.</p>
</li>
<li>
<p>2021-12-17: Support <code>authorizedCollections</code> option in <code>listCollections</code> command.</p>
</li>
<li>
<p>2021-04-22: Update to use secondaryOk.</p>
</li>
<li>
<p>2020-03-18: MongoDB 4.4 no longer includes <code>ns</code> field in <code>idIndex</code> field for <code>listCollections</code> responses.</p>
</li>
<li>
<p>2019-03-21: The method that returns a list of collection names should be named <code>listCollectionNames</code>. The method that
returns a list of collection objects may be named <code>listMongoCollections</code>.</p>
</li>
<li>
<p>2018-07-03: Clarify that <code>nameOnly</code> must not be used with filters other than <code>name</code>.</p>
</li>
<li>
<p>2018-05-18: Support <code>nameOnly</code> option in <code>listCollections</code> command.</p>
</li>
<li>
<p>2017-09-27: Clarify reason for filtering collection names containing '$'.</p>
</li>
<li>
<p>2015-01-14: Clarify trimming of database name. Put preferred method name for listing collections with a cursor as
return value.</p>
</li>
<li>
<p>2014-12-18: Update with the server change to return a cursor for <code>listCollections</code>.</p>
</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="index-management"><a class="header" href="#index-management">Index Management</a></h1>
<ul>
<li>Status: Accepted</li>
<li>Minimum Server Version: 3.6</li>
</ul>
<hr />
<h2 id="specification-29"><a class="header" href="#specification-29">Specification</a></h2>
<p>The index management spec defines a set of behaviour in the drivers for creating, removing and viewing indexes in a
collection. It defines implementation details when required but also provides flexibility in the driver in that one or
both of 2 unique APIs can be chosen to be implemented.</p>
<h3 id="definitions-5"><a class="header" href="#definitions-5">Definitions</a></h3>
<h4 id="meta-31"><a class="header" href="#meta-31">META</a></h4>
<p>The keywords "MUST", "MUST NOT", "REQUIRED", "SHALL", "SHALL NOT", "SHOULD", "SHOULD NOT", "RECOMMENDED", "MAY", and
"OPTIONAL" in this document are to be interpreted as described in <a href="https://www.ietf.org/rfc/rfc2119.txt">RFC 2119</a>.</p>
<h4 id="terms-21"><a class="header" href="#terms-21">Terms</a></h4>
<p><strong>Collection</strong></p>
<p>The term <code>Collection</code> references the object in the driver that represents a collection on the server.</p>
<p><strong>Cursor</strong></p>
<p>The term <code>Cursor</code> references the driver's cursor object.</p>
<p><strong>Iterable</strong></p>
<p>The term <code>Iterable</code> is to describe an object that is a sequence of elements that can be iterated over.</p>
<p><strong>Document</strong></p>
<p>The term <code>Document</code> refers to the implementation in the driver's language of a BSON document.</p>
<p><strong>Result</strong></p>
<p>The term <code>Result</code> references the object that is normally returned by the driver as the result of a command execution. In
the case of situations where an actual command is not executed, rather an insert or a query, an object that adheres to
the same interface must be returned with as much information as possible that could be obtained from the operation.</p>
<h3 id="guidance"><a class="header" href="#guidance">Guidance</a></h3>
<h4 id="documentation-2"><a class="header" href="#documentation-2">Documentation</a></h4>
<p>The documentation provided in code below is merely for driver authors and SHOULD NOT be taken as required documentation
for the driver.</p>
<h4 id="operations-1"><a class="header" href="#operations-1">Operations</a></h4>
<p>All drivers MUST offer at least one of the sections of operations, the Standard API or the Index View API. The driver
MAY elect to have both. Implementation details are noted in the comments when a specific implementation is required.
Within each API, all methods are REQUIRED unless noted otherwise in the comments.</p>
<h4 id="operation-parameters"><a class="header" href="#operation-parameters">Operation Parameters</a></h4>
<p>All drivers MUST include the specified parameters in each operation. This does not preclude a driver from offering more.
A driver SHOULD NOT require a user to specify the options parameter if they wish to use the server defaults.</p>
<p>As of 3.4 (see <a href="https://jira.mongodb.org/browse/SERVER-769">https://jira.mongodb.org/browse/SERVER-769</a>) the server validates options passed to the <code>createIndexes</code>
command -- drivers should be aware when testing that passing arbitrary options when the driver does not validate them
could fail on the server.</p>
<h4 id="deviations-2"><a class="header" href="#deviations-2">Deviations</a></h4>
<p>A non-exhaustive list of acceptable deviations are as follows:</p>
<ul>
<li>Using named parameters in place of an options hash or class. For instance,
<code>collection.create_index({x: 1}, commit_quorum="majority")</code>.</li>
<li>When using an <code>Options</code> class, if multiple <code>Options</code> classes are structurally equatable, it is permissible to
consolidate them into one with a clear name. For instance, it would be permissible to use the name
<code>CreateIndexOptions</code> as the options for <code>createIndex</code> and <code>createIndexes</code>.</li>
</ul>
<h4 id="naming-1"><a class="header" href="#naming-1">Naming</a></h4>
<p>All drivers MUST name operations and parameters as defined in the following sections. Exceptions to this rule are noted
in the appropriate section. Class and interface names may vary according to the driver and language best practices.</p>
<h4 id="naming-deviations-6"><a class="header" href="#naming-deviations-6">Naming Deviations</a></h4>
<p>When deviating from a defined name, an author should consider if the altered name is recognizable and discoverable to
the user of another driver.</p>
<p>A non-exhaustive list of acceptable naming deviations are as follows:</p>
<ul>
<li>Using "maxTimeMS" as an example, .NET would use "MaxTime" where it's type is a TimeSpan structure that includes units.
However, calling it "MaximumTime" would not be acceptable.</li>
<li>Using "CreateIndexOptions" as an example, Javascript wouldn't need to name it while other drivers might prefer to call
it "CreateIndexArgs" or "CreateIndexParams".</li>
<li>Acceptable naming deviations should fall within the basic style of the language. For example, <code>createIndex</code> would be a
required name in Java, where camel-case method names are used, but in Ruby <code>create_index</code> would be acceptable.</li>
</ul>
<h4 id="index-name-generation"><a class="header" href="#index-name-generation">Index Name Generation</a></h4>
<p>When the client generates a name for an index based on the keys, the driver MUST generate the name as key-direction
pairs, separated by underscores. For example, the key <code>{ name: 1, dob: -1 }</code> MUST generate an index name of
<code>name_1_dob_-1</code>.</p>
<p>Note there is one exception to this rule on the <code>_id</code> field. The server uses an index name with no direction, <code>_id_</code>,
which cannot be overridden.</p>
<h4 id="timeouts-1"><a class="header" href="#timeouts-1">Timeouts</a></h4>
<p>Drivers MUST enforce timeouts for all operations per the
<a href="index-management/../client-side-operations-timeout/client-side-operations-timeout.html">Client Side Operations Timeout</a> specification. All
operations that return cursors MUST support the timeout options documented in the
<a href="index-management/../client-side-operations-timeout/client-side-operations-timeout.html#cursors">Cursors</a> section of that specification.</p>
<h3 id="standard-api"><a class="header" href="#standard-api">Standard API</a></h3>
<pre><code class="language-typescript">interface Collection {

  /**
   * This is a convenience method for creating a single index. This MUST call the
   * createIndexes method and pass the provided specification document in a
   * sequence to that method with the same options.
   *
   * @return The name of the created index.
   *
   * @note Drivers MAY opt to implement this method signature, the signature that
   *   takes an IndexModel as a parameter, or for those languages with method
   *   overloading MAY decide to implement both.
   *
   * @note Drivers MAY combine the two options types into a single one. If the options are
   *   explicitly typed, the combined options type MUST be named CreateIndexOptions or an acceptable
   *   variation.
   */
  createIndex(keys: Document, indexOptions: Optional&lt;IndexOptions&gt;, options: Optional&lt;CreateIndexOptions&gt;): String;

  /**
   * @see Comments above.
   */
  createIndex(model: IndexModel, options: Optional&lt;CreateIndexOptions&gt;): String

  /**
   * Creates multiple indexes in the collection.
   * 
   * In all server versions, this MUST execute a createIndexes command.
   *
   * @return The names of all the indexes that were created.
   */
  createIndexes(models: Iterable&lt;IndexModel&gt;, options: Optional&lt;CreateIndexesOptions&gt;): Iterable&lt;String&gt;;

  /**
   * Drops a single index from the collection by the index name.
   *
   * In all server versions this MUST execute a dropIndexes command.
   *
   * @note If the string passed is '*', the driver MUST raise an error since
   *   more than one index would be dropped.
   */
  dropIndex(name: String, options: Optional&lt;DropIndexOptions&gt;): Result;

  /**
   * Attempts to drop a single index from the collection given the keys and options.
   *
   * In all server versions this MUST execute a dropIndexes command.
   *
   * This is OPTIONAL until partial indexes are implemented.
   *
   * @note Drivers MAY opt to implement this method signature, the signature that
   *   takes an IndexModel as a parameter, or for those languages with method
   *   overloading MAY decide to implement both.
   *
   * @note Drivers MAY combine the two options types into a single one. If the options are
   *   explicitly typed, the combined options type MUST be named DropIndexOptions or an acceptable
   *   variation.
   */
  dropIndex(keys: Document, indexOptions: IndexOptions, options: Optional&lt;DropIndexOptions&gt;): Result;

  /**
   * @see Comments above.
   */
  dropIndex(model: IndexModel, options: Optional&lt;DropIndexOptions&gt;): Result;

  /**
   * Drops all indexes in the collection.
   */
  dropIndexes(options: Optional&lt;DropIndexesOptions&gt;): Result;

  /**
   * Gets index information for all indexes in the collection. The behavior for 
   * enumerating indexes is described in the :ref:`Enumerating Indexes` section.
   *
   */
  listIndexes(options: Optional&lt;ListIndexesOptions&gt;): Cursor;
}

interface CreateIndexOptions {
  /**
   * Specifies how many data-bearing members of a replica set, including the primary, must
   * complete the index builds successfully before the primary marks the indexes as ready.
   *
   * This option accepts the same values for the "w" field in a write concern plus "votingMembers",
   * which indicates all voting data-bearing nodes.
   *
   * This option is only supported by servers &gt;= 4.4. Drivers MUST manually raise an error if this option
   * is specified when creating an index on a pre 4.4 server. See the Q&amp;A section for the rationale behind this.
   *
   * @note This option is sent only if the caller explicitly provides a value. The default is to not send a value.
   *
   * @since MongoDB 4.4
   */
  commitQuorum: Optional&lt;Int32 | String&gt;;

  /**
   * The maximum amount of time to allow the index build to take before returning an error.
   *
   * @note This option is sent only if the caller explicitly provides a value. The default is to not send a value.
   */
  maxTimeMS: Optional&lt;Int64&gt;;

  /**
   * Enables users to specify an arbitrary comment to help trace the operation through
   * the database profiler, currentOp and logs. The default is to not send a value.
   *
   * @see https://www.mongodb.com/docs/manual/reference/command/createIndexes/
   *
   * @since MongoDB 4.4
   */
  comment: Optional&lt;any&gt;;
}

interface CreateIndexesOptions {
  // same as CreateIndexOptions
}

interface DropIndexOptions {
 /**
   * The maximum amount of time to allow the index drop to take before returning an error.
   *
   * @note This option is sent only if the caller explicitly provides a value. The default is to not send a value.
   */
  maxTimeMS: Optional&lt;Int64&gt;;

  /**
   * Enables users to specify an arbitrary comment to help trace the operation through
   * the database profiler, currentOp and logs. The default is to not send a value.
   *
   * @see https://www.mongodb.com/docs/manual/reference/command/dropIndexes/
   *
   * @since MongoDB 4.4
   */
  comment: Optional&lt;any&gt;;
}

interface DropIndexesOptions {
  // same as DropIndexOptions
}
</code></pre>
<h4 id="examples-2"><a class="header" href="#examples-2">Examples</a></h4>
<p>Create an index in a collection.</p>
<p>Ruby:</p>
<pre><code class="language-ruby">collection.create_index({ name: 1 }, { unique: true })
</code></pre>
<p>Java:</p>
<pre><code class="language-java">collection.createIndex(new Document("name", 1), new IndexOptions().unique(true));
</code></pre>
<p>Produces the shell equivalent (&gt;= 2.6.0) of:</p>
<pre><code class="language-javascript">db.runCommand({
  createIndexes: "users",
  indexes: [
    { key: { name: 1 }, name: "name_1", unique: true }
  ]
});
</code></pre>
<p>Create multiple indexes in a collection.</p>
<p>Ruby:</p>
<pre><code class="language-ruby">collection.create_indexes([
  { key: { name: 1 }, unique: true },
  { key: { age: -1 }, name: "age" }
])
</code></pre>
<p>Java:</p>
<pre><code class="language-java">collection.createIndexes(asList(
  new IndexModel(new Document("name", 1), new IndexOptions().unique(true)),
  new IndexModel(new Document("age", -1), new IndexOptions().name("age"))
));
</code></pre>
<p>Produces the shell equivalent (&gt;= 2.6.0) of:</p>
<pre><code class="language-javascript">db.runCommand({
  createIndexes: "users",
  indexes: [
    { key: { name: 1 }, name: "name_1", unique: true },
    { key: { age: -1 }, name: "age" }
  ]
});
</code></pre>
<p>Drop an index in a collection.</p>
<p>Ruby:</p>
<pre><code class="language-ruby">collection.drop_index("age")
</code></pre>
<p>Java:</p>
<pre><code class="language-java">collection.dropIndex("age");
</code></pre>
<p>Produces the shell equivalent of:</p>
<pre><code class="language-javascript">db.runCommand({ dropIndexes: "users", index: "age" });
</code></pre>
<p>Drop all indexes in a collection.</p>
<p>Ruby:</p>
<pre><code class="language-ruby">collection.drop_indexes
</code></pre>
<p>Java:</p>
<pre><code class="language-java">collection.dropIndexes();
</code></pre>
<p>Produces the shell equivalent of:</p>
<pre><code class="language-javascript">db.runCommand({ dropIndexes: "users", index: "*" });
</code></pre>
<p>List all indexes in a collection.</p>
<p>Ruby:</p>
<pre><code class="language-ruby">collection.list_indexes
</code></pre>
<p>Java:</p>
<pre><code class="language-java">collection.listIndexes();
</code></pre>
<p>Produces the shell equivalent (&gt;= 3.0.0) of:</p>
<pre><code class="language-javascript">db.runCommand({ listIndexes: "users" });
</code></pre>
<h3 id="index-view-api"><a class="header" href="#index-view-api">Index View API</a></h3>
<pre><code class="language-typescript">interface Collection {

  /**
   * Returns the index view for this collection.
   */
  indexes(options: Optional&lt;ListIndexesOptions&gt;): IndexView;
}

interface IndexView extends Iterable&lt;Document&gt; {

  /**
   * Enumerates the index information for all indexes in the collection. This should be
   * implemented as described in the :ref:`Enumerate Indexes` section, although the naming
   * requirement is dropped in favor of the driver language standard for handling iteration
   * over a sequence of objects.
   *
   * @see https://github.com/mongodb/specifications/blob/master/source/enumerate-indexes.md
   *
   * @note For drivers that cannot make the IndexView iterable, they MUST implement a list
   *   method. See below.
   */
  iterator(): Iterator&lt;Document&gt;;

  /**
   * For drivers that cannot make IndexView iterable, they MUST implement this method to
   * return a list of indexes. In the case of async drivers, this MAY return a Future&lt;Cursor&gt;
   *  or language/implementation equivalent.
   * 
   *  If drivers are unable to make the IndexView iterable, they MAY opt to provide the options for 
   *  listing search indexes via the `list` method instead of the `Collection.indexes` method.

   */
  list(): Cursor;

  /**
   * This is a convenience method for creating a single index. This MUST call the
   * createMany method and pass the provided specification document in a
   * sequence to that method with the same options.
   *
   * @return The name of the created index.
   *
   * @note Drivers MAY opt to implement this method signature, the signature that
   *   takes an IndexModel as a parameter, or for those languages with method
   *   overloading MAY decide to implement both.
   *
   * @note Drivers MAY combine the two options types into a single one. If the options are
   *   explicitly typed, the combined options type MUST be named CreateOneIndexOptions or an acceptable
   *   variation.
   */
  createOne(keys: Document, indexOptions: IndexOptions, options: Optional&lt;CreateOneIndexOptions&gt;): String;

  /**
   * @see Comments above.
   */
  createOne(model: IndexModel, options: Optional&lt;CreateOneIndexOptions&gt;): String

  /**
   * Creates multiple indexes in the collection.
   *
   * For all server versions this method MUST execute a createIndexes command.
   *
   * @return The names of the created indexes.
   *
   * @note Each specification document becomes the "key" field in the document that
   *   is inserted or the command.
   *   
   */
  createMany(models: Iterable&lt;IndexModel&gt;, options: Optional&lt;CreateManyIndexesOptions&gt;): Iterable&lt;String&gt;;

  /**
   * Drops a single index from the collection by the index name.
   *
   * In all server versions this MUST execute a dropIndexes command.
   *
   * @note If the string passed is '*', the driver MUST raise an error since
   *   more than one index would be dropped.
   */
  dropOne(name: String, options: Optional&lt;DropOneIndexOptions&gt;): Result;

  /**
   * Attempts to drop a single index from the collection given the keys and options.
   * This is OPTIONAL until partial indexes are implemented.
   *
   * In all server versions this MUST execute a dropIndexes command.
   *
   * @note Drivers MAY opt to implement this method signature, the signature that
   *   takes an IndexModel as a parameter, or for those languages with method
   *   overloading MAY decide to implement both.
   *
   * @note Drivers MAY combine the two options types into a single one. If the options are
   *   explicitly typed, the combined options type MUST be named DropOneIndexOptions or an acceptable
   *   variation.
   */
  dropOne(keys: Document, indexOptions: IndexOptions, options: Optional&lt;DropOneIndexOptions&gt;): Result;

  /**
   * @see Comments above.
   */
  dropOne(model: IndexModel, options: Optional&lt;DropOneIndexOptions&gt;): Result;

  /**
   * Drops all indexes in the collection.
   */
  dropAll(options: Optional&lt;DropAllIndexesOptions&gt;): Result;
}

interface CreateOneIndexOptions {
  // same as CreateIndexOptions in the Standard API
}

interface CreateManyIndexesOptions {
  // same as CreateIndexesOptions in the Standard API
}

interface DropOneIndexOptions {
  // same as DropIndexOptions in the Standard API
}

interface DropAllIndexesOptions {
  // same as DropIndexesOptions in the Standard API
}
</code></pre>
<h4 id="examples-3"><a class="header" href="#examples-3">Examples</a></h4>
<p>Create an index in a collection.</p>
<p>Ruby:</p>
<pre><code class="language-ruby">collection.indexes.create_one({ name: 1 }, { unique: true })
</code></pre>
<p>Java:</p>
<pre><code class="language-java">collection.indexes().createOne(new Document("name", 1), new IndexOptions().unique(true));
</code></pre>
<p>Produces the shell equivalent (&gt;= 2.6.0) of:</p>
<pre><code class="language-javascript">db.runCommand({
  createIndexes: "users",
  indexes: [
    { key: { name: 1 }, name: "name_1", unique: true }
  ]
});
</code></pre>
<p>Create multiple indexes in a collection.</p>
<p>Ruby:</p>
<pre><code class="language-ruby">collection.indexes.create_many([
  { key: { name: 1 }, unique: true },
  { key: { age: -1 }, name: "age" }
])
</code></pre>
<p>Java:</p>
<pre><code class="language-java">collection.indexes().createMany(asList(
  new IndexModel(new Document("name", 1), new IndexOptions().unique(true),
  new IndexModel(new Document("age", -1), new IndexOptions().name("age")
));
</code></pre>
<p>Produces the shell equivalent (&gt;= 2.6.0) of:</p>
<pre><code class="language-javascript">db.runCommand({
  createIndexes: "users",
  indexes: [
    { key: { name: 1 }, name: "name_1", unique: true },
    { key: { age: -1 }, name: "age" }
  ]
});
</code></pre>
<p>Drop an index in a collection.</p>
<p>Ruby:</p>
<pre><code class="language-ruby">collection.indexes.drop_one("age")
</code></pre>
<p>Java:</p>
<pre><code class="language-java">collection.indexes().dropOne("age");
</code></pre>
<p>Produces the shell equivalent of:</p>
<pre><code class="language-javascript">db.runCommand({ dropIndexes: "users", index: "age" });
</code></pre>
<p>Drop all indexes in a collection.</p>
<p>Ruby:</p>
<pre><code class="language-ruby">collection.indexes.drop_all
</code></pre>
<p>Java:</p>
<pre><code class="language-java">collection.indexes().dropAll();
</code></pre>
<p>Produces the shell equivalent of:</p>
<pre><code class="language-javascript">db.runCommand({ dropIndexes: "users", index: "*" });
</code></pre>
<p>List all indexes in a collection.</p>
<p>Ruby:</p>
<pre><code class="language-ruby">collection.indexes.each do |document|
  p document
end
</code></pre>
<p>Java:</p>
<pre><code class="language-java">for (BsonDocument document: collection.indexes()) {
  /* ... */
}
</code></pre>
<p>Produces the shell equivalent (&gt;= 3.0.0) of:</p>
<pre><code class="language-javascript">var indexes = db.runCommand({ listIndexes: "users" });
for (index in indexes) {
  console.log(index);
}
</code></pre>
<h3 id="common-api-components"><a class="header" href="#common-api-components">Common API Components</a></h3>
<pre><code class="language-typescript">interface IndexModel {

  /**
   * Contains the required keys for the index.
   */
  keys: Document;

  /**
   * Contains the options for the index.
   */
  options: IndexOptions;
}

interface IndexOptions {

  /**
   * Optionally tells the server to build the index in the background and not block
   * other tasks.
   *
   * @note Starting in MongoDB 4.2, this option is ignored by the server.
   * @see https://www.mongodb.com/docs/manual/reference/command/createIndexes/
   * @deprecated 4.2
   */
  background: Boolean;

  /**
   * Optionally specifies the length in time, in seconds, for documents to remain in
   * a collection.
   */
  expireAfterSeconds: Int32;

  /**
   * Optionally specify a specific name for the index outside of the default generated
   * name. If none is provided then the name is generated in the format "[field]_[direction]".
   *
   * Note that if an index is created for the same key pattern with different collations,
   * a name must be provided by the user to avoid ambiguity.
   *
   * @example For an index of name: 1, age: -1, the generated name would be "name_1_age_-1".
   */
  name: String;
  
  /**
   * Optionally tells the index to only reference documents with the specified field in
   * the index.
   */
  sparse: Boolean;

  /**
   * Optionally used only in MongoDB 3.0.0 and higher. Allows users to configure the storage
   * engine on a per-index basis when creating an index.
   */
  storageEngine: Document;

  /**
   * Optionally forces the index to be unique.
   */
  unique: Boolean;

  /**
   * Optionally specifies the index version number, either 0 or 1.
   */
  version: Int32;

  /**
   * Optionally specifies the default language for text indexes.
   * Is 'english' if none is provided.
   */
  defaultLanguage: String;

  /**
   * Optionally Specifies the field in the document to override the language.
   */
  languageOverride: String;

  /**
   * Optionally provides the text index version number.
   *
   * MongoDB 2.4 can only support version 1.
   *
   * MongoDB 2.6 and higher may support version 1 or 2.
   */
  textIndexVersion: Int32;

  /**
   * Optionally specifies fields in the index and their corresponding weight values.
   */
  weights: Document;

  /**
   * Optionally specifies the 2dsphere index version number.
   *
   * MongoDB 2.4 can only support version 1.
   *
   * MongoDB 2.6 and higher may support version 1 or 2.
   */
  2dsphereIndexVersion: Int32;

  /**
   * Optionally specifies the precision of the stored geo hash in the 2d index, from 1 to 32.
   */
  bits: Int32;

  /**
   * Optionally sets the maximum boundary for latitude and longitude in the 2d index.
   */
  max: Double;

  /**
   * Optionally sets the minimum boundary for latitude and longitude in the index in a
   * 2d index.
   */
  min: Double;

  /**
   * Optionally specifies the number of units within which to group the location values
   * in a geo haystack index.
   */
  bucketSize: Int32;

  /**
   * Optionally specifies a filter for use in a partial index. Only documents that match the
   * filter expression are included in the index. New in MongoDB 3.2.
   */
  partialFilterExpression: Document;

  /**
   * Optionally specifies a collation to use for the index in MongoDB 3.4 and higher.
   * If not specified, no collation is sent and the default collation of the collection
   * server-side is used.
   */
  collation: Document;

  /**
   * Optionally specifies the wildcard projection of a wildcard index.
   */
  wildcardProjection: Document;

  /**
   * Optionally specifies that the index should exist on the target collection but should not be used by the query
   * planner when executing operations.
   *
   * This option is only supported by servers &gt;= 4.4.
   */
  hidden: Boolean;

  /**
   * Optionally specifies that this index is clustered.  This is not a valid option to provide to
   * 'createIndexes', but can appear in the options returned for an index via 'listIndexes'.  To
   * create a clustered index, create a new collection using the 'clusteredIndex' option.
   *
   * This options is only supported by servers &gt;= 6.0.
   */
   clustered: Boolean;
}

interface ListIndexesOptions {
  /**
   * Enables users to specify an arbitrary comment to help trace the operation through
   * the database profiler, currentOp and logs. The default is to not send a value.
   *
   * If a comment is provided, drivers MUST attach this comment to all
   * subsequent getMore commands run on the same cursor.
   *
   * @see https://www.mongodb.com/docs/manual/reference/command/listIndexes/
   *
   * @since MongoDB 4.4
   */
  comment: Optional&lt;any&gt;;

  /**
   * Configures the batch size of the cursor returned from the ``listIndexes`` command.
   * 
   * @note drivers MAY chose to support batchSize on the ListIndexesOptions.
   */
  batchSize: Optional&lt;Int32&gt;;
}
</code></pre>
<h3 id="enumerating-indexes"><a class="header" href="#enumerating-indexes">Enumerating Indexes</a></h3>
<p>For all server versions, drivers MUST run a <code>listIndexes</code> command when enumerating indexes.</p>
<p>Drivers SHOULD use the method name <code>listIndexes</code> for a method that returns all indexes with a cursor return type.
Drivers MAY use an idiomatic variant that fits the language the driver is for. An exception is made for drivers
implementing the index view API.</p>
<p>In MongoDB 4.4, the <code>ns</code> field was removed from the index specifications returned from the <code>listIndexes</code> command.</p>
<ul>
<li>For drivers that report those index specifications in the form of documents or dictionaries, no special handling is
necessary, but any documentation of the contents of the documents/dictionaries MUST indicate that the <code>ns</code> field will
no longer be present in MongoDB 4.4+. If the contents of the documents/dictionaries are undocumented, then no special
mention of the <code>ns</code> field is necessary.</li>
<li>For drivers that report those index specifications in the form of statically defined models, the driver MUST manually
populate the <code>ns</code> field of the models with the appropriate namespace if the server does not report it in the
<code>listIndexes</code> command response. The <code>ns</code> field is not required to be a part of the models, however.</li>
</ul>
<p><span id="enumerate-indexes"></span></p>
<h4 id="getting-index-names"><a class="header" href="#getting-index-names">Getting Index Names</a></h4>
<p>Drivers MAY implement a method to enumerate all indexes, and return only the index names. The helper operates the same
as the following example:</p>
<p>Example:</p>
<pre><code>&gt; a = [];
[ ]
&gt; db.runCommand( { listIndexes: 'poiConcat' } ).indexes.forEach(function(i) { a.push(i.name); } );
&gt; a
[ "_id_", "ty_1", "l_2dsphere", "ts_1" ]
</code></pre>
<h3 id="search-indexes"><a class="header" href="#search-indexes">Search Indexes</a></h3>
<p>Server 7.0 introduced three new server commands and a new aggregation stage to facilitate management of search indexes.
Drivers MUST provide an API similar to the existing index management API specifically for search indexes. Drivers MAY
choose to implement either the standard API or the index view API.</p>
<h4 id="search-index-management-helper-options"><a class="header" href="#search-index-management-helper-options">Search Index Management Helper Options</a></h4>
<p>There are currently no supported options for any of the search index management commands. To future proof drivers
implementations so that any options added in the future do not constitute a breaking change to drivers, empty options
structs have been added as placeholders. If a driver's language has a mechanism to add options in a non-breaking manner
(i.e., method overloading) drivers MAY omit the empty options structs from their search index management helpers.</p>
<p><code>listSearchIndexes</code> is implemented using an aggregation pipeline. The list helper MUST support a driver's aggregation
options as outline in the <a href="index-management/../crud/crud.html#read">CRUD specification</a>. Drivers MAY combine the aggregation options with
any future <code>listSearchIndexes</code> stage options, if that is idiomatic for a driver's language.</p>
<h4 id="asynchronicity"><a class="header" href="#asynchronicity">Asynchronicity</a></h4>
<p>The search index commands are asynchronous and return from the server before the index is successfully updated, created
or dropped. In order to determine when an index has been created / updated, users are expected to run the
<code>listSearchIndexes</code> repeatedly until index changes appear.</p>
<p>An example, from Javascript:</p>
<pre><code class="language-typescript">const name = await collection.createSearchIndex({ definition: { ... fill out definition } })
while (!(await collection.listSearchIndexes({ name }).hasNext())) {
  await setTimeout(1000);
}
</code></pre>
<h4 id="where-are-read-concern-and-write-concern"><a class="header" href="#where-are-read-concern-and-write-concern">Where are read concern and write concern?</a></h4>
<p>These commands internally proxy the search index management commands to a separate process that runs alongside an Atlas
cluster. As such, read concern and write concern are not relevant for the search index management commands.</p>
<p>Drivers MUST NOT apply a read concern or write concern to the commands. Atlas search index management commands return an
error if a <code>readConcern</code> or <code>writeConcern</code> field is present in the command.</p>
<h4 id="consistency-with-existing-apis"><a class="header" href="#consistency-with-existing-apis">Consistency with Existing APIs</a></h4>
<p>Drivers SHOULD strive for a search index management API that is as consistent as possible with their existing index
management API.</p>
<h4 id="namespacenotfound-errors"><a class="header" href="#namespacenotfound-errors">NamespaceNotFound Errors</a></h4>
<p>Some drivers suppress NamespaceNotFound errors for CRUD helpers. Drivers MAY suppress NamespaceNotFound errors from the
search index management helpers.</p>
<p>Drivers MUST suppress NamespaceNotFound errors for the <code>dropSearchIndex</code> helper. Drop operations should be idempotent:</p>
<pre><code class="language-typescript">await collection.dropSearchIndex('my-test-index');
// subsequent calls should behave the same for the user as the first call
await collection.dropSearchIndex('my-test-index');
await collection.dropSearchIndex('my-test-index');
</code></pre>
<h4 id="common-interfaces"><a class="header" href="#common-interfaces">Common Interfaces</a></h4>
<pre><code class="language-typescript">interface SearchIndexModel {
  /**
   * Document describing the index to create.
   *
   * The definition syntax depends on whether you create a standard search index
   * or a vector search index.
   *
   * @see https://www.mongodb.com/docs/manual/reference/command/createSearchIndexes/
   */
  definition: Document;

  /**
   * Contains the options for the index.
   */
  options: SearchIndexOptions;
}

interface SearchIndexOptions {
  /**
   * Name of the search index to create.
   *
   * The server will use "default" if this option is not specified.
   */
  name: Optional&lt;string&gt;;

  /**
   * Type of search index to create. Defaults to "search" if not provided.
   *
   * Specify "search" for a standard search index or "vectorSearch" for a vector
   * search index.
   *
   * The server will use "search" if this option is not specified.
   */
  type: Optional&lt;string&gt;;
}

/**
 * The following interfaces are empty but are provided as placeholders for drivers that cannot 
 * add options in a non-breaking manner, if options are added in the future.
 */
interface CreateSearchIndexOptions {} 
interface UpdateSearchIndexOptions {}
interface ListSearchIndexOptions {}
interface DropSearchIndexOptions {}
</code></pre>
<h4 id="standard-api-for-search-indexes"><a class="header" href="#standard-api-for-search-indexes">Standard API for Search Indexes</a></h4>
<pre><code class="language-typescript">interface Collection {
  /**
   * Convenience method for creating a single search index.
   * 
   * @return The name of the created search index
   * 
   * @note Drivers MAY opt to implement this method signature, the signature that
   *   takes an SearchIndexModel as a parameter, or for those languages with method
   *   overloading MAY decide to implement both.
   *   
   * @note Drivers MAY combine the `indexOptions` with the `createSearchIndexOptions`, if that is idiomatic for their language.
   */
  createSearchIndex(definition: Document, indexOptions: Optional&lt;SearchIndexOptions&gt;, createSearchIndexOptions: Optional&lt;CreateSearchIndexOptions&gt;): String;

  /**
   * Convenience method for creating a single index.
   * 
   * @return The name of the created search index
   * 
   * @note Drivers MAY opt to implement this method signature, the signature that
   *   takes an name and a definition as parameters, or for those languages with method
   *   overloading MAY decide to implement both.
   */
  createSearchIndex(model: SearchIndexModel, options: Optional&lt;CreateSearchIndexOptions&gt;): String;

  /**
   * Creates multiple search indexes on the collection.
   * 
   * @return An iterable of the newly created index names.
   */
  createSearchIndexes(models: Iterable&lt;SearchIndexModel&gt;, options: CreateSearchIndexOptions): Iterable&lt;String&gt;;

  /**
   * Updates the search index with the given name to use the provided 
   * definition.
   */
  updateSearchIndex(name: String, definition: Document, options: Optional&lt;UpdateSearchIndexOptions&gt;): void;

  /**
   * Drops the search index with the given name.
   */
  dropSearchIndex(name: String, options: Optional&lt;DropSearchIndexOptions&gt;): void;

  /**
   * Gets index information for one or more search indexes in the collection.
   *
   * If name is not specified, information for all indexes on the specified collection will be returned.
   */
  listSearchIndexes(name: Optional&lt;String&gt;, aggregationOptions: Optional&lt;AggregationOptions&gt;, listIndexOptions: Optional&lt;ListSearchIndexOptions&gt;): Cursor&lt;Document&gt;;
}
</code></pre>
<h4 id="index-view-api-for-search-indexes"><a class="header" href="#index-view-api-for-search-indexes">Index View API for Search Indexes</a></h4>
<pre><code class="language-typescript">interface Collection {
  /**
   * Returns the search index view for this collection.
   */
  searchIndexes(name: Optional&lt;String&gt;, aggregateOptions: Optional&lt;AggregationOptions&gt;, options: Optional&lt;ListSearchIndexOptions&gt;): SearchIndexView;
}

interface SearchIndexView extends Iterable&lt;Document&gt; {
  /**
   * Enumerates the index information for all search indexes in the collection. 
   *
   * @note For drivers that cannot make the IndexView iterable, they MUST implement a list
   *   method. See below.
   */
  iterator(): Iterator&lt;Document&gt;;

  /**
   * For drivers that cannot make SearchIndexView iterable, they MUST implement this method to
   * return a list of indexes. In the case of async drivers, this MAY return a Future&lt;Cursor&gt;
   *  or language/implementation equivalent.
   *  
   *  If drivers are unable to make the SearchIndexView iterable, they MAY opt to provide the options for 
   *  listing search indexes via the `list` method instead of the `Collection.searchIndexes` method.
   */
  list(): Cursor&lt;Document&gt;;


  /**
   * This is a convenience method for creating a single index.
   *
   * @return The name of the created index.
   *
   * @note Drivers MAY opt to implement this method signature, the signature that
   *   takes an SearchIndexModel as a parameter, or for those languages with method
   *   overloading MAY decide to implement both.
   *   
   * @note Drivers MAY combine the `indexOptions` with the `createSearchIndexOptions`, if that is idiomatic for their language.
   */
  createOne(definition: Document, indexOptions: Optional&lt;SearchIndexOptions&gt;, createSearchIndexOptions: Optional&lt;CreateSearchIndexOptions&gt;): String;

  /**
   * This is a convenience method for creating a single index.
   *
   * @return The name of the created index.
   *
   * @note Drivers MAY opt to implement this method signature, the signature that
   *   takes an name and a definition as parameters, or for those languages with method
   *   overloading MAY decide to implement both.
   */
  createOne(model: SearchIndexModel, options: Optional&lt;CreateSearchIndexOptions&gt;): String;

  /**
   * Creates multiple search indexes in the collection.
   *
   * @return The names of the created indexes.
   */
  createMany(models: Iterable&lt;SearchIndexModel&gt;, options: Optional&lt;CreateSearchIndexOptions&gt;): Iterable&lt;String&gt;;

  /**
   * Drops a single search index from the collection by the index name.
   */
  dropOne(name: String, options: Optional&lt;DropSearchIndexOptions&gt;): Result;

  /**
   * Updates a single search index from the collection by the index name.
   */
  updateOne(name: String, definition: Document, options: Optional&lt;UpdateSearchIndexOptions&gt;): Result;
}
</code></pre>
<h3 id="q--a-5"><a class="header" href="#q--a-5">Q &amp; A</a></h3>
<p>Q: Where is write concern?</p>
<p>The <code>createIndexes</code> and <code>dropIndexes</code> commands take a write concern that indicates how the write is acknowledged. Since
all operations defined in this specification are performed on a collection, it's uncommon that two different index
operations on the same collection would use a different write concern. As such, the most natural place to indicate write
concern is on the client, the database, or the collection itself and not the operations within it.</p>
<p>However, it might be that a driver needs to expose write concern to a user per operation for various reasons. It is
permitted to allow a write concern option, but since writeConcern is a top-level command option, it MUST NOT be
specified as part of an <code>IndexModel</code> passed into the helper. It SHOULD be specified via the options parameter of the
helper. For example, it would be ambiguous to specify write concern for one or more models passed to <code>createIndexes()</code>,
but it would not be to specify it via the <code>CreateIndexesOptions</code>.</p>
<p>Q: What does the commitQuorum option do?</p>
<p>Prior to MongoDB 4.4, secondaries would simply replicate index builds once they were completed on the primary. Building
indexes requires an exclusive lock on the collection being indexed, so the secondaries would be blocked from replicating
all other operations while the index build took place. This would introduce replication lag correlated to however long
the index build took.</p>
<p>Starting in MongoDB 4.4, secondaries build indexes simultaneously with the primary, and after starting an index build,
the primary will wait for a certain number of data-bearing nodes, including itself, to have completed the build before
it commits the index. <code>commitQuorum</code> configures this node requirement. Once the index is committed, all the secondaries
replicate the commit too. If a secondary had already completed the index build, the commit will be quick, and no new
replication lag would be introduced. If a secondary had not finished building the index before the primary committed it
(e.g. if <code>commitQuorum: 0</code> was used), then that secondary may lag behind the primary while it finishes building and
committing the index.</p>
<p>The server-default value for <code>commitQuorum</code> is "votingMembers", which means the primary will wait for all voting
data-bearing nodes to complete building the index before it commits it.</p>
<p>Q: Why would a user want to specify a non-default <code>commitQuorum</code></p>
<p>Like <code>w: "majority"</code>, <code>commitQuorum: "votingMembers"</code> doesn't consider non-voting data-bearing nodes such as analytics
nodes. If a user wanted to ensure these nodes didn't lag behind, then they would specify
<code>commitQuorum: &lt;total number of data-bearing nodes, including non-voting nodes&gt;</code>. Alternatively, if they wanted to
ensure only specific non-voting nodes didn't lag behind, they could specify a
<a href="https://www.mongodb.com/docs/manual/reference/replica-configuration/#rsconf.settings.getLastErrorModes">custom getLastErrorMode based on the nodes' tag sets</a>
(e.g. <code>commitQuorum: &lt;custom getLastErrorMode name&gt;</code>).</p>
<p>Additionally, if a user has a high tolerance for replication lag, they can set a lower value for <code>commitQuorum</code>. This is
useful for situations where certain secondaries take longer to build indexes than the primaries, and the user doesn't
care if they lag behind.</p>
<p>Q: What is the difference between write concern and <code>commitQuorum</code>?</p>
<p>While these two options share a lot in terms of how they are specified, they configure entirely different things.
<code>commitQuorum</code> determines how much new replication lag an index build can tolerably introduce, but it says nothing of
durability. Write concern specifies the durability requirements of an index build, but it makes no guarantees about
introducing replication lag.</p>
<p>For instance, an index built with <code>writeConcern: { w: 1 }, commitQuorum: "votingMembers"</code> could possibly be rolled back,
but it will not introduce any new replication lag. Likewise, an index built with
<code>writeConcern: { w: "majority", j: true }, commitQuorum: 0</code> will not be rolled back, but it may cause the secondaries to
lag. To ensure the index is both durable and will not introduce replication lag on any data-bearing voting secondary,
<code>writeConcern: { w: "majority", j: true }, commitQuorum: "votingMembers"</code> must be used.</p>
<p>Also note that, since indexes are built simultaneously, higher values of <code>commitQuorum</code> are not as expensive as higher
values of <code>writeConcern</code>.</p>
<p>Q: Why does the driver manually throw errors if the <code>commitQuorum</code> option is specified against a pre 4.4 server?<br>
Starting in 3.4, the server validates all options passed to the <code>createIndexes</code> command, but due to a bug in versions
4.2.0-4.2.5 of the server (SERVER-47193), specifying <code>commitQuorum</code> does not result in an error. The option is used
internally by the server on those versions, and its value could have adverse effects on index builds. To prevent users
from mistakenly specifying this option, drivers manually verify it is only sent to 4.4+ servers.</p>
<h4 id="changelog-31"><a class="header" href="#changelog-31">Changelog</a></h4>
<ul>
<li>
<p>2024-09-05: Moved options in SearchIndexModel to SearchIndexOptions for consistency with IndexModel and IndexOptions.</p>
</li>
<li>
<p>2024-03-06: Added <code>type</code> option to SearchIndexOptions.</p>
</li>
<li>
<p>2024-03-05: Migrated from reStructuredText to Markdown.</p>
</li>
<li>
<p>2023-11-08: Clarify that <code>readConcern</code> and <code>writeConcern</code> must not be applied to search index management commands.</p>
</li>
<li>
<p>2023-07-27: Add search index management clarifications.</p>
</li>
<li>
<p>2023-05-18: Add the search index management API.</p>
</li>
<li>
<p>2023-05-10: Merge index enumeration and index management specs and get rid of references to legacy server versions.</p>
</li>
<li>
<p>2022-10-05: Remove spec front matter and reformat changelog.</p>
</li>
<li>
<p>2022-04-18: Added the <code>clustered</code> attribute to <code>IndexOptions</code> in order to support clustered collections.</p>
</li>
<li>
<p>2022-02-10: Specified that <code>getMore</code> command must explicitly send inherited comment.</p>
</li>
<li>
<p>2022-02-01: Added comment field to helper methods.</p>
</li>
<li>
<p>2022-01-19: Require that timeouts be applied per the client-side operations timeout spec.</p>
</li>
<li>
<p>2020-03-30: Added options types to various helpers. Introduced <code>commitQuorum</code> option. Added deprecation message for
<code>background</code> option.</p>
</li>
<li>
<p>2019-04-24: Added <code>wildcardProjection</code> attribute to <code>IndexOptions</code> in order to support setting a wildcard projection
on a wildcard index.</p>
</li>
<li>
<p>2017-06-07: Include listIndexes() in Q&amp;A about maxTimeMS.</p>
</li>
<li>
<p>2017-05-31: Add Q &amp; A addressing write concern and maxTimeMS option.</p>
</li>
<li>
<p>2016-10-11: Added note on 3.4 servers validation options passed to <code>createIndexes</code>. Add note on server generated name
for the <code>_id</code> index.</p>
</li>
<li>
<p>2016-08-08: Fixed <code>collation</code> language to not mention a collection default.</p>
</li>
<li>
<p>2016-05-19: Added <code>collation</code> attribute to <code>IndexOptions</code> in order to support setting a collation on an index.</p>
</li>
<li>
<p>2015-09-17: Added <code>partialFilterExpression</code> attribute to <code>IndexOptions</code> in order to support partial indexes. Fixed
"provides" typo.</p>
</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="crud-api"><a class="header" href="#crud-api">CRUD API</a></h1>
<ul>
<li>Status: Accepted</li>
<li>Minimum Server Version: 2.6</li>
</ul>
<hr />
<h2 id="abstract-31"><a class="header" href="#abstract-31">Abstract</a></h2>
<p>The CRUD API defines a set of related methods and structures defining a driver's API. As not all languages/frameworks
have the same abilities, parts of the spec may or may not apply. These sections have been called out.</p>
<h2 id="specification-30"><a class="header" href="#specification-30">Specification</a></h2>
<p>This specification is about <a href="crud/crud.html#guidance">Guidance</a> in 3 areas related to the CRUD API as well as a specification for the
API itself. It does not define implementation details and provides room and flexibility for the idioms and differences
in languages and frameworks.</p>
<h3 id="definitions-6"><a class="header" href="#definitions-6">Definitions</a></h3>
<h4 id="meta-32"><a class="header" href="#meta-32">META</a></h4>
<p>The keywords "MUST", "MUST NOT", "REQUIRED", "SHALL", "SHALL NOT", "SHOULD", "SHOULD NOT", "RECOMMENDED", "MAY", and
"OPTIONAL" in this document are to be interpreted as described in <a href="https://www.ietf.org/rfc/rfc2119.txt">RFC 2119</a>.</p>
<h4 id="terms-22"><a class="header" href="#terms-22">Terms</a></h4>
<p><strong>Collection:</strong></p>
<p>The term <code>interface Collection</code> will be seen in most of the sections. Each driver will likely have a class or interface
defined for the concept of a collection. Operations appearing inside the <code>interface Collection</code> are required operations
to be present on a driver's concept of a collection.</p>
<p><strong>Iterable:</strong></p>
<p>The term <code>Iterable</code> will be seen as a return type from some of the <a href="crud/crud.html#read">Read</a> methods. Its use is as that of a
sequence of items. For instance, <code>collection.find({})</code> returns a sequence of documents that can be iterated over.</p>
<h3 id="guidance-1"><a class="header" href="#guidance-1">Guidance</a></h3>
<h4 id="documentation-3"><a class="header" href="#documentation-3">Documentation</a></h4>
<p>The documentation provided in code below is merely for driver authors and SHOULD NOT be taken as required documentation
for the driver.</p>
<h4 id="operations-2"><a class="header" href="#operations-2">Operations</a></h4>
<p>All drivers MUST offer the operations defined in the following sections. This does not preclude a driver from offering
more.</p>
<h4 id="operation-parameters-1"><a class="header" href="#operation-parameters-1">Operation Parameters</a></h4>
<p>All drivers MUST offer the same options for each operation as defined in the following sections. This does not preclude
a driver from offering more. A driver SHOULD NOT require a user to specify optional parameters, denoted by the
<code>Optional&lt;&gt;</code> signature. Unless otherwise specified, optional values should not be sent to the server.</p>
<h5 id="deviations-3"><a class="header" href="#deviations-3">Deviations</a></h5>
<p>A non-exhaustive list of acceptable deviations are as follows:</p>
<ul>
<li>
<p>Using named parameters instead of an options hash. For instance, <code>collection.find({x:1}, sort: {a: -1})</code>.</p>
</li>
<li>
<p>When using an <code>Options</code> class, if multiple <code>Options</code> classes are structurally equatable, it is permissible to
consolidate them into one with a clear name. For instance, it would be permissible to use the name <code>UpdateOptions</code> as
the options for <code>UpdateOne</code> and <code>UpdateMany</code>.</p>
</li>
<li>
<p>Using a fluent style builder for find or aggregate:</p>
<pre><code class="language-typescript">collection.find({x: 1}).sort({a: -1}).skip(10);
</code></pre>
<p>When using a fluent-style builder, all options should be named rather than inventing a new word to include in the
pipeline (like options). Required parameters are still required to be on the initiating method.</p>
<p>In addition, it is imperative that documentation indicate when the order of operations is important. For instance,
skip and limit in find is order irrelevant where skip and limit in aggregate is not.</p>
</li>
</ul>
<h4 id="naming-2"><a class="header" href="#naming-2">Naming</a></h4>
<p>All drivers MUST name operations, objects, and parameters as defined in the following sections.</p>
<p>Deviations are permitted as outlined below.</p>
<h5 id="deviations-4"><a class="header" href="#deviations-4">Deviations</a></h5>
<p>When deviating from a defined name, an author should consider if the altered name is recognizable and discoverable to
the user of another driver.</p>
<p>A non-exhaustive list of acceptable naming deviations are as follows:</p>
<ul>
<li>Using "batchSize" as an example, Java would use "batchSize" while Python would use "batch_size". However, calling it
"batchCount" would not be acceptable.</li>
<li>Using "maxTimeMS" as an example, .NET would use "MaxTime" where it's type is a TimeSpan structure that includes units.
However, calling it "MaximumTime" would not be acceptable.</li>
<li>Using "FindOptions" as an example, Javascript wouldn't need to name it while other drivers might prefer to call it
"FindArgs" or "FindParams". However, calling it "QueryOptions" would not be acceptable.</li>
<li>Using "isOrdered" rather than "ordered". Some languages idioms prefer the use of "is", "has", or "was" and this is
acceptable.</li>
</ul>
<h4 id="timeouts-2"><a class="header" href="#timeouts-2">Timeouts</a></h4>
<p>Drivers MUST enforce timeouts for all operations per the
<a href="crud/../client-side-operations-timeout/client-side-operations-timeout.html">Client Side Operations Timeout</a> specification. All
operations that return cursors MUST support the timeout options documented in the
<a href="crud/../client-side-operations-timeout/client-side-operations-timeout.html#cursors">Cursors</a> section of that specification.
All explain helpers MUST support the timeout options documented in the
<a href="crud/../client-side-operations-timeout/client-side-operations-timeout.html#explain">Explain Helpers</a> section of that
specification.</p>
<h3 id="api-1"><a class="header" href="#api-1">API</a></h3>
<h4 id="read"><a class="header" href="#read">Read</a></h4>
<blockquote>
<p>[!NOTE]
The term <code>Iterable&lt;T&gt;</code> is used below to indicate many of T. This spec is flexible on what that means as different
drivers will have different requirements, types, and idioms.</p>
</blockquote>
<pre><code class="language-typescript">interface Collection {

  /**
   * Runs an aggregation framework pipeline.
   *
   * Note: $out and $merge are special pipeline stages that cause no results
   * to be returned from the server. As such, the iterable here would never
   * contain documents. Drivers MAY setup a cursor to be executed upon
   * iteration against the output collection such that if a user were to
   * iterate the return value, results would be returned.
   *
   * Note: result iteration should be backed by a cursor. Depending on the implementation,
   * the cursor may back the returned Iterable instance or an iterator that it produces.
   *
   * @see https://www.mongodb.com/docs/manual/reference/command/aggregate/
   */
  aggregate(pipeline: Document[], options: Optional&lt;AggregateOptions&gt;): Iterable&lt;Document&gt;;

  /**
   * Gets the number of documents matching the filter.
   *
   * **This method is DEPRECATED and should not be implemented in new drivers.**
   *
   * @see https://www.mongodb.com/docs/manual/reference/command/count/
     @deprecated 4.0
   */
  count(filter: Document, options: Optional&lt;CountOptions&gt;): Int64;

  /**
   * Count the number of documents in a collection that match the given
   * filter. Note that an empty filter will force a scan of the entire
   * collection. For a fast count of the total documents in a collection
   * see estimatedDocumentCount.
   *
   * See "Count API Details" section below.
   */
  countDocuments(filter: Document, options: Optional&lt;CountOptions&gt;): Int64;

  /**
   * Gets an estimate of the count of documents in a collection using collection metadata.
   *
   * See "Count API Details" section below for implementation and documentation
   * requirements.
   */
  estimatedDocumentCount(options: Optional&lt;EstimatedDocumentCountOptions&gt;): Int64;

  /**
   * Finds the distinct values for a specified field across a single collection.
   *
   * Note: the results are backed by the "values" array in the distinct command's result
   * document. This differs from aggregate and find, where results are backed by a cursor.
   *
   * @see https://www.mongodb.com/docs/manual/reference/command/distinct/
   */
  distinct(fieldName: string, filter: Document, options: Optional&lt;DistinctOptions&gt;): Iterable&lt;any&gt;;

  /**
   * Finds the documents matching the model.
   *
   * Note: The filter parameter below equates to the $query meta operator. It cannot
   * contain other meta operators like $maxScan. However, do not validate this document
   * as it would be impossible to be forwards and backwards compatible. Let the server
   * handle the validation.
   *
   * Note: result iteration should be backed by a cursor. Depending on the implementation,
   * the cursor may back the returned Iterable instance or an iterator that it produces.
   *
   * @see https://www.mongodb.com/docs/manual/core/read-operations-introduction/
   */
  find(filter: Document, options: Optional&lt;FindOptions&gt;): Iterable&lt;Document&gt;;

}

interface Database {

  /**
   * Runs an aggregation framework pipeline on the database for pipeline stages
   * that do not require an underlying collection, such as $currentOp and $listLocalSessions.
   *
   * Note: result iteration should be backed by a cursor. Depending on the implementation,
   * the cursor may back the returned Iterable instance or an iterator that it produces.
   *
   * @see https://www.mongodb.com/docs/manual/reference/command/aggregate/#dbcmd.aggregate
   */
  aggregate(pipeline: Document[], options: Optional&lt;AggregateOptions&gt;): Iterable&lt;Document&gt;;

}

class AggregateOptions {

  /**
   * Enables writing to temporary files. When set to true, aggregation stages
   * can write data to the _tmp subdirectory in the dbPath directory.
   *
   * This option is sent only if the caller explicitly provides a value. The default
   * is to not send a value.
   *
   * @see https://www.mongodb.com/docs/manual/reference/command/aggregate/
   */
  allowDiskUse: Optional&lt;Boolean&gt;;

  /**
   * The number of documents to return per batch.
   *
   * This option is sent only if the caller explicitly provides a value. The default is to not send a value.
   * If specified, drivers SHOULD apply this option to both the original aggregate command and subsequent
   * getMore operations on the cursor.
   *
   * Drivers MUST NOT specify a batchSize of zero in an aggregate command that includes an $out or $merge stage,
   * as that will prevent the pipeline from executing. Drivers SHOULD leave the cursor.batchSize command option
   * unset in an aggregate command that includes an $out or $merge stage.
   *
   * @see https://www.mongodb.com/docs/manual/reference/command/aggregate/
   */
  batchSize: Optional&lt;Int32&gt;;

  /**
   * If true, allows the write to opt-out of document level validation. This only applies
   * when the $out or $merge stage is specified.
   *
   * This option is sent only if the caller explicitly provides a true value. The default is to not send a value.
   * For servers &lt; 3.2, this option is ignored and not sent as document validation is not available.
   *
   * @see https://www.mongodb.com/docs/manual/reference/command/aggregate/
   */
  bypassDocumentValidation: Optional&lt;Boolean&gt;;

  /**
   * Specifies a collation.
   *
   * This option is sent only if the caller explicitly provides a value. The default is to not send a value.
   * For servers &lt; 3.4, the driver MUST raise an error if the caller explicitly provides a value.
   *
   * @see https://www.mongodb.com/docs/manual/reference/command/aggregate/
   */
  collation: Optional&lt;Document&gt;;

  /**
   * The maximum amount of time to allow the query to run.
   *
   * This option is sent only if the caller explicitly provides a value. The default is to not send a value.
   *
   * NOTE: This option is deprecated in favor of timeoutMS.
   *
   * @see https://www.mongodb.com/docs/manual/reference/command/aggregate/
   */
  maxTimeMS: Optional&lt;Int64&gt;;

  /**
   * The maximum amount of time for the server to wait on new documents to satisfy a tailable cursor
   * query.
   *
   * This options only applies to aggregations which return a TAILABLE_AWAIT cursor. Drivers
   * SHOULD always send this value, if the cursor is not a TAILABLE_AWAIT cursor the server will
   * ignore it.
   *
   * @note this option is an alias for maxTimeMS, used on getMore commands
   * @note this option is not set on the aggregate command
   */
  maxAwaitTimeMS: Optional&lt;Int64&gt;;

  /**
   * Enables users to specify an arbitrary comment to help trace the operation through
   * the database profiler, currentOp and logs. The default is to not send a value.
   *
   * The comment can be any valid BSON type for server versions 4.4 and above.
   * Server versions between 3.6 and 4.2 only support string as comment,
   * and providing a non-string type will result in a server-side error.
   * Older server versions do not support comment for aggregate command at all,
   * and providing one will result in a server-side error.
   *
   * If a comment is provided, drivers MUST attach this comment to all
   * subsequent getMore commands run on the same cursor for server
   * versions 4.4 and above. For server versions below 4.4 drivers MUST NOT
   * attach a comment to getMore commands.
   */
  comment: Optional&lt;any&gt;;

  /**
   * The index to use for the aggregation. The hint does not apply to $lookup and $graphLookup stages.
   * Specify either the index name as a string or the index key pattern. If specified,
   * then the query system will only consider plans using the hinted index.
   *
   * This option is sent only if the caller explicitly provides a value. The default is to not send a value.
   *
   * @see https://www.mongodb.com/docs/manual/reference/command/aggregate/
   */
  hint: Optional&lt;(String | Document)&gt;;

  /**
   * Map of parameter names and values. Values must be constant or closed
   * expressions that do not reference document fields. Parameters can then be
   * accessed as variables in an aggregate expression context (e.g. "$$var").
   *
   * This option is sent only if the caller explicitly provides a value. The default is to not send a value.
   * This option is only supported by servers &gt;= 5.0. Older servers &gt;= 2.6 (and possibly earlier) will report an error for using this option.
   *
   * @see https://www.mongodb.com/docs/manual/reference/command/aggregate/
   */
  let: Optional&lt;Document&gt;;
}

class CountOptions {

  /**
   * Specifies a collation.
   *
   * This option is sent only if the caller explicitly provides a value. The default is to not send a value.
   * For servers &lt; 3.4, the driver MUST raise an error if the caller explicitly provides a value.
   */
  collation: Optional&lt;Document&gt;;

  /**
   * The index to use. Specify either the index name as a string or the index key pattern.
   * If specified, then the query system will only consider plans using the hinted index.
   *
   * This option is sent only if the caller explicitly provides a value. The default is to not send a value.
   */
  hint: Optional&lt;(String | Document)&gt;;

  /**
   * The maximum number of documents to count.
   *
   * This option is sent only if the caller explicitly provides a value. The default is to not send a value.
   */
  limit: Optional&lt;Int64&gt;;

  /**
   * The maximum amount of time to allow the operation to run.
   *
   * This option is sent only if the caller explicitly provides a value. The default is to not send a value.
   *
   * NOTE: This option is deprecated in favor of timeoutMS.
   */
  maxTimeMS: Optional&lt;Int64&gt;;

  /**
   * The number of documents to skip before counting.
   *
   * This option is sent only if the caller explicitly provides a value. The default is to not send a value.
   */
  skip: Optional&lt;Int64&gt;;

  /**
   * Enables users to specify an arbitrary comment to help trace the operation through
   * the database profiler, currentOp and logs. The default is to not send a value.
   *
   * The comment can be any valid BSON type for server versions 4.4 and above.
   * Server versions prior to 4.4 do not support comment for count command,
   * and providing one will result in a server-side error.
   */
  comment: Optional&lt;any&gt;;
}

class EstimatedDocumentCountOptions {

  /**
   * The maximum amount of time to allow the operation to run.
   *
   * This option is sent only if the caller explicitly provides a value. The default is to not send a value.
   *
   * NOTE: This option is deprecated in favor of timeoutMS.
   */
  maxTimeMS: Optional&lt;Int64&gt;;

  /**
   * Enables users to specify an arbitrary comment to help trace the operation through
   * the database profiler, currentOp and logs. The default is to not send a value.
   *
   * The comment can be any valid BSON type for server versions 4.4.14 and above.
   * For server versions between 4.4.0 and 4.4.14 string comment is supported.
   * Servers versions below 4.4.0 do not support comment for count command,
   * which is used to implement estimatedDocumentCount. Therefore, providing a
   * comment may result in a server-side error.
   */
  comment: Optional&lt;any&gt;;
}

class DistinctOptions {

  /**
   * Specifies a collation.
   *
   * This option is sent only if the caller explicitly provides a value. The default is to not send a value.
   * For servers &lt; 3.4, the driver MUST raise an error if the caller explicitly provides a value.
   *
   * @see https://www.mongodb.com/docs/manual/reference/command/distinct/
   */
  collation: Optional&lt;Document&gt;;

  /**
   * The maximum amount of time to allow the query to run.
   *
   * This option is sent only if the caller explicitly provides a value. The default is to not send a value.
   *
   * NOTE: This option is deprecated in favor of timeoutMS.
   *
   * @see https://www.mongodb.com/docs/manual/reference/command/distinct/
   */
  maxTimeMS: Optional&lt;Int64&gt;;

  /**
   * Enables users to specify an arbitrary comment to help trace the operation through
   * the database profiler, currentOp and logs. The default is to not send a value.
   *
   * The comment can be any valid BSON type for server versions 4.4 and above.
   * Server versions prior to 4.4 do not support comment for distinct command,
   * and providing one will result in a server-side error.
   */
  comment: Optional&lt;any&gt;;
}

enum CursorType {
  /**
   * The default value. A vast majority of cursors will be of this type.
   */
  NON_TAILABLE,
  /**
   * Tailable means the cursor is not closed when the last data is retrieved.
   * Rather, the cursor marks the final object’s position. You can resume
   * using the cursor later, from where it was located, if more data were
   * received. Like any "latent cursor", the cursor may become invalid at
   * some point (CursorNotFound) – for example if the final object it
   * references were deleted.
   *
   * @see https://www.mongodb.com/docs/meta-driver/latest/legacy/mongodb-wire-protocol/#op-query
   */
  TAILABLE,
  /**
   * Combines the tailable option with awaitData, as defined below.
   *
   * Use with TailableCursor. If we are at the end of the data, block for a
   * while rather than returning no data. After a timeout period, we do return
   * as normal. The default is true.
   *
   * @see https://www.mongodb.com/docs/meta-driver/latest/legacy/mongodb-wire-protocol/#op-query
   */
  TAILABLE_AWAIT
}

class FindOptions {

  /**
   * Enables writing to temporary files on the server. When set to true, the server
   * can write temporary data to disk while executing the find operation.
   *
   * This option is sent only if the caller explicitly provides a value. The default
   * is to not send a value.
   *
   * This option is only supported by servers &gt;= 4.4. Older servers &gt;= 3.2 will report an error for using this option.
   * For servers &lt; 3.2, the driver MUST raise an error if the caller explicitly provides a value.
   *
   * @see https://www.mongodb.com/docs/manual/reference/command/find/
   */
  allowDiskUse: Optional&lt;Boolean&gt;;

  /**
   * Get partial results from a mongos if some shards are down (instead of throwing an error).
   *
   * This option is sent only if the caller explicitly provides a value. The default is to not send a value.
   * For servers &lt; 3.2, the Partial wire protocol flag is used and defaults to false.
   *
   * @see https://www.mongodb.com/docs/manual/reference/command/find/
   */
  allowPartialResults: Optional&lt;Boolean&gt;;

  /**
   * The number of documents to return per batch.
   *
   * This option is sent only if the caller explicitly provides a value. The default is to not send a value.
   * For servers &lt; 3.2, this is combined with limit to create the wire protocol numberToReturn value.
   * If specified, drivers SHOULD apply this option to both the original query operation and subsequent
   * getMore operations on the cursor.
   *
   * @see https://www.mongodb.com/docs/manual/reference/command/find/
   */
  batchSize: Optional&lt;Int32&gt;;

  /**
   * Specifies a collation.
   *
   * This option is sent only if the caller explicitly provides a value. The default is to not send a value.
   * For servers &lt; 3.4, the driver MUST raise an error if the caller explicitly provides a value.
   *
   * @see https://www.mongodb.com/docs/manual/reference/command/find/
   */
  collation: Optional&lt;Document&gt;;

  /**
   * Enables users to specify an arbitrary comment to help trace the operation through
   * the database profiler, currentOp and logs. The default is to not send a value.
   *
   * The comment can be any valid BSON type for server versions 4.4 and above.
   * Server versions prior to 4.4 only support string as comment,
   * and providing a non-string type will result in a server-side error.
   *
   * If a comment is provided, drivers MUST attach this comment to all
   * subsequent getMore commands run on the same cursor for server
   * versions 4.4 and above. For server versions below 4.4 drivers MUST NOT
   * attach a comment to getMore commands.
   */
  comment: Optional&lt;any&gt;;

  /**
   * Indicates the type of cursor to use. This value includes both
   * the tailable and awaitData options.
   *
   * This option is sent only if the caller explicitly provides a value. The default is to not send a value.
   * For servers &lt; 3.2, the AwaitData and Tailable wire protocol flags are used and default to false.
   *
   * @see https://www.mongodb.com/docs/manual/reference/command/find/
   */
  cursorType: Optional&lt;CursorType&gt;;

  /**
   * The index to use. Specify either the index name as a string or the index key pattern.
   * If specified, then the query system will only consider plans using the hinted index.
   *
   * This option is sent only if the caller explicitly provides a value. The default is to not send a value.
   *
   * @see https://www.mongodb.com/docs/manual/reference/command/find/
   */
  hint: Optional&lt;(String | Document)&gt;;

  /**
   * The maximum number of documents to return.
   *
   * This option is sent only if the caller explicitly provides a value. The default is to not send a value.
   * For servers &lt; 3.2, this is combined with batchSize to create the wire protocol numberToReturn value.
   *
   * A negative limit implies that the caller has requested a single batch of results. For servers &gt;= 3.2, singleBatch
   * should be set to true and limit should be converted to a positive value. For servers &lt; 3.2, the wire protocol
   * numberToReturn value may be negative.
   *
   * @see https://www.mongodb.com/docs/manual/reference/command/find/
   */
  limit: Optional&lt;Int64&gt;;

  /**
   * The exclusive upper bound for a specific index.
   *
   * This option is sent only if the caller explicitly provides a value. The default is to not send a value.
   *
   * @see https://www.mongodb.com/docs/manual/reference/command/find/
   */
  max: Optional&lt;Document&gt;;

  /**
   * The maximum amount of time for the server to wait on new documents to satisfy a tailable cursor
   * query. This only applies to a TAILABLE_AWAIT cursor. When the cursor is not a TAILABLE_AWAIT cursor,
   * this option is ignored.
   *
   * This option is sent only if the caller explicitly provides a value. The default is to not send a value.
   * For servers &lt; 3.2, this option is ignored and not sent as maxTimeMS does not exist in the OP_GET_MORE wire protocol.
   *
   * Note: This option is specified as "maxTimeMS" in the getMore command and not provided as part of the
   * initial find command.
   *
   * @see https://www.mongodb.com/docs/manual/reference/command/find/
   */
  maxAwaitTimeMS: Optional&lt;Int64&gt;;

  /**
   * Maximum number of documents or index keys to scan when executing the query.
   *
   * This option is sent only if the caller explicitly provides a value. The default is to not send a value.
   *
   * @see https://www.mongodb.com/docs/manual/reference/command/find/
   * @deprecated 4.0
   */
  maxScan: Optional&lt;Int64&gt;;

  /**
   * The maximum amount of time to allow the query to run.
   *
   * This option is sent only if the caller explicitly provides a value. The default is to not send a value.
   *
   * NOTE: This option is deprecated in favor of timeoutMS.
   *
   * @see https://www.mongodb.com/docs/manual/reference/command/find/
   */
  maxTimeMS: Optional&lt;Int64&gt;;

  /**
   * The inclusive lower bound for a specific index.
   *
   * This option is sent only if the caller explicitly provides a value. The default is to not send a value.
   *
   * @see https://www.mongodb.com/docs/manual/reference/command/find/
   */
  min: Optional&lt;Document&gt;;

  /**
   * The server normally times out idle cursors after an inactivity period (10 minutes)
   * to prevent excess memory use. Set this option to prevent that.
   *
   * This option is sent only if the caller explicitly provides a value. The default is to not send a value.
   * For servers &lt; 3.2, the NoCursorTimeout wire protocol flag is used and defaults to false.
   *
   * @see https://www.mongodb.com/docs/manual/reference/command/find/
   */
  noCursorTimeout: Optional&lt;Boolean&gt;;

  /**
   * Enables optimization when querying the oplog for a range of ts values
   *
   * Note: this option is intended for internal replication use only.
   *
   * This option is sent only if the caller explicitly provides a value. The default is to not send a value.
   * For servers &lt; 3.2, the OplogReplay wire protocol flag is used and defaults to false.
   * For servers &gt;= 4.4, the server will ignore this option if set (see: SERVER-36186).
   *
   * @see https://www.mongodb.com/docs/manual/reference/command/find/
   * @deprecated 4.4
   */
  oplogReplay: Optional&lt;Boolean&gt;;

  /**
   * Limits the fields to return for all matching documents.
   *
   * This option is sent only if the caller explicitly provides a value. The default is to not send a value.
   *
   * @see https://www.mongodb.com/docs/manual/reference/command/find/
   */
  projection: Optional&lt;Document&gt;;

  /**
   * If true, returns only the index keys in the resulting documents.
   *
   * This option is sent only if the caller explicitly provides a value. The default is to not send a value.
   *
   * @see https://www.mongodb.com/docs/manual/reference/command/find/
   */
  returnKey: Optional&lt;Boolean&gt;;

  /**
   * Determines whether to return the record identifier for each document. If true, adds a field $recordId to the returned documents.
   *
   * This option is sent only if the caller explicitly provides a value. The default is to not send a value.
   *
   * @see https://www.mongodb.com/docs/manual/reference/command/find/
   */
  showRecordId: Optional&lt;Boolean&gt;;

  /**
   * The number of documents to skip before returning.
   *
   * This option is sent only if the caller explicitly provides a value. The default is to not send a value.
   * For servers &lt; 3.2, this is a wire protocol parameter that defaults to 0.
   *
   * @see https://www.mongodb.com/docs/manual/reference/command/find/
   */
  skip: Optional&lt;Int64&gt;;

  /**
   * Prevents the cursor from returning a document more than once because of an intervening write operation.
   *
   * This option is sent only if the caller explicitly provides a value. The default is to not send a value.
   *
   * @see https://www.mongodb.com/docs/manual/reference/command/find/
   * @deprecated 4.0
   */
  snapshot: Optional&lt;Boolean&gt;;

  /**
   * The order in which to return matching documents.
   *
   * This option is sent only if the caller explicitly provides a value. The default is to not send a value.
   *
   * @see https://www.mongodb.com/docs/manual/reference/command/find/
   */
  sort: Optional&lt;Document&gt;;

  /**
   * Map of parameter names and values. Values must be constant or closed
   * expressions that do not reference document fields. Parameters can then be
   * accessed as variables in an aggregate expression context (e.g. "$$var").
   *
   * This option is sent only if the caller explicitly provides a value. The default is to not send a value.
   * This option is only supported by servers &gt;= 5.0. Older servers &gt;= 2.6 (and possibly earlier) will report an error for using this option.
   *
   * @see https://www.mongodb.com/docs/manual/reference/command/find/
   */
  let: Optional&lt;Document&gt;;
}
</code></pre>
<h5 id="count-api-details"><a class="header" href="#count-api-details">Count API Details</a></h5>
<p>MongoDB drivers provide two helpers for counting the number of documents in a collection, estimatedDocumentCount and
countDocuments. The names were chosen to make it clear how they behave and exactly what they do. The
estimatedDocumentCount helper returns an estimate of the count of documents in the collection using collection metadata,
rather than counting the documents or consulting an index. The countDocuments helper counts the documents that match the
provided query filter using an aggregation pipeline.</p>
<p>The count() helper is deprecated. It has always been implemented using the <code>count</code> command. The behavior of the count
command differs depending on the options passed to it and may or may not provide an accurate count. When no query filter
is provided the count command provides an estimate using collection metadata. Even when provided with a query filter the
count command can return inaccurate results with a sharded cluster
<a href="https://www.mongodb.com/docs/manual/reference/command/count/#behavior">if orphaned documents exist or if a chunk migration is in progress</a>.
The countDocuments helper avoids these sharded cluster problems entirely when used with MongoDB 3.6+, and when using
<code>Primary</code> read preference with older sharded clusters.</p>
<h5 id="estimateddocumentcount"><a class="header" href="#estimateddocumentcount">estimatedDocumentCount</a></h5>
<p>The estimatedDocumentCount function is implemented using the <code>count</code> command with no query filter, skip, limit, or other
options that would alter the results. The only supported options are listed in the <code>EstimatedDocumentCountOptions</code> type
defined above.</p>
<p>Drivers MUST document that, due to an oversight in versions 5.0.0-5.0.8 of MongoDB, the <code>count</code> command, which
estimatedDocumentCount uses in its implementation, was not included in v1 of the Stable API, and so users of the Stable
API with estimatedDocumentCount are recommended to upgrade their server version to 5.0.9+ or set <code>apiStrict: false</code> to
avoid encountering errors.</p>
<p>Drivers MUST document that the <code>count</code> server command is used to implement estimatedDocumentCount and that users can
find more information via <a href="https://www.mongodb.com/docs/manual/reference/command/count/#behavior">Count: Behavior</a>.</p>
<p>The 5.0-compat versions of many drivers updated their estimatedDocumentCount implementations to use the <code>$collStats</code>
aggregation stage instead of the <code>count</code> command. This had the unintended consequence of breaking estimatedDocumentCount
on views, and so the change was seen as a backwards-incompatible regression and reverted. The release notes for the
driver versions that include the reversion from <code>$collStats</code> back to <code>count</code> MUST document the following:</p>
<ul>
<li>The 5.0-compat release accidentally broke estimatedDocumentCount on views by changing its implementation to use
<code>aggregate</code> and a <code>$collStats</code> stage instead of the <code>count</code> command.</li>
<li>The new release is fixing estimatedDocumentCount on views by reverting back to using <code>count</code> in its implementation.</li>
<li>Due to an oversight, the <code>count</code> command was omitted from the Stable API in server versions 5.0.0 - 5.0.8 and 5.1.0 -
5.3.1, so users of the Stable API with estimatedDocumentCount are recommended to upgrade their MongoDB clusters to
5.0.9 or 5.3.2 (if on Atlas) or set <code>apiStrict: false</code> when constructing their MongoClients.</li>
</ul>
<h5 id="countdocuments"><a class="header" href="#countdocuments">countDocuments</a></h5>
<p>The countDocuments function is implemented using the <code>$group</code> aggregate pipeline stage with <code>$sum</code>. Applications must be
required to pass a value for filter, but an empty document is supported:</p>
<pre><code class="language-typescript">pipeline = [{'$match': filter}]
if (skip) {
  pipeline.push({'$skip': skip})
}
if (limit) {
  pipeline.push({'$limit': limit})
}
pipeline.push({'$group': {'_id': 1, 'n': {'$sum': 1}}})
</code></pre>
<p>The count of documents is returned in the <code>n</code> field, similar to the <code>count</code> command. countDocuments options other than
filter, skip, and limit are added as options to the <code>aggregate</code> command.</p>
<p>In the event this aggregation is run against an empty collection, an empty array will be returned with no <code>n</code> field.
Drivers MUST interpret this result as a <code>0</code> count.</p>
<h5 id="combining-limit-and-batch-size-for-the-wire-protocol"><a class="header" href="#combining-limit-and-batch-size-for-the-wire-protocol">Combining Limit and Batch Size for the Wire Protocol</a></h5>
<p>The OP_QUERY wire protocol only contains a numberToReturn value which drivers must calculate to get expected limit and
batch size behavior. Subsequent calls to OP_GET_MORE should use the user-specified batchSize or default to 0. If the
result is larger than the max Int32 value, an error MUST be raised as the computed value is impossible to send to the
server. Below is pseudo-code for calculating numberToReturn for OP_QUERY.</p>
<pre><code class="language-typescript">function calculateFirstNumberToReturn(options: FindOptions): Int32 {
  Int32 numberToReturn;
  Int32 limit = options.limit || 0;
  Int32 batchSize = options.batchSize || 0;

  if (limit &lt; 0) {
    numberToReturn = limit;
  }
  else if (limit == 0) {
    numberToReturn = batchSize;
  }
  else if (batchSize == 0) {
    numberToReturn = limit;
  }
  else if (limit &lt; batchSize) {
    numberToReturn = limit;
  }
  else {
    numberToReturn = batchSize;
  }

  return numberToReturn;
}
</code></pre>
<p>Because of this anomaly in the wire protocol, it is up to the driver to enforce the user-specified limit. Each driver
MUST keep track of how many documents have been iterated and stop iterating once the limit has been reached. When the
limit has been reached, if the cursor is still open, a driver MUST kill the cursor.</p>
<h5 id="database-level-aggregation"><a class="header" href="#database-level-aggregation">Database-level aggregation</a></h5>
<p>The server supports several collection-less aggregation source stages like <code>$currentOp</code> and <code>$listLocalSessions</code>. The
database aggregate command requires a collection name of 1 for collection-less source stages. Drivers support for
database-level aggregation will allow users to receive a cursor from these collection-less aggregation source stages.</p>
<h4 id="write"><a class="header" href="#write">Write</a></h4>
<h5 id="insert-update-replace-delete-and-bulk-writes"><a class="header" href="#insert-update-replace-delete-and-bulk-writes">Insert, Update, Replace, Delete, and Bulk Writes</a></h5>
<pre><code class="language-typescript">interface Collection {

  /**
   * Executes multiple write operations.
   *
   * An error MUST be raised if the requests parameter is empty.
   *
   * For servers &lt; 3.4, if a collation was explicitly set for any request, an error MUST be raised
   * and no documents sent.
   *
   * NOTE: see the FAQ about the previous bulk API and how it relates to this.
   * @see https://www.mongodb.com/docs/manual/reference/command/delete/
   * @see https://www.mongodb.com/docs/manual/reference/command/insert/
   * @see https://www.mongodb.com/docs/manual/reference/command/update/
   * @throws InvalidArgumentException if requests is empty
   * @throws BulkWriteException
   */
  bulkWrite(requests: WriteModel[], options: Optional&lt;BulkWriteOptions&gt;): Optional&lt;BulkWriteResult&gt;;

  /**
   * Inserts the provided document. If the document is missing an identifier,
   * the driver should generate one.
   *
   * @see https://www.mongodb.com/docs/manual/reference/command/insert/
   * @throws WriteException
   */
  insertOne(document: Document, options: Optional&lt;InsertOneOptions&gt;): Optional&lt;InsertOneResult&gt;;

  /**
   * Inserts the provided documents. If any documents are missing an identifier,
   * the driver should generate them.
   *
   * An error MUST be raised if the documents parameter is empty.
   *
   * Note that this uses the bulk insert command underneath and should not
   * use OP_INSERT.
   *
   * @see https://www.mongodb.com/docs/manual/reference/command/insert/
   * @throws InvalidArgumentException if documents is empty
   * @throws BulkWriteException
   */
  insertMany(documents: Iterable&lt;Document&gt;, options: Optional&lt;InsertManyOptions&gt;): Optional&lt;InsertManyResult&gt;;

  /**
   * Deletes one document.
   *
   * @see https://www.mongodb.com/docs/manual/reference/command/delete/
   * @throws WriteException
   */
  deleteOne(filter: Document, options: Optional&lt;DeleteOptions&gt;): Optional&lt;DeleteResult&gt;;

  /**
   * Deletes multiple documents.
   *
   * @see https://www.mongodb.com/docs/manual/reference/command/delete/
   * @throws WriteException
   */
  deleteMany(filter: Document, options: Optional&lt;DeleteOptions&gt;): Optional&lt;DeleteResult&gt;;

  /**
   * Replaces a single document.
   *
   * @see https://www.mongodb.com/docs/manual/reference/command/update/
   * @throws WriteException
   */
  replaceOne(filter: Document, replacement: Document, options: Optional&lt;ReplaceOptions&gt;): Optional&lt;UpdateResult&gt;;

  /**
   * Updates one document.
   *
   * @see https://www.mongodb.com/docs/manual/reference/command/update/
   * @throws WriteException
   */
  updateOne(filter: Document, update: (Document | Document[]), options: Optional&lt;UpdateOptions&gt;): Optional&lt;UpdateResult&gt;;

  /**
   * Updates multiple documents.
   *
   * @see https://www.mongodb.com/docs/manual/reference/command/update/
   * @throws WriteException
   */
  updateMany(filter: Document, update: (Document | Document[]), options: Optional&lt;UpdateOptions&gt;): Optional&lt;UpdateResult&gt;;
}

class BulkWriteOptions {

  /**
   * If true, when a write fails, return without performing the remaining
   * writes. If false, when a write fails, continue with the remaining writes, if any.
   * Defaults to true.
   */
  ordered: Boolean;

  /**
   * If true, allows the write to opt-out of document level validation.
   *
   * This option is sent only if the caller explicitly provides a true value. The default is to not send a value.
   * For servers &lt; 3.2, this option is ignored and not sent as document validation is not available.
   * For unacknowledged writes using OP_INSERT, OP_UPDATE, or OP_DELETE, the driver MUST raise an error if the caller explicitly provides a value.
   */
  bypassDocumentValidation: Optional&lt;Boolean&gt;;

  /**
   * Enables users to specify an arbitrary comment to help trace the operation through
   * the database profiler, currentOp and logs. The default is to not send a value.
   *
   * The comment can be any valid BSON type for server versions 4.4 and above.
   * Server versions prior to 4.4 do not support comment for write operations,
   * and providing one will result in a server-side error.
   */
  comment: Optional&lt;any&gt;;

  /**
   * Map of parameter names and values. Values must be constant or closed expressions that do not
   * reference document fields. Parameters can then be accessed as variables in an aggregate
   * expression context (e.g. "$$var").
   *
   * The let parameter must be a valid Document type for server versions 5.0 and above.
   * Server versions prior to 5.0 do not support the let parameter for bulk write operations,
   * and providing it will result in a server-side error.
   *
   * The value of let will be passed to all update and delete, but not insert, commands.
   */
  let: Optional&lt;Document&gt;;
}

class InsertOneOptions {

  /**
   * If true, allows the write to opt-out of document level validation.
   *
   * This option is sent only if the caller explicitly provides a true value. The default is to not send a value.
   * For servers &lt; 3.2, this option is ignored and not sent as document validation is not available.
   * For unacknowledged writes using OP_INSERT, the driver MUST raise an error if the caller explicitly provides a value.
   */
  bypassDocumentValidation: Optional&lt;Boolean&gt;;

  /**
   * Enables users to specify an arbitrary comment to help trace the operation through
   * the database profiler, currentOp and logs. The default is to not send a value.
   *
   * The comment can be any valid BSON type for server versions 4.4 and above.
   * Server versions prior to 4.4 do not support comment for insert command,
   * and providing one will result in a server-side error.
   */
  comment: Optional&lt;any&gt;;
}

class InsertManyOptions {

  /**
   * If true, allows the write to opt-out of document level validation.
   *
   * This option is sent only if the caller explicitly provides a true value. The default is to not send a value.
   * For servers &lt; 3.2, this option is ignored and not sent as document validation is not available.
   * For unacknowledged writes using OP_INSERT, the driver MUST raise an error if the caller explicitly provides a value.
   */
  bypassDocumentValidation: Optional&lt;Boolean&gt;;

  /**
   * If true, when an insert fails, return without performing the remaining
   * writes. If false, when a write fails, continue with the remaining writes, if any.
   * Defaults to true.
   */
  ordered: Boolean;

  /**
   * Enables users to specify an arbitrary comment to help trace the operation through
   * the database profiler, currentOp and logs. The default is to not send a value.
   *
   * The comment can be any valid BSON type for server versions 4.4 and above.
   * Server versions prior to 4.4 do not support comment for insert command,
   * and providing one will result in a server-side error.
   */
  comment: Optional&lt;any&gt;;
}

class UpdateOptions {

  /**
   * A set of filters specifying to which array elements an update should apply.
   *
   * This option is sent only if the caller explicitly provides a value. The default is to not send a value.
   * For servers &lt; 3.6, the driver MUST raise an error if the caller explicitly provides a value.
   * For unacknowledged writes using OP_UPDATE, the driver MUST raise an error if the caller explicitly provides a value.
   *
   * @see https://www.mongodb.com/docs/manual/reference/command/update/
   */
  arrayFilters: Optional&lt;Array&lt;Document&gt;&gt;;

  /**
   * If true, allows the write to opt-out of document level validation.
   *
   * This option is sent only if the caller explicitly provides a true value. The default is to not send a value.
   * For servers &lt; 3.2, this option is ignored and not sent as document validation is not available.
   * For unacknowledged writes using OP_UPDATE, the driver MUST raise an error if the caller explicitly provides a value.
   */
  bypassDocumentValidation: Optional&lt;Boolean&gt;;

  /**
   * Specifies a collation.
   *
   * This option is sent only if the caller explicitly provides a value. The default is to not send a value.
   * For servers &lt; 3.4, the driver MUST raise an error if the caller explicitly provides a value.
   * For unacknowledged writes using OP_UPDATE, the driver MUST raise an error if the caller explicitly provides a value.
   *
   * @see https://www.mongodb.com/docs/manual/reference/command/update/
   */
  collation: Optional&lt;Document&gt;;

  /**
   * The index to use. Specify either the index name as a string or the index key pattern.
   * If specified, then the query system will only consider plans using the hinted index.
   *
   * This option is sent only if the caller explicitly provides a value. The default is to not send a value.
   * This option is only supported by servers &gt;= 4.2. Older servers &gt;= 3.4 will report an error for using this option.
   * For servers &lt; 3.4, the driver MUST raise an error if the caller explicitly provides a value.
   * For unacknowledged writes using OP_UPDATE, the driver MUST raise an error if the caller explicitly provides a value.
   * For unacknowledged writes using OP_MSG and servers &lt; 4.2, the driver MUST raise an error if the caller explicitly provides a value.
   *
   * @see https://www.mongodb.com/docs/manual/reference/command/update/
   */
  hint: Optional&lt;(String | Document)&gt;;

  /**
   * When true, creates a new document if no document matches the query.
   *
   * This option is sent only if the caller explicitly provides a value. The default is to not send a value.
   *
   * @see https://www.mongodb.com/docs/manual/reference/command/update/
   */
  upsert: Optional&lt;Boolean&gt;;


  /**
   * Map of parameter names and values. Values must be constant or closed
   * expressions that do not reference document fields. Parameters can then be
   * accessed as variables in an aggregate expression context (e.g. "$$var").
   *
   * This option is sent only if the caller explicitly provides a value. The default is to not send a value.
   * This option is only supported by servers &gt;= 5.0. Older servers &gt;= 2.6 (and possibly earlier) will report an error for using this option.
   *
   * @see https://www.mongodb.com/docs/manual/reference/command/update/
   */
  let: Optional&lt;Document&gt;;

  /**
   * Enables users to specify an arbitrary comment to help trace the operation through
   * the database profiler, currentOp and logs. The default is to not send a value.
   *
   * The comment can be any valid BSON type for server versions 4.4 and above.
   * Server versions prior to 4.4 do not support comment for update command,
   * and providing one will result in a server-side error.
   */
  comment: Optional&lt;any&gt;;
}

class ReplaceOptions {

  /**
   * If true, allows the write to opt-out of document level validation.
   *
   * This option is sent only if the caller explicitly provides a true value. The default is to not send a value.
   * For servers &lt; 3.2, this option is ignored and not sent as document validation is not available.
   * For unacknowledged writes using OP_UPDATE, the driver MUST raise an error if the caller explicitly provides a value.
   */
  bypassDocumentValidation: Optional&lt;Boolean&gt;;

  /**
   * Specifies a collation.
   *
   * This option is sent only if the caller explicitly provides a value. The default is to not send a value.
   * For servers &lt; 3.4, the driver MUST raise an error if the caller explicitly provides a value.
   * For unacknowledged writes using OP_UPDATE, the driver MUST raise an error if the caller explicitly provides a value.
   *
   * @see https://www.mongodb.com/docs/manual/reference/command/update/
   */
  collation: Optional&lt;Document&gt;;

  /**
   * The index to use. Specify either the index name as a string or the index key pattern.
   * If specified, then the query system will only consider plans using the hinted index.
   *
   * This option is sent only if the caller explicitly provides a value. The default is to not send a value.
   * This option is only supported by servers &gt;= 4.2. Older servers &gt;= 3.4 will report an error for using this option.
   * For servers &lt; 3.4, the driver MUST raise an error if the caller explicitly provides a value.
   * For unacknowledged writes using OP_UPDATE, the driver MUST raise an error if the caller explicitly provides a value.
   * For unacknowledged writes using OP_MSG and servers &lt; 4.2, the driver MUST raise an error if the caller explicitly provides a value.
   *
   * @see https://www.mongodb.com/docs/manual/reference/command/update/
   */
  hint: Optional&lt;(String | Document)&gt;;

  /**
   * When true, creates a new document if no document matches the query.
   *
   * This option is sent only if the caller explicitly provides a value. The default is to not send a value.
   *
   * @see https://www.mongodb.com/docs/manual/reference/command/update/
   */
  upsert: Optional&lt;Boolean&gt;;

  /**
   * Map of parameter names and values. Values must be constant or closed
   * expressions that do not reference document fields. Parameters can then be
   * accessed as variables in an aggregate expression context (e.g. "$$var").
   *
   * This option is sent only if the caller explicitly provides a value. The default is to not send a value.
   * This option is only supported by servers &gt;= 5.0. Older servers &gt;= 2.6 (and possibly earlier) will report an error for using this option.
   *
   * @see https://www.mongodb.com/docs/manual/reference/command/update/
   */
  let: Optional&lt;Document&gt;;

  /**
   * Enables users to specify an arbitrary comment to help trace the operation through
   * the database profiler, currentOp and logs. The default is to not send a value.
   *
   * The comment can be any valid BSON type for server versions 4.4 and above.
   * Server versions prior to 4.4 do not support comment for update command,
   * and providing one will result in a server-side error.
   */
  comment: Optional&lt;any&gt;;
}

class DeleteOptions {

  /**
   * Specifies a collation.
   *
   * This option is sent only if the caller explicitly provides a value. The default is to not send a value.
   * For servers &lt; 3.4, the driver MUST raise an error if the caller explicitly provides a value.
   * For unacknowledged writes using OP_DELETE, the driver MUST raise an error if the caller explicitly provides a value.
   *
   * @see https://www.mongodb.com/docs/manual/reference/command/delete/
   */
  collation: Optional&lt;Document&gt;;

  /**
   * The index to use. Specify either the index name as a string or the index key pattern.
   * If specified, then the query system will only consider plans using the hinted index.
   *
   * This option is sent only if the caller explicitly provides a value. The default is to not send a value.
   * This option is only supported by servers &gt;= 4.4. Older servers &gt;= 3.4 will report an error for using this option.
   * For servers &lt; 3.4, the driver MUST raise an error if the caller explicitly provides a value.
   * For unacknowledged writes using OP_DELETE, the driver MUST raise an error if the caller explicitly provides a value.
   * For unacknowledged writes using OP_MSG and servers &lt; 4.4, the driver MUST raise an error if the caller explicitly provides a value.
   *
   * @see https://www.mongodb.com/docs/manual/reference/command/delete/
   */
  hint: Optional&lt;(String | Document)&gt;;

  /**
   * Map of parameter names and values. Values must be constant or closed
   * expressions that do not reference document fields. Parameters can then be
   * accessed as variables in an aggregate expression context (e.g. "$$var").
   *
   * This option is sent only if the caller explicitly provides a value. The default is to not send a value.
   * This option is only supported by servers &gt;= 5.0. Older servers &gt;= 2.6 (and possibly earlier) will report an error for using this option.
   *
   * @see https://www.mongodb.com/docs/manual/reference/command/delete/
   */
  let: Optional&lt;Document&gt;;

  /**
   * Enables users to specify an arbitrary comment to help trace the operation through
   * the database profiler, currentOp and logs. The default is to not send a value.
   *
   * The comment can be any valid BSON type for server versions 4.4 and above.
   * Server versions prior to 4.4 do not support comment for delete command,
   * and providing one will result in a server-side error.
   */
  comment: Optional&lt;any&gt;;
}
</code></pre>
<h6 id="bulk-write-models"><a class="header" href="#bulk-write-models">Bulk Write Models</a></h6>
<pre><code class="language-typescript">interface WriteModel {
  // marker interface for writes that can be batched together.
}

class InsertOneModel implements WriteModel {

  /**
   * The document to insert.
   *
   * @see https://www.mongodb.com/docs/manual/reference/command/insert/
   */
  document: Document;
}

class DeleteOneModel implements WriteModel {

  /**
   * The filter to limit the deleted documents.
   *
   * @see https://www.mongodb.com/docs/manual/reference/command/delete/
   */
  filter: Document;

  /**
   * Specifies a collation.
   *
   * This option is sent only if the caller explicitly provides a value. The default is to not send a value.
   * For servers &lt; 3.4, the driver MUST raise an error if the caller explicitly provides a value.
   * For unacknowledged writes using OP_DELETE, the driver MUST raise an error if the caller explicitly provides a value.
   *
   * @see https://www.mongodb.com/docs/manual/reference/command/delete/
   */
  collation: Optional&lt;Document&gt;;

  /**
   * The index to use. Specify either the index name as a string or the index key pattern.
   * If specified, then the query system will only consider plans using the hinted index.
   *
   * This option is sent only if the caller explicitly provides a value. The default is to not send a value.
   * This option is only supported by servers &gt;= 4.4. Older servers &gt;= 3.4 will report an error for using this option.
   * For servers &lt; 3.4, the driver MUST raise an error if the caller explicitly provides a value.
   * For unacknowledged writes using OP_DELETE, the driver MUST raise an error if the caller explicitly provides a value.
   * For unacknowledged writes using OP_MSG and servers &lt; 4.4, the driver MUST raise an error if the caller explicitly provides a value.
   *
   * @see https://www.mongodb.com/docs/manual/reference/command/delete/
   */
  hint: Optional&lt;(String | Document)&gt;;
}

class DeleteManyModel implements WriteModel {

  /**
   * The filter to limit the deleted documents.
   *
   * @see https://www.mongodb.com/docs/manual/reference/command/delete/
   */
  filter: Document;

  /**
   * Specifies a collation.
   *
   * This option is sent only if the caller explicitly provides a value. The default is to not send a value.
   * For servers &lt; 3.4, the driver MUST raise an error if the caller explicitly provides a value.
   * For unacknowledged writes using OP_DELETE, the driver MUST raise an error if the caller explicitly provides a value.
   *
   * @see https://www.mongodb.com/docs/manual/reference/command/delete/
   */
  collation: Optional&lt;Document&gt;;

  /**
   * The index to use. Specify either the index name as a string or the index key pattern.
   * If specified, then the query system will only consider plans using the hinted index.
   *
   * This option is sent only if the caller explicitly provides a value. The default is to not send a value.
   * This option is only supported by servers &gt;= 4.4. Older servers &gt;= 3.4 will report an error for using this option.
   * For servers &lt; 3.4, the driver MUST raise an error if the caller explicitly provides a value.
   * For unacknowledged writes using OP_DELETE or OP_MSG, the driver MUST raise an error if the caller explicitly provides a value.
   *
   * @see https://www.mongodb.com/docs/manual/reference/command/delete/
   */
  hint: Optional&lt;(String | Document)&gt;;
}

class ReplaceOneModel implements WriteModel {

  /**
   * The filter to limit the replaced document.
   *
   * @see https://www.mongodb.com/docs/manual/reference/command/update/
   */
  filter: Document;

  /**
   * The document with which to replace the matched document.
   *
   * @see https://www.mongodb.com/docs/manual/reference/command/update/
   */
  replacement: Document;

  /**
   * Specifies a collation.
   *
   * This option is sent only if the caller explicitly provides a value. The default is to not send a value.
   * For servers &lt; 3.4, the driver MUST raise an error if the caller explicitly provides a value.
   * For unacknowledged writes using OP_UPDATE, the driver MUST raise an error if the caller explicitly provides a value.
   *
   * @see https://www.mongodb.com/docs/manual/reference/command/update/
   */
  collation: Optional&lt;Document&gt;;

  /**
   * The index to use. Specify either the index name as a string or the index key pattern.
   * If specified, then the query system will only consider plans using the hinted index.
   *
   * This option is sent only if the caller explicitly provides a value. The default is to not send a value.
   * This option is only supported by servers &gt;= 4.2. Older servers &gt;= 3.4 will report an error for using this option.
   * For servers &lt; 3.4, the driver MUST raise an error if the caller explicitly provides a value.
   * For unacknowledged writes using OP_UPDATE, the driver MUST raise an error if the caller explicitly provides a value.
   * For unacknowledged writes using OP_MSG and servers &lt; 4.2, the driver MUST raise an error if the caller explicitly provides a value.
   *
   * @see https://www.mongodb.com/docs/manual/reference/command/update/
   */
  hint: Optional&lt;(String | Document)&gt;;

  /**
   * When true, creates a new document if no document matches the query.
   *
   * This option is sent only if the caller explicitly provides a value. The default is to not send a value.
   *
   * @see https://www.mongodb.com/docs/manual/reference/command/update/
   */
  upsert: Optional&lt;Boolean&gt;;
}

class UpdateOneModel implements WriteModel {

  /**
   * The filter to limit the updated documents.
   *
   * @see https://www.mongodb.com/docs/manual/reference/command/update/
   */
  filter: Document;

  /**
   * A document or pipeline containing update operators.
   *
   * @see https://www.mongodb.com/docs/manual/reference/command/update/
   */
  update: (Document | Document[]);

  /**
   * A set of filters specifying to which array elements an update should apply.
   *
   * This option is sent only if the caller explicitly provides a value. The default is to not send a value.
   * For servers &lt; 3.6, the driver MUST raise an error if the caller explicitly provides a value.
   * For unacknowledged writes using OP_UPDATE, the driver MUST raise an error if the caller explicitly provides a value.
   *
   * @see https://www.mongodb.com/docs/manual/reference/command/update/
   */
  arrayFilters: Optional&lt;Array&lt;Document&gt;&gt;;

  /**
   * Specifies a collation.
   *
   * This option is sent only if the caller explicitly provides a value. The default is to not send a value.
   * For servers &lt; 3.4, the driver MUST raise an error if the caller explicitly provides a value.
   * For unacknowledged writes using OP_UPDATE, the driver MUST raise an error if the caller explicitly provides a value.
   *
   * @see https://www.mongodb.com/docs/manual/reference/command/update/
   */
  collation: Optional&lt;Document&gt;;

  /**
   * The index to use. Specify either the index name as a string or the index key pattern.
   * If specified, then the query system will only consider plans using the hinted index.
   *
   * This option is sent only if the caller explicitly provides a value. The default is to not send a value.
   * This option is only supported by servers &gt;= 4.2. Older servers &gt;= 3.4 will report an error for using this option.
   * For servers &lt; 3.4, the driver MUST raise an error if the caller explicitly provides a value.
   * For unacknowledged writes using OP_UPDATE, the driver MUST raise an error if the caller explicitly provides a value.
   * For unacknowledged writes using OP_MSG and servers &lt; 4.2, the driver MUST raise an error if the caller explicitly provides a value.
   *
   * @see https://www.mongodb.com/docs/manual/reference/command/update/
   */
  hint: Optional&lt;(String | Document)&gt;;

  /**
   * When true, creates a new document if no document matches the query.
   *
   * This option is sent only if the caller explicitly provides a value. The default is to not send a value.
   *
   * @see https://www.mongodb.com/docs/manual/reference/command/update/
   */
  upsert: Optional&lt;Boolean&gt;;
}

class UpdateManyModel implements WriteModel {

  /**
   * The filter to limit the updated documents.
   *
   * @see https://www.mongodb.com/docs/manual/reference/command/update/
   */
  filter: Document;

  /**
   * A document or pipeline containing update operators.
   *
   * @see https://www.mongodb.com/docs/manual/reference/command/update/
   */
  update: (Document | Document[]);

  /**
   * A set of filters specifying to which array elements an update should apply.
   *
   * This option is sent only if the caller explicitly provides a value. The default is to not send a value.
   * For servers &lt; 3.6, the driver MUST raise an error if the caller explicitly provides a value.
   * For unacknowledged writes using OP_UPDATE, the driver MUST raise an error if the caller explicitly provides a value.
   *
   * @see https://www.mongodb.com/docs/manual/reference/command/update/
   */
  arrayFilters: Optional&lt;Array&lt;Document&gt;&gt;;

  /**
   * Specifies a collation.
   *
   * This option is sent only if the caller explicitly provides a value. The default is to not send a value.
   * For servers &lt; 3.4, the driver MUST raise an error if the caller explicitly provides a value.
   * For unacknowledged writes using OP_UPDATE, the driver MUST raise an error if the caller explicitly provides a value.
   *
   * @see https://www.mongodb.com/docs/manual/reference/command/update/
   */
  collation: Optional&lt;Document&gt;;

  /**
   * The index to use. Specify either the index name as a string or the index key pattern.
   * If specified, then the query system will only consider plans using the hinted index.
   *
   * This option is sent only if the caller explicitly provides a value. The default is to not send a value.
   * This option is only supported by servers &gt;= 4.2. Older servers &gt;= 3.4 will report an error for using this option.
   * For servers &lt; 3.4, the driver MUST raise an error if the caller explicitly provides a value.
   * For unacknowledged writes using OP_UPDATE, the driver MUST raise an error if the caller explicitly provides a value.
   * For unacknowledged writes using OP_MSG and servers &lt; 4.2, the driver MUST raise an error if the caller explicitly provides a value.
   *
   * @see https://www.mongodb.com/docs/manual/reference/command/update/
   */
  hint: Optional&lt;(String | Document)&gt;;

  /**
   * When true, creates a new document if no document matches the query.
   *
   * This option is sent only if the caller explicitly provides a value. The default is to not send a value.
   *
   * @see https://www.mongodb.com/docs/manual/reference/command/update/
   */
  upsert: Optional&lt;Boolean&gt;;
}
</code></pre>
<h6 id="write-results"><a class="header" href="#write-results">Write Results</a></h6>
<p>The acknowledged property is defined for languages/frameworks without a sufficient optional type. Hence, a driver may
choose to return an optional result (e.g. <code>Optional&lt;BulkWriteResult&gt;</code>) such that unacknowledged writes don't have a
value and acknowledged writes do have a value.</p>
<blockquote>
<p>[!NOTE]
If you have a choice, consider providing the acknowledged member and raising an error if the other fields are accessed
in an unacknowledged write. Instead of users receiving a null reference exception, you have the opportunity to provide
an informative error message indicating the correct way to handle the situation. For instance, "The insertedCount
member is not available when the write was unacknowledged. Check the acknowledged member to avoid this error."</p>
</blockquote>
<p>Any result class with all parameters marked NOT REQUIRED is ultimately NOT REQUIRED as well. For instance, the
<code>InsertOneResult</code> has all NOT REQUIRED parameters and is therefore also NOT REQUIRED allowing a driver to use "void" as
the return value for the <code>insertOne</code> method.</p>
<pre><code class="language-typescript">class BulkWriteResult {

  /**
   * Indicates whether this write result was acknowledged. If not, then all
   * other members of this result will be undefined.
   *
   * NOT REQUIRED: Drivers may choose to not provide this property.
   */
  acknowledged: Boolean;

  /**
   * Number of documents inserted.
   */
  insertedCount: Int64;

  /**
   * Map of the index of the operation to the id of the inserted document.
   *
   * NOT REQUIRED: Drivers may choose to not provide this property.
   */
  insertedIds: Map&lt;Int64, any&gt;;

  /**
   * Number of documents matched for update.
   */
  matchedCount: Int64;

  /**
   * Number of documents modified.
   */
  modifiedCount: Int64;

  /**
   * Number of documents deleted.
   */
  deletedCount: Int64;

  /**
   * Number of documents upserted.
   */
  upsertedCount: Int64;

  /**
   * Map of the index of the operation to the id of the upserted document.
   */
  upsertedIds: Map&lt;Int64, any&gt;;

}

/**
 * Note: this class is "NOT REQUIRED" since all of its fields are marked
 * "NOT REQUIRED". Drivers that do not implement this class SHOULD use void
 * as the return type for insertOne.
 */
class InsertOneResult {

  /**
   * Indicates whether this write result was acknowledged. If not, then all
   * other members of this result will be undefined.
   *
   * NOT REQUIRED: Drivers may choose to not provide this property.
   */
  acknowledged: Boolean;

  /**
   * The identifier that was inserted. If the server generated the identifier, this value
   * will be null as the driver does not have access to that data.
   *
   * NOT REQUIRED: Drivers may choose to not provide this property.
   */
  insertedId: any;

}

/**
 * Note: this class is "NOT REQUIRED" since all of its fields are marked
 * "NOT REQUIRED". Drivers that do not implement this class SHOULD use void
 * as the return type for insertMany.
 */
class InsertManyResult {

  /**
   * Indicates whether this write result was acknowledged. If not, then all
   * other members of this result will be undefined.
   *
   * NOT REQUIRED: Drivers may choose to not provide this property.
   */
  acknowledged: Boolean;

  /**
   * Map of the index of the inserted document to the id of the inserted document.
   *
   * NOT REQUIRED: Drivers may choose to not provide this property.
   */
  insertedIds: Map&lt;Int64, any&gt;;

}

class DeleteResult {

  /**
   * Indicates whether this write result was acknowledged. If not, then all
   * other members of this result will be undefined.
   *
   * NOT REQUIRED: Drivers may choose to not provide this property.
   */
  acknowledged: Boolean;

  /**
   * The number of documents that were deleted.
   */
  deletedCount: Int64;

}

class UpdateResult {

  /**
   * Indicates whether this write result was acknowledged. If not, then all
   * other members of this result will be undefined.
   *
   * NOT REQUIRED: Drivers may choose to not provide this property.
   */
  acknowledged: Boolean;

  /**
   * The number of documents that matched the filter.
   */
  matchedCount: Int64;

  /**
   * The number of documents that were modified.
   */
  modifiedCount: Int64;

  /**
   * The number of documents that were upserted.
   *
   * NOT REQUIRED: Drivers may choose to not provide this property so long as
   * it is always possible to infer whether an upsert has taken place. Since
   * the "_id" of an upserted document could be null, a null "upsertedId" may
   * be ambiguous in some drivers. If so, this field can be used to indicate
   * whether an upsert has taken place.
   */
  upsertedCount: Int64;

  /**
   * The identifier of the inserted document if an upsert took place.
   */
  upsertedId: any;

}
</code></pre>
<h5 id="error-handling-3"><a class="header" href="#error-handling-3">Error Handling</a></h5>
<p>Defined below are error and exception types that should be reported from the various write methods. Since error types
across languages would be impossible to reconcile, the below definitions represent the fields and names for the
information that should be present. Structure isn't important as long as the information is available.</p>
<p>Drivers SHOULD report errors however they report other server errors: by raising an exception, returning "false" and
populating an error struct, or another idiom that is consistent with other server errors.</p>
<h6 id="writeconcernerror"><a class="header" href="#writeconcernerror">WriteConcernError</a></h6>
<pre><code class="language-typescript">class WriteConcernError {

  /**
   * An integer value identifying the write concern error. Corresponds to the
   * "writeConcernError.code" field in the command response.
   *
   * @see https://www.mongodb.com/docs/manual/reference/method/WriteResult/
   */
  code: Int32;

  /**
   * A document identifying the write concern setting related to the error.
   * Corresponds to the "writeConcernError.errInfo" field in the command
   * response.
   *
   * @see https://www.mongodb.com/docs/manual/reference/method/WriteResult/
   */
  details: Document;

  /**
   * A description of the error. Corresponds to the
   * "writeConcernError.errmsg" field in the command response.
   *
   * @see https://www.mongodb.com/docs/manual/reference/method/WriteResult/
   */
  message: String;

}
</code></pre>
<p>Drivers MUST construct a <code>WriteConcernError</code> from a server reply as follows:</p>
<ul>
<li>Set <code>code</code> to <code>writeConcernError.code</code>.</li>
<li>Set <code>message</code> to <code>writeConcernError.errmsg</code> if available.</li>
<li>Set <code>details</code> to <code>writeConcernError.errInfo</code> if available. Drivers MUST NOT parse inside <code>errInfo</code>.</li>
</ul>
<p>See <a href="crud/../read-write-concern/read-write-concern.html#writeconcernerror-examples">writeConcernError Examples</a> in the
Read/Write Concern spec for examples of how a server represents write concern errors in replies.</p>
<h6 id="writeerror"><a class="header" href="#writeerror">WriteError</a></h6>
<p>Write errors for <code>insert</code>, <code>update</code>, and <code>delete</code> commands are reported as objects within a <code>writeErrors</code> array field in
the command response. Drivers MUST construct a <code>WriteError</code> from a server reply as follows (where <code>writeErrors[]</code> refers
to a particular element in the array):</p>
<ul>
<li>Set <code>code</code> to <code>writeErrors[].code</code>.</li>
<li>Set <code>message</code> to <code>writeErrors[].errmsg</code> if available.</li>
<li>Set <code>details</code> to <code>writeErrors[].errInfo</code> if available. Drivers MUST NOT parse inside <code>errInfo</code>.</li>
</ul>
<p>For single-statement writes (i.e. <code>insertOne</code>, <code>updateOne</code>, <code>updateMany</code>, <code>replaceOne</code>, <code>deleteOne</code>, and <code>deleteMany</code>),
a single write error may be reported in the array and <code>writeErrors[0].index</code> will be zero.</p>
<p>For multi-statement writes (i.e. <code>insertMany</code> and <code>bulkWrite</code>), potentially many write errors may be reported in the
array and the <code>index</code> property will be set accordingly. Since the reported <code>index</code> is specific to each command, drivers
MUST adjust the index accordingly for <code>BulkWriteError.index</code>.</p>
<pre><code class="language-typescript">class WriteError {

  /**
   * An integer value identifying the write error. Corresponds to the
   * "writeErrors[].code" field in the command response.
   *
   * @see https://www.mongodb.com/docs/manual/reference/method/WriteResult/
   */
  code: Int32;

  /**
   * A document providing more information about the write error (e.g. details
   * pertaining to document validation). Corresponds to the
   * "writeErrors[].errInfo" field in the command response.
   *
   * @see https://www.mongodb.com/docs/manual/reference/method/WriteResult/
   */
  details: Document;

  /**
   * A description of the error. Corresponds to the "writeErrors[].errmsg"
   * field in the command response.
   *
   * @see https://www.mongodb.com/docs/manual/reference/method/WriteResult/
   */
  message: String;

}

class BulkWriteError : WriteError {

  /**
   * The index of the request that errored. This is derived in part from the
   * "writeErrors[].index" field in the command response; however, drivers
   * MUST adjust the index accordingly for bulk writes that execute multiple
   * writes commands.
   */
  index: Int32;

  /**
   * The request that errored.
   *
   * NOT REQUIRED: Drivers may choose to not provide this property.
   */
  request: Optional&lt;WriteModel&gt;;

}

/**
 * NOTE: Only one of writeConcernError or writeError will be populated at a time. Your driver must present the offending
 * error to the user.
 */
class WriteException {

  /**
   * The error that occurred on account of write concern failure.
   */
  writeConcernError: Optional&lt;WriteConcernError&gt;;

  /**
   * The error that occurred on account of a non-write concern failure.
   */
  writeError: Optional&lt;WriteError&gt;;

}

class BulkWriteException {

  /**
   * The requests that were sent to the server.
   *
   * NOT REQUIRED: Drivers may choose to not provide this property.
   */
  processedRequests: Optional&lt;Iterable&lt;WriteModel&gt;&gt;;

  /**
   * The requests that were not sent to the server.
   *
   * NOT REQUIRED: Drivers may choose to not provide this property.
   */
  unprocessedRequests: Optional&lt;Iterable&lt;WriteModel&gt;&gt;;

  /**
   * The intermediary write result for any operations that succeeded before
   * the bulk write was interrupted.
   *
   * NOT REQUIRED: Drivers may choose to not provide this property.
   */
  writeResult: Optional&lt;BulkWriteResult&gt;;

  /**
   * The error that occurred on account of write concern failure. If the error was a Write Concern related, this field must be present.
   */
  writeConcernError: Optional&lt;WriteConcernError&gt;;

  /**
   * The error that occurred on account of a non-write concern failure. This might be empty if the error was a Write Concern related error.
   */
  writeErrors: Optional&lt;Iterable&lt;BulkWriteError&gt;&gt;;

}
</code></pre>
<p><span id="find"></span></p>
<h5 id="find-and-modify"><a class="header" href="#find-and-modify">Find And Modify</a></h5>
<pre><code class="language-typescript">interface Collection {

  /**
   * Finds a single document and deletes it, returning the original. The document to return may be null.
   *
   * @see https://www.mongodb.com/docs/manual/reference/command/findAndModify/
   * @throws WriteException
   */
  findOneAndDelete(filter: Document, options: Optional&lt;FindOneAndDeleteOptions&gt;): Optional&lt;Document&gt;;

  /**
   * Finds a single document and replaces it, returning either the original or the replaced
   * document. The document to return may be null.
   *
   * @see https://www.mongodb.com/docs/manual/reference/command/findAndModify/
   * @throws WriteException
   */
  findOneAndReplace(filter: Document, replacement: Document, options: Optional&lt;FindOneAndReplaceOptions&gt;): Optional&lt;Document&gt;;

  /**
   * Finds a single document and updates it, returning either the original or the updated
   * document. The document to return may be null.
   *
   * @see https://www.mongodb.com/docs/manual/reference/command/findAndModify/
   * @throws WriteException
   */
  findOneAndUpdate(filter: Document, update: (Document | Document[]), options: Optional&lt;FindOneAndUpdateOptions&gt;): Optional&lt;Document&gt;;

}

enum ReturnDocument {
  /**
   * Indicates to return the document before the update, replacement, or insert occurred.
   */
   BEFORE,
  /**
   * Indicates to return the document after the update, replacement, or insert occurred.
   */
   AFTER
}

class FindOneAndDeleteOptions {

  /**
   * Specifies a collation.
   *
   * This option is sent only if the caller explicitly provides a value. The default is to not send a value.
   * For servers &lt; 3.4, the driver MUST raise an error if the caller explicitly provides a value.
   *
   * @see https://www.mongodb.com/docs/manual/reference/command/findAndModify/
   */
  collation: Optional&lt;Document&gt;;

  /**
   * The index to use. Specify either the index name as a string or the index key pattern.
   * If specified, then the query system will only consider plans using the hinted index.
   *
   * This option is sent only if the caller explicitly provides a value. The default is to not send a value.
   * This option is only supported by servers &gt;= 4.4. Older servers &gt;= 4.2 will report an error for using this option.
   * For servers &lt; 4.2, the driver MUST raise an error if the caller explicitly provides a value.
   * For unacknowledged writes and servers &lt; 4.4, the driver MUST raise an error if the caller explicitly provides a value.
   *
   * @see https://www.mongodb.com/docs/manual/reference/command/findAndModify/
   */
  hint: Optional&lt;(String | Document)&gt;;

  /**
   * The maximum amount of time to allow the query to run.
   *
   * This option is sent only if the caller explicitly provides a value. The default is to not send a value.
   *
   * NOTE: This option is deprecated in favor of timeoutMS.
   *
   * @see https://www.mongodb.com/docs/manual/reference/command/findAndModify/
   */
  maxTimeMS: Optional&lt;Int64&gt;;

  /**
   * Limits the fields to return for all matching documents.
   *
   * This option is sent only if the caller explicitly provides a value. The default is to not send a value.
   *
   * Note: this option is mapped to the "fields" findAndModify command option.
   *
   * @see https://www.mongodb.com/docs/manual/tutorial/project-fields-from-query-results
   */
  projection: Optional&lt;Document&gt;;

  /**
   * Determines which document the operation modifies if the query selects multiple documents.
   *
   * This option is sent only if the caller explicitly provides a value. The default is to not send a value.
   *
   * @see https://www.mongodb.com/docs/manual/reference/command/findAndModify/
   */
  sort: Optional&lt;Document&gt;;

  /**
   * Map of parameter names and values. Values must be constant or closed
   * expressions that do not reference document fields. Parameters can then be
   * accessed as variables in an aggregate expression context (e.g. "$$var").
   *
   * This option is sent only if the caller explicitly provides a value. The default is to not send a value.
   * This option is only supported by servers &gt;= 5.0. Older servers &gt;= 2.6 (and possibly earlier) will report an error for using this option.
   *
   * @see https://www.mongodb.com/docs/manual/reference/command/findAndModify/
   */
  let: Optional&lt;Document&gt;;

  /**
   * Enables users to specify an arbitrary comment to help trace the operation through
   * the database profiler, currentOp and logs. The default is to not send a value.
   *
   * The comment can be any valid BSON type for server versions 4.4 and above.
   * Server versions prior to 4.4 do not support comment for findAndModify command,
   * and providing one will result in a server-side error.
   */
  comment: Optional&lt;any&gt;;
}

class FindOneAndReplaceOptions {

  /**
   * If true, allows the write to opt-out of document level validation.
   *
   * This option is sent only if the caller explicitly provides a true value. The default is to not send a value.
   * For servers &lt; 3.2, this option is ignored and not sent as document validation is not available.
   */
  bypassDocumentValidation: Optional&lt;Boolean&gt;;

  /**
   * Specifies a collation.
   *
   * This option is sent only if the caller explicitly provides a value. The default is to not send a value.
   * For servers &lt; 3.4, the driver MUST raise an error if the caller explicitly provides a value.
   *
   * @see https://www.mongodb.com/docs/manual/reference/command/findAndModify/
   */
  collation: Optional&lt;Document&gt;;

  /**
   * The index to use. Specify either the index name as a string or the index key pattern.
   * If specified, then the query system will only consider plans using the hinted index.
   *
   * This option is sent only if the caller explicitly provides a value. The default is to not send a value.
   * This option is only supported by servers &gt;= 4.4. Older servers &gt;= 4.2 will report an error for using this option.
   * For servers &lt; 4.2, the driver MUST raise an error if the caller explicitly provides a value.
   * For unacknowledged writes and servers &lt; 4.4, the driver MUST raise an error if the caller explicitly provides a value.
   *
   * @see https://www.mongodb.com/docs/manual/reference/command/findAndModify/
   */
  hint: Optional&lt;(String | Document)&gt;;

  /**
   * The maximum amount of time to allow the query to run.
   *
   * This option is sent only if the caller explicitly provides a value. The default is to not send a value.
   *
   * NOTE: This option is deprecated in favor of timeoutMS.
   *
   * @see https://www.mongodb.com/docs/manual/reference/command/findAndModify/
   */
  maxTimeMS: Optional&lt;Int64&gt;;

  /**
   * Limits the fields to return for all matching documents.
   *
   * This option is sent only if the caller explicitly provides a value. The default is to not send a value.
   *
   * Note: this option is mapped to the "fields" findAndModify command option.
   *
   * @see https://www.mongodb.com/docs/manual/tutorial/project-fields-from-query-results
   */
  projection: Optional&lt;Document&gt;;

  /**
   * When ReturnDocument.After, returns the replaced or inserted document rather than the original.
   *
   * This option is sent only if the caller explicitly provides a value. The default is to not send a value.
   *
   * Note: this option is mapped to the "new" findAndModify boolean field. ReturnDocument.Before represents false,
   * and ReturnDocument.After represents true.
   *
   * @see https://www.mongodb.com/docs/manual/reference/command/findAndModify/
   */
  returnDocument: Optional&lt;ReturnDocument&gt;;

  /**
   * Determines which document the operation modifies if the query selects multiple documents.
   *
   * This option is sent only if the caller explicitly provides a value. The default is to not send a value.
   *
   * @see https://www.mongodb.com/docs/manual/reference/command/findAndModify/
   */
  sort: Optional&lt;Document&gt;;

  /**
   * When true, findAndModify creates a new document if no document matches the query.
   *
   * This option is sent only if the caller explicitly provides a value. The default is to not send a value.
   *
   * @see https://www.mongodb.com/docs/manual/reference/command/findAndModify/
   */
  upsert: Optional&lt;Boolean&gt;;

  /**
   * Map of parameter names and values. Values must be constant or closed
   * expressions that do not reference document fields. Parameters can then be
   * accessed as variables in an aggregate expression context (e.g. "$$var").
   *
   * This option is sent only if the caller explicitly provides a value. The default is to not send a value.
   * This option is only supported by servers &gt;= 5.0. Older servers &gt;= 2.6 (and possibly earlier) will report an error for using this option.
   *
   * @see https://www.mongodb.com/docs/manual/reference/command/findAndModify/
   */
  let: Optional&lt;Document&gt;;

  /**
   * Enables users to specify an arbitrary comment to help trace the operation through
   * the database profiler, currentOp and logs. The default is to not send a value.
   *
   * The comment can be any valid BSON type for server versions 4.4 and above.
   * Server versions prior to 4.4 do not support comment for findAndModify command,
   * and providing one will result in a server-side error.
   */
  comment: Optional&lt;any&gt;;
}

class FindOneAndUpdateOptions {

  /**
   * A set of filters specifying to which array elements an update should apply.
   *
   * This option is sent only if the caller explicitly provides a value. The default is to not send a value.
   * For servers &lt; 3.6, the driver MUST raise an error if the caller explicitly provides a value.
   *
   * @see https://www.mongodb.com/docs/manual/reference/command/update/
   */
  arrayFilters: Optional&lt;Array&lt;Document&gt;&gt;;

  /**
   * If true, allows the write to opt-out of document level validation.
   *
   * This option is sent only if the caller explicitly provides a true value. The default is to not send a value.
   * For servers &lt; 3.2, this option is ignored and not sent as document validation is not available.
   */
  bypassDocumentValidation: Optional&lt;Boolean&gt;;

  /**
   * Specifies a collation.
   *
   * This option is sent only if the caller explicitly provides a value. The default is to not send a value.
   * For servers &lt; 3.4, the driver MUST raise an error if the caller explicitly provides a value.
   *
   * @see https://www.mongodb.com/docs/manual/reference/command/findAndModify/
   */
  collation: Optional&lt;Document&gt;;

  /**
   * The index to use. Specify either the index name as a string or the index key pattern.
   * If specified, then the query system will only consider plans using the hinted index.
   *
   * This option is sent only if the caller explicitly provides a value. The default is to not send a value.
   * This option is only supported by servers &gt;= 4.4. Older servers &gt;= 4.2 will report an error for using this option.
   * For servers &lt; 4.2, the driver MUST raise an error if the caller explicitly provides a value.
   * For unacknowledged writes and servers &lt; 4.4, the driver MUST raise an error if the caller explicitly provides a value.
   *
   * @see https://www.mongodb.com/docs/manual/reference/command/findAndModify/
   */
  hint: Optional&lt;(String | Document)&gt;;

  /**
   * The maximum amount of time to allow the query to run.
   *
   * NOTE: This option is deprecated in favor of timeoutMS.
   *
   * @see https://www.mongodb.com/docs/manual/reference/command/findAndModify/
   */
  maxTimeMS: Optional&lt;Int64&gt;;

  /**
   * Limits the fields to return for all matching documents.
   *
   * This option is sent only if the caller explicitly provides a value. The default is to not send a value.
   *
   * Note: this option is mapped to the "fields" findAndModify command option.
   *
   * @see https://www.mongodb.com/docs/manual/tutorial/project-fields-from-query-results
   */
  projection: Optional&lt;Document&gt;;

  /**
   * When ReturnDocument.After, returns the replaced or inserted document rather than the original.
   *
   * This option is sent only if the caller explicitly provides a value. The default is to not send a value.
   *
   * Note: this option is mapped to the "new" findAndModify boolean field. ReturnDocument.Before represents false,
   * and ReturnDocument.After represents true.
   *
   * @see https://www.mongodb.com/docs/manual/reference/command/findAndModify/
   */
  returnDocument: Optional&lt;ReturnDocument&gt;;

  /**
   * Determines which document the operation modifies if the query selects multiple documents.
   *
   * This option is sent only if the caller explicitly provides a value. The default is to not send a value.
   *
   * @see https://www.mongodb.com/docs/manual/reference/command/findAndModify/
   */
  sort: Optional&lt;Document&gt;;

  /**
   * When true, creates a new document if no document matches the query.
   *
   * This option is sent only if the caller explicitly provides a value. The default is to not send a value.
   *
   * @see https://www.mongodb.com/docs/manual/reference/command/findAndModify/
   */
  upsert: Optional&lt;Boolean&gt;;

  /**
   * Map of parameter names and values. Values must be constant or closed
   * expressions that do not reference document fields. Parameters can then be
   * accessed as variables in an aggregate expression context (e.g. "$$var").
   *
   * This option is sent only if the caller explicitly provides a value. The default is to not send a value.
   * This option is only supported by servers &gt;= 5.0. Older servers &gt;= 2.6 (and possibly earlier) will report an error for using this option.
   *
   * @see https://www.mongodb.com/docs/manual/reference/command/findAndModify/
   */
  let: Optional&lt;Document&gt;;

  /**
   * Enables users to specify an arbitrary comment to help trace the operation through
   * the database profiler, currentOp and logs. The default is to not send a value.
   *
   *
   * The comment can be any valid BSON type for server versions 4.4 and above.
   * Server versions prior to 4.4 do not support comment for findAndModify command,
   * and providing one will result in a server-side error.
   */
  comment: Optional&lt;any&gt;;
}
</code></pre>
<h5 id="update-vs-replace-validation"><a class="header" href="#update-vs-replace-validation">Update vs. Replace Validation</a></h5>
<p>The <code>update</code> family of operations require that the update document parameter MUST have only atomic modifiers. In
practice, this means that introspection needs to happen on that document to enforce this. However, it is enough to only
check the first element in the document. If it begins with a <code>$</code> sign and the rest of the document's elements do not,
the server will throw an error. Note that it is required that an update document have at least one atomic modifier.</p>
<p>The <code>replace</code> family of operations require that the replacement document parameter MUST NOT begin with an atomic
modifier. In practice, this means that introspection needs to happen on that document to enforce this. However, it is
enough to only check the first element in the document. If it does not begin with a <code>$</code> sign but an element later on
does, the server will throw an error.</p>
<h5 id="aggregation-pipelines-with-write-stages"><a class="header" href="#aggregation-pipelines-with-write-stages">Aggregation Pipelines with Write Stages</a></h5>
<p>This section discusses special considerations for aggregation pipelines that contain write stages (e.g. <code>$out</code>,
<code>$merge</code>).</p>
<h6 id="returning-a-cursor-on-the-output-collection"><a class="header" href="#returning-a-cursor-on-the-output-collection">Returning a cursor on the output collection</a></h6>
<p>As noted in the documentation for the <code>aggregate</code> helper earlier in this document, <code>$out</code> and <code>$merge</code> are special
pipeline stages that cause no results to be returned from the server. As such, drivers MAY setup a cursor to be executed
upon iteration against the output collection and return that instead of an iterable that would otherwise have no
results.</p>
<p>Drivers that do so for <code>$merge</code> MAY remind users that such a cursor may return more documents than were written by the
aggregation (e.g. documents that existed in the collection prior to <code>$merge</code> being executed).</p>
<h6 id="read-preferences-and-server-selection"><a class="header" href="#read-preferences-and-server-selection">Read preferences and server selection</a></h6>
<p>This section is only applicable if an explicit (i.e. per-operation) or inherited (e.g. from a Collection) read
preference is available and it is <em>not</em> a primary read preference (i.e. <code>{ "mode": "primary" }</code>).</p>
<p>Historically, only primaries could execute an aggregation pipeline with <code>$out</code> or <code>$merge</code> and drivers never considered
a read preference for the operation. As of <code>featureCompatibilityVersion</code> 4.4, secondaries can now execute pipelines with
<code>$out</code> or <code>$merge</code>. Since drivers do not track <code>featureCompatibilityVersion</code>, the decision to consider a read preference
for such a pipeline will depend on the wire version(s) of the server(s) to which the driver is connected.</p>
<p>If there are one or more available servers and one or more of those servers is pre-5.0 (i.e. wire version &lt; 13),
drivers MUST NOT use the available read preference and MUST instead select a server using a primary read preference.</p>
<p>Otherwise, if there are either no available servers, all available servers are 5.0+ (i.e. wire version &gt;= 13), or the
topology type is LoadBalanced (we can assume the backing mongos is 5.0+), drivers MUST use the available read
preference.</p>
<p>Drivers SHOULD augment their
<a href="crud/../server-selection/server-selection.html#server-selection-algorithm">server selection algorithm</a> such that this logic
can be enforced within a single server selection attempt.</p>
<p>Drivers MUST discern the read preference used to select a server for the operation, which SHALL be used for specifying
the <a href="crud/../message/OP_MSG.html#global-command-arguments">$readPreference global command argument</a> and
<a href="crud/../server-selection/server-selection.html#passing-read-preference-to-mongos-and-load-balancers">passing read preference to mongos and load balancers</a>
(if applicable).</p>
<h3 id="explain-1"><a class="header" href="#explain-1">Explain</a></h3>
<blockquote>
<p>[!NOTE]
Explain helpers are optional. Drivers that do not provide explain helpers may ignore this section.</p>
</blockquote>
<pre><code class="language-typescript">interface ExplainOptions {
  /**
   * The maximum amount of time to allow the explain to run.
   *
   * This option is sent only if the caller explicitly provides a value. The default is to not send a value.
   *
   * NOTE: This option is deprecated in favor of timeoutMS.
   */
  maxTimeMS: Optional&lt;Int64&gt;;
}
</code></pre>
<p>Drivers MUST ensure that its helper permits users to specify a timeout (maxTimeMS or timeoutMS) for the explain command
specifically. An example, using Node, might look like:</p>
<pre><code class="language-typescript">collection.find({ name: 'john doe' }).explain({ maxTimeMS: 1000 });

// sends:
{ 
  explain: { find: &lt;collection&gt;, query: { name: 'john doe' } },
  maxTimeMS: 1000
}

collection.find({ name: 'john doe' }).explain({ timeoutMS: 1000 });

// sends:
{ 
  explain: { find: &lt;collection&gt;, query: { name: 'john doe' } },
  maxTimeMS: &lt;1000 - min rtt&gt;
}
</code></pre>
<p>Drivers MUST document how users can specify options on their explain helpers.</p>
<h2 id="test-plan-24"><a class="header" href="#test-plan-24">Test Plan</a></h2>
<p>See the <a href="crud/tests/README.html">README</a> for tests.</p>
<h2 id="motivation-4"><a class="header" href="#motivation-4">Motivation</a></h2>
<p>Current drivers have chosen slightly different names and semantics for the same operations and options. In addition, not
all drivers offer all the same operations and methods. As such, it is difficult to transition from driver to driver
making the jobs of polyglot developers, documentation authors, and support engineers more difficult.</p>
<h2 id="backwards-compatibility-21"><a class="header" href="#backwards-compatibility-21">Backwards Compatibility</a></h2>
<p>This spec should be mostly backwards compatible as it is very lenient. Drivers finding a backwards compatibility problem
should attempt to work around it using an acceptable deviation. In rare cases, a driver may need to break backwards
compatibility. This should be done in accordance with a versioning scheme indicating that a backwards compatible break
may have occurred in conjunction with release documentation and warnings.</p>
<h2 id="reference-implementation-18"><a class="header" href="#reference-implementation-18">Reference Implementation</a></h2>
<p>See Test Plan</p>
<h2 id="related-terminology"><a class="header" href="#related-terminology">Related Terminology</a></h2>
<p>If a driver needs to refer to items in the following list, the below are the accepted forms of those terms and
deviations from the Naming section are still permissible.</p>
<ul>
<li>Read Preference: readPreference</li>
<li>Read Concern: readConcern</li>
<li>Write Concern: writeConcern</li>
</ul>
<h2 id="q--a-6"><a class="header" href="#q--a-6">Q &amp; A</a></h2>
<p>Q: Why do the names of the fields differ from those defined in the MongoDB manual?</p>
<p>Documentation and commands often refer to same-purposed fields with different names making it difficult to have a
cohesive API. In addition, occasionally the name was correct at one point and its purpose has expanded to a point where
the initial name doesn't accurately describe its current function.</p>
<p>In addition, responses from the servers are sometimes cryptic and used for the purposes of compactness. In these cases,
we felt the more verbose form was desirable for self-documentation purposes.</p>
<p>Q: Where is read preference?</p>
<p>Read preference is about selecting a server with which to perform a read operation, such as a query, a count, or an
aggregate. Since all operations defined in this specification are performed on a collection, it's uncommon that two
different read operations on the same collection would use a different read preference, potentially getting out-of-sync
results. As such, the most natural place to indicate read preference is on the client, the database, or the collection
itself and not the operations within it.</p>
<p>However, it might be that a driver needs to expose this selection filter to a user per operation for various reasons. As
noted before, it is permitted to specify this, along with other driver-specific options, in some alternative way.</p>
<p>Q: Where is read concern?</p>
<p>Read concern is about indicating how reads are handled. Since all operations defined in this specification are performed
on a collection, it's uncommon that two different read operations on the same collection would use a different read
concern, potentially causing mismatched and out-of-sync data. As such, the most natural place to indicate read concern
is on the client, the database, or the collection itself and not the operations within it.</p>
<p>However, it might be that a driver needs to expose read concern to a user per operation for various reasons. As noted
before, it is permitted to specify this, along with other driver-specific options, in some alternative way.</p>
<p>Q: Where is write concern?</p>
<p>Write concern is about indicating how writes are acknowledged. Since all operations defined in this specification are
performed on a collection, it's uncommon that two different write operations on the same collection would use a
different write concern, potentially causing mismatched and out-of-sync data. As such, the most natural place to
indicate write concern is on the client, the database, or the collection itself and not the operations within it. See
the <a href="crud/../read-write-concern/read-write-concern.html">Read/Write Concern specification</a> for the API of constructing a
read/write concern and associated API.</p>
<p>However, it might be that a driver needs to expose write concern to a user per operation for various reasons. As noted
before, it is permitted to specify this, along with other driver-specific options, in some alternative way.</p>
<p>Q: How do I throttle unacknowledged writes now that write concern is no longer defined on a per operation basis?</p>
<p>Some users used to throttle unacknowledged writes by using an acknowledged write concern every X number of operations.
Going forward, the proper way to handle this is by using the bulk write API.</p>
<p>Q: What is the logic for adding "One" or "Many" into the method and model names?</p>
<p>If the maximum number of documents affected can only be one, we added "One" into the name. This makes it explicit that
the maximum number of documents that could be affected is one vs. infinite.</p>
<p>In addition, the current API exposed by all our drivers has the default value for "one" or "many" set differently for
update and delete. This generally causes some issues for new developers and is a minor annoyance for existing
developers. The safest way to combat this without introducing discrepancies between drivers/driver versions or breaking
backwards compatibility was to use multiple methods, each signifying the number of documents that could be affected.</p>
<p>Q: Speaking of "One", where is <code>findOne</code>?</p>
<p>If your driver wishes to offer a <code>findOne</code> method, that is perfectly fine. If you choose to implement <code>findOne</code>, please
keep to the naming conventions followed by the <code>FindOptions</code> and keep in mind that certain things don't make sense like
limit (which should be -1), tailable, awaitData, etc...</p>
<p>Q: What considerations have been taken for the eventual merging of query and the aggregation framework?</p>
<p>In the future, it is probable that a new query engine (QE) will look very much like the aggregation framework. Given
this assumption, we know that both <code>find</code> and <code>aggregate</code> will be renderable in QE, each maintaining their ordering
guarantees for full backwards compatibility.</p>
<p>Hence, the only real concern is how to initiate a query using QE. While <code>find</code> is preferable, it would be a backwards
breaking change. It might be decided that <code>find</code> is what should be used, and all drivers will release major revisions
with this backwards breaking change. Alternatively, it might be decided that another initiator would be used.</p>
<p>Q: Didn't we just build a bulk API?</p>
<p>Yes, most drivers did just build out a bulk API (fluent-bulk-api). While unfortunate, we felt it better to have the bulk
api be consistent with the rest of the methods in the CRUD family of operations. However, the fluent-bulk-api is still
able to be used as this change is non-backwards breaking. Any driver which implemented the fluent bulk API should
deprecate it and drivers that have not built it should not do so.</p>
<p>Q: Should drivers offer explain helpers?<br />
Originally, it was determined that explain should not be exposed via
specialized APIs in drivers because it it was deemed to be an unusual use-case for a driver. We'd like users to use the
shell for this purpose. However, explain is still possible from a driver. Some drivers have historically provided
explain helpers and continue to do so. Drivers that do not offer explain helpers can run explain commands using the
runCommand API.</p>
<p>Q: What about explain?</p>
<p>Explain has been determined to be not a normal use-case for a driver. We'd like users to use the shell for this purpose.
However, explain is still possible from a driver. For find, it can be passed as a modifier. Aggregate can be run using a
runCommand method passing the explain option. In addition, server 3.0 offers an explain command that can be run using a
runCommand method.</p>
<p>Q: Where did modifiers go in FindOptions?</p>
<p>MongoDB 3.2 introduced the find command. As opposed to using the general "modifiers" field any longer, each relevant
option is listed explicitly. Some options, such as "tailable" or "singleBatch" are not listed as they are derived from
other fields. Upgrading a driver should be a simple procedure of deprecating the "modifiers" field and introducing the
new fields. When a collision occurs, the explicitly specified field should override the value in "modifiers".</p>
<p>Q: Where is <code>save</code>?</p>
<p>Drivers have historically provided a <code>save</code> method, which was syntactic sugar for upserting or inserting a document
based on whether it contained an identifier, respectively. While the <code>save</code> method may be convenient for interactive
environments, such as the shell, it was intentionally excluded from the CRUD specification for language drivers for
several reasons. The <code>save</code> method promotes a design pattern of "fetch, modify, replace" and invites race conditions in
application logic. Additionally, the split nature of <code>save</code> makes it difficult to discern at a glance if application
code will perform an insert or potentially dangerous full-document replacement. Instead of relying on <code>save</code>,
application code should know whether document already has an identifier and explicitly call <code>insertOne</code> or <code>replaceOne</code>
with the <code>upsert</code> option.</p>
<p>Q: Where is <code>useCursor</code> in AggregateOptions?</p>
<p>Inline aggregation results are no longer supported in server 3.5.2+. The
<a href="https://www.mongodb.com/docs/manual/reference/command/aggregate/">aggregate command</a> must be provided either the
<code>cursor</code> document or the <code>explain</code> boolean. AggregateOptions does not define an <code>explain</code> option. If a driver does
support an <code>explain</code> option, the <code>cursor</code> document should be omitted if <code>explain</code> is <code>true</code>. Otherwise a <code>cursor</code>
document must be added to the <code>aggregate</code> command. Regardless, <code>useCursor</code> is no longer needed. Removing <code>useCursor</code> is
a backwards breaking change, so drivers should first deprecate this option in a minor release, and remove it in a major
release.</p>
<p>Q: Where is <code>singleBatch</code> in FindOptions?</p>
<p>Drivers have historically allowed users to request a single batch of results (after which the cursor is closed) by
specifying a negative value for the <code>limit</code> option. For servers &lt; 3.2, a single batch may be requested by specifying a
negative value in the <code>numberToReturn</code> wire protocol field. For servers &gt;= 3.2, the <code>find</code> command defines <code>limit</code> as a
non-negative integer option but introduces a <code>singleBatch</code> boolean option. Rather than introduce a <code>singleBatch</code> option
to FindOptions, the spec preserves the existing API for <code>limit</code> and instructs drivers to convert negative values
accordingly for servers &gt;= 3.2.</p>
<p>Q: Why are client-side errors raised for some unsupported options?</p>
<p>Server versions before 3.4 were inconsistent about reporting errors for unrecognized command options and may simply
ignore them, which means a client-side error is the only way to inform users that such options are unsupported. For
unacknowledged writes using OP_MSG, a client-side error is necessary because the server has no chance to return a
response (even though a 3.6+ server is otherwise capable of reporting errors for unrecognized options). For
unacknowledged writes using legacy opcodes (i.e. OP_INSERT, OP_UPDATE, and OP_DELETE), the message body has no field
with which to express these options so a client-side error is the only mechanism to inform the user that such options
are unsupported. The spec does not explicitly refer to unacknowledged writes using OP_QUERY primarily because a response
document is always returned and drivers generally would not consider using OP_QUERY precisely for that reason.</p>
<p>Q: Why does reverting to using <code>count</code> instead of <code>aggregate</code> with <code>$collStats</code> for estimatedDocumentCount not require a
major version bump in the drivers, even though it might break users of the Stable API?</p>
<p>SemVer
<a href="https://semver.org/#what-if-i-inadvertently-alter-the-public-api-in-a-way-that-is-not-compliant-with-the-version-number-change-ie-the-code-incorrectly-introduces-a-major-breaking-change-in-a-patch-release">allows</a>
for a library to include a breaking change in a minor or patch version if the change is required to fix another
accidental breaking change introduced in a prior version and is not expected to further break a large number of users.
Given that the original switch to <code>$collStats</code> was a breaking change due to it not working on views, the number of users
using estimatedDocumentCount with <code>apiStrict: true</code> is small, and the server is back-porting the addition of <code>count</code> to
the Stable API, it was decided that this change was acceptable to make in minor version releases of the drivers per the
aforementioned allowance in the SemVer spec.</p>
<h2 id="changelog-32"><a class="header" href="#changelog-32">Changelog</a></h2>
<ul>
<li>
<p>2024-09-12: Specify that explain helpers support maxTimeMS.</p>
</li>
<li>
<p>2024-02-20: Migrated from reStructuredText to Markdown.</p>
</li>
<li>
<p>2022-10-05: Remove spec front matter and reformat changelog.</p>
</li>
<li>
<p>2022-04-21: Revert to using the <code>count</code> command for <code>estimatedDocumentCount</code></p>
</li>
<li>
<p>2022-02-18: Add let to BulkWriteOptions.</p>
</li>
<li>
<p>2022-02-10: Specified that <code>getMore</code> command must explicitly send inherited comment.</p>
</li>
<li>
<p>2022-02-01: Add comment attribute to all helpers.</p>
</li>
<li>
<p>2022-01-27: Use optional return types for write commands and findAndModify</p>
</li>
<li>
<p>2022-01-19: Deprecate the maxTimeMS option and require that timeouts be applied per the client-side operations timeout
spec.</p>
</li>
<li>
<p>2022-01-14: Add let to ReplaceOptions</p>
</li>
<li>
<p>2021-11-10: Revise rules for applying read preference for aggregations with $out and $merge. Add let to FindOptions,
UpdateOptions, DeleteOptions, FindOneAndDeleteOptions, FindOneAndReplaceOptions, FindOneAndUpdateOptions</p>
</li>
<li>
<p>2021-09-28: Support aggregations with $out and $merge on 5.0+ secondaries</p>
</li>
<li>
<p>2021-08-31: Allow unacknowledged hints on write operations if supported by server (reverts previous change).</p>
</li>
<li>
<p>2021-06-02: Introduce WriteError.details and clarify WriteError construction</p>
</li>
<li>
<p>2021-06-01: Add let to AggregateOptions</p>
</li>
<li>
<p>2021-01-21: Update estimatedDocumentCount to use $collStats stage for servers &gt;= 4.9</p>
</li>
<li>
<p>2020-04-17: Specify that the driver must raise an error for unacknowledged hints on any write operation, regardless of
server version.</p>
</li>
<li>
<p>2020-03-19: Clarify that unacknowledged update, findAndModify, and delete operations with a hint option should raise
an error on older server versions.</p>
</li>
<li>
<p>2020-03-06: Added hint option for DeleteOne, DeleteMany, and FindOneAndDelete operations.</p>
</li>
<li>
<p>2020-01-24: Added hint option for findAndModify update/replace operations.</p>
</li>
<li>
<p>2020-01-17: Add allowDiskUse to FindOptions.</p>
</li>
<li>
<p>2020-01-14: Deprecate oplogReplay option for find command</p>
</li>
<li>
<p>2020-01-10: Clarify client-side error reporting for unsupported options</p>
</li>
<li>
<p>2020-01-10: Error if hint specified for unacknowledged update using OP_UPDATE or OP_MSG for servers &lt; 4.2</p>
</li>
<li>
<p>2019-10-28: Removed link to old language examples.</p>
</li>
<li>
<p>2019-09-26: Added hint option for update commands.</p>
</li>
<li>
<p>2019-06-07: Consistent treatment for aggregate $merge and $out stages</p>
</li>
<li>
<p>2019-05-01: Specify a document or pipeline for commands with updates in server 4.2+.</p>
</li>
<li>
<p>2019-02-20: Mark the request field of BulkWriteError as NOT REQUIRED</p>
</li>
<li>
<p>2018-11-30: Specify maxAwaitTimeMS in AggregateOptions</p>
</li>
<li>
<p>2018-11-15: Aggregate commands with an $out stage should not specify batchSize</p>
</li>
<li>
<p>2018-10-25: Note how results are backed for aggregate, distinct, and find operations</p>
</li>
<li>
<p>2018-07-25: Added upsertedCount to UpdateResult.</p>
</li>
<li>
<p>2018-06-07: Deprecated the count helper. Added the estimatedDocumentCount and countDocuments helpers.</p>
</li>
<li>
<p>2018-03-05: Deprecate snapshot option</p>
</li>
<li>
<p>2018-03-01: Deprecate maxScan query option.</p>
</li>
<li>
<p>2018-02-06: Note that batchSize in FindOptions and AggregateOptions should also apply to getMore.</p>
</li>
<li>
<p>2018-01-26: Only send bypassDocumentValidation option if it's true, don't send false.</p>
</li>
<li>
<p>2017-10-23: Allow BulkWriteException to provide an intermediary write result.</p>
</li>
<li>
<p>2017-10-17: Document negative limit for FindOptions.</p>
</li>
<li>
<p>2017-10-09: Bumped minimum server version to 2.6 and removed references to older versions in spec and tests.</p>
</li>
<li>
<p>2017-10-09: Prohibit empty insertMany() and bulkWrite() operations.</p>
</li>
<li>
<p>2017-10-09: Split UpdateOptions and ReplaceOptions. Since replaceOne() previously used UpdateOptions, this may have BC
implications for drivers using option classes.</p>
</li>
<li>
<p>2017-10-05: Removed useCursor option from AggregateOptions.</p>
</li>
<li>
<p>2017-09-26: Added hint option to AggregateOptions.</p>
</li>
<li>
<p>2017-09-25: Added comment option to AggregateOptions.</p>
</li>
<li>
<p>2017-08-31: Added arrayFilters to bulk write update models.</p>
</li>
<li>
<p>2017-06-29: Remove requirement of using OP_KILL_CURSOR to kill cursors.</p>
</li>
<li>
<p>2017-06-27: Added arrayFilters to UpdateOptions and FindOneAndUpdateOptions.</p>
</li>
<li>
<p>2017-06-26: Added FAQ entry for omission of save method.</p>
</li>
<li>
<p>2017-05-12: Removed extra "collation" option added to several bulk write models.</p>
</li>
<li>
<p>2017-01-09: Removed modifiers from FindOptions and added in all options.</p>
</li>
<li>
<p>2017-01-09: Changed the value type of FindOptions.skip and FindOptions.limit to Int64 with a note related to
calculating batchSize for opcode writes.</p>
</li>
<li>
<p>2017-01-09: Reworded description of how default values are handled and when to send certain options.</p>
</li>
<li>
<p>2016-09-23: Included collation option in the bulk write models.</p>
</li>
<li>
<p>2016-08-05: Added in collation option.</p>
</li>
<li>
<p>2015-11-05: Typos in comments about bypassDocumentValidation</p>
</li>
<li>
<p>2015-10-16: Added maxAwaitTimeMS to FindOptions.</p>
</li>
<li>
<p>2015-10-01: Moved bypassDocumentValidation into BulkWriteOptions and removed it from the individual write models.</p>
</li>
<li>
<p>2015-09-16: Added bypassDocumentValidation.</p>
</li>
<li>
<p>2015-09-16: Added readConcern notes.</p>
</li>
<li>
<p>2015-06-17: Added limit/batchSize calculation logic.</p>
</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="collation"><a class="header" href="#collation">Collation</a></h1>
<ul>
<li>Status: Accepted</li>
<li>Minimum Server Version: 1.8</li>
</ul>
<hr />
<h2 id="abstract-32"><a class="header" href="#abstract-32">Abstract</a></h2>
<p>As of MongoDB server version 3.4 (maxWireVersion 5), a collation option is supported by the query system for matching
and sorting on language strings in a locale-aware fashion.</p>
<p>A driver MUST support a Collation option for each of the relevant operations in server versions &gt;= 3.4 (maxWireVersion
5) and MUST throw an error if a user supplies a Collation option for the operation and the selected server has
maxWireVersion &lt; 5 or if the user is using opcode-based unacknowledged writes.</p>
<p>The CRUD and Index Management specs include the collation option in descriptions of API elements where it is supported.
This document provides more details on the specific driver behavior required to handle the collation option.</p>
<h2 id="meta-33"><a class="header" href="#meta-33">META</a></h2>
<p>The keywords "MUST", "MUST NOT", "REQUIRED", "SHALL", "SHALL NOT", "SHOULD", "SHOULD NOT", "RECOMMENDED", "MAY", and
"OPTIONAL" in this document are to be interpreted as described in <a href="https://www.ietf.org/rfc/rfc2119.txt">RFC 2119</a>.</p>
<h2 id="design-rationale-23"><a class="header" href="#design-rationale-23">Design Rationale</a></h2>
<h3 id="collation-is-not-a-setting-on-a-driver-client-collection-or-database-object"><a class="header" href="#collation-is-not-a-setting-on-a-driver-client-collection-or-database-object">Collation is not a setting on a driver Client, Collection, or Database object</a></h3>
<p>MongoDB supports a server-side collation default on a collection. It is problematic to add a default Collation option on
a driver’s Collection or Database object, because automatic collection and index creation would bypass any driver
object's Collation setting. Additionally, this would have a number of performance implications in the context of bulk
writes: any bulk write on a Collection object having a default Collation would require iterating through each operation
and adding a Collation document.</p>
<p>After the initial release of server version 3.4, many users will want to apply Collations to all operations on an
existing collection. Such users will have to supply the Collation option to each operation explicitly; however,
eventually the majority of users wishing to use Collations on all operations on a collection will create a collection
with a server-side default. We chose to favor user verbosity right now over abstracting the feature for short-term
gains.</p>
<h3 id="drivers-throw-an-error-if-a-user-supplies-collation-and-the-selected-server-does-not-support-the-feature"><a class="header" href="#drivers-throw-an-error-if-a-user-supplies-collation-and-the-selected-server-does-not-support-the-feature">Drivers throw an error if a user supplies Collation and the selected server does not support the feature</a></h3>
<p>Server versions earlier than 3.4 don't always throw an error if an unknown option is supplied to certain operations.
Because a Collation defines how documents are matched and sorted for both read and write operations, behavior
differences between server versions are significant. Drivers therefore MUST throw an error if a user specifies a
Collation and the selected server has a maxWireVersion &lt; 5 or if using opcode-based unacknowledged writes.</p>
<h2 id="specification-31"><a class="header" href="#specification-31">Specification</a></h2>
<h3 id="collation-document-model"><a class="header" href="#collation-document-model">Collation Document Model</a></h3>
<p>For naming and deviation guidance, see the <a href="collation/../crud/crud.html#naming">CRUD specification</a>. Defined below are the
constructs for drivers. Note that the only required field is <code>locale</code>, but the driver should let the server validate the
presence of this field.</p>
<pre><code class="language-typescript">class Collation {
  /**
   * The locale.
   */
  locale: String

  /**
   * The case level.
   */
  caseLevel: Optional&lt;Boolean&gt;

  /**
   * The case ordering.
   */
  caseFirst: Optional&lt;String&gt;

  /**
   * The number of comparison levels to use.
   */
  strength: Optional&lt;Integer&gt;

  /**
   * Whether to order numbers based on numerical order and not collation order.
   */
  numericOrdering: Optional&lt;Boolean&gt;

  /**
   * Whether spaces and punctuation are considered base characters.
   */
  alternate: Optional&lt;String&gt;

  /**
   * Which characters are affected by alternate: "shifted".
   */
  maxVariable: Optional&lt;String&gt;

  /**
   * If true, normalizes text into Unicode NFD.
   */
  normalization: Optional&lt;Boolean&gt;

  /**
   * Causes secondary differences to be considered in reverse order, as it is done in the French language.
   */
  backwards: Optional&lt;Boolean&gt;
}
</code></pre>
<h4 id="unknown-options"><a class="header" href="#unknown-options">Unknown Options</a></h4>
<p>For forward compatibility, a driver MUST NOT raise an error when a user provides unknown options or values. The driver
MUST NOT validate collation document types; the driver relies on the server to validate values and other contents of the
collation document.</p>
<h4 id="generic-command-method"><a class="header" href="#generic-command-method">Generic Command Method</a></h4>
<p>If a driver offers a generic <code>RunCommand</code> method on the <code>database</code> object, the driver MUST NOT validate whether the
provided command document contains a "collation" subdocument, and MUST NOT check the server's wire version before
sending the command including the "collation" subdocument.</p>
<h3 id="api-2"><a class="header" href="#api-2">API</a></h3>
<p>The driver helpers that must support a collation option include the create collection helper, any CRUD API components
relying on the MongoDB query system (including updates and deletes) and some index management helpers. The CRUD-related
commands that take a collation option are:</p>
<ul>
<li>aggregate</li>
<li>count</li>
<li>distinct</li>
<li>find (command only)</li>
<li>findAndModify</li>
<li>geoNear</li>
<li>group</li>
<li>mapReduce</li>
<li>delete (command only)</li>
<li>update (command only)</li>
</ul>
<p>The collation option is sent to the server in the form of a BSON Document. See the
<a href="collation/../crud/crud.html#naming">CRUD specification</a> for details on supporting the option in the CRUD API.</p>
<p>Driver helpers manipulating or using indexes MUST support a collation option. These include creating, deleting, and
hinting an index. See the <a href="collation/../index-management/index-management.html">Index Management specification</a> for details.</p>
<h3 id="require-maxwireversion-5"><a class="header" href="#require-maxwireversion-5">Require maxWireVersion 5</a></h3>
<p>Drivers MUST require the server's maxWireVersion &gt;= 5 to support Collations. When a collation is explicitly specified
for a server with maxWireVersion &lt; 5, the driver MUST raise an error.</p>
<h3 id="opcode-based-unacknowledged-writes"><a class="header" href="#opcode-based-unacknowledged-writes">Opcode-based Unacknowledged Writes</a></h3>
<p>The driver MUST NOT allow collation with opcodes, because the server doesn't support it. If a driver uses opcode-based
writes when the write concern is unacknowledged, the driver MUST raise an error if a collation is explicitly set.</p>
<h3 id="setting-a-default-collation-on-a-collection"><a class="header" href="#setting-a-default-collation-on-a-collection">Setting a default collation on a collection</a></h3>
<p>Drivers MUST allow the create command to accept a parameter called "collation". For example,</p>
<pre><code class="language-typescript">db.command({
    create: "myCollection",
    collation: {locale: "en_US"}
});
</code></pre>
<h3 id="bulkwrite-api"><a class="header" href="#bulkwrite-api">BulkWrite API</a></h3>
<p>If maxWireVersion &lt; 5, the driver MUST inspect each BulkWrite operation model for a collation and MUST raise an error
and MUST NOT send any operations to the server if a collation is explicitly specified on an operation. For example, the
user will provide BulkWrite operation models as in the following example:</p>
<pre><code class="language-typescript">db.collection.bulkWrite([
  {insertOne: { ... }},

  {updateOne: { filter: { name: "PING" },
                        update: { $set: { name: "pong" }},
                        collation: { locale: "en_US", strength: 2 }}},
  {updateMany: {..., collation: {...}}},
  {replaceOne: {..., collation: {...}}},
  {deleteOne: {..., collation: {...}}},
  {deleteMany: {..., collation: {...}}}
]);
</code></pre>
<p>The driver must inspect each operation for a Collation if maxWireVersion is &lt; 5 and fail the entire bulkWrite if a
collation was explicitly specified. In the example above, that means even the insertOne (without Collation) MUST NOT be
sent.</p>
<h2 id="test-plan-25"><a class="header" href="#test-plan-25">Test Plan</a></h2>
<p>There is no specific test plan for driver Collation support; however drivers should test each affected CRUD, Index
Management API, and collection creation/modification component to ensure that Collation is a supported option.</p>
<p>In addition, drivers should test that two indexes can be created with identical key patterns and different collations. A
custom name must be provided for one of them. Then, the test should ensure that the correct index is dropped when
delete_one is called with an index name.</p>
<p>Drivers should also test that errors are raised in each place Collation can be provided to a API method and the selected
server has maxWireVersion &lt; 5.</p>
<h2 id="backwards-compatibility-22"><a class="header" href="#backwards-compatibility-22">Backwards Compatibility</a></h2>
<p>There should be no backwards compatibility concerns.</p>
<h2 id="reference-implementation-19"><a class="header" href="#reference-implementation-19">Reference Implementation</a></h2>
<p>Reference Implementation:</p>
<ul>
<li><a href="https://jira.mongodb.org/browse/RUBY-1126">RUBY-1126</a></li>
<li><a href="https://jira.mongodb.org/browse/JAVA-2241">JAVA-2241</a></li>
</ul>
<h2 id="q--a-7"><a class="header" href="#q--a-7">Q &amp; A</a></h2>
<p>Q: Insert doesn’t take a collation?</p>
<p>A: No, only queries take collation. A collation is a per operation value, it does not affect how the data is stored.</p>
<p>Q: Delete and Update take a collation?</p>
<p>A: Yes, delete and update operations use the query system to match against a provided delete/update filter. Providing a
collation when deleting a document matching <code>ObjectID()</code> doesn’t change anything, but matching a string value would.</p>
<p>Q: How do I create a collection with default collation? Does it affect my existing collection creation helper?</p>
<p>A: A collection with a default collation can be created using the create helper and by providing a collation option.</p>
<h2 id="changelog-33"><a class="header" href="#changelog-33">Changelog</a></h2>
<ul>
<li>2024-02-15: Migrated from reStructuredText to Markdown.</li>
<li>2022-10-05: Remove spec front matter and reformat changelog.</li>
<li>2017-05-15: Minor markup fixes in API section.</li>
<li>2016-08-31: Initial version.</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="write-commands-specification"><a class="header" href="#write-commands-specification">Write Commands Specification</a></h1>
<ul>
<li>Status: Accepted</li>
<li>Minimum Server Version: 2.6</li>
</ul>
<hr />
<h2 id="goals-1"><a class="header" href="#goals-1">Goals</a></h2>
<ul>
<li>Method to do writes (insert/update/delete) that declares the write concern up front</li>
<li>Support for batch operations</li>
<li>As efficient as possible</li>
<li>getLastError is disallowed after anything except old style write ops</li>
</ul>
<h2 id="non-goals-1"><a class="header" href="#non-goals-1">Non-Goals</a></h2>
<ul>
<li>We're not specifying nor building any generic mechanism for feature discovery here</li>
<li>We're not specifying nor building any generic way to be backwards compatible</li>
</ul>
<h2 id="requests-format"><a class="header" href="#requests-format">Requests Format</a></h2>
<p>We use a very similar request format for all insert, update, and delete commands, described below. A request contains
parameters on how to apply the batch items and, of course, the batch items themselves.</p>
<h3 id="generic-fields"><a class="header" href="#generic-fields">Generic Fields</a></h3>
<ul>
<li><code>&lt;write op&gt;</code>: mandatory, with a string type, where <code>&lt;write op&gt;</code> can be <code>insert</code>, <code>update</code>, or <code>delete</code> and the content
string is a valid collection name against which the write should be directed. The <code>&lt;write op&gt;</code> must be the first key
in the document. For example:</li>
</ul>
<pre><code class="language-javascript">db.runCommand{ { update: "users", ...
</code></pre>
<ul>
<li><code>writeConcern</code>: optional, with a valid write concern BSONObj type, which contains the journaling, replication, and/or
time out parameters that will be used at the end of the batch application. The default write concern for a mongod
server can be set as a replica set configuration option, or if there is no replica set default the fallback is
<code>{ w: 1 }</code>. For example:</li>
</ul>
<pre><code class="language-javascript">..., writeConcern: { w: 2 }, ...
</code></pre>
<p>Note that the write concern will be issued at the end of the batch application.</p>
<p>We also support the "unusual" write concern: <code>{ w : 0 }</code>, which means the user is uninterested in the result of the
write at this time. In this protocol, there is no provision to ignore the response packet. The protocol, however, sends
a very condensed response when it sees that write concern (e.g. omits everything but the <code>ok</code> field).</p>
<ul>
<li><code>ordered</code>: optional, with a boolean type. If true, applies the batch's items in the same order the items appear, ie.
sequentially. If <code>ordered</code> is false, the server applies the batch items in no particular order -- possibly, in
parallel. The default value is true, sequential. For example:</li>
</ul>
<pre><code class="language-javascript">..., ordered: false, ...
</code></pre>
<ul>
<li>
<p><code>metadata</code>: RESERVED FOR MONGOS USE, future use.</p>
</li>
<li>
<p><code>failFast</code>: NOT YET USED, RESERVED FOR FUTURE USE. Optional, with a boolean type. If false, allows the batch to
continue processing even if some elements in the batch have errors. If true, the batch will stop on first error(s) it
detects (write concern will not be applied). Defaults to true for ordered batches, and false for unordered batches.</p>
</li>
</ul>
<h3 id="batch-items-format"><a class="header" href="#batch-items-format">Batch Items Format</a></h3>
<p>We describe the array of batch items to be applied according to which type of write operation we'd like to perform.</p>
<p><span id="insert"></span></p>
<ul>
<li>For inserts, <code>documents</code> array: mandatory, with an array of objects type. Objects must be valid for insertion. For
example:</li>
</ul>
<pre><code class="language-javascript">{ insert: "coll",
  documents: [ &lt;obj&gt;, &lt;obj&gt;, ... ],
  ...
}
</code></pre>
<p><span id="update"></span></p>
<ul>
<li>For updates, an <code>updates</code> array: mandatory, with an array of update objects type. Update objects must contain the
query expression <code>q</code>, an update expression <code>u</code> fields, and, optionally, a boolean <code>multi</code> if several documents may be
changed, and a boolean <code>upsert</code> if updates can become inserts. Both optional fields default to false. For example:</li>
</ul>
<pre><code class="language-javascript">{ update: "coll",
  updates: [
      { q : &lt;query&gt;, u : &lt;update&gt;, multi : &lt;multi&gt;, upsert : &lt;upsert&gt; },
      ...
  ],
  ...
}
</code></pre>
<p><span id="delete"></span></p>
<ul>
<li>for deletes a <code>deletes</code> array: mandatory, with an array of delete object type. For example:</li>
</ul>
<pre><code class="language-javascript">{ delete: "coll",
  deletes : [
      { q : &lt;query&gt;, limit : &lt;num&gt; },
      ...
  ],
  ...
}
</code></pre>
<p>Note that, to avoid accidentally deleting more documents than intended, we force the <code>limit</code> field to be present all the
time. When all documents that satisfy <code>q</code> should be deleted set <code>limit</code> to zero, as opposed to being omitted.</p>
<p>Note: The only valid values for <code>limit</code> is 1 and 0.</p>
<h3 id="request-size-limits"><a class="header" href="#request-size-limits">Request Size Limits</a></h3>
<p>Supporting unlimited batch sizes poses two problems - the BSONObj internal size limit is 16 MiB + 16 KiB (for command
overhead), and a small write operation may have a much larger response. In order to ensure a batch can be correctly
processed, two limits must be respected.</p>
<p>Both of these limits can be found using hello():</p>
<ul>
<li><code>maxBsonObjectSize</code> : currently 16 MiB, this is the maximum size of writes (excluding command overhead) that should be
sent to the server. Documents to be inserted, query documents for updates and deletes, and update expression documents
must be &lt;= this size. Once these documents have been assembled into a write command the total size may exceed
<code>maxBsonObjectSize</code> by a maximum of 16 KiB, allowing users to insert documents up to <code>maxBsonObjectSize</code>.</li>
<li><code>maxWriteBatchSize</code> : this is the maximum number of inserts, updates, or deletes that can be included in a write
batch. If more than this number of writes are included, the server cannot guarantee space in the response document to
reply to the batch.</li>
</ul>
<p>If the batch is too large in size or bytes, the command may fail.</p>
<h2 id="response-format"><a class="header" href="#response-format">Response Format</a></h2>
<p>There are two types of responses to any command:</p>
<ul>
<li>a <code>command failure</code>, which indicates the command itself did not complete successfully. Example command failures
include failure to authorize, failure to parse, operation aborted by user, and unexpected errors during execution
(these should be very rare).</li>
<li>successful command execution, which for write commands may include write errors.</li>
</ul>
<h3 id="command-failure-fields"><a class="header" href="#command-failure-fields">Command Failure Fields</a></h3>
<p>All commands have the same format when they fail unexpectedly:</p>
<p><code>{ ok : 0, code : &lt;error code&gt;, errmsg : &lt;human-readable string&gt; }</code></p>
<p>When a batch write command fails this way, like other commands, no guarantees are made about the state of the writes
which were sent. Particular error codes may indicate more about what occurred, but those codes are outside the scope of
this spec.</p>
<h3 id="general-response-fields"><a class="header" href="#general-response-fields">General Response Fields</a></h3>
<p>Again, like other commands, batch write commands return <code>{ ok : 1, ... }</code> when they complete successfully. Importantly,
successful execution of a batch write command may include reporting of unsuccessful writes (write errors) and write
concern application (write concern error).</p>
<p>The main body of a successful response is below:</p>
<p><span id="ok"></span></p>
<ul>
<li><code>ok</code>: Mandatory field, (double)"1" if operation was executed. Does not mean successfully. For example, duplicate key
error will still set ok = 1</li>
</ul>
<p><span id="n"></span></p>
<ul>
<li><code>n</code>: Mandatory field, with a positive numeric type or zero. This field contains the aggregated number of documents
successfully affected by the entire write command. This includes the number of documents inserted, upserted, updated,
and deleted. We do not report on the individual number of documents affected by each batch item. If the application
would wish so, then the application should issue one-item batches.</li>
</ul>
<p><span id="writeErrors"></span></p>
<ul>
<li><code>writeErrors</code>: Optional field, an array of write errors. For every batch write that had an error, there is one BSON
error document in the array describing the error. (See the <a href="server_write_commands/server_write_commands.html#error-document">Error Document</a> section.)</li>
</ul>
<p><span id="writeConcernError"></span></p>
<ul>
<li><code>writeConcernError</code>: Optional field, which may contain a BSON error document indicating an error occurred while
applying the write concern (or an error indicating that the write concern was not applied). (See the
<a href="server_write_commands/server_write_commands.html#error-document">Error Document</a> section.)</li>
</ul>
<h3 id="situational-fields"><a class="header" href="#situational-fields">Situational Fields</a></h3>
<p>We use the fields above for all responses, regardless of the request type. But some request types require additional
response information, as described below.</p>
<p><span id="nModified"></span></p>
<ul>
<li><code>nModified</code>: Optional field, with a positive numeric type or zero. Zero is the default value. This field is only and
always present for batch updates. <code>nModified</code> is the physical number of documents affected by an update, while <code>n</code> is
the logical number of documents matched by the update's query. For example, if we have 100 documents like :</li>
</ul>
<pre><code class="language-javascript">{ bizName: "McD", employees: ["Alice", "Bob", "Carol"] }
</code></pre>
<p>and we are adding a single new employee using <code>$addToSet</code> for each business document, <code>n</code> is useful to ensure all
businesses have been updated, and <code>nModified</code> is useful to know which businesses actually added a new employee.</p>
<p><span id="upserted"></span></p>
<ul>
<li><code>upserted</code>: Optional field, with an array type. If any upserts occurred in the batch, the array contains a BSON
document listing the <code>index</code> and <code>_id</code> of the newly upserted document in the database.</li>
</ul>
<p><span id="lastOp"></span></p>
<ul>
<li><code>lastOp</code>: MONGOD ONLY. Optional field, with a timestamp type, indicating the latest opTime on the server after all
documents were processed.</li>
<li><code>electionId</code>: MONGOD ONLY. Optional ObjectId field representing the last primary election Id.</li>
</ul>
<h3 id="error-document"><a class="header" href="#error-document">Error Document</a></h3>
<p>For a write error or a write concern error, the following fields will appear in the error document:</p>
<p><span id="code"></span></p>
<ul>
<li><code>code</code>: Mandatory field with integer format. Contains a numeric code corresponding to a certain type of error.</li>
</ul>
<p><span id="errInfo"></span></p>
<ul>
<li><code>errInfo</code>: Optional field, with a BSONObj format. This field contains structured information about an error that can
be processed programmatically. For example, if a request returns with a shard version error, we may report the proper
shard version as a sub-field here. For another example, if a write concern timeout occurred, the information
previously reported on <code>wtimeout</code> would be reported here. The format of this field depends on the code above.</li>
</ul>
<p><span id="errmsg"></span></p>
<ul>
<li><code>errmsg</code>: Mandatory field, containing a human-readable version of the error.</li>
</ul>
<p><span id="index"></span></p>
<ul>
<li><code>index</code>: WRITE ERROR ONLY. The index of the erroneous batch item relative to request batch order. Batch items indexes
start with 0.</li>
</ul>
<h2 id="examples-4"><a class="header" href="#examples-4">Examples</a></h2>
<h3 id="successful-case"><a class="header" href="#successful-case">Successful case</a></h3>
<p>Note that <code>ok: 1</code> by itself does <strong>not</strong> mean that an insert, update, or delete was executed successfully, just that the
batch was processed successfully. <code>ok: 1</code> merely means "all operations executed". <code>n</code> reports how many items from that
batch were affected by the operation.</p>
<h2 id="insert"><a class="header" href="#insert">Insert</a></h2>
<p>Request:</p>
<pre><code class="language-javascript">{ insert: "coll", documents: [ {a: 1} ] }
</code></pre>
<p>Response:</p>
<pre><code class="language-javascript">{ "ok" : 1, "n" : 1 }
</code></pre>
<p>Request:</p>
<pre><code class="language-javascript">{ insert: "coll", documents: [ {a: 1}, {b: 2}, {c: 3}, {d: 4} ] }
</code></pre>
<p>Response:</p>
<pre><code class="language-javascript">{ "ok" : 1, "n" : 4 }
</code></pre>
<h2 id="delete"><a class="header" href="#delete">Delete</a></h2>
<p>Request:</p>
<pre><code class="language-javascript">{ delete: "coll", deletes: [ { q: {b: 2}, limit: 1} ] }
</code></pre>
<p>Response:</p>
<pre><code class="language-javascript">{ "ok" : 1, "n" : 1 }
</code></pre>
<p>Request:</p>
<pre><code class="language-javascript">{
 delete: "coll",
 deletes:
 [
     {
         q: {a: 1},
         limit: 0
     },
     {
         q: {c: 3},
         limit: 1
     }
 ]
}
</code></pre>
<p>Response:</p>
<pre><code class="language-javascript">{ "ok" : 1, "n" : 3 }
</code></pre>
<h2 id="update"><a class="header" href="#update">Update</a></h2>
<p>Request:</p>
<pre><code class="language-javascript">{
  update: "coll",
  "updates":
  [
      {
          q: { d: 4 },
          u: { $set: {d: 5} }
      }
  ]
}
</code></pre>
<p>Response:</p>
<pre><code class="language-javascript">{ "ok" : 1, "nModified" : 1, "n" : 1 }
</code></pre>
<h3 id="checking-if-command-failed"><a class="header" href="#checking-if-command-failed">Checking if command failed</a></h3>
<p>To check if a write command failed:</p>
<pre><code class="language-python">if (ok == 0) {
  // The command itself failed (authentication failed.., syntax error)
} else if (writeErrors is array) {
  // Couldn't write the data (duplicate key.., out of disk space..)
} else if (writeConcernError is object) {
  // Operation took to long on secondary, hit wtimeout ...,
}
</code></pre>
<h3 id="command-failure-to-parse-or-authenticate"><a class="header" href="#command-failure-to-parse-or-authenticate">Command failure to parse or authenticate</a></h3>
<p>Request:</p>
<pre><code class="language-javascript">{ update: "coll",
  updates: [
    { q: {a:1}, x: {$set: {b: 2} } },
    { q: {a:2}, u: {$set: {c: 2} } }
  ]
}
</code></pre>
<p>Response:</p>
<pre><code class="language-javascript">{ ok: 0,
  code: &lt;number&gt;,
  errmsg: "Failed to parse batched update request, missing update expression 'u' field"
}

{ ok: 0,
  code: &lt;number&gt;,
  errmsg: "Not authorized to perform update"
}
</code></pre>
<p>Note that no information is given about command execution - if this was performed against a mongos, for example, the
batch may or may not have been partially applied - there is no programmatic way to determine this.</p>
<h3 id="write-concern-failure"><a class="header" href="#write-concern-failure">Write concern failure</a></h3>
<p>Request:</p>
<pre><code class="language-javascript">{ insert: "coll", documents: [ {a: 1}, {a:2} ], writeConcern: {w: 3, wtimeout: 100} }
</code></pre>
<p>Response:</p>
<pre><code class="language-javascript">{ ok: 1,
  n: 2,
  writeConcernError: {
    code : &lt;number&gt;,
    errInfo: { wtimeout : true },
    errmsg: "Could not replicate operation within requested timeout"
  }
}
</code></pre>
<h3 id="mixed-failures"><a class="header" href="#mixed-failures">Mixed failures</a></h3>
<p>Request:</p>
<pre><code class="language-javascript">db.coll.ensureIndex( {a:1}, {unique: true} )
{ insert: "coll",
  documents: [
    { a: 1 },
    { a: 1 },
    { a: 2 }
  ],
  ordered: false,
  writeConcern: { w: 3, wtimeout: 100 }
}
</code></pre>
<p>Response:</p>
<pre><code class="language-javascript">{ ok: 1,
  n: 2,
  writeErrors: [
    { index: 1,
      code: &lt;number&gt;,
      errmsg: "Attempt to insert duplicate key when unique index is present"
    }
  ],
  writeConcernError: {
    code: &lt;number&gt;,
    errInfo : { wtimeout : true },
    errmsg: "Could not replicate operation within requested timeout"
  }
}
</code></pre>
<p>Note that the field <code>n</code> in the response came back with 2, even though there are three items in the batch. This means
that there must be an entry in <code>writeErrors</code> for the item that failed. Note also that the request turned off <code>ordered</code>,
so the write concern error was hit when trying to replicate batch items 0 and 2.</p>
<p>Just to illustrate the support for <code>{w:0}</code>, here's how the response would look, had the request asked for that write
concern.</p>
<p>Response:</p>
<pre><code class="language-javascript">{ ok: 1 }
</code></pre>
<h2 id="faq-1"><a class="header" href="#faq-1">FAQ</a></h2>
<h3 id="why-are-_id-values-generated-client-side-by-default-for-new-documents"><a class="header" href="#why-are-_id-values-generated-client-side-by-default-for-new-documents">Why are <code>_id</code> values generated client-side by default for new documents?</a></h3>
<p>Though drivers may expose configuration options to prevent this behavior, by default a new <code>ObjectId</code> value will be
created client-side before an <code>insert</code> operation.</p>
<p>This design decision primarily stems from the fact that MongoDB is a distributed database and the typical unique
auto-incrementing scalar value most RDBMS' use for generating a primary key would not be robust enough, necessitating
the need for a more robust data type (<code>ObjectId</code> in this case). These <code>_id</code> values can be generated either on the client
or the server, however when done client-side a new document's <code>_id</code> value is immediately available for use without the
need for a network round trip.</p>
<p>Prior to MongoDB 3.6, an <code>insert</code> operation would use the <code>OP_INSERT</code> opcode of the wire protocol to send the operation,
and retrieve the results subsequently with a <code>getLastError</code> command. If client-side <code>_id</code> values were omitted, this
command response wouldn't contain the server-created <code>_id</code> values for new documents. Following MongoDB 3.6 when all
commands would be issued using the <code>OP_MSG</code> wire protocol opcode (<code>insert</code> included), the response to the command still
wouldn't contain the <code>_id</code> values for inserted documents.</p>
<h3 id="can-a-driver-still-use-the-op_insert-op_delete-op_update"><a class="header" href="#can-a-driver-still-use-the-op_insert-op_delete-op_update">Can a driver still use the <code>OP_INSERT</code>, <code>OP_DELETE</code>, <code>OP_UPDATE</code>?</a></h3>
<p>The
<a href="https://www.mongodb.com/docs/manual/release-notes/6.0-compatibility/#legacy-opcodes-removed">legacy opcodes were removed in MongoDB 6.0</a>.
As of MongoDB 3.6 these opcodes were superseded by
<a href="https://www.mongodb.com/docs/manual/reference/mongodb-wire-protocol/#op_msg">OP_MSG</a>, however all server versions up
until 6.0 continued to support the legacy opcodes.</p>
<h3 id="can-an-application-still-issue-requests-with-write-concerns-w-0"><a class="header" href="#can-an-application-still-issue-requests-with-write-concerns-w-0">Can an application still issue requests with write concerns {w: 0}?</a></h3>
<p>Yes. The drivers are still required to serve a {w:0} write concern by returning the control to the application as soon
as possible. But a driver should send the request to the server via a write command and should, therefore, take the
corresponding response off the wire -- even if the caller is not interested in that result.</p>
<h3 id="what-happens-if-a-driver-receives-a-write-request-against-an-old-server"><a class="header" href="#what-happens-if-a-driver-receives-a-write-request-against-an-old-server">What happens if a driver receives a write request against an old server?</a></h3>
<p>It must convert that request into write operations + gle's and use the old op codes.</p>
<h3 id="are-we-discontinuing-the-use-of-getlasterror"><a class="header" href="#are-we-discontinuing-the-use-of-getlasterror">Are we discontinuing the use of getLastError?</a></h3>
<p>Yes but as of 2.6 the existing getLastError behavior is supported for backward compatibility.</p>
<h2 id="changelog-34"><a class="header" href="#changelog-34">Changelog</a></h2>
<ul>
<li>
<p>2024-07-31: Migrated from reStructuredText to Markdown.</p>
</li>
<li>
<p>2024-06-04: Add FAQ entry outlining client-side <code>_id</code> value generation Update FAQ to indicate legacy opcodes were
removed</p>
</li>
<li>
<p>2022-10-05: Revise spec front matter and reformat changelog.</p>
</li>
<li>
<p>2022-07-25: Remove outdated value for <code>maxWriteBatchSize</code></p>
</li>
<li>
<p>2021-04-22: Updated to use hello command</p>
</li>
<li>
<p>2014-05-15: Removed text related to bulk operations; see the Bulk API spec for bulk details. Clarified some
paragraphs; re-ordered the response field sections.</p>
</li>
<li>
<p>2014-05-14: First public version</p>
</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="bulk-api"><a class="header" href="#bulk-api">Bulk API</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="bulk-write"><a class="header" href="#bulk-write">Bulk Write</a></h1>
<ul>
<li>Status: Accepted</li>
<li>Minimum Server Version: 8.0</li>
</ul>
<h2 id="abstract-33"><a class="header" href="#abstract-33">Abstract</a></h2>
<p>This specification defines the driver API for the <code>bulkWrite</code> server command introduced in MongoDB 8.0. The API defined
in this specification allows users to perform insert, update, and delete operations against mixed namespaces in a
minimized number of round trips, and to receive detailed results for each operation performed. This API is distinct from
the <a href="crud/../crud/crud.html#insert-update-replace-delete-and-bulk-writes">collection-level bulkWrite method</a> defined in the
CRUD specification.</p>
<h2 id="specification-32"><a class="header" href="#specification-32">Specification</a></h2>
<blockquote>
<p>[!NOTE]
The <code>BulkWriteOptions</code>, <code>BulkWriteResult</code>, and <code>BulkWriteException</code> types defined in this specification are similar to
those used for the <code>MongoCollection.bulkWrite</code> method. Statically typed drivers MUST NOT reuse their existing
definitions for these types for the <code>MongoClient.bulkWrite</code> API and MUST introduce new types. If naming conflicts
arise, drivers SHOULD prepend "Client" to the new type names (e.g. <code>ClientBulkWriteOptions</code>).</p>
</blockquote>
<h3 id="mongoclientbulkwrite-interface"><a class="header" href="#mongoclientbulkwrite-interface"><code>MongoClient.bulkWrite</code> Interface</a></h3>
<pre><code class="language-typescript">interface MongoClient {
    /**
     * Executes a list of mixed write operations.
     *
     * @throws BulkWriteException
     */
    bulkWrite(models: NamespaceWriteModelPair[], options: Optional&lt;BulkWriteOptions&gt;): BulkWriteResult;
}
</code></pre>
<h3 id="write-models"><a class="header" href="#write-models">Write Models</a></h3>
<p>A <code>WriteModel</code> defines a single write operation to be performed as part of a bulk write.</p>
<pre><code class="language-typescript">/**
 * Unifying interface for the various write model types. Drivers may also use an enum with
 * variants for each write model for this type.
 */
interface WriteModel {}

class InsertOneModel implements WriteModel {
    /**
     * The document to insert.
     */
    document: Document;
}

class UpdateOneModel implements WriteModel {
    /**
     * The filter to apply.
     */
    filter: Document;

    /**
     * The update document or pipeline to apply to the selected document.
     */
    update: (Document | Document[]);

    /**
     * A set of filters specifying to which array elements an update should apply.
     *
     * This option is sent only if the caller explicitly provides a value.
     */
    arrayFilters: Optional&lt;Document[]&gt;;

    /**
     * Specifies a collation.
     *
     * This option is sent only if the caller explicitly provides a value.
     */
    collation: Optional&lt;Document&gt;;

    /**
     * The index to use. Specify either the index name as a string or the index key pattern. If
     * specified, then the query system will only consider plans using the hinted index.
     *
     * This option is only sent if the caller explicitly provides a value.
     */
    hint: Optional&lt;Document | String&gt;;

    /**
     * When true, creates a new document if no document matches the query.
     *
     * This option is only sent if the caller explicitly provides a value. The server's default
     * value is false.
     */
    upsert: Optional&lt;Boolean&gt;;
}

class UpdateManyModel implements WriteModel {
    /**
     * The filter to apply.
     */
    filter: Document;

    /**
     * The update document or pipeline to apply to the selected documents.
     */
    update: (Document | Document[]);

    /**
     * A set of filters specifying to which array elements an update should apply.
     *
     * This option is sent only if the caller explicitly provides a value.
     */
    arrayFilters: Optional&lt;Document[]&gt;;

    /**
     * Specifies a collation.
     *
     * This option is sent only if the caller explicitly provides a value.
     */
    collation: Optional&lt;Document&gt;;

    /**
     * The index to use. Specify either the index name as a string or the index key pattern. If
     * specified, then the query system will only consider plans using the hinted index.
     *
     * This option is only sent if the caller explicitly provides a value.
     */
    hint: Optional&lt;Document | String&gt;;

    /**
     * When true, creates a new document if no document matches the query.
     *
     * This option is only sent if the caller explicitly provides a value. The server's default
     * value is false.
     */
    upsert: Optional&lt;Boolean&gt;;
}

class ReplaceOneModel implements WriteModel {
    /**
     * The filter to apply.
     */
    filter: Document;

    /**
     * The replacement document.
     */
    replacement: Document;

    /**
     * Specifies a collation.
     *
     * This option is sent only if the caller explicitly provides a value.
     */
    collation: Optional&lt;Document&gt;;

    /**
     * The index to use. Specify either the index name as a string or the index key pattern. If
     * specified, then the query system will only consider plans using the hinted index.
     *
     * This option is only sent if the caller explicitly provides a value.
     */
    hint: Optional&lt;Document | String&gt;;

    /**
     * When true, creates a new document if no document matches the query.
     *
     * This option is only sent if the caller explicitly provides a value. The server's default
     * value is false.
     */
    upsert: Optional&lt;Boolean&gt;;
}

class DeleteOneModel implements WriteModel {
    /**
     * The filter to apply.
     */
    filter: Document;

    /**
     * Specifies a collation.
     *
     * This option is sent only if the caller explicitly provides a value.
     */
    collation: Optional&lt;Document&gt;;

    /**
     * The index to use. Specify either the index name as a string or the index key pattern. If
     * specified, then the query system will only consider plans using the hinted index.
     *
     * This option is only sent if the caller explicitly provides a value.
     */
    hint: Optional&lt;Document | String&gt;;
}

class DeleteManyModel implements WriteModel {
    /**
     * The filter to apply.
     */
    filter: Document;

    /**
     * Specifies a collation.
     *
     * This option is sent only if the caller explicitly provides a value.
     */
    collation: Optional&lt;Document&gt;;

    /**
     * The index to use. Specify either the index name as a string or the index key pattern. If
     * specified, then the query system will only consider plans using the hinted index.
     *
     * This option is only sent if the caller explicitly provides a value.
     */
    hint: Optional&lt;Document | String&gt;;
}
</code></pre>
<p>Each write model provided to <code>MongoClient.bulkWrite</code> in the <code>models</code> parameter MUST have a corresponding namespace that
defines the collection on which the operation should be performed. Drivers SHOULD design this pairing in whichever way
is most idiomatic for its language. For example, drivers may:</p>
<ul>
<li>Include a required <code>namespace</code> field on each <code>WriteModel</code> variant and accept a list of <code>WriteModel</code> objects for the
<code>models</code> parameter.</li>
<li>Accept a list of <code>(Namespace, WriteModel)</code> tuples for <code>models</code>.</li>
<li>Define the following pair class:</li>
</ul>
<pre><code class="language-typescript">class NamespaceWriteModelPair {
    /**
     * The namespace on which to perform the write.
     */
    namespace: Namespace;

    /**
     * The write to perform.
     */
    model: WriteModel;
}
</code></pre>
<p>Drivers MUST throw an exception if the list provided for <code>models</code> is empty.</p>
<h4 id="update-vs-replace-document-validation"><a class="header" href="#update-vs-replace-document-validation">Update vs. replace document validation</a></h4>
<p>Update documents provided in <code>UpdateOne</code> and <code>UpdateMany</code> write models are required only to contain atomic modifiers
(i.e. keys that start with "$"). Drivers MUST throw an error if an update document is empty or if the document's first
key does not start with "$". Drivers MUST rely on the server to return an error if any other entries in the update
document are not atomic modifiers. Drivers are not required to perform validation on update pipelines.</p>
<p>Replacement documents provided in <code>ReplaceOne</code> write models are required not to contain atomic modifiers. Drivers MUST
throw an error if a replacement document is nonempty and its first key starts with "$". Drivers MUST rely on the server
to return an error if any other entries in the replacement document are atomic modifiers.</p>
<h3 id="options-1"><a class="header" href="#options-1">Options</a></h3>
<pre><code class="language-typescript">class BulkWriteOptions {
    /**
     * Whether the operations in this bulk write should be executed in the order in which they were
     * specified. If false, writes will continue to be executed if an individual write fails. If
     * true, writes will stop executing if an individual write fails.
     *
     * Defaults to true.
     */
    ordered: Optional&lt;Boolean&gt;;

    /**
     * If true, allows the writes to opt out of document-level validation.
     *
     * This option is only sent if the caller explicitly provides a value. The server's default
     * value is false.
     */
    bypassDocumentValidation: Optional&lt;Boolean&gt;;

    /**
     * A map of parameter names and values to apply to all operations within the bulk write. Value
     * must be constant or closed expressions that do not reference document fields. Parameters can
     * then be accessed as variables in an aggregate expression context (e.g. "$$var").
     *
     * This option is only sent if the caller explicitly provides a value.
     */
    let: Optional&lt;Document&gt;;

    /**
     * The write concern to use for this bulk write.
     */
    writeConcern: Optional&lt;WriteConcern&gt;;

    /**
     * Enables users to specify an arbitrary comment to help trace the operation through
     * the database profiler, currentOp and logs.
     *
     * This option is only sent if the caller explicitly provides a value.
     */
    comment: Optional&lt;BSON value&gt;;

    /**
     * Whether detailed results for each successful operation should be included in the returned
     * BulkWriteResult.
     *
     * Defaults to false. This value corresponds inversely to the errorsOnly field in the bulkWrite
     * command.
     */
    verboseResults: Optional&lt;Boolean&gt;;
}
</code></pre>
<h3 id="result"><a class="header" href="#result">Result</a></h3>
<pre><code class="language-typescript">class BulkWriteResult {
    /**
     * Indicates whether this write result was acknowledged.
     *
     * NOT REQUIRED TO IMPLEMENT. See below for guidance on modeling unacknowledged results.
     */
    acknowledged: Boolean;

    /**
     * Indicates whether this result contains verbose results.
     *
     * NOT REQUIRED TO IMPLEMENT. See below for guidance on modeling verbose results.
     */
    hasVerboseResults: Boolean;

    /**
     * The total number of documents inserted across all insert operations.
     */
    insertedCount: Int64;

    /**
     * The total number of documents upserted across all update operations.
     */
    upsertedCount: Int64;

    /**
     * The total number of documents matched across all update operations.
     */
    matchedCount: Int64;

    /**
     * The total number of documents modified across all update operations.
     */
    modifiedCount: Int64;

    /**
     * The total number of documents deleted across all delete operations.
     */
    deletedCount: Int64;

    /**
     * The results of each individual insert operation that was successfully performed.
     *
     * NOT REQUIRED TO IMPLEMENT. See below for guidance on modeling verbose results.
     */
    insertResults: Map&lt;Index, InsertOneResult&gt;;

    /**
     * The results of each individual update operation that was successfully performed.
     *
     * NOT REQUIRED TO IMPLEMENT. See below for guidance on modeling verbose results.
     */
    updateResults: Map&lt;Index, UpdateResult&gt;;

    /**
     * The results of each individual delete operation that was successfully performed.
     *
     * NOT REQUIRED TO IMPLEMENT. See below for guidance on modeling verbose results.
     */
    deleteResults: Map&lt;Index, DeleteResult&gt;;
}

class InsertOneResult {
    /**
     * The _id of the inserted document.
     */
    insertedId: Any;
}

class UpdateResult {
    /**
     * The number of documents that matched the filter.
     */
    matchedCount: Int64;

    /**
     * The number of documents that were modified.
     */
    modifiedCount: Int64;

    /**
     * The _id field of the upserted document if an upsert occurred.
     *
     * It MUST be possible to discern between a BSON Null upserted ID value and this field being
     * unset. If necessary, drivers MAY add a didUpsert boolean field to differentiate between
     * these two cases.
     */
    upsertedId: Optional&lt;BSON value&gt;;
}

class DeleteResult {
    /**
     * The number of documents that were deleted.
     */
    deletedCount: Int64;
}
</code></pre>
<h4 id="unacknowledged-results"><a class="header" href="#unacknowledged-results">Unacknowledged results</a></h4>
<p>Users MUST be able to discern whether a <code>BulkWriteResult</code> contains acknowledged results without inspecting the
configured write concern. Drivers should follow the guidance in the CRUD specification
<a href="crud/../crud/crud.html#write-results">here</a> to determine how to model unacknowledged results.</p>
<p>If drivers expose the <code>acknowledged</code> field, they MUST document what will happen if a user attempts to access a result
value when <code>acknowledged</code> is <code>false</code> (e.g. an undefined value is returned or an error is thrown).</p>
<h4 id="summary-vs-verbose-results"><a class="header" href="#summary-vs-verbose-results">Summary vs. verbose results</a></h4>
<p>When a user does not set the <code>verboseResults</code> option to <code>true</code>, drivers MUST NOT populate the <code>insertResults</code>,
<code>updateResults</code>, and <code>deleteResults</code> fields. Users MUST be able to discern whether a <code>BulkWriteResult</code> contains these
verbose results without inspecting the value provided for <code>verboseResults</code> in <code>BulkWriteOptions</code>. Drivers can implement
this in a number of ways, including:</p>
<ul>
<li>Expose the <code>hasVerboseResults</code> field in <code>BulkWriteResult</code> as defined above. Document what will happen if a user
attempts to access the <code>insertResults</code>, <code>updateResults</code>, or <code>deleteResults</code> values when <code>hasVerboseResults</code> is false.
Drivers MAY raise an error if a user attempts to access one of these values when <code>hasVerboseResults</code> is false.</li>
<li>Embed the verbose results in an optional type:</li>
</ul>
<pre><code class="language-typescript">class BulkWriteResult {
    /**
     * The results of each individual write operation that was successfully performed.
     *
     * This value will only be populated if the verboseResults option was set to true.
     */ 
    verboseResults: Optional&lt;VerboseResults&gt;;

    /* rest of fields */
}

class VerboseResults {
    /**
     * The results of each individual insert operation that was successfully performed.
     */
    insertResults: Map&lt;Index, InsertOneResult&gt;;

    /**
     * The results of each individual update operation that was successfully performed.
     */
    updateResults: Map&lt;Index, UpdateResult&gt;;

    /**
     * The results of each individual delete operation that was successfully performed.
     */
    deleteResults: Map&lt;Index, DeleteResult&gt;;
}
</code></pre>
<ul>
<li>Define separate <code>SummaryBulkWriteResult</code> and <code>VerboseBulkWriteResult</code> types. <code>SummaryBulkWriteResult</code> MUST only
contain the summary result fields, and <code>VerboseBulkWriteResult</code> MUST contain both the summary and verbose result
fields. Return <code>VerboseBulkWriteResult</code> when <code>verboseResults</code> was set to true and <code>SummaryBulkWriteResult</code> otherwise.</li>
</ul>
<h4 id="individual-results"><a class="header" href="#individual-results">Individual results</a></h4>
<p>The <code>InsertOneResult</code>, <code>UpdateResult</code>, and <code>DeleteResult</code> classes are the same as or similar to types of the same name
defined in the <a href="crud/crud.html">CRUD specification</a>. Drivers MUST redefine these classes if their existing result classes
deviate from the definitions in this specification (e.g. if they contain acknowledgement information, which is not
applicable for individual bulk write operations). Drivers MAY reuse their existing types for these classes if they match
the ones defined here exactly.</p>
<h3 id="exception"><a class="header" href="#exception">Exception</a></h3>
<pre><code class="language-typescript">class BulkWriteException {
    /**
     * A top-level error that occurred when attempting to communicate with the server or execute
     * the bulk write. This value may not be populated if the exception was thrown due to errors
     * occurring on individual writes.
     */
    error: Optional&lt;Error&gt;;

    /**
     * Write concern errors that occurred while executing the bulk write. This list may have
     * multiple items if more than one server command was required to execute the bulk write.
     */
    writeConcernErrors: WriteConcernError[];

    /**
     * Errors that occurred during the execution of individual write operations. This map will
     * contain at most one entry if the bulk write was ordered.
     */
    writeErrors: Map&lt;Index, WriteError&gt;;

    /**
     * The results of any successful operations that were performed before the error was
     * encountered.
     */
    partialResult: Optional&lt;BulkWriteResult&gt;;
}
</code></pre>
<h3 id="index-types"><a class="header" href="#index-types">Index Types</a></h3>
<p>The <code>insertResults</code>, <code>updateResults</code>, and <code>deleteResults</code> maps in <code>BulkWriteResult</code> and the <code>writeErrors</code> map in
<code>BulkWriteException</code> specify <code>Index</code> as their key type. This value corresponds to the index of the operation in the
<code>writeModels</code> list that was provided to <code>MongoClient.bulkWrite</code>. Drivers SHOULD use their language's standard numeric
type for indexes for this type (e.g. <code>usize</code> in Rust). If no standard index type exists, drivers MUST use <code>Int64</code>.</p>
<h2 id="building-a-bulkwrite-command"><a class="header" href="#building-a-bulkwrite-command">Building a <code>bulkWrite</code> Command</a></h2>
<p>The <code>bulkWrite</code> server command has the following format:</p>
<pre><code class="language-javascript">{
    "bulkWrite": 1,
    "ops": &lt;Array&gt;,
    "nsInfo": &lt;Array&gt;,
    "errorsOnly": Optional&lt;Boolean&gt;,
    "ordered": Optional&lt;Boolean&gt;,
    "bypassDocumentValidation": Optional&lt;Boolean&gt;,
    "comment": Optional&lt;BSON value&gt;,
    "let": Optional&lt;Document&gt;,
    ...additional operation-agnostic fields
}
</code></pre>
<p>Drivers MUST use document sequences (<a href="crud/../message/OP_MSG.html"><code>OP_MSG</code></a> payload type 1) for the <code>ops</code> and <code>nsInfo</code> fields.</p>
<p>The <code>bulkWrite</code> command is executed on the "admin" database.</p>
<h3 id="operations-3"><a class="header" href="#operations-3">Operations</a></h3>
<p>The <code>ops</code> field is a list of write operation documents. The first entry in each document has the name of the operation
(i.e. "insert", "update", or "delete") as its key and the index in the <code>nsInfo</code> array of the namespace on which the
operation should be performed as its value. The documents have the following format:</p>
<h4 id="insert-1"><a class="header" href="#insert-1">Insert</a></h4>
<pre><code class="language-javascript">{
    "insert": &lt;Int32&gt;,
    "document": &lt;Document&gt;
}
</code></pre>
<p>If the document to be inserted does not contain an <code>_id</code> field, drivers MUST generate a new
<a href="crud/../bson-objectid/objectid.html"><code>ObjectId</code></a> and add it as the <code>_id</code> field at the beginning of the document.</p>
<h4 id="update-1"><a class="header" href="#update-1">Update</a></h4>
<pre><code class="language-javascript">{
    "update": &lt;Int32&gt;,
    "filter": &lt;Document&gt;,
    "updateMods": &lt;Document | Array&gt;,
    "multi": Optional&lt;Boolean&gt;,
    "upsert": Optional&lt;Boolean&gt;,
    "arrayFilters": Optional&lt;Array&gt;,
    "hint": Optional&lt;Document | String&gt;,
    "collation": Optional&lt;Document&gt;
}
</code></pre>
<p>The <code>update</code> command document is used for update and replace operations. For update operations, the <code>updateMods</code> field
corresponds to the <code>update</code> field in <code>UpdateOneModel</code> and <code>UpdateManyModel</code>. For replace operations, the <code>updateMods</code>
field corresponds to the <code>replacement</code> field in <code>ReplaceOneModel</code>.</p>
<h4 id="delete-1"><a class="header" href="#delete-1">Delete</a></h4>
<pre><code class="language-javascript">{
    "delete": &lt;Int32&gt;,
    "filter": &lt;Document&gt;,
    "multi": Optional&lt;Boolean&gt;,
    "hint": Optional&lt;Document | String&gt;,
    "collation": Optional&lt;Document&gt;
}
</code></pre>
<h3 id="namespace-information"><a class="header" href="#namespace-information">Namespace Information</a></h3>
<p>The <code>nsInfo</code> field is an array containing the namespaces on which the write operations should be performed. Drivers MUST
NOT include duplicate namespaces in this list. The documents in the <code>nsInfo</code> array have the following format:</p>
<pre><code class="language-javascript">{
    "ns": &lt;String&gt;
}
</code></pre>
<h3 id="errorsonly-and-verboseresults"><a class="header" href="#errorsonly-and-verboseresults"><code>errorsOnly</code> and <code>verboseResults</code></a></h3>
<p>The <code>errorsOnly</code> field indicates whether the results cursor returned in the <code>bulkWrite</code> response should contain only
errors and omit individual results. If false, both individual results for successful operations and errors will be
returned. This field is optional and defaults to false on the server.</p>
<p><code>errorsOnly</code> corresponds inversely to the <code>verboseResults</code> option defined on <code>BulkWriteOptions</code>. If the user specified a
value for <code>verboseResults</code>, drivers MUST define <code>errorsOnly</code> as the opposite of <code>verboseResults</code>. If the user did not
specify a value for <code>verboseResults</code>, drivers MUST define <code>errorsOnly</code> as <code>true</code>.</p>
<h3 id="ordered"><a class="header" href="#ordered"><code>ordered</code></a></h3>
<p>The <code>ordered</code> field defines whether writes should be executed in the order in which they were specified, and, if an
error occurs, whether the server should halt execution of further writes. It is optional and defaults to true on the
server. Drivers MUST explicitly define <code>ordered</code> as <code>true</code> in the <code>bulkWrite</code> command if a value is not specified in
<code>BulkWriteOptions</code>. This is required to avoid inconsistencies between server and driver behavior if the server default
changes in the future.</p>
<h3 id="size-limits"><a class="header" href="#size-limits">Size Limits</a></h3>
<p>The server reports a <code>maxBsonObjectSize</code> in its <code>hello</code> response. This value defines the maximum size for documents that
are inserted into the database. Documents that are sent to the server but are not intended to be inserted into the
database (e.g. command documents) have a size limit of <code>maxBsonObjectSize + 16KiB</code>. When an acknowledged write concern
is used, drivers MUST NOT perform any checks related to these size limits and MUST rely on the server to raise an error
if a limit is exceeded. However, when an unacknowledged write concern is used, drivers MUST raise an error if one of the
following limits is exceeded:</p>
<ul>
<li>The size of a document to be inserted MUST NOT exceed <code>maxBsonObjectSize</code>. This applies to the <code>document</code> field of an
<code>InsertOneModel</code> and the <code>replacement</code> field of a <code>ReplaceOneModel</code>.</li>
<li>The size of an entry in the <code>ops</code> array MUST NOT exceed <code>maxBsonObjectSize + 16KiB</code>.</li>
<li>The size of the <code>bulkWrite</code> command document MUST NOT exceed <code>maxBsonObjectSize + 16KiB</code>.</li>
</ul>
<p>See <a href="https://jira.mongodb.org/browse/SERVER-10643">SERVER-10643</a> for more details on these size limits.</p>
<h2 id="auto-encryption"><a class="header" href="#auto-encryption">Auto-Encryption</a></h2>
<p>If <code>MongoClient.bulkWrite</code> is called on a <code>MongoClient</code> configured with <code>AutoEncryptionOpts</code>, drivers MUST return an
error with the message: "bulkWrite does not currently support automatic encryption".</p>
<p>This is expected to be removed once <a href="https://jira.mongodb.org/browse/DRIVERS-2888">DRIVERS-2888</a> is implemented.</p>
<h2 id="command-batching"><a class="header" href="#command-batching">Command Batching</a></h2>
<p>Drivers MUST accept an arbitrary number of operations as input to the <code>MongoClient.bulkWrite</code> method. Because the server
imposes restrictions on the size of write operations, this means that a single call to <code>MongoClient.bulkWrite</code> may
require multiple <code>bulkWrite</code> commands to be sent to the server. Drivers MUST split bulk writes into separate commands
when the user's list of operations exceeds one or more of these maximums: <code>maxWriteBatchSize</code>, <code>maxBsonObjectSize</code> (for
<code>OP_MSG</code> payload type 0), and <code>maxMessageSizeBytes</code> (for <code>OP_MSG</code> payload type 1). Each of these values can be retrieved
from the selected server's <code>hello</code> command response. Drivers MUST merge results from multiple batches into a single
<code>BulkWriteResult</code> or <code>BulkWriteException</code> to return from <code>MongoClient.bulkWrite</code>.</p>
<p>When constructing the <code>nsInfo</code> array for a <code>bulkWrite</code> batch, drivers MUST only include the namespaces that are
referenced in the <code>ops</code> array for that batch.</p>
<h3 id="number-of-writes"><a class="header" href="#number-of-writes">Number of Writes</a></h3>
<p><code>maxWriteBatchSize</code> defines the total number of writes allowed in one command. Drivers MUST split a bulk write into
multiple commands if the user provides more than <code>maxWriteBatchSize</code> operations in the argument for <code>models</code>.</p>
<h3 id="total-message-size"><a class="header" href="#total-message-size">Total Message Size</a></h3>
<p>Drivers MUST ensure that the total size of the <code>OP_MSG</code> built for each <code>bulkWrite</code> command does not exceed
<code>maxMessageSizeBytes</code>.</p>
<p>The upper bound for the size of an <code>OP_MSG</code> includes opcode-related bytes (e.g. the <code>OP_MSG</code> header) and
operation-agnostic command field bytes (e.g. <code>txnNumber</code>, <code>lsid</code>). Drivers MUST limit the combined size of the
<code>bulkWrite</code> command document (excluding command-agnostic fields), <code>ops</code> document sequence, and <code>nsInfo</code> document
sequence to <code>maxMessageSizeBytes - 1000</code> to account for this overhead. The following pseudocode demonstrates how to
apply this limit in batch-splitting logic:</p>
<pre><code>MESSAGE_OVERHEAD_BYTES = 1000

bulkWriteCommand = Document { "bulkWrite": 1 }
bulkWriteCommand.appendOptions(bulkWriteOptions)

maxOpsNsInfoBytes = maxMessageSizeBytes - (MESSAGE_OVERHEAD_BYTES + bulkWriteCommand.numBytes())

while (writeModels.hasNext()) {
    ops = DocumentSequence {}
    nsInfo = DocumentSequence {}
    while (true) {
        if (!writeModels.hasNext()) {
            break
        }
        model = writeModels.next()

        modelDoc = writeModel.toOpsDoc()
        bytesAdded = modelDoc.numBytes()

        nsInfoDoc = null
        if (!nsInfo.contains(model.namespace)) {
            nsInfoDoc = model.namespace.toNsInfoDoc()
            bytesAdded += nsInfoDoc.numBytes()
        }

        newSize = ops.numBytes() + nsInfo.numBytes() + bytesAdded
        if (newSize &gt; maxOpsNsInfoBytes) {
            break
        } else {
            ops.push(modelDoc)
            if (nsInfoDoc != null) {
                nsInfo.push(nsInfoDoc)
            }
        }
    }

    // construct and send OP_MSG
}
</code></pre>
<p>See <a href="crud/bulk-write.html#how-was-the-op_msg-overhead-allowance-determined">this Q&amp;A entry</a> for more details on how the overhead allowance
was determined.</p>
<p>Drivers MUST return an error if there is not room to add at least one operation to <code>ops</code>.</p>
<h2 id="handling-the-bulkwrite-server-response"><a class="header" href="#handling-the-bulkwrite-server-response">Handling the <code>bulkWrite</code> Server Response</a></h2>
<p>The server's response to <code>bulkWrite</code> has the following format:</p>
<pre><code class="language-javascript">{
    "ok": &lt;0 | 1&gt;,
    "cursor": {
        "id": &lt;Int64&gt;,
        "firstBatch": &lt;Array&gt;,
        "ns": &lt;String&gt;
    },
    "nErrors": &lt;Int32&gt;,
    "nInserted": &lt;Int32&gt;,
    "nUpserted": &lt;Int32&gt;,
    "nMatched": &lt;Int32&gt;,
    "nModified": &lt;Int32&gt;,
    "nDeleted": &lt;Int32&gt;,
    ...additional command-agnostic fields
}
</code></pre>
<p>Drivers MUST record the summary count fields in a <code>BulkWriteResult</code> to be returned to the user or embedded in a
<code>BulkWriteException</code> if the response indicates that at least one write was successful:</p>
<ul>
<li>For ordered bulk writes, at least one write was successful if <code>nErrors</code> is 0 or if the <code>idx</code> value for the write error
returned in the results cursor is greater than 0.</li>
<li>For unordered bulk writes, at least one write was successful if <code>nErrors</code> is less than the number of operations that
were included in the <code>bulkWrite</code> command.</li>
</ul>
<p>Drivers MUST NOT populate the <code>partialResult</code> field in <code>BulkWriteException</code> if it cannot be determined that at least one
write was successfully performed.</p>
<p>Drivers MUST attempt to consume the contents of the cursor returned in the server's <code>bulkWrite</code> response before
returning to the user. This is required regardless of whether the user requested verbose or summary results, as the
results cursor always contains any write errors that occurred. If the cursor contains a nonzero cursor ID, drivers MUST
perform <code>getMore</code> until the cursor has been exhausted. Drivers MUST use the same session used for the <code>bulkWrite</code>
command for each <code>getMore</code> call. When connected to a load balancer, drivers MUST use the connection used for the
<code>bulkWrite</code> command to create the cursor to ensure the same server is targeted.</p>
<p>The documents in the results cursor have the following format:</p>
<pre><code class="language-javascript">{
    "ok": &lt;0 | 1&gt;,
    "idx": Int32,
    "code": Optional&lt;Int32&gt;,
    "errmsg": Optional&lt;String&gt;,
    "errInfo": Optional&lt;Document&gt;,
    "n": &lt;Int32&gt;,
    "nModified": Optional&lt;Int32&gt;,
    "upserted": Optional&lt;Document with "_id" field&gt;
}
</code></pre>
<p>If an error occurred (i.e. the value for <code>ok</code> is 0), the <code>code</code>, <code>errmsg</code>, and optionally <code>errInfo</code> fields will be
populated with details about the failure.</p>
<p>If the write succeeded, (i.e. the value for <code>ok</code> is 1), <code>n</code>, <code>nModified</code>, and <code>upsertedId</code> will be populated with the
following values based on the type of write:</p>
<div class="table-wrapper"><table><thead><tr><th>Response Field</th><th>Insert</th><th>Update</th><th>Delete</th></tr></thead><tbody>
<tr><td><code>n</code></td><td>The number of documents that were inserted.</td><td>The number of documents that matched the filter.</td><td>The number of documents that were deleted.</td></tr>
<tr><td><code>nModified</code></td><td>Not present.</td><td>The number of documents that were modified.</td><td>Not present.</td></tr>
<tr><td><code>upserted</code></td><td>Not present.</td><td>A document containing the <code>_id</code> value for the upserted document. Only present if an upsert took place.</td><td>Not present.</td></tr>
</tbody></table>
</div>
<p>Note that the responses do not contain information about the type of operation that was performed. Drivers may need to
maintain the user's list of write models to infer which type of result should be recorded based on the value of <code>idx</code>.</p>
<h3 id="handling-insert-results"><a class="header" href="#handling-insert-results">Handling Insert Results</a></h3>
<p>Unlike the other result types, <code>InsertOneResult</code> contains an <code>insertedId</code> field that is generated driver-side, either by
recording the <code>_id</code> field present in the user's insert document or creating and adding one. Drivers MUST only record
these <code>insertedId</code> values in a <code>BulkWriteResult</code> when a successful response for the insert operation (i.e.
<code>{ "ok": 1, "n": 1 }</code>) is received in the results cursor. This ensures that drivers only report an <code>insertedId</code> when it
is confirmed that the insert succeeded.</p>
<h2 id="handling-errors"><a class="header" href="#handling-errors">Handling Errors</a></h2>
<h3 id="top-level-errors"><a class="header" href="#top-level-errors">Top-Level Errors</a></h3>
<p>A top-level error is any error that occurs that is not the result of a single write operation failing or a write concern
error. Examples include network errors that occur when communicating with the server, command errors (<code>{ "ok": 0 }</code>)
returned from the server, client-side errors, and errors that occur when attempting to perform a <code>getMore</code> to retrieve
results from the server.</p>
<p>When a top-level error is caused by a command error (i.e. an <code>{ "ok": 0 }</code> server response), drivers MUST provide access
to the raw server reply in the error returned to the user.</p>
<p>When a top-level error is encountered and individual results and/or errors have already been observed, drivers MUST
embed the top-level error within a <code>BulkWriteException</code> as the <code>error</code> field to retain this information. Otherwise,
drivers MAY throw an exception containing only the top-level error.</p>
<p>Encountering a top-level error MUST halt execution of a bulk write for both ordered and unordered bulk writes. This
means that drivers MUST NOT attempt to retrieve more responses from the cursor or execute any further <code>bulkWrite</code>
batches and MUST immediately throw an exception. If the results cursor has not been exhausted on the server when a
top-level error occurs, drivers MUST send the <code>killCursors</code> command to attempt to close it. The result returned from the
<code>killCursors</code> command MAY be ignored.</p>
<h3 id="write-concern-errors"><a class="header" href="#write-concern-errors">Write Concern Errors</a></h3>
<p>Write concern errors are recorded in the <code>writeConcernErrors</code> field on <code>BulkWriteException</code>. When a write concern error
is encountered, it should not terminate execution of the bulk write for either ordered or unordered bulk writes.
However, drivers MUST throw an exception at the end of execution if any write concern errors were observed.</p>
<h3 id="individual-write-errors"><a class="header" href="#individual-write-errors">Individual Write Errors</a></h3>
<p>Individual write errors retrieved from the cursor are recorded in the <code>writeErrors</code> field on <code>BulkWriteException</code>. If an
individual write error is encountered during an ordered bulk write, drivers MUST record the error in <code>writeErrors</code> and
immediately throw the exception. Otherwise, drivers MUST continue to iterate the results cursor and execute any further
<code>bulkWrite</code> batches.</p>
<h2 id="test-plan-26"><a class="header" href="#test-plan-26">Test Plan</a></h2>
<p>The majority of tests for <code>MongoClient.bulkWrite</code> are written in the
<a href="crud/../unified-test-format/unified-test-format.html">Unified Test Format</a> and reside in the CRUD unified tests directory.</p>
<p>Additional prose tests are specified <a href="crud/../crud/tests/README.html">here</a>. These tests require constructing very large
documents to test batch splitting, which is not feasible in the unified test format at the time of writing this
specification.</p>
<h2 id="future-work-13"><a class="header" href="#future-work-13">Future Work</a></h2>
<h3 id="retry-bulkwrite-when-getmore-fails-with-a-retryable-error"><a class="header" href="#retry-bulkwrite-when-getmore-fails-with-a-retryable-error">Retry <code>bulkWrite</code> when <code>getMore</code> fails with a retryable error</a></h3>
<p>When a <code>getMore</code> fails with a retryable error when attempting to iterate the results cursor, drivers could retry the
entire <code>bulkWrite</code> command to receive a fresh cursor and retry iteration. This work was omitted to minimize the scope of
the initial implementation and testing of the new bulk write API, but may be revisited in the future.</p>
<h2 id="qa-11"><a class="header" href="#qa-11">Q&amp;A</a></h2>
<h3 id="is-bulkwrite-supported-on-atlas-serverless"><a class="header" href="#is-bulkwrite-supported-on-atlas-serverless">Is <code>bulkWrite</code> supported on Atlas Serverless?</a></h3>
<p>No. See <a href="https://jira.mongodb.org/browse/CLOUDP-256344">CLOUDP-256344</a></p>
<h3 id="why-are-we-adding-a-new-bulk-write-api-rather-than-updating-the-mongocollectionbulkwrite-implementation"><a class="header" href="#why-are-we-adding-a-new-bulk-write-api-rather-than-updating-the-mongocollectionbulkwrite-implementation">Why are we adding a new bulk write API rather than updating the <code>MongoCollection.bulkWrite</code> implementation?</a></h3>
<p>The new <code>bulkWrite</code> command is only available in MongoDB 8.0+, so it cannot function as a drop-in replacement for the
existing bulk write implementation that uses the <code>insert</code>, <code>update</code>, and <code>delete</code> commands. Additionally, because the
new <code>bulkWrite</code> command allows operations against multiple collections and databases, <code>MongoClient</code> is a more
appropriate place to expose its functionality.</p>
<h3 id="why-cant-drivers-reuse-existing-bulk-write-types"><a class="header" href="#why-cant-drivers-reuse-existing-bulk-write-types">Why can't drivers reuse existing bulk write types?</a></h3>
<p>This specification introduces several types that are similar to existing types used in the <code>MongoCollection.bulkWrite</code>
API. Although these types are similar now, they may diverge in the future with the introduction of new options and
features to the <code>bulkWrite</code> command. Introducing new types also provides more clarity to users on the existing
differences between the collection-level and client-level bulk write APIs. For example, the <code>verboseResults</code> option is
only available for <code>MongoClient.bulkWrite</code>.</p>
<h3 id="why-are-bulk-write-operation-results-returned-in-a-cursor"><a class="header" href="#why-are-bulk-write-operation-results-returned-in-a-cursor">Why are bulk write operation results returned in a cursor?</a></h3>
<p>Returning results via a cursor rather than an array in the <code>bulkWrite</code> response allows full individual results and
errors to be returned without the risk of the response exceeding the maximum BSON object size. Using a cursor also
leaves open the opportunity to add <code>findAndModify</code> to the list of supported write operations in the future.</p>
<h3 id="why-was-the-verboseresults-option-introduced-and-why-is-its-default-false"><a class="header" href="#why-was-the-verboseresults-option-introduced-and-why-is-its-default-false">Why was the <code>verboseResults</code> option introduced, and why is its default <code>false</code>?</a></h3>
<p>The <code>bulkWrite</code> command returns top-level summary result counts and, optionally, individual results for each operation.
Compiling the individual results server-side and consuming these results driver-side is less performant than only
recording the summary counts. We expect that most users are not interested in the individual results of their operations
and that most users will rely on defaults, so <code>verboseResults</code> defaults to <code>false</code> to improve performance in the common
case.</p>
<h3 id="why-should-drivers-send-bypassdocumentvalidation-false-for-bulkwrite"><a class="header" href="#why-should-drivers-send-bypassdocumentvalidation-false-for-bulkwrite">Why should drivers send <code>bypassDocumentValidation: false</code> for <code>bulkWrite</code>?</a></h3>
<p><a href="https://jira.mongodb.org/browse/DRIVERS-450">DRIVERS-450</a> introduced a requirement that drivers only send a value for
<code>bypassDocumentValidation</code> on write commands if it was specified as true. The original motivation for this change is not
documented. This specification requires that drivers send <code>bypassDocumentValidation</code> in the <code>bulkWrite</code> command if it is
set by the user in <code>BulkWriteOptions</code>, regardless of its value.</p>
<p>Explicitly defining <code>bypassDocumentValidation: false</code> aligns with the server's default to perform schema validation and
thus has no effect. However, checking the value of an option that the user specified and omitting it from the command
document if it matches the server's default creates unnecessary work for drivers. Always sending the user's specified
value also safeguards against the unlikely event that the server changes the default value for
<code>bypassDocumentValidation</code> in the future.</p>
<h3 id="why-is-providing-access-to-the-raw-server-response-when-a-command-error-occurs-required"><a class="header" href="#why-is-providing-access-to-the-raw-server-response-when-a-command-error-occurs-required">Why is providing access to the raw server response when a command error occurs required?</a></h3>
<p>This allows users to access new error fields that the server may add in the future without needing to upgrade their
driver version. See <a href="https://jira.mongodb.org/browse/DRIVERS-2385">DRIVERS-2385</a> for more details.</p>
<h3 id="why-are-drivers-required-to-send-nsinfo-as-a-document-sequence"><a class="header" href="#why-are-drivers-required-to-send-nsinfo-as-a-document-sequence">Why are drivers required to send <code>nsInfo</code> as a document sequence?</a></h3>
<p><code>nsInfo</code> could exceed <code>maxBsonObjectSize</code> if a user is doing <code>maxWriteBatchSize</code> operations, each operation is on a
unique namespace, and each namespace is near the
<a href="https://www.mongodb.com/docs/manual/reference/limits/#mongodb-limit-Restriction-on-Collection-Names">maximum length</a>
allowed for namespaces given the values for these limits at the time of writing this specification. Providing <code>nsInfo</code>
as a document sequence reduces the likelihood that a driver would need to batch split a user's bulk write in this
scenario.</p>
<h3 id="how-was-the-op_msg-overhead-allowance-determined"><a class="header" href="#how-was-the-op_msg-overhead-allowance-determined">How was the <code>OP_MSG</code> overhead allowance determined?</a></h3>
<p>The Command Batching <a href="crud/bulk-write.html#total-message-size">Total Message Size</a> section uses a 1000 byte overhead allowance to
approximate the number of non-<code>bulkWrite</code>-specific bytes contained in an <code>OP_MSG</code> sent for a <code>bulkWrite</code> batch. This
number was determined by constructing <code>OP_MSG</code> messages with various fields attached to the command, including
<code>startTransaction</code>, <code>autocommit</code>, and <code>apiVersion</code>. Additional room was allocated to allow for future additions to the
<code>OP_MSG</code> structure or the introduction of new command-agnostic fields.</p>
<p>Drivers are required to use this value even if they are capable of determining the exact size of the message prior to
batch-splitting to standardize implementations across drivers and simplify batch-splitting testing.</p>
<h2 id="changelog-35"><a class="header" href="#changelog-35"><strong>Changelog</strong></a></h2>
<ul>
<li>
<p>2024-09-30: Define more options for modeling summary vs. verbose results.</p>
</li>
<li>
<p>2024-09-25: Add <code>collation</code> field to <code>update</code> document and clarify usage of <code>updateMods</code>.</p>
</li>
<li>
<p>2024-09-25: Update the <code>partialResult</code> population logic to account for ordered bulk writes.</p>
</li>
<li>
<p>2024-09-18: Relax numeric type requirements for indexes.</p>
</li>
<li>
<p>2024-05-17: Update specification status to "Accepted".</p>
</li>
<li>
<p>2024-05-10: Improve rendered format for JSON-like code blocks.</p>
</li>
<li>
<p>2024-05-08: Bulk write specification created.</p>
</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="read-and-write-concern"><a class="header" href="#read-and-write-concern">Read and Write Concern</a></h1>
<ul>
<li>Status: Accepted</li>
<li>Minimum Server Version: 2.4</li>
</ul>
<hr />
<h2 id="abstract-34"><a class="header" href="#abstract-34">Abstract</a></h2>
<p>A driver must support configuring and sending read concern and write concerns to a server. This specification defines
the API drivers must implement as well as how that API is translated into messages for communication with the server.</p>
<h2 id="meta-34"><a class="header" href="#meta-34">META</a></h2>
<p>The keywords "MUST", "MUST NOT", "REQUIRED", "SHALL", "SHALL NOT", "SHOULD", "SHOULD NOT", "RECOMMENDED", "MAY", and
"OPTIONAL" in this document are to be interpreted as described in <a href="https://www.ietf.org/rfc/rfc2119.txt">RFC 2119</a>.</p>
<h2 id="terminology-1"><a class="header" href="#terminology-1">Terminology</a></h2>
<p>MaxWireVersion The <code>maxWireVersion</code> value reported by the <code>hello</code> command.</p>
<p>Server Selection The process of selecting a server to read or write from. See
<a href="read-write-concern/../server-selection/server-selection.html">the server selection specification</a>.</p>
<h2 id="specification-33"><a class="header" href="#specification-33">Specification</a></h2>
<p>This specification includes guidance for implementing <a href="read-write-concern/read-write-concern.html#read-concern">Read Concern</a> and <a href="read-write-concern/read-write-concern.html#write-concern">Write Concern</a>
in a driver. It does not define how read and write concern behave or are implemented on the server.</p>
<h3 id="read-concern"><a class="header" href="#read-concern">Read Concern</a></h3>
<p>For naming and deviation guidance, see the <a href="read-write-concern/../crud/crud.html#naming">CRUD specification</a>. Defined below are the
constructs for drivers.</p>
<pre><code class="language-typescript">enum ReadConcernLevel {
    /**
     * This is rendered as "local" (lower-case) on the wire.
     */
    local,

    /**
     * This is rendered as "majority" (lower-case) on the wire.
     */
    majority,

    /**
     * This is rendered as "linearizable" (lower-case) on the wire.
     */
    linearizable,

    /**
     * This is rendered as "available" (lower-case) on the wire.
     */
    available,

    /**
     * This is rendered as "snapshot" (lower-case) on the wire.
     */
    snapshot
}

class ReadConcern {
  /**
   * The level of the read concern.
   */
  level: Optional&lt;ReadConcernLevel | String&gt;
}
</code></pre>
<p>The read concern option is available for the following operations:</p>
<ul>
<li><code>aggregate</code> command</li>
<li><code>count</code> command</li>
<li><code>distinct</code> command</li>
<li><code>find</code> command</li>
<li><code>mapReduce</code> command where the <code>out</code> option is <code>{ inline: 1 }</code></li>
<li><code>parallelCollectionScan</code> command</li>
<li><code>geoNear</code> command</li>
<li><code>geoSearch</code> command</li>
</ul>
<p>Starting in MongoDB 4.2, an <code>aggregate</code> command with a write stage (e.g. <code>$out</code>, <code>$merge</code>) supports a <code>readConcern</code>;
however, it does not support the "linearizable" level (attempting to do so will result in a server error).</p>
<p>Server versions before 4.2 do not support a <code>readConcern</code> at all for <code>aggregate</code> commands with a write stage.</p>
<p>The <code>mapReduce</code> command where the <code>out</code> option is anything other than <code>{ inline: 1 }</code> does not support a <code>readConcern</code>.</p>
<h4 id="unknown-levels-and-additional-options-for-string-based-readconcerns"><a class="header" href="#unknown-levels-and-additional-options-for-string-based-readconcerns">Unknown Levels and Additional Options for String Based ReadConcerns</a></h4>
<p>For forward compatibility, a driver MUST NOT raise an error when a user provides an unknown <code>level</code> or additional
options. The driver relies on the server to validate levels and other contents of the read concern.</p>
<h4 id="servers-default-read-concern"><a class="header" href="#servers-default-read-concern">Server's Default Read Concern</a></h4>
<p>When a <code>ReadConcern</code> is created but no values are specified, it should be considered the server's default <code>ReadConcern</code>.
<code>readconcern&gt;: { }</code> is not the same as <code>readconcern&gt;: { level="local"}</code>. The former is the server's default
<code>ReadConcern</code> while the latter is the user explicitly specifying a <code>ReadConcern</code> with a <code>level</code> of "local".</p>
<h4 id="snapshot-read-concern"><a class="header" href="#snapshot-read-concern">Snapshot Read Concern</a></h4>
<p>When a <code>ReadConcern</code> <code>level</code> <code>snapshot</code> is used, <code>atClusterTime</code> may be specified to indicate the desired point in time
for reading. <code>find</code>, <code>aggregate</code> and <code>distinct</code> operations executed with <code>ReadConcern</code> <code>snapshot</code> but without
<code>atClusterTime</code> will return <code>atClusterTime</code> timestamp in the server response. The obtained <code>atClusterTime</code> timestamp can
be used for subsequent read operations. <code>ReadConcern</code> <code>level</code> <code>snapshot</code> with <code>clusterTime</code> is supported in <code>find</code>,
<code>aggregate</code> and <code>distinct</code> operations.</p>
<h4 id="on-the-wire"><a class="header" href="#on-the-wire">On the Wire</a></h4>
<h5 id="read-commands"><a class="header" href="#read-commands">Read Commands</a></h5>
<p>Read commands that support <code>ReadConcern</code> take a named parameter spelled (case-sensitively) <code>readConcern</code>. See command
documentation for further examples.</p>
<p>If the <code>Client</code>, <code>Database</code>, or <code>Collection</code> being operated on either has no <code>ReadConcern</code> set, or has the server
default <code>ReadConcern</code> - <code>readconcern&gt;: { }</code>:</p>
<ul>
<li>If the <code>ReadConcern</code> specified for the command is the server default <code>readConcern: { }</code>, the driver MUST omit it when
sending the command.</li>
<li>If the <code>ReadConcern</code> specified for the command is any <code>ReadConcern</code> besides the server default, including an
explicitly specified <code>ReadConcern</code> of <code>readConcern: { level: "local" }</code>, the driver MUST include the <code>ReadConcern</code>
when sending the command.</li>
</ul>
<p>If the <code>Client</code>, <code>Database</code>, or <code>Collection</code> being operated on has a non-default <code>ReadConcern</code> specified, then the
driver MUST include the command's <code>ReadConcern</code> when sending the command. This includes if the command specifies the
server default <code>ReadConcern</code>, so that the command can override the <code>Client</code>, <code>Database</code>, or <code>Collection</code>'s <code>ReadConcern</code>
to use the server default instead.</p>
<p><span id="generic-command-method"></span></p>
<h5 id="generic-command-method-1"><a class="header" href="#generic-command-method-1">Generic Command Method</a></h5>
<p>If your driver offers a generic <code>RunCommand</code> method on your <code>database</code> object, <code>ReadConcern</code> MUST NOT be applied
automatically to any command. A user wishing to use a <code>ReadConcern</code> in a generic command must supply it manually.</p>
<h5 id="errors-1"><a class="header" href="#errors-1">Errors</a></h5>
<p><code>ReadConcern</code> errors from a server MUST NOT be handled by a driver. There is nothing a driver can do about them and any
such errors will get propagated to the user via normal error handling.</p>
<h4 id="location-specification"><a class="header" href="#location-specification">Location Specification</a></h4>
<h5 id="via-code"><a class="header" href="#via-code">Via Code</a></h5>
<p><code>ReadConcern</code> SHOULD be specifiable at the <code>Client</code>, <code>Database</code>, and <code>Collection</code> levels. Unless specified, the value
MUST be inherited from its parent and SHOULD NOT be modifiable on an existing <code>Client</code>, <code>Database</code> or <code>Collection</code>. In
addition, a driver MAY allow it to be specified on a per-operation basis in accordance with the CRUD specification.</p>
<p>For example:</p>
<pre><code class="language-typescript">var client = new MongoClient({ readConcern: { level: "local" } });

// db1's readConcern level is "local".
var db1 = client.getDatabase("db1");

// col1's readConcern level is "local"
var col1 = db1.getCollection("col_name");

// db2's readConcern level is "majority".
var db2 = client.getDatabase("db_name", { readConcern: { level: "majority" } });

// col2's readConcern level is "majority"
var col2 = db2.getCollection("col_name");

// col3's readConcern level is the server's default read concern
var col3 = db2.getCollection("col_name", { readConcern: { } });
</code></pre>
<h5 id="via-connection-string"><a class="header" href="#via-connection-string">Via Connection String</a></h5>
<p>Options</p>
<ul>
<li><code>readConcernLevel</code> - defines the level for the read concern.</li>
</ul>
<p>For example:</p>
<pre><code>mongodb://server:27017/db?readConcernLevel=majority
</code></pre>
<h4 id="errors-2"><a class="header" href="#errors-2">Errors</a></h4>
<ul>
<li>MaxWireVersion &lt; 4 Only the server's default <code>ReadConcern</code> is support by MaxWireVersion &lt; 4. When using other
<code>readConcernLevels</code> with clients reporting <code>MaxWireVersion</code> &lt; 4, the driver MUST raise an error. This check MUST
happen after server selection has occurred in the case of mixed version clusters. It is up to users to appropriately
define a <code>ReadPreference</code> such that intermittent errors do not occur.</li>
</ul>
<blockquote>
<p>[!NOTE]
<code>ReadConcern</code> is only supported for commands.</p>
</blockquote>
<h3 id="write-concern"><a class="header" href="#write-concern">Write Concern</a></h3>
<p>When a driver sends a write concern document to the server, the structure of the write concern document MUST be as
follows:</p>
<pre><code class="language-typescript">class WriteConcern {
  /**
   * If true, wait for the the write operation to get committed to the
   * journal. When unspecified, a driver MUST NOT send "j".
   *
   * @see https://www.mongodb.com/docs/manual/core/write-concern/#journaled
   */
  j: Optional&lt;Boolean&gt;,

  /**
   * When an integer, specifies the number of nodes that should acknowledge
   * the write and MUST be greater than or equal to 0.
   * When a string, indicates tags. "majority" is defined, but users
   * could specify other custom error modes.
   * When not specified, a driver MUST NOT send "w".
   */
  w: Optional&lt;Int32 | String&gt;,

  /**
   * If provided, and the write concern is not satisfied within the
   * specified timeout (in milliseconds), the server will return an error
   * for the operation. When unspecified, a driver SHOULD NOT send "wtimeout".
   *
   * The value, if provided, MUST be greater than or equal to 0.
   *
   * @see https://www.mongodb.com/docs/manual/core/write-concern/#timeouts
   */
  wtimeout: Optional&lt;Int64&gt;
}
</code></pre>
<p>When a driver provides a way for the application to specify the write concern, the following data structure SHOULD be
used. For acceptable naming and deviation guidance, see the <a href="read-write-concern/../crud/crud.html#naming">CRUD specification</a>.</p>
<pre><code class="language-typescript">class WriteConcern {
  /**
   * Corresponds to the "j" field in the WriteConcern document sent to
   * the server.
   */
  journal: Optional&lt;Boolean&gt;,

  /**
   * Corresponds to the "w" field in the WriteConcern document sent to
   * the server.
   */
  w: Optional&lt;Int32 | String&gt;,

  /**
   * Corresponds to the "wtimeout" field in the WriteConcern document sent to
   * the server.
   *
   * NOTE: This option is deprecated in favor of timeoutMS.
   */
  wtimeoutMS: Optional&lt;Int64&gt;
}
</code></pre>
<h4 id="fsync"><a class="header" href="#fsync">FSync</a></h4>
<p>FSync SHOULD be considered deprecated. Those drivers supporting the deprecated <code>fsync</code> option SHOULD treat <code>fsync</code>
identically to <code>journal</code> in terms of consistency with <code>w</code> and whether a <code>WriteConcern</code> that specifies <code>fsync</code> is
acknowledged or unacknowledged.</p>
<h4 id="wtimeoutms"><a class="header" href="#wtimeoutms">wtimeoutMS</a></h4>
<p><code>wtimeoutMS</code> MUST be considered deprecated in favor of
<a href="read-write-concern/../client-side-operations-timeout/client-side-operations-timeout.html#timeoutms">timeoutMS</a>.</p>
<h4 id="servers-default-writeconcern"><a class="header" href="#servers-default-writeconcern">Server's Default WriteConcern</a></h4>
<p>When a <code>WriteConcern</code> is created but no values are specified, it should be considered the server's default
<code>WriteConcern</code>.</p>
<p>The server has a settings field called <code>getLastErrorDefaults</code> which allows a user to customize the default behavior of a
<code>WriteConcern</code>. Because of this, <code>writeConcern: { }</code> is not the same as - <code>writeconcern: {w: 1}</code>. Sending <code>{w:1}</code>
overrides that default. As another example, <code>writeConcern: { }</code> is not the same as <code>writeConcern: {journal: false}</code>.</p>
<h4 id="inconsistent-writeconcern"><a class="header" href="#inconsistent-writeconcern">Inconsistent WriteConcern</a></h4>
<p>Drivers MUST raise an error when an inconsistent <code>WriteConcern</code> is specified. The following is an exhaustive list of
inconsistent <code>WriteConcerns</code>:</p>
<pre><code class="language-typescript">writeConcern = { w: 0, journal: true };
</code></pre>
<h4 id="unacknowledged-writeconcern"><a class="header" href="#unacknowledged-writeconcern">Unacknowledged WriteConcern</a></h4>
<p>An <code>Unacknowledged WriteConcern</code> is when (<code>w</code> equals 0) AND (<code>journal</code> is not set or is <code>false</code>).</p>
<p>These criteria indicates that the user does not care about errors from the server.</p>
<p>Examples:</p>
<pre><code class="language-typescript">writeConcern = { w: 0 }; // Unacknowledged
writeConcern = { w: 0, journal: false }; // Unacknowledged
writeConcern = { w: 0, wtimeoutMS: 100 }; // Unacknowledged
</code></pre>
<h4 id="on-the-wire-1"><a class="header" href="#on-the-wire-1">On the Wire</a></h4>
<h5 id="op_insert-op_delete-op_update"><a class="header" href="#op_insert-op_delete-op_update">OP_INSERT, OP_DELETE, OP_UPDATE</a></h5>
<p><code>WriteConcern</code> is implemented by sending the <code>getLastError</code> (GLE) command directly after the operation. Drivers SHOULD
piggy-back the GLE onto the same buffer as the operation. Regardless, GLE MUST be sent on the same connection as the
initial write operation.</p>
<p>When a user has not specified a <code>WriteConcern</code> or has specified the server's default <code>WriteConcern</code>, drivers MUST send
the GLE command without arguments. For example: <code>{ getLastError: 1 }</code></p>
<p>Drivers MUST NOT send a GLE for an <code>Unacknowledged WriteConcern</code>. In this instance, the server will not send a reply.</p>
<p>See the <code>getLastError</code> command documentation for other formatting.</p>
<h5 id="write-commands"><a class="header" href="#write-commands">Write Commands</a></h5>
<p>The <code>insert</code>, <code>delete</code>, and <code>update</code> commands take a named parameter, <code>writeConcern</code>. See the command documentation for
further examples.</p>
<p>When a user has not specified a <code>WriteConcern</code> or has specified the server's default <code>WriteConcern</code>, drivers MUST omit
the <code>writeConcern</code> parameter from the command.</p>
<p>All other <code>WriteConcerns</code>, including the <code>Unacknowledged WriteConcern</code>, MUST be sent with the <code>writeConcern</code> parameter.</p>
<blockquote>
<p>[!NOTE]
Drivers MAY use <code>OP_INSERT</code>, <code>OP_UPDATE</code>, and <code>OP_DELETE</code> when an <code>Unacknowledged WriteConcern</code> is used.</p>
</blockquote>
<h5 id="generic-command-method-2"><a class="header" href="#generic-command-method-2">Generic Command Method</a></h5>
<p>If your driver offers a generic <code>RunCommand</code> method on your <code>database</code> object, <code>WriteConcern</code> MUST NOT be applied
automatically to any command. A user wishing to use a <code>WriteConcern</code> in a generic command must manually include it in
the command document passed to the method.</p>
<p>The generic command method MUST NOT check the user's command document for a <code>WriteConcern</code> nor check whether the server
is new enough to support a write concern for the command. The method simply sends the user's command to the server
as-is.</p>
<h5 id="find-and-modify-1"><a class="header" href="#find-and-modify-1">Find And Modify</a></h5>
<p>The <code>findAndModify</code> command takes a named parameter, <code>writeConcern</code>. See command documentation for further examples.</p>
<p>If writeConcern is specified for the Collection, <code>writeConcern</code> MUST be omitted when sending <code>findAndModify</code> with
MaxWireVersion &lt; 4.</p>
<p>If the findAndModify helper accepts writeConcern as a parameter, the driver MUST raise an error with MaxWireVersion &lt;
4.</p>
<blockquote>
<p>[!NOTE]
Driver documentation SHOULD include a warning in their server 3.2 compatible releases that an elevated <code>WriteConcern</code>
may cause performance degradation when using <code>findAndModify</code>. This is because <code>findAndModify</code> will now be honoring a
potentially high latency setting where it did not before.</p>
</blockquote>
<h5 id="other-commands-that-write"><a class="header" href="#other-commands-that-write">Other commands that write</a></h5>
<p>Command helper methods for commands that write, other than those discussed above, MAY accept a write concern or write
concern options in their parameter list. If the helper accepts a write concern, the driver MUST error if the selected
server's MaxWireVersion &lt; 5 and a write concern has explicitly been specified.</p>
<p>Helper methods that apply the write concern inherited from the Collection or Database, SHOULD check whether the selected
server's MaxWireVersion &gt;= 5 and if so, include the inherited write concern in the command on the wire. If the selected
server's MaxWireVersion &lt; 5, these methods SHOULD silently omit the write concern from the command on the wire.</p>
<p>These commands that write are:</p>
<blockquote>
<ul>
<li><code>aggregate</code> with write stage (e.g. <code>$out</code>, <code>$merge</code>)</li>
<li><code>copydb</code></li>
<li><code>create</code></li>
<li><code>createIndexes</code></li>
<li><code>drop</code></li>
<li><code>dropDatabase</code></li>
<li><code>dropIndexes</code></li>
<li><code>mapReduce</code> where the <code>out</code> option is not <code>{ inline: 1 }</code></li>
<li><code>clone</code></li>
<li><code>cloneCollection</code></li>
<li><code>cloneCollectionAsCapped</code></li>
<li><code>collMod</code></li>
<li><code>convertToCapped</code></li>
<li><code>renameCollection</code></li>
<li><code>createUser</code></li>
<li><code>updateUser</code></li>
<li><code>dropUser</code></li>
</ul>
</blockquote>
<h5 id="errors-3"><a class="header" href="#errors-3">Errors</a></h5>
<p>In general, server errors associated with <code>WriteConcern</code> return successful (<code>"ok": 1</code>) responses with a
<code>writeConcernError</code> field indicating the issue. For example,</p>
<pre><code class="language-typescript">rs0:PRIMARY&gt; db.runCommand({insert: "foo", documents: [{x:1}], writeConcern: { w: "blah"}})
{
  n: 1,
  opTime: {
    ts: Timestamp(1583026145, 1),
    t: NumberLong(5)
  },
  electionId: ObjectId("7fffffff0000000000000005"),
  ok: 1,
  writeConcernError: {
    code: 79,
    codeName: "UnknownReplWriteConcern",
    errmsg: "No write concern mode named 'blah' found in replica set configuration",
    errInfo: {
      writeConcern: {
        w: "blah",
        wtimeout: 0,
        provenance: "clientSupplied"
      }
    }
  },
  $clusterTime: {
    clusterTime: Timestamp(1583026145, 1),
    signature: {
      hash: BinData(0, "AAAAAAAAAAAAAAAAAAAAAAAAAAA="),
      keyId: NumberLong(0)
    }
  },
  operationTime: Timestamp(1583026145, 1)
}
</code></pre>
<p>Drivers SHOULD parse server replies for a "writeConcernError" field and report the error only in the command-specific
helper methods for commands that write, from the list above. For example, helper methods for "findAndModify" or
"aggregate" SHOULD parse the server reply for "writeConcernError".</p>
<p>Drivers SHOULD report writeConcernErrors however they report other server errors: by raising an exception, returning
"false", or another idiom that is consistent with other server errors. Drivers SHOULD report writeConcernErrors with a
<code>WriteConcernError</code> defined in the <a href="read-write-concern/../crud/crud.html#error-handling">CRUD specification</a>.</p>
<p>Drivers SHOULD NOT parse server replies for "writeConcernError" in generic command methods.</p>
<p>(Reporting of writeConcernErrors is more complex for bulk operations, see the Bulk API Spec.)</p>
<h6 id="writeconcernerror-examples"><a class="header" href="#writeconcernerror-examples">writeConcernError Examples</a></h6>
<p>The set of possible writeConcernErrors is quite large because they can include errors caused by shutdown, stepdown,
interruption, maxTimeMS, and wtimeout. This section attempts to list all known error codes that may appear within a
writeConcernError but may not be exhaustive. Note that some errors have been abbreviated:</p>
<ul>
<li><code>{ok:1, writeConcernError: {code: 91, codeName: "ShutdownInProgress"}}</code></li>
<li><code>{ok:1, writeConcernError: {code: 189, codeName: "PrimarySteppedDown"}}</code></li>
<li><code>{ok:1, writeConcernError: {code: 11600, codeName: "InterruptedAtShutdown"}}</code></li>
<li><code>{ok:1, writeConcernError: {code: 11601, codeName: "Interrupted"}}</code></li>
<li><code>{ok:1, writeConcernError: {code: 11602, codeName: "InterruptedDueToReplStateChange"}}</code></li>
<li><code>{ok:1, writeConcernError: {code: 64, codeName: "WriteConcernFailed", errmsg: "waiting for replication timed out", errInfo: {wtimeout: True}}}</code></li>
<li><code>{ok:1, writeConcernError: {code: 64, codeName: "WriteConcernFailed", errmsg: "multiple errors reported : {...} at shardName1 :: and :: {...} at shardName2"}}</code><sup class="footnote-reference"><a href="#1">1</a></sup></li>
<li><code>{ok:1, writeConcernError: {code: 50, codeName: "MaxTimeMSExpired"}}</code></li>
<li><code>{ok:1, writeConcernError: {code: 100, codeName: "UnsatisfiableWriteConcern", errmsg: "Not enough data-bearing nodes"}}</code></li>
<li><code>{ok:1, writeConcernError: {code: 79, codeName: "UnknownReplWriteConcern"}}</code></li>
</ul>
<p>Note also that it is possible for a writeConcernError to be attached to a command failure. For example:</p>
<ul>
<li><code>{ok:0, code: 251, codeName: "NoSuchTransaction", writeConcernError: {code: 91, codeName: "ShutdownInProgress"}}</code><sup class="footnote-reference"><a href="#2">2</a></sup></li>
</ul>
<h4 id="location-specification-1"><a class="header" href="#location-specification-1">Location Specification</a></h4>
<h5 id="via-code-1"><a class="header" href="#via-code-1">Via Code</a></h5>
<p><code>WriteConcern</code> SHOULD be specifiable at the <code>Client</code>, <code>Database</code>, and <code>Collection</code> levels. Unless specified, the value
MUST be inherited from its parent and SHOULD NOT be modifiable on an existing <code>Client</code>, <code>Database</code> or <code>Collection</code>. In
addition, a driver MAY allow it to be specified on a per-operation basis in accordance with the CRUD specification.</p>
<p>For example:</p>
<pre><code class="language-typescript">var client = new MongoClient({ writeConcern: { w: 2 } });

// db1's writeConcern is {w: 2}.
var db1 = client.getDatabase("db1");

// col1's writeConcern is {w: 2}.
var col1 = db1.getCollection("col_name");

// db2's writeConcern is {journal: true}.
var db2 = client.getDatabase("db_name", { writeConcern: { journal: true } });

// col2's writeConcern {journal: true}.
var col2 = db2.getCollection("col_name");

// col3's writeConcern is the server's default write concern.
var col3 = db2.getCollection("col_name", { writeConcern: { } });

// Override col3's writeConcern.
col3.drop({ writeConcern: { w: 3 } });
</code></pre>
<h5 id="via-connection-string-1"><a class="header" href="#via-connection-string-1">Via Connection String</a></h5>
<p>Options</p>
<ul>
<li><code>w</code> - corresponds to <code>w</code> in the class definition.</li>
<li><code>journal</code> - corresponds to <code>journal</code> in the class definition.</li>
<li><code>wtimeoutMS</code> - corresponds to <code>wtimeoutMS</code> in the class definition.</li>
</ul>
<p>For example:</p>
<pre><code>mongodb://server:27017/db?w=3

mongodb://server:27017/db?journal=true

mongodb://server:27017/db?wtimeoutMS=1000

mongodb://server:27017/db?w=majority&amp;wtimeoutMS=1000
</code></pre>
<h2 id="backwards-compatibility-23"><a class="header" href="#backwards-compatibility-23">Backwards Compatibility</a></h2>
<p>There should be no backwards compatibility concerns. This specification merely deals with how to specify read and write
concerns.</p>
<h2 id="test-plan-27"><a class="header" href="#test-plan-27">Test Plan</a></h2>
<p>Yaml tests are located <a href="read-write-concern/../read-write-concern/tests/README.html">here</a></p>
<p>Below are English descriptions of other items that should be tested:</p>
<h3 id="readconcern-1"><a class="header" href="#readconcern-1">ReadConcern</a></h3>
<ol>
<li>Commands supporting a read concern MUST raise an error when MaxWireVersion is less than 4 and a non-default,
non-local read concern is specified.</li>
<li>Commands supporting a read concern MUST NOT send the default read concern to the server.</li>
<li>Commands supporting a read concern MUST send any non-default read concern to the server.</li>
</ol>
<h3 id="writeconcern-1"><a class="header" href="#writeconcern-1">WriteConcern</a></h3>
<ol>
<li>Commands supporting a write concern MUST NOT send the default write concern to the server.</li>
<li>Commands supporting a write concern MUST send any non-default acknowledged write concern to the server, either in the
command or as a getLastError.</li>
<li>On ServerVersion less than 2.6, drivers MUST NOT send a getLastError command for an Unacknowledged write concern.</li>
<li>FindAndModify helper methods MUST NOT send a write concern when the MaxWireVersion is less than 4.</li>
<li>Helper methods for other commands that write MUST NOT send a write concern when the MaxWireVersion is less than 5.</li>
</ol>
<h2 id="reference-implementation-20"><a class="header" href="#reference-implementation-20">Reference Implementation</a></h2>
<p>These are currently under construction.</p>
<h2 id="q--a-8"><a class="header" href="#q--a-8">Q &amp; A</a></h2>
<p>Q: Why is specifying a non-default <code>ReadConcern</code> for servers &lt; 3.2 an error while a non-default write concern gets
ignored in <code>findAndModify</code>? <code>findAndModify</code> is an existing command and since <code>WriteConcern</code> may be defined globally,
anyone using <code>findAndModify</code> in their applications with a non-default <code>WriteConcern</code> defined globally would have all
their <code>findAndModify</code> operations fail.</p>
<p>Q: Why does a driver send <code>{ readConcern: { level: "local" } }</code> to the server when that is the server's default? First,
to mirror how <code>WriteConcern</code> already works, <code>ReadConcern() does not equal ReadConcern(level=local)</code> in the same way that
<code>WriteConcern() does not equal WriteConcern(w=1)</code>. This is true for <code>WriteConcern</code> because the server's default could be
set differently. While this setting does not currently exist for <code>ReadConcern</code>, it is a possible eventuality and it
costs a driver nothing to be prepared for it. Second, it makes sense that if a user doesn't specify a <code>ReadConcern</code>, we
don't send one and if a user does specify a <code>ReadConcern</code>, we do send one. If the user specifies level="local", for
instance, we send it.</p>
<h2 id="changelog-36"><a class="header" href="#changelog-36">Changelog</a></h2>
<ul>
<li>
<p>2024-08-23: Migrated from reStructuredText to Markdown.</p>
</li>
<li>
<p>2015-10-16: ReadConcern of local is no longer allowed to be used when talking with MaxWireVersion &lt; 4.</p>
</li>
<li>
<p>2016-05-20: Added note about helpers for commands that write accepting a writeConcern parameter.</p>
</li>
<li>
<p>2016-06-17: Added "linearizable" to ReadConcern levels.</p>
</li>
<li>
<p>2016-07-15: Command-specific helper methods for commands that write SHOULD check the server's MaxWireVersion and
decide whether to send writeConcern. Advise drivers to parse server replies for writeConcernError and raise an
exception if found, only in command-specific helper methods that take a writeConcern parameter, not in generic command
methods. Don't mention obscure commands with no helpers.</p>
</li>
<li>
<p>2016-08-06: Further clarify that command-specific helper methods for commands that write take write concern options in
their parameter lists, and relax from SHOULD to MAY.</p>
</li>
<li>
<p>2017-03-13: reIndex silently ignores writeConcern in MongoDB 3.4 and returns an error if writeConcern is included with
MongoDB 3.5+. See <a href="https://jira.mongodb.org/browse/SERVER-27891">SERVER-27891</a>.</p>
</li>
<li>
<p>2017-11-17: Added list of commands that support readConcern</p>
</li>
<li>
<p>2017-12-18: Added "available" to Readconcern level.</p>
</li>
<li>
<p>2017-05-29: Added user management commands to list of commands that write</p>
</li>
<li>
<p>2019-01-29: Added section listing all known examples of writeConcernError.</p>
</li>
<li>
<p>2019-06-07: Clarify language for aggregate and mapReduce commands that write.</p>
</li>
<li>
<p>2019-10-31: Explicitly define write concern option mappings.</p>
</li>
<li>
<p>2020-02-13: Inconsistent write concern must be considered an error.</p>
</li>
<li>
<p>2021-04-07: Updated to use hello command.</p>
</li>
<li>
<p>2021-06-15: Added "snapshot" to Readconcern level</p>
</li>
<li>
<p>2021-07-12: Add missing commas after ReadConcernLevel enum values</p>
</li>
<li>
<p>2022-01-19: Deprecate wTimeoutMS in favor of timeoutMS.</p>
</li>
<li>
<p>2022-10-05: Remove spec front matter and reformat changelog.</p>
</li>
</ul>
<div class="footnote-definition" id="1"><sup class="footnote-definition-label">1</sup>
<p>This is only possible in a sharded cluster. When a write is routed to multiple shards and more than one shard
returns a writeConcernError, then mongos will construct a new writeConcernError with the "WriteConcernFailed" error
code and an errmsg field contains the stringified writeConcernError from each shard. Note that each shard may return
a different writeConcernError.</p>
</div>
<div class="footnote-definition" id="2"><sup class="footnote-definition-label">2</sup>
<p>See <a href="https://jira.mongodb.org/browse/SERVER-38850">https://jira.mongodb.org/browse/SERVER-38850</a></p>
</div>
<div style="break-before: page; page-break-before: always;"></div><h1 id="change-streams-1"><a class="header" href="#change-streams-1">Change Streams</a></h1>
<ul>
<li>Status: Accepted</li>
<li>Minimum Server Version: 3.6</li>
</ul>
<hr />
<h2 id="abstract-35"><a class="header" href="#abstract-35">Abstract</a></h2>
<p>As of version 3.6 of the MongoDB server a new <code>$changeStream</code> pipeline stage is supported in the aggregation framework.
Specifying this stage first in an aggregation pipeline allows users to request that notifications are sent for all
changes to a particular collection. This specification defines the means for creating change streams in drivers, as well
as behavior during failure scenarios.</p>
<h2 id="specification-34"><a class="header" href="#specification-34">Specification</a></h2>
<h3 id="definitions-7"><a class="header" href="#definitions-7">Definitions</a></h3>
<h4 id="meta-35"><a class="header" href="#meta-35">META</a></h4>
<p>The keywords "MUST", "MUST NOT", "REQUIRED", "SHALL", "SHALL NOT", "SHOULD", "SHOULD NOT", "RECOMMENDED", "MAY", and
"OPTIONAL" in this document are to be interpreted as described in <a href="https://www.ietf.org/rfc/rfc2119.txt">RFC 2119</a>.</p>
<h4 id="terms-23"><a class="header" href="#terms-23">Terms</a></h4>
<h5 id="resumable-error"><a class="header" href="#resumable-error">Resumable Error</a></h5>
<p>An error is considered resumable if it meets any of the criteria listed below. For any criteria with wire version
constraints, the driver MUST use the wire version of the connection used to do the initial <code>aggregate</code> or the <code>getMore</code>
that resulted in the error. Drivers MUST NOT check the wire version of the server after the command has been executed
when checking these constraints.</p>
<ul>
<li>
<p>Any error encountered which is not a server error (e.g. a timeout error or network error)</p>
</li>
<li>
<p>A server error with code 43 (<code>CursorNotFound</code>)</p>
</li>
<li>
<p>For servers with wire version 9 or higher (server version 4.4 or higher), any server error with the
<code>ResumableChangeStreamError</code> error label.</p>
</li>
<li>
<p>For servers with wire version less than 9, a server error with one of the following codes:</p>
<div class="table-wrapper"><table><thead><tr><th>Error Name</th><th>Error Code</th></tr></thead><tbody>
<tr><td>HostUnreachable</td><td>6</td></tr>
<tr><td>HostNotFound</td><td>7</td></tr>
<tr><td>NetworkTimeout</td><td>89</td></tr>
<tr><td>ShutdownInProgress</td><td>91</td></tr>
<tr><td>PrimarySteppedDown</td><td>189</td></tr>
<tr><td>ExceededTimeLimit</td><td>262</td></tr>
<tr><td>SocketException</td><td>9001</td></tr>
<tr><td>NotWritablePrimary</td><td>10107</td></tr>
<tr><td>InterruptedAtShutdown</td><td>11600</td></tr>
<tr><td>InterruptedDueToReplStateChange</td><td>11602</td></tr>
<tr><td>NotPrimaryNoSecondaryOk</td><td>13435</td></tr>
<tr><td>NotPrimaryOrSecondary</td><td>13436</td></tr>
<tr><td>StaleShardVersion</td><td>63</td></tr>
<tr><td>StaleEpoch</td><td>150</td></tr>
<tr><td>StaleConfig</td><td>13388</td></tr>
<tr><td>RetryChangeStream</td><td>234</td></tr>
<tr><td>FailedToSatisfyReadPreference</td><td>133</td></tr>
</tbody></table>
</div></li>
</ul>
<p>An error on an aggregate command is not a resumable error. Only errors on a getMore command may be considered resumable
errors.</p>
<h3 id="guidance-2"><a class="header" href="#guidance-2">Guidance</a></h3>
<p>For naming and deviation guidance, see the <a href="change-streams/../crud/crud.html#naming">CRUD specification</a>.</p>
<h3 id="server-specification"><a class="header" href="#server-specification">Server Specification</a></h3>
<h4 id="response-format-1"><a class="header" href="#response-format-1">Response Format</a></h4>
<p><strong>NOTE:</strong> The examples in this section are provided for illustrative purposes, and are subject to change without
warning. Drivers that provide a static type to represent ChangeStreamDocument MAY include additional fields in their
API.</p>
<p>If an aggregate command with a <code>$changeStream</code> stage completes successfully, the response contains documents with the
following structure:</p>
<pre><code class="language-typescript">class ChangeStreamDocument {
  /**
   * The id functions as an opaque token for use when resuming an interrupted
   * change stream.
   */
  _id: Document;

  /**
   * Describes the type of operation represented in this change notification.
   *
   * @note: Whether a change is reported as an event of the operation type
   * `update` or `replace` is a server implementation detail.
   *
   * @note: The server will add new `operationType` values in the future and drivers
   * MUST NOT err when they encounter a new `operationType`. Unknown `operationType`
   * values may be represented by "unknown" or the literal string value.
   */
  operationType: "insert" 
                | "update" 
                | "replace" 
                | "delete" 
                | "invalidate" 
                | "drop" 
                | "dropDatabase" 
                | "rename" 
                | "createIndexes"
                | "dropIndexes" 
                | "modify"
                | "create" 
                | "shardCollection" 
                | "refineCollectionShardKey" 
                | "reshardCollection";

  /**
   * Contains two fields: "db" and "coll" containing the database and
   * collection name in which the change happened.
   *
   * @note: Drivers MUST NOT err when extra fields are encountered in the `ns` document
   * as the server may add new fields in the future such as `viewOn`.
   */
  ns: Document;

  /**
   * Only present for ops of type 'rename'.
   *
   * The namespace, in the same format as `ns`, that a collection has been renamed to.
   */
  to: Optional&lt;Document&gt;;

  /**
   * Only present for ops of type 'rename', 'create', 'modify', 'createIndexes', 'dropIndexes', 'shardCollection', 'reshardCollection', 'refineCollectionShardKey'.
   * Only present when the `showExpandedEvents` change stream option is enabled.
   *
   * A description of the operation.
   * 
   * @since 6.0.0
   */
  operationDescription: Optional&lt;Document&gt;

  /**
   * Only present for ops of type 'insert', 'update', 'replace', and
   * 'delete'.
   *
   * For unsharded collections this contains a single field, _id, with the
   * value of the _id of the document updated.  For sharded collections,
   * this will contain all the components of the shard key in order,
   * followed by the _id if the _id isn't part of the shard key.
   */
  documentKey: Optional&lt;Document&gt;;

  /**
   * Only present for ops of type 'update'.
   */
  updateDescription: Optional&lt;UpdateDescription&gt;;

  /**
   * Always present for operations of type 'insert' and 'replace'. Also
   * present for operations of type 'update' if the user has specified
   * 'updateLookup' for the 'fullDocument' option when creating the change
   * stream.
   *
   * For operations of type 'insert' and 'replace', this key will contain the
   * document being inserted or the new version of the document that is
   * replacing the existing document, respectively.
   *
   * For operations of type 'update', this key will contain a copy of the full
   * version of the document from some point after the update occurred. If the
   * document was deleted since the updated happened, it will be null.
   *
   * Contains the point-in-time post-image of the modified document if the
   * post-image is available and either 'required' or 'whenAvailable' was
   * specified for the 'fullDocument' option when creating the change stream.
   * A post-image is always available for 'insert' and 'replace' events.
   */
  fullDocument: Document | null;

  /**
   * Contains the pre-image of the modified or deleted document if the
   * pre-image is available for the change event and either 'required' or
   * 'whenAvailable' was specified for the 'fullDocumentBeforeChange' option
   * when creating the change stream. If 'whenAvailable' was specified but the
   * pre-image is unavailable, this will be explicitly set to null.
   */
  fullDocumentBeforeChange: Document | null;

  /**
   * The wall time from the mongod that the change event originated from.
   * Populated for server versions 6.0 and above.
   */
  wallTime: Optional&lt;DateTime&gt;;

  /**
   * The `ui` field from the oplog entry corresponding to the change event.
   * 
   * Only present when the `showExpandedEvents` change stream option is enabled and for the following events
   *  - 'insert'
   *  - 'update'
   *  - 'delete'
   *  - 'createIndexes'
   *  - 'dropIndexes'
   *  - 'modify'
   *  - 'drop'
   *  - 'create'
   *  - 'shardCollection'
   *  - 'reshardCollection'
   *  - 'refineCollectionShardKey'
   *  
   * This field is a value of binary subtype 4 (UUID).
   *  
   * @since 6.0.0
   */
  collectionUUID: Optional&lt;Binary&gt;;

  /**
   * The cluster time at which the change occurred.
   */
  clusterTime: Timestamp;

}

class UpdateDescription {
  /**
   * A document containing key:value pairs of names of the fields that were
   * changed (excluding the fields reported via `truncatedArrays`), and the new value for those fields.
   *
   * Despite array fields reported via `truncatedArrays` being excluded from this field,
   * changes to fields of the elements of the array values may be reported via this field.
   * Example:
   *   original field:
   *     "arrayField": ["foo", {"a": "bar"}, 1, 2, 3]
   *   updated field:
   *     "arrayField": ["foo", {"a": "bar", "b": 3}]
   *   a potential corresponding UpdateDescription:
   *     {
   *       "updatedFields": {
   *         "arrayField.1.b": 3
   *       },
   *       "removedFields": [],
   *       "truncatedArrays": [
   *         {
   *           "field": "arrayField",
   *           "newSize": 2
   *         }
   *       ]
   *     }
   *
   * Modifications to array elements are expressed via the dot notation (https://www.mongodb.com/docs/manual/core/document/#document-dot-notation).
   * Example: an `update` which sets the element with index 0 in the array field named arrayField to 7 is reported as
   *   "updatedFields": {"arrayField.0": 7}
   */
  updatedFields: Document;

  /**
   * An array of field names that were removed from the document.
   */
  removedFields: Array&lt;String&gt;;

  /**
   * Truncations of arrays may be reported using one of the following methods:
   * either via this field or via the 'updatedFields' field. In the latter case the entire array is considered to be replaced.
   *
   * The structure of documents in this field is
   *   {
   *      "field": &lt;string&gt;,
   *      "newSize": &lt;int&gt;
   *   }
   * Example: an `update` which shrinks the array arrayField.0.nestedArrayField from size 8 to 5 may be reported as
   *   "truncatedArrays": [{"field": "arrayField.0.nestedArrayField", "newSize": 5}]
   *
   * @note The method used to report a truncation is a server implementation detail.
   * @since 4.7.0
   */
  truncatedArrays: Array&lt;Document&gt;;

  /**
   * A document containing a map that associates an update path to an array containing the path components used in the update document. This data
   * can be used in combination with the other fields in an `UpdateDescription` to determine the actual path in the document that was updated. This is 
   * necessary in cases where a key contains dot-separated strings (i.e., `{ "a.b": "c" }`) or a document contains a numeric literal string key
   * (i.e., `{ "a": { "0": "a" } }`. Note that in this scenario, the numeric key can't be the top level key, because `{ "0": "a" }` is not ambiguous - 
   * update paths would simply be `'0'` which is unambiguous because BSON documents cannot have arrays at the top level.).
   * 
   * Each entry in the document maps an update path to an array which contains the actual path used when the document was updated.  
   * For example, given a document with the following shape `{ "a": { "0": 0 } }` and an update of `{ $inc: { "a.0": 1 } }`, `disambiguatedPaths` would
   * look like the following:
   *   {
   *      "a.0": ["a", "0"]
   *   }
   * 
   * In each array, all elements will be returned as strings with the exception of array indices, which will be returned as 32 bit integers.
   * 
   * @since 6.1.0
   */
  disambiguatedPaths: Optional&lt;Document&gt;
}
</code></pre>
<p>The responses to a change stream aggregate or getMore have the following structures:</p>
<pre><code class="language-typescript">/**
 * Response to a successful aggregate.
 */
{
    ok: 1,
    cursor: {
       ns: String,
       id: Int64,
       firstBatch: Array&lt;ChangeStreamDocument&gt;,
       /**
        * postBatchResumeToken is returned in MongoDB 4.0.7 and later.
        */
       postBatchResumeToken: Document
    },
    operationTime: Timestamp,
    $clusterTime: Document,
}

/**
 * Response to a successful getMore.
 */
{
    ok: 1,
    cursor: {
       ns: String,
       id: Int64,
       nextBatch: Array&lt;ChangeStreamDocument&gt;
       /**
        * postBatchResumeToken is returned in MongoDB 4.0.7 and later.
        */
       postBatchResumeToken: Document
    },
    operationTime: Timestamp,
    $clusterTime: Document,
}
</code></pre>
<h3 id="driver-api"><a class="header" href="#driver-api">Driver API</a></h3>
<pre><code class="language-typescript">interface ChangeStream extends Iterable&lt;Document&gt; {
  /**
   * The cached resume token
   */
  private resumeToken: Document;

  /**
   * The pipeline of stages to append to an initial ``$changeStream`` stage
   */
  private pipeline: Array&lt;Document&gt;;

  /**
   * The options provided to the initial ``$changeStream`` stage
   */
  private options: ChangeStreamOptions;

  /**
   * The read preference for the initial change stream aggregation, used
   * for server selection during an automatic resume.
   */
  private readPreference: ReadPreference;
}

interface Collection {
  /**
   * @returns a change stream on a specific collection.
   */
  watch(pipeline: Document[], options: Optional&lt;ChangeStreamOptions&gt;): ChangeStream;
}

interface Database {
  /**
   * Allows a client to observe all changes in a database.
   * Excludes system collections.
   * @returns a change stream on all collections in a database
   * @since 4.0
   * @see https://www.mongodb.com/docs/manual/reference/system-collections/
   */
  watch(pipeline: Document[], options: Optional&lt;ChangeStreamOptions&gt;): ChangeStream;
}

interface MongoClient {
  /**
   * Allows a client to observe all changes in a cluster.
   * Excludes system collections.
   * Excludes the "config", "local", and "admin" databases.
   * @since 4.0
   * @returns a change stream on all collections in all databases in a cluster
   * @see https://www.mongodb.com/docs/manual/reference/system-collections/
   */
  watch(pipeline: Document[], options: Optional&lt;ChangeStreamOptions&gt;): ChangeStream;
}

class ChangeStreamOptions {
  /**
   * Allowed values: 'default', 'updateLookup', 'whenAvailable', 'required'.
   *
   * The default is to not send a value, which is equivalent to 'default'. By
   * default, the change notification for partial updates will include a delta
   * describing the changes to the document.
   *
   * When set to 'updateLookup', the change notification for partial updates
   * will include both a delta describing the changes to the document as well
   * as a copy of the entire document that was changed from some time after
   * the change occurred.
   *
   * When set to 'whenAvailable', configures the change stream to return the
   * post-image of the modified document for replace and update change events
   * if the post-image for this event is available.
   *
   * When set to 'required', the same behavior as 'whenAvailable' except that
   * an error is raised if the post-image is not available.
   *
   * For forward compatibility, a driver MUST NOT raise an error when a user
   * provides an unknown value. The driver relies on the server to validate
   * this option.
   *
   * @note this is an option of the `$changeStream` pipeline stage.
   */
  fullDocument: Optional&lt;String&gt;;

  /**
   * Allowed values: 'whenAvailable', 'required', 'off'.
   *
   * The default is to not send a value, which is equivalent to 'off'.
   *
   * When set to 'whenAvailable', configures the change stream to return the
   * pre-image of the modified document for replace, update, and delete change
   * events if it is available.
   *
   * When set to 'required', the same behavior as 'whenAvailable' except that
   * an error is raised if the pre-image is not available.
   *
   * For forward compatibility, a driver MUST NOT raise an error when a user
   * provides an unknown value. The driver relies on the server to validate
   * this option.
   *
   * @note this is an option of the `$changeStream` pipeline stage.
   */
  fullDocumentBeforeChange: Optional&lt;String&gt;;

  /**
   * Specifies the logical starting point for the new change stream.
   *
   * @note this is an option of the `$changeStream` pipeline stage.
   */
  resumeAfter: Optional&lt;Document&gt;;

  /**
   * The maximum amount of time for the server to wait on new documents to satisfy
   * a change stream query.
   *
   * This is the same field described in FindOptions in the CRUD spec.
   *
   * @see https://github.com/mongodb/specifications/blob/master/source/crud/crud.md#read
   * @note this option is an alias for `maxTimeMS`, used on `getMore` commands
   * @note this option is not set on the `aggregate` command nor `$changeStream` pipeline stage
   */
  maxAwaitTimeMS: Optional&lt;Int64&gt;;

  /**
   * The number of documents to return per batch.
   *
   * This option is sent only if the caller explicitly provides a value. The
   * default is to not send a value.
   *
   * @see https://www.mongodb.com/docs/manual/reference/command/aggregate
   * @note this is an aggregation command option
   */
  batchSize: Optional&lt;Int32&gt;;

  /**
   * Specifies a collation.
   *
   * This option is sent only if the caller explicitly provides a value. The
   * default is to not send a value.
   *
   * @see https://www.mongodb.com/docs/manual/reference/command/aggregate
   * @note this is an aggregation command option
   */
  collation: Optional&lt;Document&gt;;

  /**
   * The change stream will only provide changes that occurred at or after the
   * specified timestamp. Any command run against the server will return
   * an operation time that can be used here.
   *
   * @since 4.0
   * @see https://www.mongodb.com/docs/manual/reference/method/db.runCommand/
   * @note this is an option of the `$changeStream` pipeline stage.
   */
  startAtOperationTime: Optional&lt;Timestamp&gt;;

  /**
   * Similar to `resumeAfter`, this option takes a resume token and starts a
   * new change stream returning the first notification after the token.
   * This will allow users to watch collections that have been dropped and recreated
   * or newly renamed collections without missing any notifications.
   *
   * The server will report an error if `startAfter` and `resumeAfter` are both specified.
   *
   * @since 4.1.1
   * @see https://www.mongodb.com/docs/manual/changeStreams/#change-stream-start-after
   * @note this is an option of the `$changeStream` pipeline stage.
   */
   startAfter: Optional&lt;Document&gt;;

  /**
   * Enables users to specify an arbitrary comment to help trace the operation through
   * the database profiler, currentOp and logs. The default is to not send a value.
   *
   * The comment can be any valid BSON type for server versions 4.4 and above.
   * Server versions prior to 4.4 only support string as comment,
   * and providing a non-string type will result in a server-side error.
   *
   * If a comment is provided, drivers MUST attach this comment to all
   * subsequent getMore commands run on the same cursor for server
   * versions 4.4 and above. For server versions below 4.4 drivers MUST NOT
   * attach a comment to getMore commands.
   *
   * @see https://www.mongodb.com/docs/manual/reference/command/aggregate
   * @note this is an aggregation command option
   */
  comment: Optional&lt;any&gt;

  /**
   * Enables the server to send the 'expanded' list of change stream events.
   * The list of additional events included with this flag set are
   * - createIndexes
   * - dropIndexes
   * - modify
   * - create
   * - shardCollection
   * - reshardCollection
   * - refineCollectionShardKey
   * 
   * This flag is available in server versions greater than 6.0.0. `reshardCollection` and
   * `refineCollectionShardKey` events are not available until server version 6.1.0.
   * 
   * @note this is an option of the change stream pipeline stage
   */
  showExpandedEvents: Optional&lt;Boolean&gt;
}
</code></pre>
<p><strong>NOTE:</strong> The set of <code>ChangeStreamOptions</code> may grow over time.</p>
<h4 id="helper-method"><a class="header" href="#helper-method">Helper Method</a></h4>
<p>The driver API consists of a <code>ChangeStream</code> type, as well as three helper methods. All helpers MUST return a
<code>ChangeStream</code> instance. Implementers MUST document that helper methods are preferred to running a raw aggregation with
a <code>$changeStream</code> stage, for the purpose of supporting resumability.</p>
<p>The helper methods must construct an aggregation command with a REQUIRED initial <code>$changeStream</code> stage. A driver MUST
NOT throw a custom exception if multiple <code>$changeStream</code> stages are present (e.g. if a user also passed <code>$changeStream</code>
in the pipeline supplied to the helper), as the server will return an error.</p>
<p>The helper methods MUST determine a read concern for the operation in accordance with the
<a href="change-streams/../read-write-concern/read-write-concern.html#via-code">Read and Write Concern specification</a>. The initial implementation
of change streams on the server requires a 'majority' read concern or no read concern. Drivers MUST document this
requirement. Drivers SHALL NOT throw an exception if any other read concern is specified, but instead should depend on
the server to return an error.</p>
<p>The stage has the following shape:</p>
<pre><code class="language-typescript">{ $changeStream: ChangeStreamOptions }
</code></pre>
<p>The first parameter of the helpers specifies an array of aggregation pipeline stages which MUST be appended to the
initial stage. Drivers MUST support an empty pipeline. Languages which support default parameters MAY specify an empty
array as the default value for this parameter. Drivers SHOULD otherwise make specification of a pipeline as similar as
possible to the <a href="change-streams/../crud/crud.html#read">aggregate</a> CRUD method.</p>
<p>Additionally, implementers MAY provide a form of these methods which require no parameters, assuming no options and no
additional stages beyond the initial <code>$changeStream</code> stage:</p>
<pre><code class="language-python">for change in db.collection.watch():
    print(change)
</code></pre>
<p>Presently change streams support only a subset of available aggregation stages:</p>
<ul>
<li><code>$match</code></li>
<li><code>$project</code></li>
<li><code>$addFields</code></li>
<li><code>$replaceRoot</code></li>
<li><code>$redact</code></li>
</ul>
<p>A driver MUST NOT throw an exception if any unsupported stage is provided, but instead depend on the server to return an
error.</p>
<p>A driver MUST NOT throw an exception if a user adds, removes, or modifies fields using <code>$project</code>. The server will
produce an error if <code>_id</code> is projected out, but a user should otherwise be able to modify the shape of the change stream
event as desired. This may require the result to be deserialized to a <code>BsonDocument</code> or custom-defined type rather than
a <code>ChangeStreamDocument</code>. It is the responsibility of the user to ensure that the deserialized type is compatible with
the specified <code>$project</code> stage.</p>
<p>The aggregate helper methods MUST have no new logic related to the <code>$changeStream</code> stage. Drivers MUST be capable of
handling <a href="change-streams/../crud/crud.html#read">TAILABLE_AWAIT</a> cursors from the aggregate command in the same way they handle such
cursors from find.</p>
<h5 id="collectionwatch-helper"><a class="header" href="#collectionwatch-helper"><code>Collection.watch</code> helper</a></h5>
<p>Returns a <code>ChangeStream</code> on a specific collection</p>
<p>Command syntax:</p>
<pre><code class="language-typescript">{
  aggregate: 'collectionName'
  pipeline: [{$changeStream: {...}}, ...],
  ...
}
</code></pre>
<h5 id="databasewatch-helper"><a class="header" href="#databasewatch-helper"><code>Database.watch</code> helper</a></h5>
<ul>
<li>Since: 4.0</li>
</ul>
<p>Returns a <code>ChangeStream</code> on all collections in a database.</p>
<p>Command syntax:</p>
<pre><code class="language-typescript">{
  aggregate: 1
  pipeline: [{$changeStream: {...}}, ...],
  ...
}
</code></pre>
<p>Drivers MUST use the <code>ns</code> returned in the <code>aggregate</code> command to set the <code>collection</code> option in subsequent <code>getMore</code>
commands.</p>
<h5 id="mongoclientwatch-helper"><a class="header" href="#mongoclientwatch-helper"><code>MongoClient.watch</code> helper</a></h5>
<ul>
<li>Since: 4.0</li>
</ul>
<p>Returns a <code>ChangeStream</code> on all collections in all databases in a cluster</p>
<p>Command syntax:</p>
<pre><code class="language-typescript">{
  aggregate: 1
  pipeline: [{$changeStream: {allChangesForCluster: true, ...}}, ...],
  ...
}
</code></pre>
<p>The helper MUST run the command against the <code>admin</code> database</p>
<p>Drivers MUST use the <code>ns</code> returned in the <code>aggregate</code> command to set the <code>collection</code> option in subsequent <code>getMore</code>
commands.</p>
<h4 id="changestream"><a class="header" href="#changestream">ChangeStream</a></h4>
<p>A <code>ChangeStream</code> is an abstraction of a <a href="change-streams/../crud/crud.html#read">TAILABLE_AWAIT</a> cursor, with support for resumability.
Implementers MAY choose to implement a <code>ChangeStream</code> as an extension of an existing tailable cursor implementation. If
the <code>ChangeStream</code> is implemented as a type which owns a tailable cursor, then the implementer MUST provide a manner of
closing the change stream, as well as satisfy the requirements of extending <code>Iterable&lt;Document&gt;</code>. If your language has
an idiomatic way of disposing of resources you MAY choose to implement that in addition to, or instead of, an explicit
close method.</p>
<p>A change stream MUST track the last resume token, per
<a href="change-streams/change-streams.html#updating-the-cached-resume-token">Updating the Cached Resume Token</a>.</p>
<p>Drivers MUST raise an error on the first document received without a resume token (e.g. the user has removed <code>_id</code> with
a pipeline stage), and close the change stream. The error message SHOULD resemble "Cannot provide resume functionality
when the resume token is missing".</p>
<p>A change stream MUST attempt to resume a single time if it encounters any resumable error per
<a href="change-streams/change-streams.html#resumable-error">Resumable Error</a>. A change stream MUST NOT attempt to resume on any other type of error.</p>
<p>In addition to tracking a resume token, change streams MUST also track the read preference specified when the change
stream was created. In the event of a resumable error, a change stream MUST perform server selection with the original
read preference using the
<a href="change-streams/../server-selection/server-selection.html#rules-for-server-selection">rules for server selection</a> before attempting to
resume.</p>
<h5 id="single-server-topologies"><a class="header" href="#single-server-topologies">Single Server Topologies</a></h5>
<p>Presently, change streams cannot be initiated on single server topologies as they do not have an oplog. Drivers MUST NOT
throw an exception in this scenario, but instead rely on an error returned from the server. This allows for the server
to seamlessly introduce support for this in the future, without need to make changes in driver code.</p>
<h5 id="startatoperationtime"><a class="header" href="#startatoperationtime">startAtOperationTime</a></h5>
<ul>
<li>Since: 4.0</li>
</ul>
<p><code>startAtOperationTime</code> specifies that a change stream will only return changes that occurred at or after the specified
<code>Timestamp</code>.</p>
<p>The server expects <code>startAtOperationTime</code> as a BSON Timestamp. Drivers MUST allow users to specify a
<code>startAtOperationTime</code> option in the <code>watch</code> helpers. They MUST allow users to specify this value as a raw <code>Timestamp</code>.</p>
<p><code>startAtOperationTime</code>, <code>resumeAfter</code>, and <code>startAfter</code> are all mutually exclusive; if any two are set, the server will
return an error. Drivers MUST NOT throw a custom error, and MUST defer to the server error.</p>
<p>The <code>ChangeStream</code> MUST save the <code>operationTime</code> from the initial <code>aggregate</code> response when the following criteria are
met:</p>
<ul>
<li>None of <code>startAtOperationTime</code>, <code>resumeAfter</code>, <code>startAfter</code> were specified in the <code>ChangeStreamOptions</code>.</li>
<li>The max wire version is &gt;= <code>7</code>.</li>
<li>The initial <code>aggregate</code> response had no results.</li>
<li>The initial <code>aggregate</code> response did not include a <code>postBatchResumeToken</code>.</li>
</ul>
<h5 id="resumeafter"><a class="header" href="#resumeafter">resumeAfter</a></h5>
<p><code>resumeAfter</code> is used to resume a <code>ChangeStream</code> that has been stopped to ensure that only changes starting with the log
entry immediately <em>after</em> the provided token will be returned. If the resume token specified does not exist, the server
will return an error.</p>
<h5 id="resume-process"><a class="header" href="#resume-process">Resume Process</a></h5>
<p>Once a <code>ChangeStream</code> has encountered a resumable error, it MUST attempt to resume one time. The process for resuming
MUST follow these steps:</p>
<ul>
<li>Perform server selection.</li>
<li>Connect to selected server.</li>
<li>If there is a cached <code>resumeToken</code>:
<ul>
<li>If the <code>ChangeStream</code> was started with <code>startAfter</code> and has yet to return a result document:
<ul>
<li>The driver MUST set <code>startAfter</code> to the cached <code>resumeToken</code>.</li>
<li>The driver MUST NOT set <code>resumeAfter</code>.</li>
<li>The driver MUST NOT set <code>startAtOperationTime</code>. If <code>startAtOperationTime</code> was in the original aggregation command,
the driver MUST remove it.</li>
</ul>
</li>
<li>Else:
<ul>
<li>The driver MUST set <code>resumeAfter</code> to the cached <code>resumeToken</code>.</li>
<li>The driver MUST NOT set <code>startAfter</code>. If <code>startAfter</code> was in the original aggregation command, the driver MUST
remove it.</li>
<li>The driver MUST NOT set <code>startAtOperationTime</code>. If <code>startAtOperationTime</code> was in the original aggregation command,
the driver MUST remove it.</li>
</ul>
</li>
</ul>
</li>
<li>Else if there is no cached <code>resumeToken</code> and the <code>ChangeStream</code> has a saved operation time (either from an originally
specified <code>startAtOperationTime</code> or saved from the original aggregation) and the max wire version is &gt;= <code>7</code>:
<ul>
<li>The driver MUST NOT set <code>resumeAfter</code>.</li>
<li>The driver MUST NOT set <code>startAfter</code>.</li>
<li>The driver MUST set <code>startAtOperationTime</code> to the value of the originally used <code>startAtOperationTime</code> or the one
saved from the original aggregation.</li>
</ul>
</li>
<li>Else:
<ul>
<li>The driver MUST NOT set <code>resumeAfter</code>, <code>startAfter</code>, or <code>startAtOperationTime</code>.</li>
<li>The driver MUST use the original aggregation command to resume.</li>
</ul>
</li>
</ul>
<p>When <code>resumeAfter</code> is specified the <code>ChangeStream</code> will return notifications starting with the oplog entry immediately
<em>after</em> the provided token.</p>
<p>If the server supports sessions, the resume attempt MUST use the same session as the previous attempt's command.</p>
<p>A driver MUST ensure that consecutive resume attempts can succeed, even in the absence of any changes received by the
cursor between resume attempts.</p>
<p>A driver SHOULD attempt to kill the cursor on the server on which the cursor is opened during the resume process, and
MUST NOT attempt to kill the cursor on any other server. Any exceptions or errors that occur during the process of
killing the cursor should be suppressed, including both errors returned by the <code>killCursor</code> command and exceptions
thrown by opening, writing to, or reading from the socket.</p>
<h5 id="exposing-all-resume-tokens"><a class="header" href="#exposing-all-resume-tokens">Exposing All Resume Tokens</a></h5>
<ul>
<li>Since: 4.0.7</li>
</ul>
<p>Users can inspect the _id on each <code>ChangeDocument</code> to use as a resume token. But since MongoDB 4.0.7, aggregate and
getMore responses also include a <code>postBatchResumeToken</code>. Drivers use one or the other when automatically resuming, as
described in <a href="change-streams/change-streams.html#resume-process">Resume Process</a>.</p>
<p>Drivers MUST expose a mechanism to retrieve the same resume token that would be used to automatically resume. It MUST be
possible to use this mechanism after iterating every document. It MUST be possible for users to use this mechanism
periodically even when no documents are getting returned (i.e. <code>getMore</code> has returned empty batches). Drivers have two
options to implement this.</p>
<h6 id="option-1-changestreamgetresumetoken"><a class="header" href="#option-1-changestreamgetresumetoken">Option 1: ChangeStream::getResumeToken()</a></h6>
<pre><code class="language-typescript">interface ChangeStream extends Iterable&lt;Document&gt; {
  /**
   * Returns the cached resume token that will be used to resume
   * after the most recently returned change.
   */
  public getResumeToken() Optional&lt;Document&gt;;
}
</code></pre>
<p>This MUST be implemented in synchronous drivers. This MAY be implemented in asynchronous drivers.</p>
<h6 id="option-2-event-emitted-for-resume-token"><a class="header" href="#option-2-event-emitted-for-resume-token">Option 2: Event Emitted for Resume Token</a></h6>
<p>Allow users to set a callback to listen for new resume tokens. The exact interface is up to the driver, but it MUST meet
the following criteria:</p>
<ul>
<li>The callback is set in the same manner as a callback used for receiving change documents.</li>
<li>The callback accepts a resume token as an argument.</li>
<li>The callback (or event) MAY include an optional ChangeDocument, which is unset when called with resume tokens sourced
from <code>postBatchResumeToken</code>.</li>
</ul>
<p>A possible interface for this callback MAY look like:</p>
<pre><code class="language-typescript">interface ChangeStream extends Iterable&lt;Document&gt; {
  /**
   * Returns a resume token that should be used to resume after the most
   * recently returned change.
   */
  public onResumeTokenChanged(ResumeTokenCallback:(Document resumeToken) =&gt; void);
}
</code></pre>
<p>This MUST NOT be implemented in synchronous drivers. This MAY be implemented in asynchronous drivers.</p>
<h6 id="updating-the-cached-resume-token"><a class="header" href="#updating-the-cached-resume-token">Updating the Cached Resume Token</a></h6>
<p>The following rules describe how to update the cached <code>resumeToken</code>:</p>
<ul>
<li>When the <code>ChangeStream</code> is started:
<ul>
<li>If <code>startAfter</code> is set, cache it.</li>
<li>Else if <code>resumeAfter</code> is set, cache it.</li>
<li>Else, <code>resumeToken</code> remains unset.</li>
</ul>
</li>
<li>When <code>aggregate</code> or <code>getMore</code> returns:
<ul>
<li>If an empty batch was returned and a <code>postBatchResumeToken</code> was included, cache it.</li>
</ul>
</li>
<li>When returning a document to the user:
<ul>
<li>If it's the last document in the batch and a <code>postBatchResumeToken</code> is included, cache it.</li>
<li>Else, cache the <code>_id</code> of the document.</li>
</ul>
</li>
</ul>
<h6 id="not-blocking-on-iteration"><a class="header" href="#not-blocking-on-iteration">Not Blocking on Iteration</a></h6>
<p>Synchronous drivers MUST provide a way to iterate a change stream without blocking until a change document is returned.
This MUST give the user an opportunity to get the most up-to-date resume token, even when the change stream continues to
receive empty batches in getMore responses. This allows users to call <code>ChangeStream::getResumeToken()</code> after iterating
every document and periodically when no documents are getting returned.</p>
<p>Although the implementation of tailable awaitData cursors is not specified, this MAY be implemented with a <code>tryNext</code>
method on the change stream cursor.</p>
<p>All drivers MUST document how users can iterate a change stream and receive <em>all</em> resume token updates.
<a href="change-streams/change-streams.html#why-do-we-allow-access-to-the-resume-token-to-users">Why do we allow access to the resume token to users</a> shows an
example. The documentation MUST state that users intending to store the resume token should use this method to get the
most up to date resume token.</p>
<h5 id="timeouts-3"><a class="header" href="#timeouts-3">Timeouts</a></h5>
<p>Drivers MUST apply timeouts to change stream establishment, iteration, and resume attempts per
<a href="change-streams/../client-side-operations-timeout/client-side-operations-timeout.html#change-streams">Client Side Operations Timeout: Change Streams</a>.</p>
<h5 id="notes-and-restrictions"><a class="header" href="#notes-and-restrictions">Notes and Restrictions</a></h5>
<p><strong>1. <code>fullDocument: updateLookup</code> can result in change documents larger than 16 MiB</strong></p>
<p>There is a risk that if there is a large change to a large document, the full document and delta might result in a
document larger than the 16 MiB limitation on BSON documents. If that happens the cursor will be closed, and a server
error will be returned.</p>
<p><strong>2. Users can remove the resume token with aggregation stages</strong></p>
<p>It is possible for a user to specify the following stage:</p>
<pre><code class="language-javascript">{ $project: { _id: 0 } }
</code></pre>
<p>Similar removal of the resume token is possible with the <code>$redact</code> and <code>$replaceRoot</code> stages. While this is not
technically illegal, it makes it impossible for drivers to support resumability. Users may explicitly opt out of
resumability by issuing a raw aggregation with a <code>$changeStream</code> stage.</p>
<h2 id="rationale-2"><a class="header" href="#rationale-2">Rationale</a></h2>
<h3 id="why-helper-methods"><a class="header" href="#why-helper-methods">Why Helper Methods?</a></h3>
<p>Change streams are a first class concept similar to CRUD or aggregation; the fact that they are initiated via an
aggregation pipeline stage is merely an implementation detail. By requiring drivers to support top-level helper methods
for this feature we not only signal this intent, but also solve a number of other potential problems:</p>
<p>Disambiguation of the result type of this special-case aggregation pipeline (<code>ChangeStream</code>), and an ability to control
the behaviors of the resultant cursor</p>
<p>More accurate support for the concept of a maximum time the user is willing to wait for subsequent queries to complete
on the resultant cursor (<code>maxAwaitTimeMs</code>)</p>
<p>Finer control over the options pertaining specifically to this type of operation, without polluting the already
well-defined <code>AggregateOptions</code></p>
<p>Flexibility for future potentially breaking changes for this feature on the server</p>
<h3 id="why-are-changestreams-required-to-retry-once-on-a-resumable-error"><a class="header" href="#why-are-changestreams-required-to-retry-once-on-a-resumable-error">Why are ChangeStreams required to retry once on a resumable error?</a></h3>
<p>User experience is of the utmost importance. Errors not originating from the server are generally network errors, and
network errors can be transient. Attempting to resume an interrupted change stream after the initial error allows for a
seamless experience for the user, while subsequent network errors are likely to be an outage which can then be exposed
to the user with greater confidence.</p>
<h3 id="why-do-we-allow-access-to-the-resume-token-to-users"><a class="header" href="#why-do-we-allow-access-to-the-resume-token-to-users">Why do we allow access to the resume token to users</a></h3>
<p>Imagine a scenario in which a user wants to process each change to a collection <strong>at least once</strong>, but the application
crashes during processing. In order to overcome this failure, a user might use the following approach:</p>
<pre><code class="language-python">localChange = getChangeFromLocalStorage()
resumeToken = getResumeTokenFromLocalStorage()

if localChange:
  processChange(localChange)

try:
    change_stream = db.collection.watch([...], resumeAfter=resumeToken)
    while True:
        change = change_stream.try_next()
        persistResumeTokenToLocalStorage(change_stream.get_resume_token())
        if change:
          persistChangeToLocalStorage(change)
          processChange(change)
except Exception:
    log.error("...")
</code></pre>
<p>In this case the current change is always persisted locally, including the resume token, such that on restart the
application can still process the change while ensuring that the change stream continues from the right logical time in
the oplog. It is the application's responsibility to ensure that <code>processChange</code> is idempotent, this design merely makes
a reasonable effort to process each change <strong>at least</strong> once.</p>
<h3 id="why-is-there-no-example-of-the-desired-user-experience"><a class="header" href="#why-is-there-no-example-of-the-desired-user-experience">Why is there no example of the desired user experience?</a></h3>
<p>The specification used to include this overspecified example of the "desired user experience":</p>
<pre><code class="language-python">try:
    for change in db.collection.watch(...):
        print(change)
except Exception:
    # We know for sure it's unrecoverable:
    log.error("...")
</code></pre>
<p>It was decided to remove this example from the specification for the following reasons:</p>
<ul>
<li>Tailable + awaitData cursors behave differently in existing supported drivers.</li>
<li>There are considerations to be made for languages that do not permit interruptible I/O (such as Java), where a change
stream which blocks forever in a separate thread would necessitate killing the thread.</li>
<li>There is something to be said for an API that allows cooperation by default. The model in which a call to next only
blocks until any response is returned (even an empty batch), allows for interruption and cooperation (e.g. interaction
with other event loops).</li>
</ul>
<h3 id="why-is-an-allow-list-of-error-codes-preferable-to-a-deny-list"><a class="header" href="#why-is-an-allow-list-of-error-codes-preferable-to-a-deny-list">Why is an allow list of error codes preferable to a deny list?</a></h3>
<p>Change streams originally used a deny list of error codes to determine which errors were not resumable. However, this
allowed for the possibility of infinite resume loops if an error was not correctly deny listed. Due to the fact that all
errors aside from transient issues such as failovers are not resumable, the resume behavior was changed to use an allow
list. Part of this change was to introduce the <code>ResumableChangeStreamError</code> label so the server can add new error codes
to the allow list without requiring changes to drivers.</p>
<h3 id="why-is-cursornotfound-special-cased-when-determining-resumability"><a class="header" href="#why-is-cursornotfound-special-cased-when-determining-resumability">Why is <code>CursorNotFound</code> special-cased when determining resumability?</a></h3>
<p>With the exception of <code>CursorNotFound</code>, a server error on version 4.4 or higher is considered resumable if and only if
it contains the <code>ResumableChangeStreamError</code> label. However, this label is only added by the server if the cursor being
created or iterated is a change stream. <code>CursorNotFound</code> is returned when a <code>getMore</code> is done with a cursor ID that the
server isn't aware of and therefore can't determine if the cursor is a change stream. Marking all <code>CursorNotFound</code>
errors resumable in the server regardless of cursor type could be confusing as a user could see the
<code>ResumableChangeStreamError</code> label when iterating a non-change stream cursor. To workaround this, drivers always treat
this error as resumable despite it not having the proper error label.</p>
<h3 id="why-do-we-need-to-send-a-default-startatoperationtime-when-resuming-a-changestream"><a class="header" href="#why-do-we-need-to-send-a-default-startatoperationtime-when-resuming-a-changestream">Why do we need to send a default <code>startAtOperationTime</code> when resuming a <code>ChangeStream</code>?</a></h3>
<p><code>startAtOperationTime</code> allows a user to create a resumable change stream even when a result (and corresponding
resumeToken) is not available until a later point in time.</p>
<p>For example:</p>
<ul>
<li>A client creates a <code>ChangeStream</code>, and calls <code>watch</code></li>
<li>The <code>ChangeStream</code> sends out the initial <code>aggregate</code> call, and receives a response with no initial values. Because
there are no initial values, there is no latest resumeToken.</li>
<li>The client's network is partitioned from the server, causing the client's <code>getMore</code> to time out</li>
<li>Changes occur on the server.</li>
<li>The network is unpartitioned</li>
<li>The client attempts to resume the <code>ChangeStream</code></li>
</ul>
<p>In the above example, not sending <code>startAtOperationTime</code> will result in the change stream missing the changes that
occurred while the server and client are partitioned. By sending <code>startAtOperationTime</code>, the server will know to include
changes from that previous point in time.</p>
<h3 id="why-do-we-need-to-expose-the-postbatchresumetoken"><a class="header" href="#why-do-we-need-to-expose-the-postbatchresumetoken">Why do we need to expose the postBatchResumeToken?</a></h3>
<p>Resume tokens refer to an oplog entry. The resume token from the <code>_id</code> of a document corresponds the oplog entry of the
change. The <code>postBatchResumeToken</code> represents the oplog entry the change stream has scanned up to on the server (not
necessarily a matching change). This can be a much more recent oplog entry, and should be used to resume when possible.</p>
<p>Attempting to resume with an old resume token may degrade server performance since the server needs to scan through more
oplog entries. Worse, if the resume token is older than the last oplog entry stored on the server, then resuming is
impossible.</p>
<p>Imagine the change stream matches a very small percentage of events. On a <code>getMore</code> the server scans the oplog for the
duration of <code>maxAwaitTimeMS</code> but finds no matching entries and returns an empty response (still containing a
<code>postBatchResumeToken</code>). There may be a long sequence of empty responses. Then due to a network error, the change stream
tries resuming. If we tried resuming with the most recent <code>_id</code>, this throws out the oplog scanning the server had done
for the long sequence of getMores with empty responses. But resuming with the last <code>postBatchResumeToken</code> skips the
unnecessary scanning of unmatched oplog entries.</p>
<h2 id="test-plan-28"><a class="header" href="#test-plan-28">Test Plan</a></h2>
<p>See <a href="change-streams/tests/README.html">tests/README.md</a></p>
<h2 id="backwards-compatibility-24"><a class="header" href="#backwards-compatibility-24">Backwards Compatibility</a></h2>
<p>There should be no backwards compatibility concerns.</p>
<h2 id="reference-implementations-4"><a class="header" href="#reference-implementations-4">Reference Implementations</a></h2>
<ul>
<li>NODE (NODE-1055)</li>
<li>PYTHON (PYTHON-1338)</li>
<li>RUBY (RUBY-1228)</li>
</ul>
<h2 id="changelog-37"><a class="header" href="#changelog-37">Changelog</a></h2>
<ul>
<li>
<p>2024-02-09: Migrated from reStructuredText to Markdown.</p>
</li>
<li>
<p>2023-08-11: Update server versions for <code>$changeStreamSplitLargeEvent</code> test.</p>
</li>
<li>
<p>2023-05-22: Add spec test for <code>$changeStreamSplitLargeEvent</code>.</p>
</li>
<li>
<p>2022-10-20: Reformat changelog.</p>
</li>
<li>
<p>2022-10-05: Remove spec front matter.</p>
</li>
<li>
<p>2022-08-22: Add <code>clusterTime</code> to <code>ChangeStreamDocument</code>.</p>
</li>
<li>
<p>2022-08-17: Support <code>disambiguatedPaths</code> in <code>UpdateDescription</code>.</p>
</li>
<li>
<p>2022-05-19: Support new change stream events with <code>showExpandedEvents</code>.</p>
</li>
<li>
<p>2022-05-17: Add <code>wallTime</code> to <code>ChangeStreamDocument</code>.</p>
</li>
<li>
<p>2022-04-13: Support returning point-in-time pre and post-images with <code>fullDocumentBeforeChange</code> and <code>fullDocument</code>.</p>
</li>
<li>
<p>2022-03-25: Do not error when parsing change stream event documents.</p>
</li>
<li>
<p>2022-02-28: Add <code>to</code> to <code>ChangeStreamDocument</code>.</p>
</li>
<li>
<p>2022-02-10: Specify that <code>getMore</code> command must explicitly send inherited <code>comment</code>.</p>
</li>
<li>
<p>2022-02-01: Add <code>comment</code> to <code>ChangeStreamOptions</code>.</p>
</li>
<li>
<p>2022-01-19: Require that timeouts be applied per the client-side operations timeout specification.</p>
</li>
<li>
<p>2021-09-01: Clarify that server selection during resumption should respect normal server selection rules.</p>
</li>
<li>
<p>2021-04-29: Add <code>load-balanced</code> to test topology requirements.</p>
</li>
<li>
<p>2021-04-23: Update to use modern terminology.</p>
</li>
<li>
<p>2021-02-08: Add the <code>UpdateDescription.truncatedArrays</code> field.</p>
</li>
<li>
<p>2020-02-10: Change error handling approach to use an allow list.</p>
</li>
<li>
<p>2019-07-15: Clarify resume process for change streams started with the <code>startAfter</code> option.</p>
</li>
<li>
<p>2019-07-09: Change <code>fullDocument</code> to be an optional string.</p>
</li>
<li>
<p>2019-07-02: Fix server version for <code>startAfter</code>.</p>
</li>
<li>
<p>2019-07-01: Clarify that close may be implemented with more idiomatic patterns instead of a method.</p>
</li>
<li>
<p>2019-06-20: Fix server version for addition of <code>postBatchResumeToken</code>.</p>
</li>
<li>
<p>2019-04-12: Clarify caching process for resume token.</p>
</li>
<li>
<p>2019-04-03: Update the lowest server version that supports <code>postBatchResumeToken</code>.</p>
</li>
<li>
<p>2019-01-10: Clarify error handling for killing the cursor.</p>
</li>
<li>
<p>2018-11-06: Add handling of <code>postBatchResumeToken</code>.</p>
</li>
<li>
<p>2018-12-14: Add <code>startAfter</code> to change stream options.</p>
</li>
<li>
<p>2018-09-09: Add <code>dropDatabase</code> to change stream <code>operationType</code>.</p>
</li>
<li>
<p>2018-07-30: Remove redundant error message checks for resumable errors.</p>
</li>
<li>
<p>2018-07-27: Add drop to change stream <code>operationType</code>.</p>
</li>
<li>
<p>2018-06-14: Clarify how to calculate <code>startAtOperationTime</code>.</p>
</li>
<li>
<p>2018-05-24: Change <code>startAtClusterTime</code> to <code>startAtOperationTime</code>.</p>
</li>
<li>
<p>2018-04-18: Add helpers for Database and MongoClient, and add <code>startAtClusterTime</code> option.</p>
</li>
<li>
<p>2018-04-17: Clarify that the initial aggregate should not be retried.</p>
</li>
<li>
<p>2017-12-13: Default read concern is also accepted, not just "majority".</p>
</li>
<li>
<p>2017-11-06: Defer to Read and Write concern spec for determining a read concern for the helper method.</p>
</li>
<li>
<p>2017-09-26: Clarify that change stream options may be added later.</p>
</li>
<li>
<p>2017-09-21: Clarify that we need to close the cursor on missing token.</p>
</li>
<li>
<p>2017-09-06: Remove <code>desired user experience</code> example.</p>
</li>
<li>
<p>2017-08-22: Clarify killing cursors during resume process.</p>
</li>
<li>
<p>2017-08-16: Fix formatting of resume process.</p>
</li>
<li>
<p>2017-08-16: Add clarification regarding Resumable errors.</p>
</li>
<li>
<p>2017-08-07: Fix typo in command format.</p>
</li>
<li>
<p>2017-08-03: Initial commit.</p>
</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="find-getmore-and-killcursors-commands"><a class="header" href="#find-getmore-and-killcursors-commands">Find, getMore and killCursors commands</a></h1>
<ul>
<li>Status: Accepted</li>
<li>Minimum Server Version: 3.2</li>
</ul>
<h2 id="abstract-36"><a class="header" href="#abstract-36">Abstract</a></h2>
<p>The Find, GetMore and KillCursors commands in MongoDB 3.2 or later replace the use of the legacy OP_QUERY, OP_GET_MORE
and OP_KILL_CURSORS wire protocol messages. This specification lays out how drivers should interact with the new
commands when compared to the legacy wire protocol level messages.</p>
<h2 id="definitions-8"><a class="header" href="#definitions-8">Definitions</a></h2>
<h3 id="meta-36"><a class="header" href="#meta-36">Meta</a></h3>
<p>The keywords "MUST", "MUST NOT", "REQUIRED", "SHALL", "SHALL NOT", "SHOULD", "SHOULD NOT", "RECOMMENDED", "MAY", and
"OPTIONAL" in this document are to be interpreted as described in <a href="https://www.ietf.org/rfc/rfc2119.txt">RFC 2119</a>.</p>
<h3 id="terms-24"><a class="header" href="#terms-24">Terms</a></h3>
<h4 id="document"><a class="header" href="#document">Document</a></h4>
<p>The term Document refers to the implementation in the driver's language of a BSON document.</p>
<h4 id="command"><a class="header" href="#command">Command</a></h4>
<p>A BSON document containing the fields making up a MongoDB server command.</p>
<h4 id="wire-protocol"><a class="header" href="#wire-protocol">Wire Protocol</a></h4>
<p>The binary protocol used to talk with MongoDB over a socket. It's made up by the OP_QUERY, OP_GET_MORE, OP_KILL_CURSORS,
OP_INSERT, OP_UPDATE and OP_DELETE.</p>
<h2 id="guidance-3"><a class="header" href="#guidance-3">Guidance</a></h2>
<h3 id="documentation-4"><a class="header" href="#documentation-4">Documentation</a></h3>
<p>The documentation provided in code below is merely for driver authors and SHOULD NOT be taken as required documentation
for the driver.</p>
<h3 id="implementation-1"><a class="header" href="#implementation-1">Implementation</a></h3>
<p>If the <strong>hello</strong> command returns <strong>maxWireVersion &gt;= 4</strong>, drivers:</p>
<ul>
<li>MUST implement queries with the <code>find</code> command instead of <code>OP_QUERY</code>.</li>
<li>MUST implement cursor operations with the <code>getMore</code> and <code>killCursors</code> commands instead of <code>OP_GET_MORE</code> and
<code>OP_KILL_CURSORS</code>, respectively.</li>
<li>MUST NOT use OP_QUERY except to execute commands.</li>
</ul>
<h2 id="commands"><a class="header" href="#commands">Commands</a></h2>
<h3 id="find"><a class="header" href="#find">find</a></h3>
<p>The <a href="https://www.mongodb.com/docs/manual/reference/command/find/">find</a> command replaces the query functionality of the
OP_QUERY wire protocol message but cannot execute queries against special collections. Unlike the legacy OP_QUERY wire
protocol message, the <strong>find</strong> command cannot be used to execute other commands.</p>
<p>For a successful command, the document returned from the server has the following format:</p>
<pre><code class="language-javascript">{
  "cursor": {
    "id": &lt;int64&gt;,
    "ns": &lt;string&gt;,
    "firstBatch": [
      ...
    ]
  },
  "ok": 1
}
</code></pre>
<h4 id="special-collection-names"><a class="header" href="#special-collection-names">Special Collection names</a></h4>
<p>The find command <strong>does not support querying on system collections</strong>, so if drivers are using any system collections
instead of the inprog, killop, unlock, etc. commands they SHOULD default to using the old-style OP_QUERY.</p>
<p>Any driver that provides helpers for any of the special collections below SHOULD use the replacement commands if
<strong>hello.maxWireVersion &gt;=4</strong> or higher.</p>
<div class="table-wrapper"><table><thead><tr><th>Special collection name</th><th>Replacement Command</th></tr></thead><tbody>
<tr><td><code>$cmd.sys.inprog</code></td><td>currentOp</td></tr>
<tr><td><code>$cmd.sys.unlock</code></td><td>fsyncUnlock</td></tr>
<tr><td><code>&lt;database&gt;.system.indexes</code></td><td>listIndexes</td></tr>
<tr><td><code>&lt;database&gt;.system.namespaces</code></td><td>listCollections</td></tr>
</tbody></table>
</div>
<p>Special Collection Names</p>
<h4 id="exhaust"><a class="header" href="#exhaust">Exhaust</a></h4>
<p>This section only applies to drivers that support exhaust cursors.</p>
<p>The exhaust protocol differs based on the server version:</p>
<div class="table-wrapper"><table><thead><tr><th>Server version</th><th>Server behavior</th></tr></thead><tbody>
<tr><td>4.0 and earlier</td><td>Only supports exhaust over legacy <strong>OP_QUERY</strong>. The <strong>find</strong> command does not support the exhaust flag from <strong>OP_QUERY</strong>.</td></tr>
<tr><td>4.2 to 5.0</td><td>Supports exhaust both over legacy <strong>OP_QUERY</strong> and <strong>OP_MSG</strong>.</td></tr>
<tr><td>5.1 and later</td><td>Supports exhaust over <strong>OP_MSG</strong>.</td></tr>
</tbody></table>
</div>
<p>Therefore drivers that implement exhaust cursors:</p>
<div class="table-wrapper"><table><thead><tr><th>Server version</th><th>Driver behavior</th></tr></thead><tbody>
<tr><td>4.0 and earlier</td><td>Drivers MUST use legacy <strong>OP_QUERY</strong>.</td></tr>
<tr><td>4.2 to 5.0</td><td>Drivers SHOULD use <strong>OP_MSG</strong> but MAY use legacy <strong>OP_QUERY</strong>.</td></tr>
<tr><td>5.1 and later</td><td>Drivers MUST only use <strong>OP_MSG</strong>. Alternatively, drivers MAY fallback to a non-exhaust cursor when an exhaust cursor is requested.</td></tr>
</tbody></table>
</div>
<h4 id="interactions-with-op_query"><a class="header" href="#interactions-with-op_query">Interactions with OP_QUERY</a></h4>
<p>When sending a find operation as a find command rather than a legacy <strong>OP_QUERY</strong> find only the <strong>secondaryOk</strong> flag is
honored of the flags available in the <strong>flag</strong> field on the wire protocol.</p>
<p>For the <strong>find</strong>, <strong>getMore</strong> and <strong>killCursors</strong> commands the <strong>numberToReturn</strong> field SHOULD be -1. To execute
<strong>find</strong> commands against a secondary the driver MUST set the <strong>secondaryOk</strong> bit for the <strong>find</strong> command to
successfully execute.</p>
<p>The <strong>secondaryOk</strong> flag SHOULD not be set for all follow-up <strong>getMore</strong> and <strong>killCursors</strong> commands. The cursor on the
server keeps the original <strong>secondaryOk</strong> value first set on the <strong>find</strong> command.</p>
<p>More detailed information about the interaction of the <strong>secondaryOk</strong> with <strong>OP_QUERY</strong> can be found in the Server
Selection Spec <a href="find_getmore_killcursors_commands/../server-selection/server-selection.html#passing-read-preference-to-mongos">Passing a Read Preference</a>.</p>
<h4 id="behavior-of-limit-skip-and-batchsize"><a class="header" href="#behavior-of-limit-skip-and-batchsize">Behavior of Limit, skip and batchSize</a></h4>
<p>The <strong>find</strong> command has different semantics to the existing 3.0 and earlier <strong>OP_QUERY</strong> wire protocol message. The
<strong>limit</strong> field is a hard limit on the total number of documents returned by the cursor no matter what <strong>batchSize</strong> is
provided. This includes other limiting operations, such as the <strong>$limit</strong> aggregation pipeline stage. This differs from
existing <strong>OP_QUERY</strong> behavior where there is no server-side concept of limit and where the driver <strong>MUST</strong> keep track
of the limit on the client side and <strong>MUST</strong> send a <strong>OP_KILL_CURSORS</strong> wire protocol message when the limit is reached.</p>
<p>When setting the <strong>batchSize</strong> on the <strong>find</strong> and <strong>getMore</strong> commands the value of <strong>batchSize</strong> <strong>MUST</strong> be based on
the cursor limit calculations specified in the <a href="find_getmore_killcursors_commands/../crud/crud.html#find">CRUD</a> specification.</p>
<p>Note that with 5.0, the server-side handling of cursors with a limit has changed. Before 5.0, some cursors were
automatically closed when the limit was reached (e.g. when running <strong>find</strong> with <strong>limit</strong>), and the reply document did
not include a cursor ID (i.e. <code>cursor.id</code> was <code>0</code>). Starting with 5.0, all cursor-producing operations will return a
cursor ID if the end of the batch being returned lines up with the limit on the cursor. In this case, drivers <strong>MUST</strong>
ensure the cursor is closed on the server, either by exhausting the cursor or by using <strong>killCursors</strong> to kill it.</p>
<p>In the following example the <strong>limit</strong> is set to <strong>4</strong> and the <strong>batchSize</strong> is set to <strong>3</strong> the following commands are
executed. The last command is either <strong>killCursors</strong> or <strong>getMore</strong>, depending on how a driver ensures the cursor is
closed on 5.0:</p>
<pre><code class="language-javascript">{find: ..., batchSize:3, limit:4}
{getMore: ..., batchSize:1} // Returns remaining items but leaves cursor open on 5.0+
{...}          // Kills server-side cursor. Necessary on 5.0+
</code></pre>
<p>If there are not enough documents in the cursor to fulfill the <strong>limit</strong> defined, the cursor runs to exhaustion and is
closed, returning a cursorId of 0 to the client.</p>
<p>Below are are some examples of using <strong>limit</strong>, <strong>skip</strong> and <strong>batchSize</strong>.</p>
<p>We have 100 documents in the collection <strong>t</strong>. We execute the following <strong>find</strong> command in the shell.</p>
<pre><code class="language-javascript">var b = db.runCommand({find:"t", limit:20, batchSize:10});
db.runCommand({getMore:b.cursor.id, collection:"t", batchSize:20});
</code></pre>
<p>The <strong>find</strong> command executes and returns the first 10 results. The <strong>getMore</strong> command returns the final 10 results
reaching the <strong>limit</strong> of 20 documents.</p>
<p>The <strong>skip</strong> option works in the same way as the current <strong>OP_QUERY</strong> starting the cursor after skipping <strong>n</strong> number of
documents of the query.</p>
<pre><code class="language-javascript">var b = db.runCommand({find:"t", limit:20, batchSize:10, skip:85});
db.runCommand({getMore:b.cursor.id, collection:"t", batchSize:20});
</code></pre>
<p>The <strong>find</strong> command returns the documents 86-95 and the <strong>getMore</strong> returns the last 5 documents.</p>
<h4 id="mapping-op_query-behavior-to-the-find-command-limit-and-batchsize-fields"><a class="header" href="#mapping-op_query-behavior-to-the-find-command-limit-and-batchsize-fields">Mapping OP_QUERY behavior to the find command limit and batchSize fields</a></h4>
<p>The way that limit, batchSize and singleBatch are defined for the find command differs from how these were specified in
OP_QUERY and the CRUD spec.</p>
<p>Specifically, <em>negative</em> values for <strong>limit</strong> and <strong>batchSize</strong> are no longer allowed and the <strong>singleBatch</strong> option is
used instead of negative values.</p>
<p>In order to have consistency between old and new applications, the following transformations MUST be performed before
adding options to the <strong>find</strong> command:</p>
<pre><code>singleBatch = (limit &lt; 0) || (batchSize &lt; 0)
limit       = abs(limit)
if singleBatch:
    batchSize = (limit == 0) ? abs(batchSize) : limit
else:
    batchSize = abs(batchSize)
</code></pre>
<p>Further, after these transformation:</p>
<ul>
<li>If <strong>limit</strong> is zero, it MUST be omitted from <strong>find</strong> options</li>
<li>If <strong>batchSize</strong> is zero, it MUST be omitted from <strong>find</strong> options</li>
<li>If <strong>singleBatch</strong> is false, it MUST be omitted from <strong>find</strong> options</li>
</ul>
<h4 id="batchsize-of-1"><a class="header" href="#batchsize-of-1">BatchSize of 1</a></h4>
<p>In 3.2 a batchSize of 1 means return a single document for the find command and it will not destroy the cursor after the
first batch of documents are returned. Given a query returning 4 documents the number of commands issues will be.</p>
<ol>
<li><strong>find</strong> command with batchSize=1</li>
<li><strong>getMore</strong> command with batchSize=1</li>
<li><strong>getMore</strong> command with batchSize=1</li>
<li><strong>getMore</strong> command with batchSize=1</li>
</ol>
<p>The driver <strong>SHOULD NOT attempt to emulate the behavior seen in 3.0 or earlier</strong> as the new find command enables the
user expected behavior of allowing the first result to contain a single document when specifying batchSize=1.</p>
<h4 id="tailable-cursors-1"><a class="header" href="#tailable-cursors-1">Tailable cursors</a></h4>
<p>By default, most cursors are non-tailable. For example, a typical <code>find</code> cursor is exhausted when all results for the
filter have been returned. MongoDB also supports creating cursors that "tail" or follow the target namespace for new
data. This is done via the <code>find</code> command's <code>tailable</code> option. Querying a capped collection is one use case for a
tailable cursor. A tailable cursor can receive <code>getMore</code> responses with an empty <code>nextBatch</code> array, which does not
indicate that the cursor has been exhausted.</p>
<p>Additionally, tailable cursors may "await data" from the server, which means that the server will wait to respond to the
client's <code>getMore</code> command until new data is available or some period of time has elapsed, whichever comes first. A
tailable <code>find</code> cursor can be configured using the <code>awaitData</code> option. The amount of time the server will wait for new
data is based on the <code>maxTimeMS</code> field of the <code>getMore</code> (or server default if unspecified). If the time does expire an
empty batch will be returned. A <code>maxTimeMS</code> field cannot be sent if the cursor was not configured with <code>awaitData=true</code>.</p>
<p>To create a tailable <code>find</code> cursor you execute the following command:</p>
<pre><code class="language-typescript">interface FindCommand {
  /** The namespace to run the find command on */
  find: string;
  /** The filter to control what documents are returned */
  filter: BSONDocument;
  /** Informs the server whether to keep the cursor open even when there are no results to satisfy the query */
  tailable?: boolean;
  /**
   * Informs the server whether to block on a `getMore`'s `maxTimeMS` before returning an empty `nextBatch`.
   * This must be set if getMores are to include `maxTimeMS` values.
   */
  awaitData?: boolean;
  /** Controls the amount of milliseconds the server will allow the operations to run for */
  maxTimeMS?: PositiveIntegerNumber;
  // ... Note: additional options unrelated to tailable cursors omitted
}
</code></pre>
<p>If <strong>maxTimeMS</strong> is not set in FindOptions, the driver SHOULD refrain from setting <strong>maxTimeMS</strong> on the <strong>find</strong> or
<strong>getMore</strong> commands issued by the driver and allow the server to use its internal default value for <strong>maxTimeMS</strong>.</p>
<h4 id="semantics-of-maxtimems-for-a-driver"><a class="header" href="#semantics-of-maxtimems-for-a-driver">Semantics of maxTimeMS for a Driver</a></h4>
<p>In the case of a <strong>non-tailable cursor query</strong> OR <strong>a tailable cursor query with awaitData == false</strong>, the driver MUST
set maxTimeMS on the <strong>find</strong> command and MUST NOT set maxTimeMS on the <strong>getMore</strong> command.</p>
<p>In the case of <strong>a tailable cursor with awaitData == true</strong> the driver MUST provide a Cursor level option named
<strong>maxAwaitTimeMS</strong> (See CRUD specification for details). The <strong>maxTimeMS</strong> option on the <strong>getMore</strong> command MUST be set
to the value of the option <strong>maxAwaitTimeMS</strong>. If no <strong>maxAwaitTimeMS</strong> is specified, the driver SHOULD not set
<strong>maxTimeMS</strong> on the <strong>getMore</strong> command.</p>
<h3 id="getmore"><a class="header" href="#getmore">getMore</a></h3>
<p>The <a href="https://www.mongodb.com/docs/manual/reference/command/getMore/">getMore</a> command replaces the <strong>OP_GET_MORE</strong> wire
protocol message. The query flags passed to OP_QUERY for a getMore command MUST be secondaryOk=true when sent to a
secondary. The OP_QUERY namespace MUST be the same as for the <strong>find</strong> and <strong>killCursors</strong> commands.</p>
<pre><code class="language-typescript">interface GetMoreCommand {
  /** Set to the nonzero cursor id */
  getMore: int64;
  /** Set to the namespace returned by the initial command response */
  collection: string;
  /**
   * User configurable document count for the batch returned for this getMore.
   * Only attached to command document if nonzero.
   */
  batchSize?: PositiveIntegerNumber;
  /**
   * User configurable time limit enforced by the server.
   */
  maxTimeMS?: PositiveIntegerNumber;
  /**
   * User configurable comment that can be used to identify the operation in logs.
   * This can be any BSON value.
   */
  comment?: BSONValue;
}
</code></pre>
<p>On success, the getMore command will return the following:</p>
<pre><code class="language-typescript">interface GetMoreResponse {
  ok: 1;
  cursor: {
    /** The cursor id, this may be equal to zero indicating the cursor is exhausted or closed */
    id: int64;
    /**
     * The namespace the cursor is running on.
     * This value may be different than the namespace the driver started the cursor on, for example, database level aggregations.
     */
    ns: string;
    /**
     * The next batch of documents.
     * This array may be empty, in the case of a tailable cursor, which DOES NOT indicate the cursor is exhausted.
     */
    nextBatch: BSONArray&lt;BSONDocument&gt;;
  }
  // ... Note: additional non-relevant fields omitted
}
</code></pre>
<p>The driver's local cursor MUST update its <code>id</code> and <code>ns</code>, as well as store the <code>nextBatch</code> from every <code>getMore</code> response.</p>
<h3 id="killcursors"><a class="header" href="#killcursors">killCursors</a></h3>
<p>The <a href="https://www.mongodb.com/docs/manual/reference/command/killCursors/">killCursors</a> command replaces the
<strong>OP_KILL_CURSORS</strong> wire protocol message. The OP_QUERY namespace MUST be the same as for the <strong>find</strong> and <strong>getMore</strong>
commands. The <strong>killCursors</strong> command is optional to implement in <strong>MongoDB 3.2</strong>.</p>
<p>The command response will be as follows:</p>
<pre><code class="language-javascript">{
  "cursorsKilled": [
    &lt;cursor id 1&gt;
    &lt;cursor id 2&gt;,
    ...
    &lt;cursor id n&gt;
  ],
  "cursorsNotFound": [
    &lt;cursor id 1&gt;
    &lt;cursor id 2&gt;,
    ...
    &lt;cursor id n&gt;
  ],
  "cursorsAlive": [
    &lt;cursor id 1&gt;
    &lt;cursor id 2&gt;,
    ...
    &lt;cursor id n&gt;
  ],
  ok: 1
}
</code></pre>
<p>The <strong>cursorsAlive</strong> array contain cursors that were not possible to kill. The information SHOULD be ignored by the
driver.</p>
<h4 id="difference-from-30-op_kill_cursors"><a class="header" href="#difference-from-30-op_kill_cursors">Difference from 3.0 OP_KILL_CURSORS</a></h4>
<p>One of the differences with the new <strong>killCursors</strong> command compared to the <strong>OP_KILL_CURSORS</strong> wire protocol message is
that the <strong>killCursors</strong> command returns a response while the <strong>OP_KILL_CURSORS</strong> wire protocol does not.</p>
<p>The <strong>OP_REPLY</strong> message has the following general structure.</p>
<pre><code class="language-javascript">struct {
    int32     messageLength;  // total message size, including
                              // this

    int32     requestID;      // identifier for this message

    int32     responseTo;     // requestID from the original
                              // request(used in responses from db)

    int32     opCode;         // request type - see table below

    int32     responseFlags;  // bit vector - see details below

    int64     cursorID;       // cursor id if client needs to do
                              // get more's

    int32     startingFrom;   // where in the cursor this reply is
                              // starting

    int32     numberReturned; // number of documents in the reply

    document* documents;      // documents
}
</code></pre>
<p>For the <strong>find</strong>, <strong>getMore</strong> and <strong>killCursors</strong> MongoDB returns a single document meaning <strong>numberReturned</strong> is set to
<strong>1</strong>. This is in contrast to MongoDB 3.0 and earlier where a <strong>OP_QUERY</strong> query will set <strong>numberReturned</strong> to &gt;= 0.</p>
<p>A driver MUST deserialize the command result and extract the <strong>firstBatch</strong> and <strong>nextBatch</strong> arrays for the <strong>find</strong>
and <strong>getMore</strong> commands to access the returned documents.</p>
<p>The result from the <strong>killCursors</strong> command MAY be safely ignored.</p>
<p>If the driver supports returning <strong>raw</strong> BSON buffers instead of deserialized documents there might be a need to be able
to partially deserialize documents to be able to efficiently provide the behavior in comparison to existing <strong>OP_QUERY</strong>
queryresults.</p>
<h2 id="errors-4"><a class="header" href="#errors-4">Errors</a></h2>
<p>The <strong>find</strong> and <strong>getMore</strong> commands will report errors using the standard mechanism: an "ok: 0" field paired with
"errmsg" and "code" fields. See below for example error responses:</p>
<pre><code class="language-javascript">db.runCommand({find: "t", sort: {padding: -1}})
</code></pre>
<pre><code class="language-javascript">{
  "errmsg" : "exception: Executor error: Overflow sort stage buffered data usage of 41630570 bytes exceeds internal limit of 33554432 bytes",
  "code" : 28616,
  "ok" : 0
}
</code></pre>
<pre><code class="language-javascript">db.runCommand({find: "t", foo: "bar"})
</code></pre>
<pre><code class="language-javascript">{
  "ok" : 0,
  "errmsg" : "Failed to parse: { find: \"t\", foo: \"bar\" }. Unrecognized field 'foo'.",
  "code" : 2
}
</code></pre>
<p>Like other commands, the find and getMore commands will not use the OP_REPLY response flags.
<a href="https://www.mongodb.com/docs/meta-driver/latest/legacy/mongodb-wire-protocol/#op-reply">OP_REPLY Documentation</a></p>
<h2 id="faq-2"><a class="header" href="#faq-2">FAQ</a></h2>
<h3 id="changes-in-error-handling-for-32-tailable-cursor"><a class="header" href="#changes-in-error-handling-for-32-tailable-cursor">Changes in error handling for 3.2 tailable cursor</a></h3>
<p>Tailable cursors pointing to documents in a capped collection that get overwritten will return a zero document result in
MongoDB 3.0 or earlier but will return an error in MongoDB 3.2</p>
<h3 id="explain-command"><a class="header" href="#explain-command">Explain command</a></h3>
<p>There is no equivalent of the <code>$explain</code> modifier in the find command. The driver SHOULD use the <strong>explain</strong> command.
Information about the command can be found in the
<a href="https://www.mongodb.com/docs/manual/reference/command/explain/">Explain command reference</a>.</p>
<h3 id="readpreference-and-mongos"><a class="header" href="#readpreference-and-mongos">ReadPreference and Mongos</a></h3>
<p>The <strong>find</strong> command does not include a readPreference field. To pass a readPreference to a <strong>mongos</strong> use the
<strong>$readPreference</strong> field and format your command as.</p>
<pre><code class="language-javascript">{$query: {find: ...}, $readPreference: {}}
</code></pre>
<p>This format is general for all commands when executing against a Mongos proxy.</p>
<p>More in depth information about passing read preferences to Mongos can be found in the Server Selection Specification
<a href="find_getmore_killcursors_commands/../server-selection/server-selection.html#passing-read-preference-to-mongos">Server Selection Specification</a>.</p>
<h2 id="changelog-38"><a class="header" href="#changelog-38">Changelog</a></h2>
<ul>
<li>
<p>2024-07-30: Migrated from reStructuredText to Markdown.</p>
</li>
<li>
<p>2023-05-10: Improve tailable cursor description and update the <code>getMore</code> section code blocks.</p>
</li>
<li>
<p>2022-10-05: Remove spec front matter and reformat changelog.</p>
</li>
<li>
<p>2022-02-01: Replace examples/tables for find, getMore, and killCursors with server manual links.</p>
</li>
<li>
<p>2021-12-14: Exhaust cursors may fallback to non-exhaust cursors on 5.1+ servers. Relax requirement of OP_MSG for
exhaust cursors.</p>
</li>
<li>
<p>2021-08-27: Exhaust cursors must use OP_MSG on 3.6+ servers.</p>
</li>
<li>
<p>2021-04-06: Updated to use hello and secondaryOk.</p>
</li>
<li>
<p>2015-10-21: If no <strong>maxAwaitTimeMS</strong> is specified, the driver SHOULD not set <strong>maxTimeMS</strong> on the <strong>getMore</strong> command.</p>
</li>
<li>
<p>2015-10-13: Added guidance on batchSize values as related to the <strong>getMore</strong> command. Legacy secondaryOk flag SHOULD
not be set on getMore and killCursors commands. Introduced maxAwaitTimeMS option for setting maxTimeMS on getMore
commands when the cursor is a tailable cursor with awaitData set.</p>
</li>
<li>
<p>2015-09-30: Legacy secondaryOk flag must be set to true on <strong>getMore</strong> and <strong>killCursors</strong> commands to make drivers
have same behavior as for OP_GET_MORE and OP_KILL_CURSORS.</p>
</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="gridfs-spec"><a class="header" href="#gridfs-spec">GridFS Spec</a></h1>
<ul>
<li>Status: Accepted</li>
<li>Minimum Server Version: 2.2</li>
</ul>
<hr />
<h2 id="abstract-37"><a class="header" href="#abstract-37">Abstract</a></h2>
<p>GridFS is a convention drivers use to store and retrieve BSON binary data (type "x05") that exceeds MongoDB"s
BSON-document size limit of 16 MiB. When this data, called a <strong>user file</strong>, is written to the system, GridFS divides the
file into <strong>chunks</strong> that are stored as distinct documents in a <strong>chunks collection</strong>. To retrieve a stored file, GridFS
locates and returns all of its component chunks. Internally, GridFS creates a <strong>files collection document</strong> for each
stored file. Files collection documents hold information about stored files, and they are stored in a <strong>files
collection</strong>.</p>
<p>This spec defines a basic API for GridFS. This spec also outlines advanced GridFS features that drivers can choose to
support in their implementations. Additionally, this document attempts to clarify the meaning and purpose of all fields
in the GridFS data model, disambiguate GridFS terminology, and document configuration options that were previously
unspecified.</p>
<h2 id="definitions-9"><a class="header" href="#definitions-9">Definitions</a></h2>
<h3 id="meta-37"><a class="header" href="#meta-37">META</a></h3>
<p>The keywords "MUST", "MUST NOT", "REQUIRED", "SHALL", "SHALL NOT", "SHOULD", "SHOULD NOT", "RECOMMENDED", "MAY", and
"OPTIONAL" in this document are to be interpreted as described in <a href="https://www.ietf.org/rfc/rfc2119.txt">RFC 2119</a>.</p>
<h3 id="terms-25"><a class="header" href="#terms-25">Terms</a></h3>
<p><strong>Bucket name</strong></p>
<p>A prefix under which a GridFS system"s collections are stored. Collection names for the files and chunks collections are
prefixed with the bucket name. The bucket name MUST be configurable by the user. Multiple buckets may exist within a
single database. The default bucket name is "fs".</p>
<p><strong>Chunk</strong></p>
<p>A section of a user file, stored as a single document in the "chunks" collection of a GridFS bucket. The default size
for the data field in chunks is 255 KiB. Chunk documents have the following form:</p>
<pre><code class="language-javascript">{
  "_id" : &lt;ObjectId&gt;,
  "files_id" : &lt;TFileId&gt;,
  "n" : &lt;Int32&gt;,
  "data" : &lt;binary data&gt;
}
</code></pre>
<p><strong>_id</strong></p>
<p>a unique ID for this document of type BSON ObjectId</p>
<p><strong>files_id</strong></p>
<p>the id for this file (the <code>_id</code> from the files collection document). This field takes the type of the corresponding
<code>_id</code> in the files collection.</p>
<p><strong>_id</strong></p>
<p>the index number of this chunk, zero-based.</p>
<p><strong>data</strong></p>
<p>a chunk of data from the user file</p>
<p><strong>Chunks collection</strong></p>
<p>A collection in which chunks of a user file are stored. The name for this collection is the word 'chunks' prefixed by
the bucket name. The default is "fs.chunks".</p>
<p><strong>Empty chunk</strong></p>
<p>A chunk with a zero length "data" field.</p>
<p><strong>Files collection</strong></p>
<p>A collection in which information about stored files is stored. There will be one files collection document per stored
file. The name for this collection is the word "files" prefixed by the bucket name. The default is "fs.files".</p>
<p><strong>Files collection document</strong></p>
<p>A document stored in the files collection that contains information about a single stored file. Files collection
documents have the following form:</p>
<pre><code class="language-javascript">{
  "_id" : &lt;TFileId&gt;,
  "length" : &lt;Int64&gt;,
  "chunkSize" : &lt;Int32&gt;,
  "uploadDate" : &lt;BSON datetime, ms since Unix epoch in UTC&gt;,
  "md5" : &lt;hex string&gt;,
  "filename" : &lt;string&gt;,
  "contentType" : &lt;string&gt;,
  "aliases" : &lt;string array&gt;,
  "metadata" : &lt;Document&gt;
}
</code></pre>
<p><strong>_id</strong></p>
<p>a unique ID for this document. Usually this will be of type ObjectId, but a custom <code>_id</code> value provided by the
application may be of any type.</p>
<p><strong>length</strong></p>
<p>the length of this stored file, in bytes</p>
<p><strong>chunkSize</strong></p>
<p>the size, in bytes, of each data chunk of this file. This value is configurable by file. The default is 255 KiB.</p>
<p><strong>uploadDate</strong></p>
<p>the date and time this file was added to GridFS, stored as a BSON datetime value. The value of this field MUST be the
datetime when the upload completed, not the datetime when it was begun.</p>
<p><strong>md5</strong></p>
<p>DEPRECATED, a hash of the contents of the stored file</p>
<p><strong>filename</strong></p>
<p>the name of this stored file; this does not need to be unique</p>
<p><strong>contentType</strong></p>
<p>DEPRECATED, any MIME type, for application use only</p>
<p><strong>aliases</strong></p>
<p>DEPRECATED, for application use only</p>
<p><strong>metadata</strong></p>
<p>any additional application data the user wishes to store</p>
<p>Note: some older versions of GridFS implementations allowed applications to add arbitrary fields to the files collection
document at the root level. New implementations of GridFS will not allow this, but must be prepared to handle existing
files collection documents that might have additional fields.</p>
<p>Note: drivers SHOULD store length as Int64 and chunkSize as Int32 when creating new GridFS files. However, drivers MUST
be able to handle existing GridFS files where the length and chunkSize fields might have been stored using a different
numeric data type.</p>
<p><strong>Orphaned chunk</strong></p>
<p>A document in the chunks collections for which the "files_id" does not match any <code>_id</code> in the files collection. Orphaned
chunks may be created if write or delete operations on GridFS fail part-way through.</p>
<p><strong>Stored File</strong></p>
<p>A user file that has been stored in GridFS, consisting of a files collection document in the files collection and zero
or more documents in the chunks collection.</p>
<p><strong>Stream</strong></p>
<p>An abstraction that represents streamed I/O. In some languages a different word is used to represent this abstraction.</p>
<p><strong>TFileId</strong></p>
<p>While GridFS file id values are ObjectIds by default, an application may choose to use custom file id values, which may
be of any type. In this spec the term TFileId refers to whatever data type is appropriate in the driver's programming
language to represent a file id. This would be something like object, BsonValue or a generic <code>&lt;TFileId&gt;</code> type parameter.</p>
<p><strong>User File</strong></p>
<p>A data added by a user to GridFS. This data may map to an actual file on disk, a stream of input, a large data object,
or any other large amount of consecutive data.</p>
<h2 id="specification-35"><a class="header" href="#specification-35">Specification</a></h2>
<h3 id="guidance-4"><a class="header" href="#guidance-4">Guidance</a></h3>
<h4 id="documentation-5"><a class="header" href="#documentation-5">Documentation</a></h4>
<p>The documentation provided in code below is merely for driver authors and SHOULD NOT be taken as required documentation
for the driver.</p>
<h4 id="operations-4"><a class="header" href="#operations-4">Operations</a></h4>
<p>All drivers MUST offer the Basic API operations defined in the following sections and MAY offer the Advanced API
operations. This does not preclude a driver from offering more.</p>
<h4 id="operation-parameters-2"><a class="header" href="#operation-parameters-2">Operation Parameters</a></h4>
<p>All drivers MUST offer the same options for each operation as defined in the following sections. This does not preclude
a driver from offering more. The options parameter is optional. A driver SHOULD NOT require a user to specify optional
parameters.</p>
<h4 id="deviations-5"><a class="header" href="#deviations-5">Deviations</a></h4>
<p>A non-exhaustive list of acceptable deviations are as follows:</p>
<ul>
<li>
<p>Using named parameters instead of an options hash. For instance,</p>
<pre><code class="language-javascript">id = bucket.upload_from_stream(filename, source, chunkSizeBytes: 16 * 1024);
</code></pre>
</li>
<li>
<p>Using a fluent style for constructing a GridFSBucket instance:</p>
<pre><code class="language-javascript">bucket = new GridFSBucket(database)
  .withReadPreference(ReadPreference.Secondary);
</code></pre>
</li>
</ul>
<p>When using a fluent-style builder, all options should be named rather than inventing a new word to include in the
pipeline (like options). Required parameters are still required to be on the initiating constructor.</p>
<h4 id="timeouts-4"><a class="header" href="#timeouts-4">Timeouts</a></h4>
<p>Drivers MUST enforce timeouts for all operations per
<a href="gridfs/../client-side-operations-timeout/client-side-operations-timeout.html#gridfs-api">Client Side Operations Timeout: GridFS API</a>.</p>
<h3 id="naming-3"><a class="header" href="#naming-3">Naming</a></h3>
<p>All drivers MUST name operations, objects, and parameters as defined in the following sections.</p>
<p>Deviations are permitted as outlined below.</p>
<h4 id="deviations-6"><a class="header" href="#deviations-6">Deviations</a></h4>
<p>When deviating from a defined name, an author should consider if the altered name is recognizable and discoverable to
the user of another driver.</p>
<p>A non-exhaustive list of acceptable naming deviations are as follows:</p>
<ul>
<li>Using "bucketName" as an example, Java would use "bucketName" while Python would use "bucket_name". However, calling
it "bucketPrefix" would not be acceptable.</li>
<li>Using "maxTimeMS" as an example, .NET would use "MaxTime" where its type is a TimeSpan structure that includes units.
However, calling it "MaximumTime" would not be acceptable.</li>
<li>Using "GridFSUploadOptions" as an example, Javascript wouldn't need to name it while other drivers might prefer to
call it "GridFSUploadArgs" or "GridFSUploadParams". However, calling it "UploadOptions" would not be acceptable.</li>
<li>Languages that use a different word than "Stream" to represent a streamed I/O abstraction may replace the word
"Stream" with their language's equivalent word. For example, open_upload_stream might be called open_upload_file or
open_upload_writer if appropriate.</li>
<li>Languages that support overloading MAY shorten the name of some methods as appropriate. For example,
download_to_stream and download_to_stream_by_name MAY be overloaded download_to_stream methods with different
parameter types. Implementers are encouraged not to shorten method names unnecessarily, because even if the shorter
names are not ambiguous today they might become ambiguous in the future as new features are added.</li>
</ul>
<h2 id="api-3"><a class="header" href="#api-3">API</a></h2>
<p>This section presents two groups of features, a basic API that a driver MUST implement, and a more advanced API that
drivers MAY choose to implement additionally.</p>
<h2 id="basic-api"><a class="header" href="#basic-api">Basic API</a></h2>
<h3 id="configurable-gridfsbucket-class"><a class="header" href="#configurable-gridfsbucket-class">Configurable GridFSBucket class</a></h3>
<pre><code class="language-javascript">class GridFSBucketOptions {

  /**
   * The bucket name. Defaults to 'fs'.
   */
  bucketName : String optional;

  /**
   * The chunk size in bytes. Defaults to 255 KiB.
   */
  chunkSizeBytes : Int32 optional;

  /**
   * The write concern. Defaults to the write concern of the database.
   */
  writeConcern : WriteConcern optional;

  /**
   * The read concern. Defaults to the read concern of the database.
   */
  readConcern : ReadConcern optional;

  /**
   * The read preference. Defaults to the read preference of the database.
   */
  readPreference : ReadPreference optional;

  /**
   * TRANSITIONAL: This option is provided for backwards compatibility.
   * It MUST be supported while a driver supports MD5 and MUST be removed
   * (or made into a no-op) when a driver removes MD5 support entirely.
   * When true, the GridFS implementation will not compute MD5 checksums
   * of uploaded files. Defaults to false.
   */
  disableMD5: Boolean
}

class GridFSBucket {

  /**
   * Create a new GridFSBucket object on @db with the given @options.
   */
  GridFSBucket new(Database db, GridFSBucketOptions options=null);

}
</code></pre>
<p>Creates a new GridFSBucket object, managing a GridFS bucket within the given database.</p>
<p>GridFSBucket objects MUST allow the following options to be configurable:</p>
<ul>
<li><strong>bucketName:</strong> the name of this GridFS bucket. The files and chunks collection for this GridFS bucket are prefixed by
this name followed by a dot. Defaults to "fs". This allows multiple GridFS buckets, each with a unique name, to exist
within the same database.</li>
<li><strong>chunkSizeBytes:</strong> the number of bytes stored in chunks for new user files added through this GridFSBucket object.
This will not reformat existing files in the system that use a different chunk size. Defaults to 255 KiB.</li>
</ul>
<p>IF a driver supports configuring readConcern, readPreference or writeConcern at the database or collection level, then
GridFSBucket objects MUST also allow the following options to be configurable:</p>
<ul>
<li><strong>readConcern:</strong> defaults to the read concern on the parent database (or client object if the parent database has no
read concern).</li>
<li><strong>readPreference:</strong> defaults to the read preference on the parent database (or client object if the parent database
has no read preference).</li>
<li><strong>writeConcern:</strong> defaults to the write concern on the parent database (or client object if the parent database has no
write concern).</li>
</ul>
<p>The following option is transitional:</p>
<ul>
<li><strong>disableMD5:</strong> this allows users to disable MD5 when operating under FIPS restrictions. It is provided to allow a
transition period as drivers remove MD5 support. Until a driver removes MD5 support, drivers MUST support this option.
Following a driver's normal feature removal cycle, when MD5 support is removed, this option MUST be removed or
otherwise made into a no-op option.</li>
</ul>
<p>GridFSBucket instances are immutable. Their properties MUST NOT be changed after the instance has been created. If your
driver provides a fluent way to provide new values for properties, these fluent methods MUST return new instances of
GridFSBucket.</p>
<h3 id="indexes"><a class="header" href="#indexes">Indexes</a></h3>
<p>For efficient execution of various GridFS operations the following indexes MUST exist:</p>
<ul>
<li>an index on { filename : 1, uploadDate : 1 } on the files collection</li>
<li>a unique index on { files_id : 1, n : 1 } on the chunks collection</li>
</ul>
<p>Normally we leave it up to the user to create whatever indexes they see fit, but because GridFS is likely to be looked
at as a black box we should create these indexes automatically in a way that involves the least amount of overhead
possible.</p>
<h4 id="before-read-operations"><a class="header" href="#before-read-operations">Before read operations</a></h4>
<p>For read operations, drivers MUST assume that the proper indexes exist.</p>
<h4 id="before-write-operations"><a class="header" href="#before-write-operations">Before write operations</a></h4>
<p>Immediately before the <strong>first</strong> write operation on an instance of a GridFSBucket class is attempted (and not earlier),
drivers MUST:</p>
<ul>
<li>determine if the files collection is empty using the primary read preference mode.</li>
<li>and if so, create the indexes described above if they do not already exist</li>
</ul>
<p>To determine whether the files collection is empty drivers SHOULD execute the equivalent of the following shell command:</p>
<blockquote>
<blockquote>
<p>db.fs.files.findOne({}, { _id : 1 })</p>
</blockquote>
</blockquote>
<p>If no document is returned the files collection is empty.</p>
<p>This method of determining whether the files collection is empty should perform better than checking the count in the
case where the files collection is sharded.</p>
<p>Drivers MUST check whether the indexes already exist before attempting to create them. This supports the scenario where
an application is running with read-only authorizations.</p>
<p>When checking whether an index exists drivers MUST compare numeric values by value even when they are of different
types, because the actual type will depend on how the index was created (for example, indexes created using the shell
will have double as the type for numeric values).</p>
<p>For example, the following index specifications should all be treated as equivalent:</p>
<ul>
<li>{ filename : 1, uploadDate : 1 } // where 1 is either a 32-bit or 64-bit integer</li>
<li>{ filename : 1, uploadDate : 1.0 }</li>
<li>{ filename : 1.0, uploadDate : 1 }</li>
<li>{ filename : 1.0, uploadDate : 1.0 }</li>
</ul>
<p>If a driver determines that it should create the indexes, it MUST raise an error if the attempt to create the indexes
fails.</p>
<p>Drivers MUST create the indexes in foreground mode.</p>
<h3 id="file-upload"><a class="header" href="#file-upload">File Upload</a></h3>
<pre><code class="language-javascript">class GridFSUploadOptions {

  /**
   * The number of bytes per chunk of this file. Defaults to the
   * chunkSizeBytes in the GridFSBucketOptions.
   */
  chunkSizeBytes : Int32 optional;

  /**
   * User data for the 'metadata' field of the files collection document.
   * If not provided the driver MUST omit the metadata field from the
   * files collection document.
   */
  metadata : Document optional;

  /**
   * DEPRECATED: A valid MIME type. If not provided the driver MUST omit the
   * contentType field from the files collection document.
   *
   * Applications wishing to store a contentType should add a contentType field
   * to the metadata document instead.
   */
  contentType : String optional;

  /**
   * DEPRECATED: An array of aliases. If not provided the driver MUST omit the
   * aliases field from the files collection document.
   *
   * Applications wishing to store aliases should add an aliases field to the
   * metadata document instead.
   */
  aliases: String[] optional;

}

class GridFSBucket {

  /**
   * Opens a Stream that the application can write the contents of the file to.
   * The driver generates the file id.
   *
   * Returns a Stream to which the application will write the contents.
   *
   * Note: this method is provided for backward compatibility. In languages
   * that use generic type parameters, this method may be omitted since
   * the TFileId type might not be an ObjectId.
   */
  Stream open_upload_stream(string filename, GridFSUploadOptions options=null);

  /**
   * Opens a Stream that the application can write the contents of the file to.
   * The application provides a custom file id.
   *
   * Returns a Stream to which the application will write the contents.
   */
  Stream open_upload_stream_with_id(TFileId id, string filename, GridFSUploadOptions options=null);

  /**
   * Uploads a user file to a GridFS bucket. The driver generates the file id.
   *
   * Reads the contents of the user file from the @source Stream and uploads it
   * as chunks in the chunks collection. After all the chunks have been uploaded,
   * it creates a files collection document for @filename in the files collection.
   *
   * Returns the id of the uploaded file.
   *
   * Note: this method is provided for backward compatibility. In languages
   * that use generic type parameters, this method may be omitted since
   * the TFileId type might not be an ObjectId.
   */
  ObjectId upload_from_stream(string filename, Stream source, GridFSUploadOptions options=null);

  /**
   * Uploads a user file to a GridFS bucket. The application supplies a custom file id.
   *
   * Reads the contents of the user file from the @source Stream and uploads it
   * as chunks in the chunks collection. After all the chunks have been uploaded,
   * it creates a files collection document for @filename in the files collection.
   *
   * Note: there is no need to return the id of the uploaded file because the application
   * already supplied it as a parameter.
   */
  void upload_from_stream_with_id(TFileId id, string filename, Stream source, GridFSUploadOptions options=null);
}
</code></pre>
<p>Uploads a user file to a GridFS bucket. For languages that have a Stream abstraction, drivers SHOULD use that Stream
abstraction. For languages that do not have a Stream abstraction, drivers MUST create an abstraction that supports
streaming.</p>
<p>In the case of open_upload_stream, the driver returns a Stream to which the application will write the contents of the
file. As the application writes the contents to the returned Stream, the contents are uploaded as chunks in the chunks
collection. When the application signals it is done writing the contents of the file by calling close (or its
equivalent) on the returned Stream, a files collection document is created in the files collection. Once the Stream has
been closed (and the files collection document has been created) a driver MUST NOT allow further writes to the upload
Stream.</p>
<p>The driver MUST make the Id of the new file available to the caller. Typically a driver SHOULD make the Id available as
a property named Id on the Stream that is returned. In languages where that is not idiomatic, a driver MUST make the Id
available in a way that is appropriate for that language.</p>
<p>In the case of upload_from_stream, the driver reads the contents of the user file by consuming the the source Stream
until end of file is reached. The driver does NOT close the source Stream.</p>
<p>Drivers MUST take an "options" document with configurable parameters. Drivers for dynamic languages MUST ignore any
unrecognized fields in the options for this method (this does not apply to drivers for static languages which define an
Options class that by definition only contains valid fields).</p>
<p>Note that in GridFS, "filename" is not a unique identifier. There may be many stored files with the same filename stored
in a GridFS bucket under different ids. Multiple stored files with the same filename are called 'revisions', and the
'uploadDate' is used to distinguish newer revisions from older ones.</p>
<p><strong>Implementation details:</strong></p>
<p>If "chunkSizeBytes" is set through the options, that value MUST be used as the chunk size for this stored file. If this
parameter is not specified, the default chunkSizeBytes setting for this GridFSBucket object MUST be used instead.</p>
<p>To store a user file, the file must have a unique id. In some cases the driver can generate a unique ObjectId to serve
as the id for the file being uploaded. Otherwise the application provides the value. Drivers store the contents of the
user file in the chunks collection by breaking up the contents into chunks of size "chunkSizeBytes". For a non-empty
user file, for each n<sup>th</sup> section of the file, drivers create a chunk document and set its fields as follows:</p>
<ul>
<li>Files_id: the id generated for this stored file.</li>
<li>N: this is the n<sup>th</sup> section of the stored file, zero based.</li>
<li>Data: a section of file data, stored as BSON binary data with subtype 0x00. All chunks except the last one must be
exactly 'chunkSizeBytes' long. The last chunk can be smaller, and should only be as large as necessary.</li>
</ul>
<p>Historically, while streaming the user file, drivers computed an MD5 digest for the (now deprecated) 'md5' field of the
files collection document. If drivers preserve this behavior for backwards compatibility, they MUST provide the
'disableMD5' member of GridFSBucketOptions. When 'disableMD5' is true, drivers MUST NOT compute an MD5 digest or include
it in the files collection document. If drivers no longer support the deprecated 'md5' field, they MUST NOT provide the
'disableMD5' member (or it MUST be a no-op) and MUST NOT compute MD5.</p>
<p>After storing all chunk documents generated for the user file in the "chunks" collection, drivers create a files
collection document for the file and store it in the files collection. The fields in the files collection document are
set as follows:</p>
<div class="table-wrapper"><table><thead><tr><th>Name</th><th>Description</th></tr></thead><tbody>
<tr><td>length</td><td>the length of this stored file, in bytes.</td></tr>
<tr><td>chunksize</td><td>the chunk size in bytes used to break the user file into chunks. While the configuration option is named "chunkSizeBytes" for clarity, for legacy reasons, the files collection document uses only "chunkSize".</td></tr>
<tr><td>uploaddate</td><td>a BSON datetime object for the current time, in UTC, when the files collection document was created.</td></tr>
<tr><td>md5</td><td>MD5 checksum for this user file, computed from the file's data, stored as a hex string, if computed, otherwise omitted.</td></tr>
<tr><td>filename</td><td>the filename passed to this function, UTF-8 encoded.</td></tr>
<tr><td>contenttype</td><td>the "contentType" passed in the options, if provided; otherwise omitted.</td></tr>
<tr><td>aliases</td><td>the array passed in the options, if provided; otherwise omitted.</td></tr>
<tr><td>metadata</td><td>the "metadata" document passed in the options, if provided; otherwise omitted.</td></tr>
</tbody></table>
</div>
<p>If a user file contains no data, drivers MUST still create a files collection document for it with length set to zero.
Drivers MUST NOT create any empty chunks for this file.</p>
<p>Drivers MUST NOT run the 'filemd5' database command to confirm that all chunks were successfully uploaded. We assume
that if none of the inserts failed then the chunks must have been successfully inserted, and running the 'filemd5'
command would just be unnecessary overhead and doesn't work for sharded chunk keys anyway.</p>
<p><strong>Operation Failure</strong></p>
<p>If any of the above operations fail against the server, drivers MUST raise an error. If some inserts succeeded before
the failed operation, these become orphaned chunks. Drivers MUST NOT attempt to clean up these orphaned chunks. The
rationale is that whatever failure caused the orphan chunks will most likely also prevent cleaning up the orphaned
chunks, and any attempts to clean up the orphaned chunks will simply cause long delays before reporting the original
failure to the application.</p>
<p><strong>Aborting an upload</strong></p>
<p>Drivers SHOULD provide a mechanism to abort an upload. When using open_upload_stream, the returned Stream SHOULD have an
Abort method. When using upload_from_stream, the upload will be aborted if the source stream raises an error.</p>
<p>When an upload is aborted any chunks already uploaded MUST be deleted. Note that this differs from the case where an
attempt to insert a chunk fails, in which case drivers immediately report the failure without attempting to delete any
chunks already uploaded.</p>
<p>Abort MUST raise an error if it is unable to successfully abort the upload (for example, if an error occurs while
deleting any chunks already uploaded). However, if the upload is being aborted because the source stream provided to
upload_from_stream raised an error then the original error should be re-raised.</p>
<p>Abort MUST also close the Stream, or at least place it in an aborted state, so any further attempts to write additional
content to the Stream after Abort has been called fail immediately.</p>
<h3 id="file-download"><a class="header" href="#file-download">File Download</a></h3>
<pre><code class="language-javascript">class GridFSBucket {

  /** Opens a Stream from which the application can read the contents of the stored file
   * specified by @id.
   *
   * Returns a Stream.
   */
  Stream open_download_stream(TFileId id);

  /**
   * Downloads the contents of the stored file specified by @id and writes
   * the contents to the @destination Stream.
   */
  void download_to_stream(TFileId id, Stream destination);

}
</code></pre>
<p>Downloads a stored file from a GridFS bucket. For languages that have a Stream abstraction, drivers SHOULD use that
Stream abstraction. For languages that do not have a Stream abstraction, drivers MUST create an abstraction that
supports streaming.</p>
<p>In the case of open_download_stream, the application reads the contents of the stored file by reading from the returned
Stream until end of file is reached. The application MUST call close (or its equivalent) on the returned Stream when it
is done reading the contents.</p>
<p>In the case of download_to_stream the driver writes the contents of the stored file to the provided Stream. The driver
does NOT call close (or its equivalent) on the Stream.</p>
<p>Note: By default a file id is of type ObjectId. If an application uses custom file ids it may be of any type.</p>
<p><strong>Implementation details:</strong></p>
<p>Drivers must first retrieve the files collection document for this file. If there is no files collection document, the
file either never existed, is in the process of being deleted, or has been corrupted, and the driver MUST raise an
error.</p>
<p>Then, implementers retrieve all chunks with files_id equal to id, sorted in ascending order on "n".</p>
<p>However, when downloading a zero length stored file the driver MUST NOT issue a query against the chunks collection,
since that query is not necessary. For a zero length file, drivers return either an empty stream or send nothing to the
provided stream (depending on the download method).</p>
<p>If a networking error or server error occurs, drivers MUST raise an error.</p>
<p>As drivers stream the stored file they MUST check that each chunk received is the next expected chunk (i.e. it has the
expected "n" value) and that the data field is of the expected length. In the case of open_download_stream, if the
application stops reading from the stream before reaching the end of the stored file, any errors that might exist beyond
the point at which the application stopped reading won't be detected by the driver.</p>
<h3 id="file-deletion"><a class="header" href="#file-deletion">File Deletion</a></h3>
<pre><code class="language-javascript">class GridFSBucket {

  /**
   * Given a @id, delete this stored file"s files collection document and
   * associated chunks from a GridFS bucket.
   */
  void delete(TFileId id);

}
</code></pre>
<p>Deletes the stored file"s files collection document and associated chunks from the underlying database.</p>
<p>As noted for download(), drivers that previously used id"s of a different type MAY implement a delete() method that
accepts that type, but MUST mark that method as deprecated.</p>
<p><strong>Implementation details:</strong></p>
<p>There is an inherent race condition between the chunks and files collections. Without some transaction-like behavior
between these two collections, it is always possible for one client to delete a stored file while another client is
attempting a read of the stored file. For example, imagine client A retrieves a stored file"s files collection document,
client B deletes the stored file, then client A attempts to read the stored file"s chunks. Client A wouldn"t find any
chunks for the given stored file. To minimize the window of vulnerability of reading a stored file that is the process
of being deleted, drivers MUST first delete the files collection document for a stored file, then delete its associated
chunks.</p>
<p>If there is no such file listed in the files collection, drivers MUST raise an error. Drivers MAY attempt to delete any
orphaned chunks with files_id equal to id before raising the error.</p>
<p>If a networking or server error occurs, drivers MUST raise an error.</p>
<h3 id="generic-find-on-files-collection"><a class="header" href="#generic-find-on-files-collection">Generic Find on Files Collection</a></h3>
<pre><code class="language-javascript">class GridFSFindOptions {

  /**
   * Enables writing to temporary files on the server. When set to true, the server
   * can write temporary data to disk while executing the find operation on the files collection.
   *
   * This option is sent only if the caller explicitly provides a value. The default
   * is to not send a value. For servers &lt; 3.2, this option is ignored and not sent
   * as allowDiskUse does not exist in the OP_QUERY wire protocol.
   *
   * @see https://www.mongodb.com/docs/manual/reference/command/find/
   */
  allowDiskUse: Optional&lt;Boolean&gt;;

  /**
   * The number of documents to return per batch.
   */
  batchSize : Int32 optional;

  /**
   * The maximum number of documents to return.
   */
  limit : Int32 optional;

  /**
   * The maximum amount of time to allow the query to run.
   */
  maxTimeMS: Int64 optional;

  /**
   * The server normally times out idle cursors after an inactivity period
   * to prevent excess memory use. Set this option to prevent that.
   */
  noCursorTimeout : Boolean optional;

  /**
   * The number of documents to skip before returning.
   */
  skip : Int32 optional;

  /**
   * The order by which to sort results. Defaults to not sorting.
   */
  sort : Document optional;

}

class GridFSBucket {

  /**
   * Find and return the files collection documents that match @filter.
   */
  Iterable find(Document filter, GridFSFindOptions options=null);

}
</code></pre>
<p>This call will trigger a find() operation on the files collection using the given filter. Drivers returns a sequence of
documents that can be iterated over. Drivers return an empty or null set when there are no matching files collection
documents. As the number of files could be large, drivers SHOULD return a cursor-like iterable type and SHOULD NOT
return a fixed-size array type.</p>
<p><strong>Implementation details:</strong></p>
<p>Drivers SHOULD NOT perform any validation on the filter. If the filter contains fields that do not exist within files
collection documents, then an empty result set will be returned.</p>
<p>Drivers MUST propagate the GridFSFindOptions to the FindOptions passed to the underlying Find operation.</p>
<p>Drivers MUST document how users query files collection documents, including how to query metadata, e.g. using a filter
like { metadata.fieldname : "some_criteria" }.</p>
<h2 id="advanced-api"><a class="header" href="#advanced-api">Advanced API</a></h2>
<h3 id="file-download-by-filename"><a class="header" href="#file-download-by-filename">File Download by Filename</a></h3>
<pre><code class="language-javascript">class GridFSDownloadByNameOptions {

  /**
   * Which revision (documents with the same filename and different uploadDate)
   * of the file to retrieve. Defaults to -1 (the most recent revision).
   *
   * Revision numbers are defined as follows:
   * 0 = the original stored file
   * 1 = the first revision
   * 2 = the second revision
   * etc…
   * -2 = the second most recent revision
   * -1 = the most recent revision
   */
  revision : Int32 optional;

}

class GridFSBucket {

  /** Opens a Stream from which the application can read the contents of the stored file
   * specified by @filename and the revision in @options.
   *
   * Returns a Stream.
   */
  Stream open_download_stream_by_name(string filename, GridFSDownloadByNameOptions options=null);

  /**
   * Downloads the contents of the stored file specified by @filename and by the
   * revision in @options and writes the contents to the @destination Stream.
   */
  void download_to_stream_by_name(string filename, Stream destination,
    GridFSDownloadByNameOptions options=null);

}
</code></pre>
<p>Retrieves a stored file from a GridFS bucket. For languages that have a Stream abstraction, drivers SHOULD use that
Stream abstraction. For languages that do not have a Stream abstraction, drivers MUST create an abstraction that
supports streaming.</p>
<p><strong>Implementation details:</strong></p>
<p>If there is no file with the given filename, or if the requested revision does not exist, drivers MUST raise an error
with a distinct message for each case.</p>
<p>Drivers MUST select the files collection document of the file to-be-returned by running a query on the files collection
for the given filename, sorted by uploadDate (either ascending or descending, depending on the revision requested) and
skipping the appropriate number of documents. For negative revision numbers, the sort is descending and the number of
documents to skip equals (-revision - 1). For non-negative revision numbers, the sort is ascending and the number of
documents to skip equals the revision number.</p>
<p>If a networking error or server error occurs, drivers MUST raise an error.</p>
<h3 id="partial-file-retrieval"><a class="header" href="#partial-file-retrieval">Partial File Retrieval</a></h3>
<p>In the case of open_download_stream, drivers SHOULD support partial file retrieval by allowing the application to read
only part of the stream. If a driver does support reading only part of the stream, it MUST do so using the standard
stream methods of its language for seeking to a position in a stream and reading the desired amount of data from that
position. This is the preferred method of supporting partial file retrieval.</p>
<p>In the case of download_to_stream, drivers are not required to support partial file retrieval. If they choose to do so,
drivers can support this operation by adding "start" and "end" to their supported options for download_to_stream. These
values represent non-negative byte offsets from the beginning of the file. When "start" and "end" are specified, drivers
return the bytes of the file in <code>[start, end)</code>. If "start" and "end" are equal no data is returned.</p>
<p>If either "start" or "end" is invalid, drivers MUST raise an error. These values are considered invalid if they are
negative, greater than the file length, or if "start" is greater than "end".</p>
<p>When performing partial reads, drivers SHOULD use the file"s "chunkSize" to calculate which chunks contain the desired
section and avoid reading unneeded documents from the "chunks" collection.</p>
<h3 id="renaming-stored-files"><a class="header" href="#renaming-stored-files">Renaming stored files</a></h3>
<pre><code class="language-javascript">class GridFSBucket {

  /**
   * Renames the stored file with the specified @id.
   */
  void rename(TFileId id, string new_filename);

}
</code></pre>
<p>Sets the filename field in the stored file"s files collection document to the new filename.</p>
<p><strong>Implementation details:</strong></p>
<p>Drivers construct and execute an update_one command on the files collection using <code>{ _id: @id }</code> as the filter and
<code>{ $set : { filename : "new_filename" } }</code> as the update parameter.</p>
<p>To rename multiple revisions of the same filename, users must retrieve the full list of files collection documents for a
given filename and execute "rename" on each corresponding <code>_id</code>.</p>
<p>If there is no file with the given id, drivers MUST raise an error.</p>
<h3 id="dropping-an-entire-gridfs-bucket"><a class="header" href="#dropping-an-entire-gridfs-bucket">Dropping an entire GridFS bucket</a></h3>
<pre><code class="language-javascript">class GridFSBucket {

  /**
   * Drops the files and chunks collections associated with
   * this bucket.
   */
  void drop();

}
</code></pre>
<p>This method drops the files and chunks collections associated with this GridFS bucket.</p>
<p>Drivers should drop the files collection first, and then the chunks collection.</p>
<h2 id="test-plan-29"><a class="header" href="#test-plan-29">Test Plan</a></h2>
<p>TBD</p>
<h2 id="motivation-for-change-16"><a class="header" href="#motivation-for-change-16">Motivation for Change</a></h2>
<p>The <a href="https://www.mongodb.com/docs/manual/core/gridfs/">existing GridFS documentation</a> is only concerned with the
underlying data model for this feature, and does not specify what basic set of features an implementation of GridFS
should or should not provide. As a result, GridFS is currently implemented across drivers, but with varying APIs,
features, and behavior guarantees. Current implementations also may not conform to the existing documentation.</p>
<p>This spec documents minimal operations required by all drivers offering GridFS support, along with optional features
that drivers may choose to support. This spec is also explicit about what features/behaviors of GridFS are not specified
and should not be supported. Additionally, this spec validates and clarifies the existing data model, deprecating fields
that are undesirable or incorrect.</p>
<h2 id="design-rationale-24"><a class="header" href="#design-rationale-24">Design Rationale</a></h2>
<p>Why is the default chunk size 255 KiB?</p>
<p>On MMAPv1, the server provides documents with extra padding to allow for in-place updates. When the "data" field of a
chunk is limited to 255 KiB, it ensures that the whole chunk document (the chunk data along with an <code>_id</code> and other
information) will fit into a 256 KiB section of memory, making the best use of the provided padding. Users setting
custom chunk sizes are advised not to use round power-of-two values, as the whole chunk document is likely to exceed
that space and demand extra padding from the system. WiredTiger handles its memory differently, and this optimization
does not apply. However, because application code generally won"t know what storage engine will be used in the database,
always avoiding round power-of-two chunk sizes is recommended.</p>
<p>Why can"t I alter documents once they are in the system?</p>
<p>GridFS works with documents stored in multiple collections within MongoDB. Because there is currently no way to
atomically perform operations across collections in MongoDB, there is no way to alter stored files in a way that
prevents race conditions between GridFS clients. Updating GridFS stored files without that server functionality would
involve a data model that could support this type of concurrency, and changing the GridFS data model is outside of the
scope of this spec.</p>
<p>Why provide a "rename" method?</p>
<p>By providing users with a reasonable alternative for renaming a file, we can discourage users from writing directly to
the files collections under GridFS. With this approach we can prevent critical files collection documents fields from
being mistakenly altered.</p>
<p>Why is there no way to perform arbitrary updates on the files collection?</p>
<p>The rename helper defined in this spec allows users to easily rename a stored file. While updating files collection
documents in other, more granular ways might be helpful for some users, validating such updates to ensure that other
files collection document fields remain protected is a complicated task. We leave the decision of how best to provide
this functionality to a future spec.</p>
<p>What is the "md5" field of a files collection document and how was it used?</p>
<p>"md5" holds an MD5 checksum that is computed from the original contents of a user file. Historically, GridFS did not use
acknowledged writes, so this checksum was necessary to ensure that writes went through properly. With acknowledged
writes, the MD5 checksum is still useful to ensure that files in GridFS have not been corrupted. A third party directly
accessing the 'files' and "chunks" collections under GridFS could, inadvertently or maliciously, make changes to
documents that would make them unusable by GridFS. Comparing the MD5 in the files collection document to a re-computed
MD5 allows detecting such errors and corruption. However, drivers now assume that the stored file is not corrupted, and
applications that want to use the MD5 value to check for corruption must do so themselves.</p>
<p>Why store the MD5 checksum instead of creating the hash as-needed?</p>
<p>The MD5 checksum must be computed when a file is initially uploaded to GridFS, as this is the only time we are
guaranteed to have the entire uncorrupted file. Computing it on-the-fly as a file is read from GridFS would ensure that
our reads were successful, but guarantees nothing about the state of the file in the system. A successful check against
the stored MD5 checksum guarantees that the stored file matches the original and no corruption has occurred.</p>
<p>Why are MD5 checksums now deprecated? What should users do instead?</p>
<p>MD5 is prohibited by FIPS 140-2. Operating systems and libraries operating in FIPS mode do not provide the MD5
algorithm. To avoid a broken GridFS feature on such systems, the use of MD5 with GridFS is deprecated, should not be
added to new implementations, and should be removed from existing implementations according to the deprecation policy of
individual drivers. Applications that desire a file digest should implement it outside of GridFS and store it with other
file metadata.</p>
<p>Why do drivers no longer need to call the filemd5 command on upload?</p>
<p>When a chunk is inserted and no error occurs the application can assume that the chunk was correctly inserted. No other
operations that insert or modify data require the driver to double check that the operation succeeded. It can be assumed
that any errors would have been detected by use of the appropriate write concern. Using filemd5 also prevents users from
sharding chunk keys.</p>
<p>What about write concern?</p>
<p>This spec leaves the choice of how to set write concern to driver authors. Implementers may choose to accept write
concern through options on the given methods, to set a configurable write concern on the GridFS object, to enforce a
single write concern for all GridFS operations, or to do something different.</p>
<p>If a user has given GridFS a write concern of 0, should we perform MD5 calculations? (If supported for backwards
compatibility)</p>
<p>Yes, because the checksum is used for detecting future corruption or misuse of GridFS collections.</p>
<p>Is GridFS limited by sharded systems?</p>
<p>For best performance, clients using GridFS on a sharded system should use a shard key that ensures all chunks for a
given stored file are routed to the same shard. Therefore, if the chunks collection is sharded, you should shard on the
files_id. Normally only the chunks collection benefits from sharding, since the files collection is usually small.
Otherwise, there are no limitations to GridFS on sharded systems.</p>
<p>Why is contentType deprecated?</p>
<p>Most fields in the files collection document are directly used by the driver, with the exception of: metadata,
contentType and aliases. All information that is purely for use of the application should be embedded in the 'metadata'
document. Users of GridFS who would like to store a contentType for use in their applications are encouraged to add a
'contentType' field to the "metadata" document instead of using the deprecated top-level "contentType" field.</p>
<p>Why are aliases deprecated?</p>
<p>The "aliases" field of the files collection documents was misleading. It implies that a file in GridFS could be accessed
by alternate names when, in fact, none of the existing implementations offer this functionality. For GridFS
implementations that retrieve stored files by filename or support specifying specific revisions of a stored file, it is
unclear how "aliases" should be interpreted. Users of GridFS who would like to store alternate filenames for use in
their applications are encouraged to add an "aliases" field to the "metadata" document instead of using the deprecated
top-level "aliases" field.</p>
<p>What happened to the put and get methods from earlier drafts?</p>
<p>Upload and download are more idiomatic names that more clearly indicate their purpose. Get and put are often associated
with getting and setting properties of a class, and using them instead of download and upload was confusing.</p>
<p>Why aren't there methods to upload and download byte arrays?</p>
<p>We assume that GridFS files are usually quite large and therefore that the GridFS API must support streaming. Most
languages have easy ways to wrap a stream around a byte array. Drivers are free to add helper methods that directly
support uploading and downloading GridFS files as byte arrays.</p>
<p>Should drivers report an error if a stored file has extra chunks?</p>
<p>The length and the chunkSize fields of the files collection document together imply exactly how many chunks a stored
file should have. If the chunks collection has any extra chunks the stored file is in an inconsistent state. Ideally we
would like to report that as an error, but this is an extremely unlikely state and we don't want to pay a performance
penalty checking for an error that is almost never there. Therefore, drivers MAY ignore extra chunks.</p>
<p>Why have we changed our mind about requiring the file id to be an ObjectId?</p>
<p>This spec originally required the file id for all new GridFS files to be an ObjectId and specified that the driver
itself would be the one to generate the ObjectId when a new file was uploaded. While this sounded like a good idea, it
has since become evident that there are valid use cases for an application to want to generate its own file id, and that
an application wouldn't necessarily want to use ObjectId as the type of the file id. The most common case where an
application would want to use a custom file id is when the chunks collection is to be sharded and the application wants
to use a custom file id that is suitable for sharding. Accordingly, we have relaxed this spec to allow an application to
supply a custom file id (of any type) when uploading a new file.</p>
<p>How can we maintain backward compatibility while supporting custom file ids?</p>
<p>For most methods supporting custom file ids is as simple as relaxing the type of the id parameter from ObjectId to
something more general like object or BSON value (or to a type parameter like <code>&lt;TFileId&gt;</code> in languages that support
generic methods). In a few cases new methods were added to support custom file ids. The original upload_from_stream
method returned an ObjectId, and support for custom file ids is implemented by adding a new method that takes the custom
file id as an additional parameter. Drivers should continue to support the original method if possible to maintain
backward compatibility. This spec does not attempt to completely mandate how each driver should maintain backward
compatibility, as different languages have different approaches and capabilities for maintaining backward compatibility.</p>
<h2 id="backwards-compatibility-25"><a class="header" href="#backwards-compatibility-25">Backwards Compatibility</a></h2>
<p>This spec presents a new API for GridFS systems, which may break existing functionality for some drivers. The following
are suggestions for ways to mitigate these incompatibilities.</p>
<p>File revisions</p>
<p>This document presents a basic API that does not support specifying specific revisions of a stored file, and an advanced
API that does. Drivers MAY choose to implement whichever API is closest to the functionality they now support. Note that
the methods for file insertion are the same whether specifying specific revisions is supported or not.</p>
<p>Method names</p>
<p>If drivers provide methods that conform to the functionality outlined in this document, drivers MAY continue to provide
those methods under their existing names. In this case, drivers SHOULD make it clear in their documentation that these
methods have equivalents defined in the spec under a different name.</p>
<p>ContentType field</p>
<p>Drivers MAY continue to create a "contentType'" field within files collection documents, so that applications depending
on this field continue to work. However, drivers SHOULD make it clear in their documentation that this field is
deprecated, and is not used at all in driver code. Documentation SHOULD encourage users to store contentType in the
"metadata" document instead.</p>
<p>Aliases field</p>
<p>Drivers MAY continue to create an "aliases" field within files collection documents, so that applications depending on
this field continue to work. However, drivers SHOULD make it clear in their documentation that this field is deprecated,
and is not used at all in driver code. Documentation SHOULD encourage users to store aliases in the "metadata" document
instead.</p>
<h2 id="reference-implementation-21"><a class="header" href="#reference-implementation-21">Reference Implementation</a></h2>
<p>TBD</p>
<h2 id="future-work-14"><a class="header" href="#future-work-14">Future work</a></h2>
<p>Changes to the GridFS data model are out-of-scope for this spec, but may be considered for the future.</p>
<p>The ability to alter or append to existing GridFS files has been cited as something that would greatly improve the
system. While this functionality is not in-scope for this spec (see "Why can"t I alter documents once they are in the
system?") it is a potential area of growth for the future.</p>
<h2 id="changelog-39"><a class="header" href="#changelog-39">Changelog</a></h2>
<ul>
<li>2024-02-27: Migrated from reStructuredText to Markdown.</li>
<li>2016-05-10: Support custom file ids</li>
<li>2016-10-07: Drivers SHOULD handle any numeric type of length and chunkSize</li>
<li>2016-10-07: Added ReadConcern to the GridFS spec</li>
<li>2016-10-07: Modified a JSON test that was testing optional behavior</li>
<li>2018-01-31: Deprecated MD5, and specified an option to disable MD5 until removed</li>
<li>2018-07-05: Must not use 'filemd5'</li>
<li>2020-01-17: Added allowDiskUse to GridFSFindOptions</li>
<li>2022-01-19: Require that timeouts be applied per the client-side operations timeout spec</li>
<li>2022-10-05: Remove spec front matter and reformat changelog.</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="stable-api-for-drivers"><a class="header" href="#stable-api-for-drivers">Stable API For Drivers</a></h1>
<ul>
<li>Status: Accepted</li>
<li>Minimum Server Version: N/A</li>
</ul>
<hr />
<h2 id="abstract-38"><a class="header" href="#abstract-38">Abstract</a></h2>
<p>As MongoDB moves toward more frequent releases (a.k.a. continuous delivery), we want to enable users to take advantage
of our rapidly released features, without exposing applications to incompatible server changes due to automatic server
upgrades. A stable API will help accomplish that goal.</p>
<h2 id="meta-38"><a class="header" href="#meta-38">META</a></h2>
<p>The keywords "MUST", "MUST NOT", "REQUIRED", "SHALL", "SHALL NOT", "SHOULD", "SHOULD NOT", "RECOMMENDED", "MAY", and
"OPTIONAL" in this document are to be interpreted as described in <a href="https://www.ietf.org/rfc/rfc2119.txt">RFC 2119</a>.</p>
<p>This document tends to use "SHOULD" more frequently than other specifications, but mainly in the context of providing
guidance on writing test files. This is discussed in more detail in <a href="versioned-api/versioned-api.html#design-rationale">Design Rationale</a>.</p>
<h2 id="specification-36"><a class="header" href="#specification-36">Specification</a></h2>
<h3 id="background"><a class="header" href="#background">Background</a></h3>
<p>When applications interact with MongoDB, both the driver and the server participate in executing operations. Therefore,
when determining application compatibility with MongoDB, both the driver and the server behavior must be taken into
account.</p>
<p>An application can specify the server API version when creating MongoClient. When this is done:</p>
<ul>
<li>The client sends the specified API version to the server, causing the server to behave in a manner compatible with
that API version.</li>
<li>The driver will behave in a manner compatible with a server configured with that API version, regardless of the
server's actual release version.</li>
</ul>
<p>Presently there is no specification for how a driver must behave when a particular server API version is requested, or
what driver operations are subject to API compatibility guarantees. Such requirements may be stipulated in subsequent
specifications.</p>
<p>This specification requires MongoClient to validate that it supports the specified server API version, if any, but does
not define what such support means.</p>
<h3 id="mongoclient-changes-2"><a class="header" href="#mongoclient-changes-2"><code>MongoClient</code> changes</a></h3>
<p><code>MongoClient</code> instances accept a new <code>serverApi</code> option to allow the user to declare an API version:</p>
<pre><code class="language-typescript">class MongoClient {
    MongoClient(... serverApi: ServerApi);
}

enum ServerApiVersion {
    v1 = "1",
}

class ServerApi {
    version: string|ServerApiVersion;
    strict: Optional&lt;Boolean&gt;; // Default false
    deprecationErrors: Optional&lt;Boolean&gt;; // Default false
}
</code></pre>
<p>Drivers SHOULD group the <code>serverApi</code> option with other similar client options like <code>autoEncryptionOpts</code>. Drivers MUST
NOT allow specification of any stable API options via the connection string. See the
<a href="versioned-api/versioned-api.html#design-rationale">Design Rationale</a> for more details.</p>
<h4 id="serverapiversion-enumeration"><a class="header" href="#serverapiversion-enumeration">ServerApiVersion enumeration</a></h4>
<p>This specification and subsequent specifications will define the known API versions. Drivers SHOULD define an
enumeration containing the known API versions, using the version identifiers given. Drivers MAY deviate from the version
identifiers used in this and subsequent specifications if doing so is necessary given the driver's programming
language's constraints. Drivers MUST ensure that adding new API versions to this enumeration does not result in backward
compatibility breaks in non-major releases. This can be the case in languages that allow exhaustive <code>switch</code> statements
(e.g. Swift).</p>
<p>Drivers for languages that don't have enums (e.g. PHP) MUST expose the version as a string, but SHOULD offer constants
to allow for IDE features such as code completion. In these cases, the driver MUST validate (e.g. when the application
provides a version string to the <code>ServerApi</code> class) that the version string is valid and trigger a client-side error if
an unknown API version was used.</p>
<h4 id="serverapi-class"><a class="header" href="#serverapi-class">ServerApi class</a></h4>
<p>The <code>ServerApi</code> class stores an API version, along with flags that decide whether or not unknown or deprecated commands
in the specified API version trigger a server-side error. A <code>version</code> MUST be specified when declaring an API version,
while the <code>strict</code> and <code>deprecationErrors</code> options are both optional. The <code>ServerApi</code> class is considered immutable;
changes to the declared API version MUST be prohibited.</p>
<h4 id="declared-version-inheritance"><a class="header" href="#declared-version-inheritance">Declared Version Inheritance</a></h4>
<p>Drivers MUST ensure that users cannot override the API version declared in the <code>MongoClient</code> instance. This includes the
<code>MongoDatabase</code> and <code>MongoCollection</code> classes, as well as any operations in these classes. See the rationale for more
details.</p>
<h3 id="sending-declared-api-version-to-the-server"><a class="header" href="#sending-declared-api-version-to-the-server">Sending Declared API Version to the Server</a></h3>
<p>The declared API version MUST be sent to the server as part of every command request, with the exception of the cases
listed below. Drivers MUST NOT use a server's reported <code>maxWireVersion</code> to decide whether it supports the stable API.
The server will reply with an error if the declared API version is not supported, or if the command does not support API
versioning options. If the user does not declare an API version, the driver MUST NOT send any API versioning options to
the server.</p>
<p>If an API version is declared then the driver MUST use <code>OP_MSG</code> for all messages, including the initial handshake.</p>
<h4 id="command-syntax"><a class="header" href="#command-syntax">Command Syntax</a></h4>
<p>The options from the declared API version are mapped to the following command options:</p>
<div class="table-wrapper"><table><thead><tr><th><strong>ServerApi field</strong></th><th><strong>Command option</strong></th></tr></thead><tbody>
<tr><td><code>version</code></td><td><code>apiVersion</code></td></tr>
<tr><td><code>strict</code></td><td><code>apiStrict</code></td></tr>
<tr><td><code>deprecationErrors</code></td><td><code>apiDeprecationErrors</code></td></tr>
</tbody></table>
</div>
<p>If an API version was declared, drivers MUST add the <code>apiVersion</code> option to every command that is sent to a server.
Drivers MUST add the <code>apiStrict</code> and <code>apiDeprecationErrors</code> options if they were specified by the user, even when the
specified value is equal to the server default. Drivers MUST NOT add any API versioning options if the user did not
specify them. This includes the <code>getMore</code> command as well as all commands that are part of a transaction. A previous
version of this specification excluded those commands, but that has since changed in the server.</p>
<h4 id="handshake-behavior"><a class="header" href="#handshake-behavior">Handshake behavior</a></h4>
<p>If an API version was declared, drivers MUST NOT use the legacy hello command during the initial handshake or
afterwards. Instead, drivers MUST use the <code>hello</code> command exclusively and use the <code>OP_MSG</code> protocol. If the server does
not support <code>hello</code>, the server description MUST reflect this with an <code>Unknown</code> server type.</p>
<h4 id="cursors-2"><a class="header" href="#cursors-2">Cursors</a></h4>
<p>For <code>getMore</code>, drivers MUST submit API parameters. If the values given do not match the API parameters given in the
cursor-initiating command, the server will reply with an error.</p>
<h4 id="transactions-1"><a class="header" href="#transactions-1">Transactions</a></h4>
<p>When running commands as part of a transaction, drivers MUST send API parameters with all commands that are part of a
transaction, including <code>commitTransaction</code> and <code>abortTransaction</code>. If the API parameters for a command in a transaction
do not match those of the transaction-starting command, the server will reply with an error.</p>
<h4 id="generic-command-helper"><a class="header" href="#generic-command-helper">Generic command helper</a></h4>
<p>Drivers that offer a generic command helper (e.g. <code>command()</code> or <code>runCommand()</code>) MUST NOT inspect the command document
to detect API versioning options. As with all other commands, drivers MUST inherit the API version from the client.
Specifying API versioning options in the command document and declaring an API version on the client is not supported.
Drivers MUST document that the behaviour of the command helper is undefined in this case.</p>
<h2 id="design-rationale-25"><a class="header" href="#design-rationale-25">Design Rationale</a></h2>
<h3 id="no-uri-options"><a class="header" href="#no-uri-options">No URI Options</a></h3>
<p>Since changing the API version can cause the application to behave differently, drivers MUST NOT allow users to change
the declared API version without deploying code changes. This ensures that users don't copy a connection string with a
declared API version that may be different from what their application expects. A URI option can be added later if we
realise our users need it, while the opposite is not easily accomplished.</p>
<h3 id="dont-allow-overriding-the-declared-api-version"><a class="header" href="#dont-allow-overriding-the-declared-api-version">Don't Allow Overriding the Declared API Version</a></h3>
<p>While users are used to overriding options like read preference, read concern, and write concern in <code>MongoDatabase</code> and
<code>MongoCollection</code> objects, or on an operation level, we explicitly decided against this for the declared API version.
With a single API version available to start, we can't anticipate what use cases users may have to override the API
version. Not including this feature at the beginning allows us to gather feedback on use cases and add the features
users are looking for. On the other hand, adding the ability to override the declared API version can't be undone until
a future major release, which is almost impossible to accomplish across all drivers.</p>
<h3 id="generic-command-helper-behaviour"><a class="header" href="#generic-command-helper-behaviour">Generic Command Helper Behaviour</a></h3>
<p>The runCommand helper is a way for the user to run a native command with the driver doing little to no inspection in the
command. This allows users to run arbitrary commands that may not have helpers in the driver, or to pass options that
are not supported by the driver version they are currently using. Commands run using this helper do not inherit any
<code>readConcern</code> or <code>writeConcern</code> options that may have been set on the <code>MongoClient</code> or <code>MongoDatabase</code> objects.</p>
<p>However, the declared API version is a different case. We are introducing this feature to give users a certain peace of
mind when upgrading driver or server versions, by ensuring that their code will continue to show the same behaviour
they've gotten used to. This includes all commands run using the generic command helper. Thus, the helper will inherit
the API version declared on the client.</p>
<h3 id="hardcode-supported-versions-in-drivers"><a class="header" href="#hardcode-supported-versions-in-drivers">Hardcode supported versions in drivers</a></h3>
<p>Since a new API version might require driver changes (e.g. to account for removed commands), we don't yet know what
changes drivers must make for a future version. Until we do, we must prevent users from choosing any unknown API
version.</p>
<h2 id="backward-compatibility"><a class="header" href="#backward-compatibility">Backward Compatibility</a></h2>
<p>Driver changes are fully backward compatible. Not declaring an API version when creating a client may cause an error if
the server was started with the <code>requireApiVersion</code> option enabled, but this is outside of driver control.</p>
<h2 id="future-work-15"><a class="header" href="#future-work-15">Future Work</a></h2>
<h3 id="overriding-the-declared-api-version"><a class="header" href="#overriding-the-declared-api-version">Overriding the Declared API Version</a></h3>
<p>In the future, we may want to allow users to override the declared API version on a <code>MongoDatabase</code>, <code>MongoCollection</code>,
or individual operation level. However, this is not necessary until there is a different API version and we have data on
why and how users would want to override the declared API version.</p>
<h3 id="stable-crud-api"><a class="header" href="#stable-crud-api">Stable CRUD API</a></h3>
<p>Drivers may also want to provide specialized <code>MongoClient</code>, <code>MongoDatabase</code>, and <code>MongoCollection</code> classes to only
include features that are part of the stable API. This is not covered in this specification.</p>
<h2 id="changelog-40"><a class="header" href="#changelog-40">Changelog</a></h2>
<ul>
<li>
<p>2024-09-10: Migrated from reStructuredText to Markdown.</p>
</li>
<li>
<p>2022-10-05: Remove spec front matter and reformat changelog.</p>
</li>
<li>
<p>2022-02-24: Rename Versioned API to Stable API</p>
</li>
<li>
<p>2022-01-14: Require <code>OP_MSG</code> for all messages including the initial step of<br />
the handshake when using stable API.</p>
</li>
<li>
<p>2021-05-05: Require sending stable API parameters with <code>getMore</code> and<br />
transaction-continuing commands.</p>
</li>
<li>
<p>2021-04-20: Require using <code>hello</code> when using the stable API.</p>
</li>
<li>
<p>2021-04-10: Replaced usages of <code>acceptAPIVersion2</code> with <code>acceptApiVersion2</code>.</p>
</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="client-side-encryption-1"><a class="header" href="#client-side-encryption-1">Client Side Encryption</a></h1>
<ul>
<li>Status: Accepted</li>
<li>Minimum Server Version: 4.2 (CSFLE), 6.0 (Queryable Encryption)</li>
<li>Version: 1.14.0</li>
</ul>
<hr />
<h2 id="abstract-39"><a class="header" href="#abstract-39">Abstract</a></h2>
<p>MongoDB 4.2 introduced support for client side encryption, guaranteeing that sensitive data can only be encrypted and
decrypted with access to both MongoDB and a separate key management provider (supporting AWS, Azure, GCP, a local
provider, and KMIP). Once enabled, data can be seamlessly encrypted and decrypted with minimal application code changes.
6.0 introduced the next generation of client side encryption based on a Structured Encryption framework which allows
expressive encrypted search operations. This spec covers both capabilities - 1st generation, "Client Side Field Level
Encryption" and generation 2, "Queryable Encryption" - as the associated core cryptographic library and supporting
drivers share a common codebase.</p>
<h2 id="meta-39"><a class="header" href="#meta-39">META</a></h2>
<p>The keywords "MUST", "MUST NOT", "REQUIRED", "SHALL", "SHALL NOT", "SHOULD", "SHOULD NOT", "RECOMMENDED", "MAY", and
"OPTIONAL" in this document are to be interpreted as described in <a href="https://www.ietf.org/rfc/rfc2119.txt">RFC 2119</a>.</p>
<h2 id="terms-26"><a class="header" href="#terms-26">Terms</a></h2>
<p><strong>encrypted MongoClient</strong></p>
<p>A MongoClient with client side encryption enabled.</p>
<p><strong>data key</strong></p>
<p>A key used to encrypt and decrypt BSON values. Data keys are encrypted with a key management service (e.g. AWS KMS) and
stored within a document in the MongoDB key vault collection (see
<a href="client-side-encryption/client-side-encryption.html#key-vault-collection-schema-for-data-keys">Key vault collection schema for data keys</a> for a description of the data
key document). Therefore, a client needs access to both MongoDB and the external KMS service to utilize a data key.</p>
<p><strong>MongoDB key vault collection</strong></p>
<p>A MongoDB collection designated to contain data keys. This can either be co-located with the data-bearing cluster, or in
a separate external MongoDB cluster.</p>
<p><strong>Key Management Service (KMS)</strong></p>
<p>An external service providing fixed-size encryption/decryption. Only data keys are encrypted and decrypted with KMS.</p>
<p><strong>KMS providers</strong></p>
<blockquote>
<p>A map of KMS providers to credentials. Configured client-side. Example:</p>
<pre><code class="language-python">kms_providers = {
   "aws": {
      "accessKeyId": AWS_KEYID,
      "secretAccessKey": AWS_SECRET,
   },
   "local": {
      "key": LOCAL_KEK
   },
}
</code></pre>
</blockquote>
<p><strong>KMS provider</strong></p>
<p>A configured KMS. Identified by a key in the KMS providers map. The key has the form "<KMS provider type>" or
"<KMS provider type>:<KMS
provider name>". Examples: "aws" or "aws:myname". In <a href="client-side-encryption/client-side-encryption.html#libmongocrypt">libmongocrypt</a>, the key
is referred to as the KMS ID.</p>
<p><strong>KMS provider type</strong></p>
<p>The type of backing KMS. Identified by the string: "aws", "azure", "gcp", "kmip", or "local".</p>
<p><strong>KMS provider name</strong></p>
<p>An optional name to identify a KMS provider. Enables configuring multiple KMS providers with the same KMS provider type
(e.g. "aws:name1" and "aws:name2" can refer to different AWS accounts).</p>
<p><strong>Customer Master Key (CMK)</strong></p>
<p>The underlying key AWS KMS uses to encrypt and decrypt. See
<a href="https://docs.aws.amazon.com/kms/latest/developerguide/concepts.html#master_keys">AWS Key Management Service Concepts</a>.</p>
<p><strong>schema</strong></p>
<p>A MongoDB JSON Schema (either supplied by the server or client-side) which may include metadata about encrypted fields.
This is a JSON Schema based on draft 4 of the JSON Schema specification,
<a href="https://www.mongodb.com/docs/manual/reference/operator/query/jsonSchema/">as documented in the MongoDB manual.</a>.</p>
<p><strong><a href="client-side-encryption/client-side-encryption.html#libmongocrypt">libmongocrypt</a></strong></p>
<p>A library, written in C, that coordinates communication, does encryption/decryption, caches key and schemas.
<a href="https://github.com/mongodb/libmongocrypt">Located here</a>.</p>
<p><strong><a href="client-side-encryption/client-side-encryption.html#mongocryptd">mongocryptd</a></strong></p>
<p>A local process the driver communicates with to determine how to encrypt values in a command.</p>
<p><strong><a href="client-side-encryption/client-side-encryption.html#crypt_shared">crypt_shared</a></strong></p>
<p>This term, spelled in all-lowercase with an underscore, refers to the client-side field-level-encryption dynamic library
provided as part of a MongoDB Enterprise distribution. It replaces <a href="client-side-encryption/client-side-encryption.html#mongocryptd">mongocryptd</a> as the method of
<a href="client-side-encryption/../bson-binary-encrypted/binary-encrypted.html#intent-to-encrypt">marking-up a database command for encryption</a>.</p>
<p>See also:</p>
<blockquote>
<ul>
<li><a href="client-side-encryption/client-side-encryption.html#crypt_shared">Introduction on crypt_shared</a></li>
<li><a href="client-side-encryption/client-side-encryption.html#enabling-crypt_shared">Enabling crypt_shared</a></li>
</ul>
</blockquote>
<p><strong>ciphertext</strong></p>
<p>One of the data formats of <a href="client-side-encryption/../bson-binary-encrypted/binary-encrypted.html">BSON binary encrypted</a>, representing an
encoded BSON document containing encrypted ciphertext and metadata.</p>
<p><strong>FLE</strong></p>
<p>FLE is the first version of Client-Side Field Level Encryption. FLE is almost entirely client-side with the exception of
server-side JSON schema.</p>
<p><strong>Queryable Encryption</strong></p>
<p>Queryable Encryption the second version of Client-Side Field Level Encryption. Data is encrypted client-side. Queryable
Encryption supports indexed encrypted fields, which are further processed server-side.</p>
<p><strong>In-Use Encryption</strong></p>
<p>Is an umbrella term describing the both FLE and Queryable Encryption.</p>
<p><strong>encryptedFields</strong></p>
<p>A BSON document describing the Queryable Encryption encrypted fields. This is analogous to the JSON Schema in FLE. The
following is an example encryptedFields in extended canonical JSON:</p>
<pre><code class="language-javascript">{
    "escCollection": "enxcol_.CollectionName.esc",
    "ecocCollection": "enxcol_.CollectionName.ecoc",
    "fields": [
        {
            "path": "firstName",
            "keyId": { "$binary": { "subType": "04", "base64": "AAAAAAAAAAAAAAAAAAAAAA==" }},
            "bsonType": "string",
            "queries": {"queryType": "equality"}
        },
        {
            "path": "ssn",
            "keyId": { "$binary": { "subType": "04", "base64": "BBBBBBBBBBBBBBBBBBBBBB==" }},
            "bsonType": "string"
        }
    ]
}
</code></pre>
<p>The acronyms within <code>encryptedFields</code> are defined as follows:</p>
<ul>
<li>ECOC: Encrypted Compaction Collection</li>
<li>ESC: Encrypted State Collection</li>
</ul>
<h2 id="introduction"><a class="header" href="#introduction">Introduction</a></h2>
<p>Client side encryption enables users to specify what fields in a collection must be encrypted, and the driver
automatically encrypts commands and decrypts results. Automatic encryption is enterprise only. But users can manually
encrypt and decrypt with a new ClientEncryption object.</p>
<p>Client side encryption requires MongoDB 4.2 compatible drivers, and is only supported against 4.2 or higher servers. See
<a href="client-side-encryption/client-side-encryption.html#why-is-a-42-server-required">Why is a 4.2 server required?</a>.</p>
<p>The following shows basic usage of the new API.</p>
<pre><code class="language-python"># The schema map identifies fields on collections that must undergo encryption.

schema_map = open("./schemas.json", "r").read()

# AWS KMS is used to decrypt data keys stored in the key vault collection.

aws_creds = open("./aws_credentials.json", "r").read()

# A client is configured for automatic encryption and decryption by passing
# AutoEncryptionOpts. Automatic encryption is an enterprise only feature.

opts = AutoEncryptionOpts(
    kms_providers={"aws": aws_creds},
    key_vault_namespace="db.datakeys",
    schema_map=schema_map)

db = MongoClient(auto_encryption_opts=opts).db

# Commands are encrypted, as determined by the JSON Schema from the schema_map.
db.coll.insert_one({"ssn": "457-55-5462"})

# Replies are decrypted.
print(db.coll.find_one()) # { "ssn": "457-55-5462" } but stored and transported as ciphertext.

# A ClientEncryption object is used for explicit encryption, decryption, and creating data keys.
opts = ClientEncryptionOpts(kms_providers=kms, key_vault_namespace="db.datakeys")
clientencryption = ClientEncryption(client, opts)

# Use a ClientEncryption to create new data keys.
# The master key identifies the CMK on AWS KMS to use for encrypting the data key.
master_key = open("./aws_masterkey.json", "r").read()
opts = DataKeyOpts (master_key=master_key)
created_key_id = clientencryption.create_data_key("aws", opts)

# Use a ClientEncryption to explicitly encrypt and decrypt.
opts = EncryptOpts(key_id=created_key_id,
    algorithm="AEAD_AES_256_CBC_HMAC_SHA_512-Random")
encrypted = clientencryption.encrypt("secret text", opts)
decrypted = clientencryption.decrypt(encrypted)
</code></pre>
<p>There are many moving parts to client side encryption with lots of similar sounding terms. Before proceeding to
implement the specification, the following background should provide some context.</p>
<p>The driver interacts with multiple components to implement client side encryption.</p>
<p><img src="client-side-encryption/includes/components.png" alt="image" /></p>
<p>The driver communicates with…</p>
<ul>
<li><strong>MongoDB cluster</strong> to get remote JSON Schemas.</li>
<li><strong>MongoDB key vault collection</strong> to get encrypted data keys and create new data keys.</li>
<li><strong>A KMS Provider</strong> to decrypt fetched data keys and encrypt new data keys.</li>
<li><strong>mongocryptd</strong> to ask what values in BSON commands must be encrypted (unless <a href="client-side-encryption/client-side-encryption.html#crypt_shared">crypt_shared</a> is in
use).</li>
</ul>
<p>The MongoDB key vault may be the same as the MongoDB cluster. Users may choose to have data key stored on a separate
MongoDB cluster, or co-locate with their data.</p>
<h3 id="mongodb-key-vault-collection"><a class="header" href="#mongodb-key-vault-collection">MongoDB Key Vault collection</a></h3>
<p>The key vault collection is a special MongoDB collection containing key documents. See the appendix section
<a href="client-side-encryption/client-side-encryption.html#key-vault-collection-schema-for-data-keys">Key vault collection schema for data keys</a> for a description of the
documents.</p>
<p>The key material in the key vault collection is encrypted with a separate KMS service. Therefore, encryption and
decryption requires access to a MongoDB cluster and the KMS service.</p>
<h3 id="kms-provider"><a class="header" href="#kms-provider">KMS Provider</a></h3>
<p>A KMS provider (AWS KMS, Azure Key Vault, GCP KMS, the local provider, or KMIP) is used to decrypt data keys after
fetching from the MongoDB Key Vault, and encrypt newly created data keys. Refer to <a href="client-side-encryption/client-side-encryption.html#kmsproviders">KMSProviders</a> for the
shape of the KMS provider options.</p>
<h3 id="mongocryptd"><a class="header" href="#mongocryptd">mongocryptd</a></h3>
<p><code>mongocryptd</code> is a singleton local process needed for auto-encryption when no <a href="client-side-encryption/client-side-encryption.html#crypt_shared">crypt_shared</a> library is
used. It speaks the MongoDB wire protocol and the driver uses <a href="client-side-encryption/client-side-encryption.html#mongocryptd">mongocryptd</a> by connecting with a
MongoClient. By default, if <a href="client-side-encryption/client-side-encryption.html#crypt_shared">crypt_shared</a> is unavailable, the driver should attempt to automatically
spawn <a href="client-side-encryption/client-side-encryption.html#mongocryptd">mongocryptd</a>. If the MongoClient is configured with <code>extraOptions.mongocryptdBypassSpawn</code> set to
<code>true</code>, OR <code>bypassAutoEncryption</code> is set to <code>true</code>, OR <code>bypassQueryAnalysis</code> is set to <code>true</code> then the driver will not
attempt to spawn <a href="client-side-encryption/client-side-encryption.html#mongocryptd">mongocryptd</a>.</p>
<p>The <a href="client-side-encryption/client-side-encryption.html#mongocryptd">mongocryptd</a> process is responsible for self terminating after idling for a time period. If
<a href="client-side-encryption/client-side-encryption.html#extraoptions.cryptsharedlibrequired">extraOptions.cryptSharedLibRequired</a> is set to <code>true</code>, the driver will not
connect to <a href="client-side-encryption/client-side-encryption.html#mongocryptd">mongocryptd</a> and instead rely on <a href="client-side-encryption/client-side-encryption.html#crypt_shared">crypt_shared</a> being available.</p>
<h3 id="crypt_shared"><a class="header" href="#crypt_shared">crypt_shared</a></h3>
<p><a href="client-side-encryption/client-side-encryption.html#crypt_shared">crypt_shared</a> is a dynamically-loaded C++ library providing query analysis for auto-encryption. It
replaces <a href="client-side-encryption/client-side-encryption.html#mongocryptd">mongocryptd</a> for performing query analysis to -
<a href="client-side-encryption/../bson-binary-encrypted/binary-encrypted.html#intent-to-encrypt">mark-up sensitive fields within a command</a>.</p>
<p>Drivers are not required to load and interact with <a href="client-side-encryption/client-side-encryption.html#crypt_shared">crypt_shared</a> directly. Instead, they inform
<a href="client-side-encryption/client-side-encryption.html#libmongocrypt">libmongocrypt</a> where to find <a href="client-side-encryption/client-side-encryption.html#crypt_shared">crypt_shared</a> and <a href="client-side-encryption/client-side-encryption.html#libmongocrypt">libmongocrypt</a> will
handle <a href="client-side-encryption/client-side-encryption.html#crypt_shared">crypt_shared</a> communication automatically.</p>
<p>See also: <a href="client-side-encryption/client-side-encryption.html#enabling-crypt_shared">Enabling crypt_shared</a> for information on using enabling the
<a href="client-side-encryption/client-side-encryption.html#crypt_shared">crypt_shared</a> library.</p>
<h3 id="libmongocrypt"><a class="header" href="#libmongocrypt">libmongocrypt</a></h3>
<p>libmongocrypt is a C library providing crypto and coordination with external components.
<a href="https://github.com/mongodb/libmongocrypt">Located here</a>.</p>
<p><strong>libmongocrypt is responsible for…</strong></p>
<ul>
<li>orchestrating an internal state machine.</li>
<li>asking the driver to perform I/O, then handling the responses.
<ul>
<li>includes constructing KMS HTTP requests and parsing KMS responses.</li>
</ul>
</li>
<li>doing encryption and decryption.</li>
<li>caching data keys.</li>
<li>caching results of listCollections.</li>
<li>creating key material.</li>
</ul>
<p><strong>The driver is responsible for…</strong></p>
<ul>
<li>performing all I/O needed at every state:
<ul>
<li>speaking to <a href="client-side-encryption/client-side-encryption.html#mongocryptd">mongocryptd</a> to mark commands (unless <a href="client-side-encryption/client-side-encryption.html#crypt_shared">crypt_shared</a> is used).</li>
<li>fetching encrypted data keys from key vault collection (mongod).</li>
<li>running listCollections on mongod.</li>
<li>decrypting encrypted data keys with KMS over TLS.</li>
</ul>
</li>
<li>doing I/O asynchronously as needed.</li>
</ul>
<p>See <a href="client-side-encryption/client-side-encryption.html#why-require-including-a-c-library">Why require including a C library?</a></p>
<h2 id="user-facing-api"><a class="header" href="#user-facing-api">User facing API</a></h2>
<p>Drivers MUST NOT preclude future options from being added to any of the new interfaces.</p>
<p>Drivers MAY represent the options types in a way that is idiomatic to the driver or language. E.g. options MAY be a BSON
document or dictionary type. The driver MAY forego validating options and instead defer validation to the underlying
implementation.</p>
<p>Drivers MAY deviate the spelling of option names to conform to their language's naming conventions and implement options
in an idiomatic way (e.g. keyword arguments, builder classes, etc.).</p>
<p>Drivers MAY use a native UUID type in place of a parameter or return type specified as a BSON binary with subtype 0x04
as described in <a href="client-side-encryption/../bson-binary-uuid/uuid.html">Handling of Native UUID Types</a>.</p>
<h3 id="mongoclient-changes-3"><a class="header" href="#mongoclient-changes-3">MongoClient Changes</a></h3>
<p><span id="MongoClient"></span></p>
<pre><code class="language-typescript">class MongoClient {
   MongoClient(... autoEncryptionOpts: AutoEncryptionOpts);

   // Implementation details.
   private mongocrypt_t libmongocrypt_handle; // Handle to libmongocrypt.
   private Optional&lt;MongoClient&gt; mongocryptd_client; // Client to mongocryptd.
   private MongoClient keyvault_client; // Client used to run find on the key vault collection. This is either an external MongoClient, the parent MongoClient, or internal_client.
   private MongoClient metadata_client; // Client used to run listCollections. This is either the parent MongoClient or internal_client.
   private Optional&lt;MongoClient&gt; internal_client; // An internal MongoClient. Created if no external keyVaultClient was set, or if a metadataClient is needed

   // Exposition-only, used for caching automatic Azure credentials. The cached credentials may be globally cached.
   private cachedAzureAccessToken?: AzureAccessToken;
   private azureAccessTokenExpireTime?: PointInTime;
}
</code></pre>
<p><span id="AutoEncryptionOpts"></span></p>
<pre><code class="language-typescript">class AutoEncryptionOpts {
   keyVaultClient: Optional&lt;MongoClient&gt;;
   keyVaultNamespace: String;
   kmsProviders: KMSProviders;
   schemaMap: Optional&lt;Map&lt;String, Document&gt;&gt;; // Maps namespace to a local schema
   bypassAutoEncryption: Optional&lt;Boolean&gt;; // Default false.
   extraOptions: Optional&lt;Map&lt;String, Value&gt;&gt;;
   tlsOptions?: KMSProvidersTLSOptions; // Maps KMS provider to TLS options.
   encryptedFieldsMap: Optional&lt;Map&lt;String, Document&gt;&gt;; // Maps namespace to encryptedFields.
   // bypassQueryAnalysis disables automatic analysis of outgoing commands.
   // Set bypassQueryAnalysis to true to use explicit encryption on indexed fields
   // without the MongoDB Enterprise Advanced licensed crypt_shared library.
   bypassQueryAnalysis: Optional&lt;Boolean&gt;; // Default false.
}
</code></pre>
<p>A MongoClient can be configured to automatically encrypt collection commands and decrypt results.</p>
<p>Drivers MUST document that auto encryption is an enterprise-only feature and that auto encryption only occurs on
collection level operations by including the following in the driver documentation for AutoEncryptionOpts:</p>
<blockquote>
<p>Automatic encryption is an enterprise only feature that only applies to operations on a collection. Automatic
encryption is not supported for operations on a database or view, and operations that are not bypassed will result in
error (see <a href="client-side-encryption/client-side-encryption.html#libmongocrypt-auto-encryption-allow-list">libmongocrypt: Auto Encryption Allow-List</a>). To bypass
automatic encryption for all operations, set bypassAutoEncryption=true in AutoEncryptionOpts.</p>
</blockquote>
<p>Explicit encryption/decryption and automatic decryption is a community feature. A MongoClient configured with
bypassAutoEncryption=true will still automatically decrypt.</p>
<p>Drivers MUST document that auto encryption requires the authenticated user to have the listCollections privilege action
by including the following in the driver documentation for MongoClient:</p>
<blockquote>
<p>Automatic encryption requires the authenticated user to have the
<a href="https://www.mongodb.com/docs/manual/reference/command/listCollections/#dbcmd.listCollections">listCollections privilege action</a>.</p>
</blockquote>
<p>See
<a href="client-side-encryption/client-side-encryption.html#why-is-client-side-encryption-configured-on-a-mongoclient">Why is client side encryption configured on a MongoClient?</a></p>
<h4 id="keyvaultnamespace"><a class="header" href="#keyvaultnamespace">keyVaultNamespace</a></h4>
<p>The key vault collection namespace refers to a collection that contains all data keys used for encryption and decryption
(aka the key vault collection). Data keys are stored as documents in a special MongoDB collection. Data keys are
protected with encryption by a KMS provider (AWS KMS, Azure key vault, GCP KMS, a local master key, or KMIP).</p>
<h4 id="keyvaultclient"><a class="header" href="#keyvaultclient">keyVaultClient</a></h4>
<p>The key vault collection is assumed to reside on the same MongoDB cluster as indicated by the connecting URI. But the
optional keyVaultClient can be used to route data key queries to a separate MongoDB cluster.</p>
<p>If a <code>keyVaultClient</code> is not passed, and the parent <code>MongoClient</code> is configured with a limited <code>maxPoolSize</code>, the
<code>keyVaultClient</code> is set to an internal <code>MongoClient</code>. See
<a href="client-side-encryption/client-side-encryption.html#keyvaultclient-metadataclient-and-the-internal-mongoclient">keyVaultClient, metadataClient, and the internal MongoClient</a>
for configuration behavior.</p>
<p>See
<a href="client-side-encryption/client-side-encryption.html#whats-the-deal-with-metadataclient-keyvaultclient-and-the-internal-client">What's the deal with metadataClient, keyVaultClient, and the internal client?</a></p>
<h4 id="keyvaultclient-metadataclient-and-the-internal-mongoclient"><a class="header" href="#keyvaultclient-metadataclient-and-the-internal-mongoclient">keyVaultClient, metadataClient, and the internal MongoClient</a></h4>
<p>The following pseudo-code describes the configuration behavior for the three <code>MongoClient</code> objects:</p>
<pre><code>def getOrCreateInternalClient (client, clientOpts):
   if client.internalClient != None:
      return client.internalClient
   internalClientOpts = copy(clientOpts)
   internalClientOpts.autoEncryptionOpts = None
   internalClientOpts.minPoolSize = 0
   client.internalClient = MongoClient (internalClientOpts)
   return client.internalClient

def configureAutoEncryptionClients (client, clientOpts):
   if clientOpts.autoEncryptionOpts.keyVaultClient != None:
      client.keyVaultClient = clientOpts.autoEncryptionOpts.keyVaultClient
   elif clientOpts.maxPoolSize == 0:
      client.keyVaultClient = client
   else:
      client.keyVaultClient = getOrCreateInternalClient (client, clientOpts)

   if clientOpts.autoEncryptionOpts.bypassAutomaticEncryption:
      client.metadataClient = None
   elif clientOpts.maxPoolSize == 0:
      client.metadataClient = client
   else:
      client.metadataClient = getOrCreateInternalClient (client, clientOpts)
</code></pre>
<p>Configuring the internal <code>MongoClient</code> MUST match the parent <code>MongoClient</code>, except <code>minPoolSize</code> is set to <code>0</code> and
<code>AutoEncryptionOpts</code> is omitted. This includes copying the options and host information from the URI, and other non-URI
configuration (monitoring callbacks, stable API, etc.).</p>
<p>Drivers MUST document that an additional <code>MongoClient</code> may be created, using the following as a template:</p>
<blockquote>
<p>If a <code>MongoClient</code> with a limited connection pool size (i.e a non-zero <code>maxPoolSize</code>) is configured with
<code>AutoEncryptionOpts</code>, a separate internal <code>MongoClient</code> is created if any of the following are true:</p>
<ul>
<li><code>AutoEncryptionOpts.keyVaultClient</code> is not passed.</li>
<li><code>AutoEncryptionOpts.bypassAutomaticEncryption</code> is <code>false</code>.</li>
</ul>
<p>If an internal <code>MongoClient</code> is created, it is configured with the same options as the parent <code>MongoClient</code> except
<code>minPoolSize</code> is set to <code>0</code> and <code>AutoEncryptionOpts</code> is omitted.</p>
</blockquote>
<p>See
<a href="client-side-encryption/client-side-encryption.html#whats-the-deal-with-metadataclient-keyvaultclient-and-the-internal-client">What's the deal with metadataClient, keyVaultClient, and the internal client?</a></p>
<p><span id="GCPKMSOptions"></span> <span id="AWSKMSOptions"></span> <span id="KMSProvider"></span>
<span id="KMSProviders"></span> <span id="AzureAccessToken"></span> <span id="kmsproviders"></span></p>
<h4 id="kmsproviders"><a class="header" href="#kmsproviders">kmsProviders</a></h4>
<p>The <code>kmsProviders</code> property may be specified on <a href="client-side-encryption/client-side-encryption.html#ClientEncryptionOpts">ClientEncryptionOpts</a> or
<a href="client-side-encryption/client-side-encryption.html#AutoEncryptionOpts">AutoEncryptionOpts</a>. Multiple KMS providers may be specified, each using a specific property on
the <a href="client-side-encryption/client-side-encryption.html#kmsproviders">KMSProviders</a> object. The options differ for each KMS provider type. The "local" KMS provider type
is configured with master key material. The external providers are configured with credentials to authenticate.</p>
<p>Throughout this document, the KMS provider is annotated as - <code>KMSProvider</code>, but this name is for <em>exposition only</em>:
drivers MUST accept arbitrary strings at runtime for forward-compatibility.</p>
<pre><code class="language-typescript">interface KMSProviders {
   aws?: AWSKMSOptions | { /* Empty (See "Automatic Credentials") */ };
   azure?: AzureKMSOptions | { /* Empty (See "Automatic Credentials") */ };
   gcp?: GCPKMSOptions | { /* Empty (See "Automatic Credentials") */ };
   local?: LocalKMSOptions;
   kmip?: KMIPKMSOptions;

   // KMS providers may be specified with an optional name suffix separated by a colon.
   // Named KMS providers do not support "Automatic Credentials".
   // Note: the named KMS providers strings below are not valid Typescript regexes. They are intended for exposition only.
   "^aws:[a-zA-Z0-9_]+$"?: AWSKMSOptions;
   "^azure:[a-zA-Z0-9_]+$"?: AzureKMSOptions;
   "^gcp:[a-zA-Z0-9_]+$"?: GCPKMSOptions;
   "^local:[a-zA-Z0-9_]+$"?: LocalKMSOptions;
   "^kmip:[a-zA-Z0-9_]+$"?: KMIPKMSOptions;
};

// KMSProvider is a string identifying a KMS provider. Note: For forward
// compatibility, any string should be accepted.
type KMSProvider = string;

interface AWSKMSOptions {
   accessKeyId: string;
   secretAccessKey: string;
   sessionToken?: string; // Required for temporary AWS credentials.
};

type AzureKMSOptions = AzureKMSCredentials | AzureAccessToken;

interface AzureKMSCredentials {
   tenantId: string;
   clientId: string;
   clientSecret: string;
   identityPlatformEndpoint?: string; // Defaults to login.microsoftonline.com
};

interface AzureAccessToken {
   accessToken: string;
};

type GCPKMSOptions = GCPKMSCredentials | GCPKMSAccessToken

interface GCPKMSCredentials {
   email: string;
   privateKey: byte[] | string; // May be passed as a base64 encoded string.
   endpoint?: string; // Defaults to oauth2.googleapis.com
};

interface GCPKMSAccessToken {
   accessToken: string;
}

interface LocalKMSOptions {
   key: byte[96] | string; // The master key used to encrypt/decrypt data keys. May be passed as a base64 encoded string.
};

interface KMIPKMSOptions {
   endpoint: string;
};
</code></pre>
<p>The following shows an example object of <code>KMSProviders</code>:</p>
<pre><code class="language-yaml">{
   # Pass credentials for AWS:
   "aws": { "accessKeyId": "foo", "secretAccessKey": "bar" },
   # Use an empty document to enable "Automatic Credentials" for Azure:
   "azure": {},
   # Pass an access token for GCP:
   "gcp": { "accessToken": "foo" },
   # Pass a 96 byte base64 encoded string for the local KMS provider.
   "local": { "key": "Mng0NCt4ZHVUYUJCa1kxNkVyNUR1QURhZ2h2UzR2d2RrZzh0cFBwM3R6NmdWMDFBMUN3YkQ5aXRRMkhGRGdQV09wOGVNYUMxT2k3NjZKelhaQmRCZGJkTXVyZG9uSjFk" }
   # Pass the endpoint for KMIP:
   "kmip": { "endpoint": "localhost:5698" }
   # Pass credentials for a different AWS account by appending a name.
   # Note: credentials with a name do not support "Automatic Credentials".
   "aws:name2": { "accessKeyId": "foo2", "secretAccessKey": "bar2" }
}
</code></pre>
<p><span id="automatic-credentials"></span></p>
<h5 id="automatic-credentials"><a class="header" href="#automatic-credentials">Automatic Credentials</a></h5>
<p>Certain values of <a href="client-side-encryption/client-side-encryption.html#kmsproviders">KMSProviders</a> indicate a request by the user that the associated KMS providers should
be populated lazily on-demand. The driver MUST be able to populate the respective options object on-demand
if-and-only-if such respective credentials are needed. The request for KMS credentials will be indicated by
<a href="client-side-encryption/client-side-encryption.html#libmongocrypt">libmongocrypt</a> only once they are needed.</p>
<p>When such a state is detected, <a href="client-side-encryption/client-side-encryption.html#libmongocrypt">libmongocrypt</a> will call back to the driver by entering the
<code>MONGOCRYPT_CTX_NEED_KMS_CREDENTIALS</code> state, upon which the driver should fill in the KMS options automatically.</p>
<p>Automatic credentials are only supported for the KMS provider types <code>aws</code>, <code>gcp</code>, and <code>azure</code>. KMS providers containing
a name (e.g. <code>aws:myname</code>) do not support automatic credentials. Attempting to configure a KMS provider with a name for
automatic credentials results in a runtime error from <a href="client-side-encryption/client-side-encryption.html#libmongocrypt">libmongocrypt</a>. See
<a href="client-side-encryption/client-side-encryption.html#why-do-on-demand-kms-credentials-not-support-named-kms-providers">Why do on-demand KMS credentials not support named KMS providers?</a></p>
<blockquote>
<p>[!NOTE]
Drivers MUST NOT eagerly fill an empty KMS options property.</p>
</blockquote>
<p>Once requested, drivers MUST create a new <a href="client-side-encryption/client-side-encryption.html#kmsproviders">KMSProviders</a> $P$ according to the following process:</p>
<ol>
<li>Let $K$ be the <a href="client-side-encryption/client-side-encryption.html#kmsproviders">kmsProviders</a> value provided by the user as part of the original
<a href="client-side-encryption/client-side-encryption.html#ClientEncryptionOpts">ClientEncryptionOpts</a> or <a href="client-side-encryption/client-side-encryption.html#AutoEncryptionOpts">AutoEncryptionOpts</a>.</li>
<li>Initialize $P$ to an empty <a href="client-side-encryption/client-side-encryption.html#kmsproviders">KMSProviders</a> object.</li>
<li>If $K$ contains an <code>aws</code> property, and that property is an empty map:
<ol>
<li>Attempt to obtain credentials $C$ from the environment using similar logic as is detailed in
<a href="client-side-encryption/../auth/auth.html#obtaining-credentials">the obtaining-AWS-credentials section from the Driver Authentication specification</a>,
but ignoring the case of loading the credentials from a URI</li>
<li>If credentials $C$ were successfully loaded, create a new <a href="client-side-encryption/client-side-encryption.html#AWSKMSOptions">AWSKMSOptions</a> map from $C$ and insert
that map onto $P$ as the <code>aws</code> property.</li>
</ol>
</li>
<li>If $K$ contains an <code>gcp</code> property, and that property is an empty map:
<ol>
<li>Attempt to obtain credentials $C$ from the environment logic as is detailed in
<a href="client-side-encryption/client-side-encryption.html#obtaining-gcp-credentials">Obtaining GCP Credentials</a>.</li>
<li>If credentials $C$ were successfully loaded, create a new <a href="client-side-encryption/client-side-encryption.html#GCPKMSOptions">GCPKMSOptions</a> map from $C$ and insert
that map onto $P$ as the <code>gcp</code> property.</li>
</ol>
</li>
<li>If $K$ contains an <code>azure</code> property, and that property is an empty map:
<ol>
<li>If there is a <code>cachedAzureAccessToken</code> AND the duration until <code>azureAccessTokenExpireTime</code> is greater than one
minute, insert <code>cachedAzureAccessToken</code> as the <code>azure</code> property on $P$.</li>
<li>Otherwise:
<ol>
<li>Let $t_0$ be the current time.</li>
<li>Attempt to obtain an Azure VM Managed Identity Access Token $T$ as detailed in
<a href="client-side-encryption/client-side-encryption.html#obtaining-an-access-token-for-azure-key-vault">Obtaining an Access Token for Azure Key Vault</a>.</li>
<li>If a token $T$ with expire duration $d_{exp}$ were obtained successfully, create a new
<a href="client-side-encryption/client-side-encryption.html#AzureAccessToken">AzureAccessToken</a> object with $T$ as the <code>accessToken</code> property. Insert that
<a href="client-side-encryption/client-side-encryption.html#AzureAccessToken">AzureAccessToken</a> object into $P$ as the <code>azure</code> property. Record the generated
<a href="client-side-encryption/client-side-encryption.html#AzureAccessToken">AzureAccessToken</a> in <code>cachedAzureAccessToken</code>. Record the <code>azureAccessTokenExpireTime</code> as
$t_0 + d_{exp}$.</li>
</ol>
</li>
</ol>
</li>
<li>Return $P$ as the additional KMS providers to <a href="client-side-encryption/client-side-encryption.html#libmongocrypt">libmongocrypt</a>.</li>
</ol>
<p><span id="obtaining-gcp-credentials"></span></p>
<h5 id="obtaining-gcp-credentials"><a class="header" href="#obtaining-gcp-credentials">Obtaining GCP Credentials</a></h5>
<p>Set <code>HOST</code> to <code>metadata.google.internal</code>.</p>
<p>Send an HTTP request to the URL <code>http://&lt;HOST&gt;/computeMetadata/v1/instance/service-accounts/default/token</code> with the
header <code>Metadata-Flavor: Google</code>.</p>
<p>If the HTTP response code is not 200, return an error including the body of the HTTP response in the error message.</p>
<p>Parse the HTTP response body as JSON. If parsing fails, return an error including the body of the HTTP response in the
error message.</p>
<p>Check the parsed JSON for the field "access_token". If "access_token" is not present, return an error including the body
of the HTTP response in the error message.</p>
<p>Return "access_token" as the credential.</p>
<h5 id="obtaining-an-access-token-for-azure-key-vault"><a class="header" href="#obtaining-an-access-token-for-azure-key-vault">Obtaining an Access Token for Azure Key Vault</a></h5>
<p>Virtual machines running on the Azure platform have one or more <em>Managed Identities</em> associated with them. From within
the VM, an identity can be used by obtaining an access token via HTTP from the <em>Azure Instance Metadata Service</em> (IMDS).
<a href="https://docs.microsoft.com/en-us/azure/active-directory/managed-identities-azure-resources/how-to-use-vm-token#get-a-token-using-http">See this documentation for more information</a></p>
<blockquote>
<p>[!NOTE]
To optimize for testability, it is recommended to implement an isolated abstraction for communication with IMDS. This
will aide in the implementation of the prose tests of the communication with an IMDS server.</p>
</blockquote>
<p>The below steps should be taken:</p>
<ol>
<li>
<p>Let $U$ be a new URL, initialized from the URL string <code>"http://169.254.169.254/metadata/identity/oauth2/token"</code></p>
</li>
<li>
<p>Add a query parameter <code>api-version=2018-02-01</code> to $U$.</p>
</li>
<li>
<p>Add a query parameter <code>resource=https://vault.azure.net/</code> to $U$.</p>
</li>
<li>
<p>Prepare an HTTP GET request $Req$ based on $U$.</p>
<blockquote>
<p>[!NOTE]
All query parameters on $U$ should be appropriately percent-encoded</p>
</blockquote>
</li>
<li>
<p>Add HTTP headers <code>Metadata: true</code> and <code>Accept: application/json</code> to $Req$.</p>
</li>
<li>
<p>Issue $Req$ to the Azure IMDS server <code>169.254.169.254:80</code>. Let $Resp$ be the response from the server. If the HTTP
response is not completely received within ten seconds, consider the request to have timed out, and return an error
instead of an access token.</p>
</li>
<li>
<p>If $Resp_{status} ≠ 200$, obtaining the access token has failed, and the HTTP response body of $Resp$ encodes
information about the error that occurred. Return an error including the HTTP response body instead of an access
token.</p>
</li>
<li>
<p>Otherwise, let $J$ be the JSON document encoded in the HTTP response body of $Resp$.</p>
</li>
<li>
<p>The result access token $T$ is given as the <code>access_token</code> string property of $J$. Return $T$ as the resulting
access token.</p>
</li>
<li>
<p>The resulting "expires in" duration $d_{exp}$ is a count of seconds given as an ASCII-encoded integer string
<code>expires_in</code> property of $J$.</p>
</li>
</ol>
<blockquote>
<p>[!NOTE]
If JSON decoding of $Resp$ fails, or the <code>access_token</code> property is absent from $J$, this is a protocol error from
IMDS. Indicate this error to the requester of the access token.</p>
</blockquote>
<blockquote>
<p>[!NOTE]
If an Azure VM has more than one managed identity, requesting an access token requires additional query parameters to
disambiguate the request. For simplicity, these parameters are omitted, and only VMs that have a single managed
identity are supported.</p>
</blockquote>
<h5 id="kms-provider-tls-options"><a class="header" href="#kms-provider-tls-options">KMS provider TLS options</a></h5>
<p>Drivers MUST provide TLS options to configure TLS connections KMS providers.</p>
<p>The TLS options SHOULD be consistent with the existing TLS options for MongoDB server TLS connections. The TLS options
MUST enable setting a custom client certificate, equivalent to the <code>tlsCertificateKeyFile</code> URI option.</p>
<p>Drivers SHOULD provide API that is consistent with configuring TLS options for MongoDB server TLS connections. New API
to support the TLS options MUST support future addition of KMS providers without requiring a driver API change. The
following is an example:</p>
<pre><code class="language-typescript">class AutoEncryptionOpts {
   // setTLSOptions accepts a map of KMS providers to TLSOptions.
   // The TLSOptions apply to any TLS socket required to communicate
   // with the KMS provider.
   setTLSOptions (opts: KMSProvidersTLSOptions)
}

class ClientEncryptionOpts {
   // setTLSOptions accepts a map of KMS providers to TLSOptions.
   // The TLSOptions apply to any TLS socket required to communicate
   // with the KMS provider.
   setTLSOptions (opts: KMSProvidersTLSOptions)
}
</code></pre>
<p>Drivers MUST raise an error if the TLS options are set to disable TLS. The error MUST contain the message "TLS is
required".</p>
<p>Drivers SHOULD raise an error if insecure TLS options are set. The error MUST contain the message "Insecure TLS options
prohibited". This includes options equivalent to the following URI options:</p>
<ul>
<li><code>tlsInsecure</code></li>
<li><code>tlsAllowInvalidCertificates</code></li>
<li><code>tlsAllowInvalidHostnames</code></li>
<li><code>tlsDisableCertificateRevocationCheck</code></li>
</ul>
<p>Drivers MUST NOT raise an error if <code>tlsDisableOCSPEndpointCheck</code> is set. Setting <code>tlsDisableOCSPEndpointCheck</code> may
prevent operation errors when OCSP responders are unresponsive.</p>
<p>See the OCSP specification for a description of the default values of
<a href="client-side-encryption/../ocsp-support/ocsp-support.html#tlsdisableocspendpointcheck">tlsDisableOCSPEndpointCheck</a> and
<a href="client-side-encryption/../ocsp-support/ocsp-support.html#tlsdisablecertificaterevocationcheck">tlsDisableCertificateRevocationCheck</a> Drivers
MUST NOT modify the default value of <code>tlsDisableOCSPEndpointCheck</code> and <code>tlsDisableCertificateRevocationCheck</code> for KMS
TLS connections.</p>
<p>See <a href="client-side-encryption/client-side-encryption.html#why-do-kms-providers-require-tls-options">Why do KMS providers require TLS options?</a></p>
<h4 id="schemamap"><a class="header" href="#schemamap">schemaMap</a></h4>
<p>Automatic encryption is configured with an "encrypt" field in a collection's JSONSchema. By default, a collection's
JSONSchema is periodically polled with the listCollections command. But a JSONSchema may be specified locally with the
schemaMap option. Drivers MUST document that a local schema is more secure and MUST include the following in the driver
documentation for MongoClient:</p>
<blockquote>
<p>Supplying a schemaMap provides more security than relying on JSON Schemas obtained from the server. It protects
against a malicious server advertising a false JSON Schema, which could trick the client into sending unencrypted data
that should be encrypted.</p>
</blockquote>
<p>Drivers MUST document that a local schema only applies to client side encryption, and specifying JSON Schema features
unrelated to encryption will result in error. Drivers MUST include the following in the driver documentation for
MongoClient:</p>
<blockquote>
<p>Schemas supplied in the schemaMap only apply to configuring automatic encryption for client side encryption. Other
validation rules in the JSON schema will not be enforced by the driver and will result in an error.</p>
</blockquote>
<h4 id="bypassautoencryption"><a class="header" href="#bypassautoencryption">bypassAutoEncryption</a></h4>
<p>Drivers MUST disable auto encryption when the 'bypassAutoEncryption' option is true and not try to spawn mongocryptd.
Automatic encryption may be disabled with the bypassAutoEncryption option. See
<a href="client-side-encryption/client-side-encryption.html#why-is-there-a-bypassautoencryption">Why is there a bypassAutoEncryption?</a>.</p>
<h4 id="extraoptions"><a class="header" href="#extraoptions">extraOptions</a></h4>
<p>The extraOptions relate to the mongocryptd process, an implementation detail described in the
<a href="client-side-encryption/client-side-encryption.html#implementation">Implementation</a> section:</p>
<pre><code class="language-typescript">{
   // Defaults to "mongodb://localhost:27020".
   mongocryptdURI: Optional&lt;String&gt;,

   // Defaults to false.
   mongocryptdBypassSpawn: Optional&lt;Boolean&gt;,

   // Used for spawning. Defaults to empty string and spawns mongocryptd from system path.
   mongocryptdSpawnPath: Optional&lt;String&gt;,

   // Passed when spawning mongocryptd. If omitted, this defaults to ["--idleShutdownTimeoutSecs=60"]
   mongocryptdSpawnArgs: Optional&lt;Array[String]&gt;

   // Override the path used to load the crypt_shared library
   cryptSharedLibPath: Optional&lt;string&gt;;

   // If 'true', refuse to continue encryption without a crypt_shared library
   cryptSharedLibRequired: boolean;
}
</code></pre>
<p>Drivers MUST implement extraOptions in a way that allows deprecating/removing options in the future without an API
break, such as with a BSON document or map type instead of a struct type with fixed fields. See
<a href="client-side-encryption/client-side-encryption.html#why-are-extraoptions-and-kmsproviders-maps">Why are extraOptions and kmsProviders maps?</a>.</p>
<p><span id="extraoptions.cryptsharedlibpath"></span></p>
<h5 id="extraoptionscryptsharedlibpath"><a class="header" href="#extraoptionscryptsharedlibpath"><code>extraOptions.cryptSharedLibPath</code></a></h5>
<ul>
<li>Type: <code>undefined | string</code></li>
<li>Default: <code>undefined</code></li>
</ul>
<p>Allow the user to specify an absolute path to a <a href="client-side-encryption/client-side-encryption.html#crypt_shared">crypt_shared</a> dynamic library to load. Refer:</p>
<ul>
<li><a href="client-side-encryption/client-side-encryption.html#overriding-the-crypt_shared-library-path">Overriding the crypt_shared Library Path</a></li>
<li><a href="client-side-encryption/client-side-encryption.html#path-resolution-behavior">Path Resolution Behavior</a></li>
<li><a href="client-side-encryption/client-side-encryption.html#enabling-crypt_shared">Enabling crypt_shared</a></li>
</ul>
<p><span id="extraoptions.cryptsharedlibrequired"></span></p>
<h5 id="extraoptionscryptsharedlibrequired"><a class="header" href="#extraoptionscryptsharedlibrequired"><code>extraOptions.cryptSharedLibRequired</code></a></h5>
<ul>
<li>Type: <code>boolean</code></li>
<li>Default: <code>false</code></li>
</ul>
<p>If <code>true</code>, the driver MUST refuse to continue unless <a href="client-side-encryption/client-side-encryption.html#crypt_shared">crypt_shared</a> was loaded successfully.</p>
<p>If, after initializing a <code>libmongocrypt_handle</code>, <a href="client-side-encryption/client-side-encryption.html#crypt_shared">crypt_shared</a> is detected to be unavailable AND
<a href="client-side-encryption/client-side-encryption.html#extraoptions.cryptsharedlibrequired">extraOptions.cryptSharedLibRequired</a> is <code>true</code>, the driver MUST consider the
<code>libmongocrypt_handle</code> to be invalid and return an error to the user. Refer:</p>
<p><span id="managing-mongocryptd"></span> <span id="detecting-crypt_shared-availability"></span></p>
<h4 id="encryptedfieldsmap"><a class="header" href="#encryptedfieldsmap">encryptedFieldsMap</a></h4>
<p><code>encryptedFieldsMap</code> maps a collection namespace to an <code>encryptedFields</code>.</p>
<p><code>encryptedFieldsMap</code> only applies to Queryable Encryption.</p>
<p>If a collection is present on both the <code>encryptedFieldsMap</code> and <code>schemaMap</code>, <a href="client-side-encryption/client-side-encryption.html#libmongocrypt">libmongocrypt</a> will error
on initialization. See <code>fle2-and-fle1-error</code>.</p>
<p>If a collection has a set of encrypted fields, the behavior of <code>CreateCollection()</code> and <code>Collection.Drop()</code> is altered.
An additional helper, <code>CreateEncryptedCollection()</code> has been defined as a convenience wrapper around
<code>CreateCollection()</code>. See <code>fle2-createcollection-drop</code>.</p>
<p>Automatic encryption in Queryable Encryption is configured with the <code>encryptedFields</code>.</p>
<p>If a collection is not present on the <code>encryptedFields</code> a server-side collection <code>encryptedFields</code> may be used by
<a href="client-side-encryption/client-side-encryption.html#libmongocrypt">libmongocrypt</a>. Drivers MUST include the following in the documentation for MongoClient:</p>
<blockquote>
<p>Supplying an <code>encryptedFieldsMap</code> provides more security than relying on an <code>encryptedFields</code> obtained from the
server. It protects against a malicious server advertising a false <code>encryptedFields</code>.</p>
</blockquote>
<h4 id="bypassqueryanalysis"><a class="header" href="#bypassqueryanalysis">bypassQueryAnalysis</a></h4>
<p>See <a href="client-side-encryption/client-side-encryption.html#why-is-bypassqueryanalysis-needed">Why is bypassQueryAnalysis needed?</a>.</p>
<h3 id="queryable-encryption-create-and-drop-collection-helpers"><a class="header" href="#queryable-encryption-create-and-drop-collection-helpers">Queryable Encryption Create and Drop Collection Helpers</a></h3>
<p>A collection supporting Queryable Encryption requires an index and three additional collections.</p>
<p><span id="GetEncryptedFields"></span></p>
<h4 id="collection-encryptedfields-lookup-getencryptedfields"><a class="header" href="#collection-encryptedfields-lookup-getencryptedfields">Collection <code>encryptedFields</code> Lookup (GetEncryptedFields)</a></h4>
<p>The convenience methods support the following lookup process for finding the <code>encryptedFields</code> associated with a
collection.</p>
<p>Assume an exposition-only function $GetEncryptedFields(opts, collName, dbName, askDb)$, where $opts$ is a set of
options, $collName$ is the name of the collection, $dbName$ is the name of the database associated with that collection,
and $askDb$ is a boolean value. The resulting <code>encryptedFields</code> $EF$ is found by:</p>
<ol>
<li>Let $QualName$ be the string formed by joining$dbName$ and $collName$ with an ASCII dot <code>"."</code>.</li>
<li>If $opts$ contains an <code>"encryptedFields"</code> property, then $EF$ is the value of that property.</li>
<li>Otherwise, if <code>AutoEncryptionOptions.encryptedFieldsMap</code> contains an element named by $QualName$, then $EF$ is the
value of that element.</li>
<li>Otherwise, if $askDb$ is <code>true</code>:
<ol>
<li>Issue a <code>listCollections</code> command against the database named by $dbName$, filtered by <code>{name: &lt;collName&gt;}</code>. Let
the result be the document $L$.</li>
<li>If $L$ contains an <code>options</code> document element, and that element contains an <code>encryptedFields</code> document element,
$EF$ is $L$ <code>["options"]["encryptedFields"]</code>.</li>
<li>Otherwise, $EF$ is <em>not-found</em></li>
</ol>
</li>
<li>Otherwise, $EF$ is considered <em>not-found</em>.</li>
</ol>
<p><span id="create-collection-helper"></span></p>
<h4 id="create-collection-helper"><a class="header" href="#create-collection-helper">Create Collection Helper</a></h4>
<p>Drivers MUST support a BSON document option named <code>encryptedFields</code> for any
<a href="https://www.mongodb.com/docs/manual/reference/command/create">create</a> command helpers (e.g.
<code>Database.createCollection()</code>). This option will be interpreted by the helper method and MUST be passed to the
<a href="https://www.mongodb.com/docs/manual/reference/command/create">create</a> command.</p>
<blockquote>
<p>[!NOTE]
Users are not expected to set the <code>escCollection</code> and <code>ecocCollection</code> options in <code>encryptedFields</code>.
<a href="https://jira.mongodb.org/browse/SERVER-74069">SERVER-74069</a> added server-side validation for those fields and no
longer allows names to deviate from the following:</p>
<ul>
<li><code>enxcol_.&lt;collectionName&gt;.esc</code></li>
<li><code>enxcol_.&lt;collectionName&gt;.ecoc</code></li>
</ul>
<p>Drivers MUST NOT document the <code>escCollection</code> and <code>ecocCollection</code> options.</p>
</blockquote>
<p>For a helper function, <code>CreateCollection(collectionName, collectionOptions)</code> with the name of the database associated as
$dbName$, look up the encrypted fields <code>encryptedFields</code> for the collection as $GetEncryptedFields(collectionOptions,
collectionName, dbName, false)$ (<a href="client-side-encryption/client-side-encryption.html#GetEncryptedFields">See here</a>).</p>
<p>If a set of <code>encryptedFields</code> was found, then do the following operations. If any of the following operations error, the
remaining operations are not attempted:</p>
<ul>
<li>Check the wire version of the writable server. If the wire version is less than 21 (for server 7.0.0), return an error
containing the error message: "Driver support of Queryable Encryption is incompatible with server. Upgrade server to
use Queryable Encryption."</li>
<li>Create the collection with name <code>encryptedFields["escCollection"]</code> as a clustered collection using the options
<code>{clusteredIndex: {key: {_id: 1}, unique: true}}</code>. If <code>encryptedFields["escCollection"]</code> is not set, use the
collection name <code>enxcol_.&lt;collectionName&gt;.esc</code>. Creating this collection MUST NOT check if the collection namespace is
in the <code>AutoEncryptionOpts.encryptedFieldsMap</code>. the collection namespace is in the
<code>AutoEncryptionOpts.encryptedFieldsMap</code>.</li>
<li>Create the collection with name <code>encryptedFields["ecocCollection"]</code> as a clustered collection using the options
<code>{clusteredIndex: {key: {_id: 1}, unique: true}}</code>. If <code>encryptedFields["ecocCollection"]</code> is not set, use the
collection name <code>enxcol_.&lt;collectionName&gt;.ecoc</code>. Creating this collection MUST NOT check if the collection namespace
is in the <code>AutoEncryptionOpts.encryptedFieldsMap</code>.</li>
<li>Create the collection <code>collectionName</code> with <code>collectionOptions</code> and the option <code>encryptedFields</code> set to the
<code>encryptedFields</code>.</li>
<li>Create the the index <code>{"__safeContent__": 1}</code> on collection <code>collectionName</code>.</li>
</ul>
<h4 id="create-encrypted-collection-helper"><a class="header" href="#create-encrypted-collection-helper">Create Encrypted Collection Helper</a></h4>
<p>To support automatic generation of encryption data keys, a helper $CreateEncryptedCollection(CE, database, collName,
collOpts, kmsProvider, masterKey)$ is defined, where $CE$ is a <a href="client-side-encryption/client-side-encryption.html#clientencryption">ClientEncryption</a> object,
$kmsProvider$ is a <a href="client-side-encryption/client-side-encryption.html#KMSProvider">KMSProvider</a> and $masterKey$ is equivalent to the $masterKey$ defined in
<a href="client-side-encryption/client-side-encryption.html#datakeyopts">DataKeyOpts</a>. It has the following behavior:</p>
<ul>
<li>If $collOpts$ contains an <code>"encryptedFields"</code> property, then $EF$ is the value of that property. Otherwise, report an
error that there are no <code>encryptedFields</code> defined for the collection.</li>
<li>Let $EF'$ be a copy of $EF$. Update $EF'$ in the following manner:
<ul>
<li>Let $Fields$ be the <code>"fields"</code> element within $EF'$.</li>
<li>If $Fields$ is present and is an array value, then for each element $F$ of <code>Fields</code>:
<ul>
<li>If $F$ is not a document element, skip it.</li>
<li>Otherwise, if $F$ has a <code>"keyId"</code> named element $K$ and $K$ is a <code>null</code> value:
<ul>
<li>Create a <a href="client-side-encryption/client-side-encryption.html#datakeyopts">DataKeyOpts</a> named $dkOpts$ with the $masterKey$ argument.</li>
<li>Let $D$ be the result of <code>CE.createDataKey(kmsProvider, dkOpts)</code>.</li>
<li>If generating $D$ resulted in an error $E$, the entire $CreateEncryptedCollection$ must now fail with error $E$.
Return the partially-formed $EF'$ with the error so that the caller may know what datakeys have already been
created by the helper.</li>
<li>Replace $K$ in $F$ with $D$.</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>Create a new set of options $collOpts'$ duplicating $collOpts$. Set the <code>"encryptedFields"</code> named element of
$collOpts'$ to $EF'$.</li>
<li>Invoke the <code>CreateCollection</code> helper as $CreateCollection(database, collName, collOpts')$. Return the resulting
collection and the generated $EF'$. If an error occurred, return the resulting $EF$ with the error so that the caller
may know what datakeys have already been created by the helper.</li>
</ul>
<p>Drivers MUST document that $createEncryptedCollection$ does not affect any auto encryption settings on existing
MongoClients that are already configured with auto encryption. Users must configure auto encryption after creating the
encrypted collection with the $createEncryptedCollection$ helper.</p>
<h4 id="drop-collection-helper"><a class="header" href="#drop-collection-helper">Drop Collection Helper</a></h4>
<p>Drivers MUST support a BSON document option named <code>encryptedFields</code> for any
<a href="https://www.mongodb.com/docs/manual/reference/command/drop">drop</a> command helpers (e.g. <code>Database.dropCollection()</code>,
<code>Collection.drop()</code>). This option will only be interpreted by the helper method and MUST NOT be passed to the
<a href="https://www.mongodb.com/docs/manual/reference/command/drop">drop</a> command.</p>
<blockquote>
<p>[!NOTE]
Users are not expected to set the <code>escCollection</code> and <code>ecocCollection</code> options in <code>encryptedFields</code>.
<a href="https://jira.mongodb.org/browse/SERVER-74069">SERVER-74069</a> added server-side validation for those fields and no
longer allows names to deviate from the following:</p>
<ul>
<li><code>enxcol_.&lt;collectionName&gt;.esc</code></li>
<li><code>enxcol_.&lt;collectionName&gt;.ecoc</code></li>
</ul>
<p>Drivers SHOULD NOT document the <code>escCollection</code> and <code>ecocCollection</code> options.</p>
</blockquote>
<p>For a helper function <code>DropCollection(dropOptions)</code> with associated collection named $collName$ and database named
$dbName$, look up the encrypted fields <code>encryptedFields</code> as $GetEncryptedFields(dropOptions, collName, dbname, true)$
(<a href="client-side-encryption/client-side-encryption.html#GetEncryptedFields">See here</a>).</p>
<p>If a set of <code>encryptedFields</code> was found, then perform the following operations. If any of the following operations
error, the remaining operations are not attempted. A <code>namespace not found</code> error returned from the server (server error
code 26) MUST be ignored:</p>
<ul>
<li>Drop the collection with name <code>encryptedFields["escCollection"]</code>. If <code>encryptedFields["escCollection"]</code> is not set,
use the collection name <code>enxcol_.&lt;collectionName&gt;.esc</code>.</li>
<li>Drop the collection with name <code>encryptedFields["ecocCollection"]</code>. If <code>encryptedFields["ecocCollection"]</code> is not set,
use the collection name <code>enxcol_.&lt;collectionName&gt;.ecoc</code>.</li>
<li>Drop the collection <code>collectionName</code>.</li>
</ul>
<h3 id="clientencryption"><a class="header" href="#clientencryption">ClientEncryption</a></h3>
<pre><code class="language-typescript">class ClientEncryption {
   ClientEncryption(opts: ClientEncryptionOpts);

   // The "Create Encrypted Collection" helper is a convenience function wrapping CreateCollection. It will
   // create a collection with encrypted fields, automatically allocating and assigning new data encryption
   // keys. It returns a handle to the new collection, as well as a document consisting of the generated
   // "encryptedFields" options. Refer to "Create Encrypted Collection Helper"
   createEncryptedCollection(database: Database, collName: string, collOpts, kmsProvider: KMSProvider, masterKey: Optional&lt;Document&gt;): [Collection, Document];

   // Creates a new key document and inserts into the key vault collection.
   // Returns the _id of the created document as a UUID (BSON binary subtype 0x04).
   createDataKey(kmsProvider: KMSProvider, opts: DataKeyOpts | null): Binary;

   // Decrypts multiple data keys and (re-)encrypts them with a new masterKey, or with their current masterKey if a new one is not given.
   // The updated fields of each rewrapped data key is updated in the key vault collection as part of a single bulk write operation.
   // If no data key matches the given filter, no bulk write operation is executed.
   // Returns a RewrapManyDataKeyResult.
   rewrapManyDataKey(filter: Document, opts: RewrapManyDataKeyOpts | null): RewrapManyDataKeyResult;

   // Removes the key document with the given UUID (BSON binary subtype 0x04) from the key vault collection.
   // Returns the result of the internal deleteOne() operation on the key vault collection.
   deleteKey(id: Binary): DeleteResult;

   // Finds a single key document with the given UUID (BSON binary subtype 0x04).
   // Returns the result of the internal find() operation on the key vault collection.
   getKey(id: Binary): Optional&lt;Document&gt;;

   // Finds all documents in the key vault collection.
   // Returns the result of the internal find() operation on the key vault collection.
   getKeys(): Iterable&lt;Document&gt;;

   // Adds a keyAltName to the keyAltNames array of the key document in the key vault collection with the given UUID (BSON binary subtype 0x04).
   // Returns the previous version of the key document.
   addKeyAltName(id: Binary, keyAltName: String): Optional&lt;Document&gt;;

   // Removes a keyAltName from the keyAltNames array of the key document in the key vault collection with the given UUID (BSON binary subtype 0x04).
   // Returns the previous version of the key document.
   removeKeyAltName(id: Binary, keyAltName: String): Optional&lt;Document&gt;;

   // Returns a key document in the key vault collection with the given keyAltName.
   getKeyByAltName(keyAltName: String): Optional&lt;Document&gt;;

   // Encrypts a BsonValue with a given key and algorithm.
   // Returns an encrypted value (BSON binary of subtype 6). The underlying implementation MAY return an error for prohibited BSON values.
   encrypt(value: BsonValue, opts: EncryptOpts): Binary;

   // encryptExpression encrypts a Match Expression or Aggregate Expression to query a range index.
   // `expr` is expected to be a BSON document of one of the following forms:
   // 1. A Match Expression of this form:
   //   {$and: [{&lt;field&gt;: {$gt: &lt;value1&gt;}}, {&lt;field&gt;: {$lt: &lt;value2&gt; }}]}
   // 2. An Aggregate Expression of this form:
   //   {$and: [{$gt: [&lt;fieldpath&gt;, &lt;value1&gt;]}, {$lt: [&lt;fieldpath&gt;, &lt;value2&gt;]}]
   // $gt may also be $gte. $lt may also be $lte.
   // Only supported when queryType is "range" and algorithm is "Range".
   encryptExpression(expr: Document, opts: EncryptOpts): Document;

   // Decrypts an encrypted value (BSON binary of subtype 6).
   // Returns the original BSON value.
   decrypt(value: Binary): BsonValue;

   // Implementation details.
   private mongocrypt_t libmongocrypt_handle;
   private MongoClient keyvault_client;
}
</code></pre>
<p><span id="ClientEncryptionOpts"></span></p>
<p><span id="KMSProvidersTLSOptions"></span></p>
<pre><code class="language-typescript">interface ClientEncryptionOpts {
   keyVaultClient: MongoClient;
   keyVaultNamespace: String;
   kmsProviders: KMSProviders;
   tlsOptions?: KMSProvidersTLSOptions; // Maps KMS provider to TLS options.
};

interface KMSProvidersTLSOptions {
   // Map the KMS providers to a set of TLS options
   [provider: KMSProvider]: TLSOptionsMap;
};
</code></pre>
<p>The ClientEncryption encapsulates explicit operations on a key vault collection that cannot be done directly on a
MongoClient. Similar to configuring auto encryption on a MongoClient, it is constructed with a MongoClient (to a MongoDB
cluster containing the key vault collection), KMS provider configuration, keyVaultNamespace, and tlsOptions. It provides
an API for explicitly encrypting and decrypting values, and managing data keys in the key vault collection.</p>
<p>See
<a href="client-side-encryption/client-side-encryption.html#why-do-we-have-a-separate-top-level-type-for-clientencryption">Why do we have a separate top level type for ClientEncryption?</a>
and
<a href="client-side-encryption/client-side-encryption.html#why-do-we-need-to-pass-a-client-to-create-a-clientencryption">Why do we need to pass a client to create a ClientEncryption?</a></p>
<p>When implementing behavior and error handling for key vault functions, Drivers SHOULD assume the presence of a unique
index in the key vault collection on the <code>keyAltNames</code> field with a partial index filter for only documents where
<code>keyAltNames</code> exists when implementing behavior of key management functions. Drivers MAY choose to not validate or
enforce the existence of the unique index, but MUST still be capable of handling errors that such a unique index may
yield.</p>
<p>See
<a href="client-side-encryption/client-side-encryption.html#why-arent-we-creating-a-unique-index-in-the-key-vault-collection">Why aren't we creating a unique index in the key vault collection?</a></p>
<h3 id="datakeyopts"><a class="header" href="#datakeyopts">DataKeyOpts</a></h3>
<pre><code class="language-typescript">class DataKeyOpts {
   masterKey: Optional&lt;Document&gt;
   keyAltNames: Optional&lt;Array[String]&gt; // An alternative to _id to reference a key.
   keyMaterial: Optional&lt;BinData&gt;
}
</code></pre>
<h4 id="masterkey"><a class="header" href="#masterkey">masterKey</a></h4>
<p>The masterKey document identifies a KMS-specific key used to encrypt the new data key. If kmsProvider has KMS provider
type "aws", the masterKey is required and has the following fields:</p>
<pre><code class="language-typescript">{
   region: String,
   key: String, // The Amazon Resource Name (ARN) to the AWS customer master key (CMK).
   endpoint: Optional&lt;String&gt; // An alternate host identifier to send KMS requests to. May include port number. Defaults to "kms.&lt;region&gt;.amazonaws.com"
}
</code></pre>
<p>If the kmsProvider has KMS provider type "azure", the masterKey is required and has the following fields:</p>
<pre><code class="language-typescript">{
   keyVaultEndpoint: String, // Host with optional port. Example: "example.vault.azure.net".
   keyName: String,
   keyVersion: Optional&lt;String&gt; // A specific version of the named key, defaults to using the key's primary version.
}
</code></pre>
<p>If the kmsProvider has KMS provider type "gcp", the masterKey is required and has the following fields:</p>
<pre><code class="language-typescript">{
   projectId: String,
   location: String,
   keyRing: String,
   keyName: String,
   keyVersion: Optional&lt;String&gt;, // A specific version of the named key, defaults to using the key's primary version.
   endpoint: Optional&lt;String&gt; // Host with optional port. Defaults to "cloudkms.googleapis.com".
}
</code></pre>
<p>If the kmsProvider has KMS provider type "local", the masterKey is not applicable.</p>
<p>If the kmsProvider has KMS provider type "kmip", the masterKey is required and has the following fields:</p>
<pre><code class="language-javascript">{
   keyId: Optional&lt;String&gt;, // keyId is the KMIP Unique Identifier to a 96 byte KMIP Secret Data managed object.
                            // If keyId is omitted, the driver creates a random 96 byte KMIP Secret Data managed object.
   endpoint: Optional&lt;String&gt;, // Host with optional port.
   delegated: Optional&lt;Boolean&gt; // If true, this key should be decrypted by the KMIP server.
}
</code></pre>
<p>Drivers MUST document the expected fields in the masterKey document for the "aws", "azure", "gcp", and "kmip" KMS
provider types. Additionally, they MUST document that masterKey is <strong>required</strong> for these KMS provider types and is not
optional.</p>
<p>The value of <code>endpoint</code> or <code>keyVaultEndpoint</code> is a host name with optional port number separated by a colon. E.g.
"kms.us-east-1.amazonaws.com" or "kms.us-east-1.amazonaws.com:443". It is assumed that the host name is not an IP
address or IP literal. Though drivers MUST NOT inspect the value of "endpoint" that a user sets when creating a data
key, a driver will inspect it when connecting to KMS to determine a port number if present.</p>
<h4 id="keyaltnames"><a class="header" href="#keyaltnames">keyAltNames</a></h4>
<p>An optional list of string alternate names used to reference a key. If a key is created with alternate names, then
encryption may refer to the key by the unique alternate name instead of by <code>_id</code>. The following example shows creating
and referring to a data key by alternate name:</p>
<pre><code class="language-python">opts = DataKeyOpts(keyAltNames=["name1"])
clientencryption.create_data_key ("local", opts)
# reference the key with the alternate name
opts = EncryptOpts(keyAltName="name1", algorithm="AEAD_AES_256_CBC_HMAC_SHA_512-Random")
clientencryption.encrypt("457-55-5462", opts)
</code></pre>
<h4 id="keymaterial"><a class="header" href="#keymaterial">keyMaterial</a></h4>
<p>An optional BinData of 96 bytes to use as custom key material for the data key being created. If <code>keyMaterial</code> is given,
the custom key material is used for encrypting and decrypting data. Otherwise, the key material for the new data key is
generated from a cryptographically secure random device.</p>
<h3 id="rewrapmanydatakey"><a class="header" href="#rewrapmanydatakey">rewrapManyDataKey</a></h3>
<p>If applicable, drivers MUST document that users must upgrade dependencies if necessary to avoid being impacted by
<a href="https://jira.mongodb.org/browse/MONGOCRYPT-464">MONGOCRYPT-464</a>.</p>
<p>If applicable, drivers MUST return an error if rewrapManyDataKey is called with libmongocrypt 1.5.1 or 1.5.0.</p>
<h3 id="rewrapmanydatakeyopts"><a class="header" href="#rewrapmanydatakeyopts">RewrapManyDataKeyOpts</a></h3>
<pre><code class="language-typescript">class RewrapManyDataKeyOpts {
   provider: String
   masterKey: Optional&lt;Document&gt;
}
</code></pre>
<p>The <code>masterKey</code> document MUST have the fields corresponding to the given <code>provider</code> as specified in
<a href="client-side-encryption/client-side-encryption.html#masterkey">masterKey</a>. <code>masterKey</code> MUST NOT be given if it is not applicable for the given <code>provider</code>.</p>
<h3 id="rewrapmanydatakeyresult"><a class="header" href="#rewrapmanydatakeyresult">RewrapManyDataKeyResult</a></h3>
<pre><code class="language-typescript">class RewrapManyDataKeyResult {
   bulkWriteResult: Optional&lt;BulkWriteResult&gt;;
}
</code></pre>
<p><code>bulkWriteResult</code> is the <a href="client-side-encryption/../crud/crud.html#write-results">result of the bulk write operation</a> used to update the key
vault collection with one or more rewrapped data keys. If <code>rewrapManyDataKey()</code> does not find any matching keys to
rewrap, no bulk write operation will be executed and this field will be unset. This field may also be unset if the bulk
write operation is unacknowledged as permitted by the <a href="client-side-encryption/../crud/crud.html#write-results">CRUD API Spec</a>.</p>
<p>See
<a href="client-side-encryption/client-side-encryption.html#why-does-rewrapmanydatakey-return-rewrapmanydatakeyresult-instead-of-bulkwriteresult">Why does rewrapManyDataKey return RewrapManyDataKeyResult instead of BulkWriteResult?</a></p>
<h3 id="encryptopts"><a class="header" href="#encryptopts">EncryptOpts</a></h3>
<pre><code class="language-typescript">class EncryptOpts {
   keyId : Optional&lt;Binary&gt;
   keyAltName: Optional&lt;String&gt;
   algorithm: String,
   contentionFactor: Optional&lt;Int64&gt;,
   queryType: Optional&lt;String&gt;
   rangeOpts: Optional&lt;RangeOpts&gt;
}

// RangeOpts specifies index options for a Queryable Encryption field supporting "range" queries.
// min, max, trimFactor, sparsity, and precision must match the values set in the encryptedFields of the destination collection.
// For double and decimal128, min/max/precision must all be set, or all be unset.
class RangeOpts {
   // min is the minimum value for the encrypted index. Required if precision is set.
   min: Optional&lt;BSONValue&gt;,
   // max is the maximum value for the encrypted index. Required if precision is set.
   max: Optional&lt;BSONValue&gt;,
   // trimFactor may be used to tune performance. When omitted, a default value is used.
   trimFactor: Optional&lt;Int32&gt;,
   // sparsity may be used to tune performance. When omitted, a default value is used.
   sparsity: Optional&lt;Int64&gt;,
   // precision determines the number of significant digits after the decimal point. May only be set for double or decimal128.
   precision: Optional&lt;Int32&gt;
}
</code></pre>
<p>Explicit encryption requires a key and algorithm. Keys are either identified by <code>_id</code> or by alternate name. Exactly one
is required.</p>
<h4 id="keyid"><a class="header" href="#keyid">keyId</a></h4>
<p>Identifies a data key by <code>_id</code>. The value is a UUID (binary subtype 4).</p>
<h4 id="keyaltname"><a class="header" href="#keyaltname">keyAltName</a></h4>
<p>Identifies a key vault collection document by 'keyAltName'.</p>
<h4 id="algorithm"><a class="header" href="#algorithm">algorithm</a></h4>
<p>One of the strings:</p>
<ul>
<li>"AEAD_AES_256_CBC_HMAC_SHA_512-Deterministic"</li>
<li>"AEAD_AES_256_CBC_HMAC_SHA_512-Random"</li>
<li>"Indexed"</li>
<li>"Unindexed"</li>
<li>"Range"</li>
</ul>
<p>The result of explicit encryption with the "Indexed" or "Range" algorithm must be processed by the server to insert or
query. Drivers MUST document the following behavior:</p>
<blockquote>
<p>To insert or query with an "Indexed" or "Range" encrypted payload, use a <code>MongoClient</code> configured with
<code>AutoEncryptionOpts</code>. <code>AutoEncryptionOpts.bypassQueryAnalysis</code> may be true. <code>AutoEncryptionOpts.bypassAutoEncryption</code>
must be false.</p>
</blockquote>
<h4 id="contentionfactor"><a class="header" href="#contentionfactor">contentionFactor</a></h4>
<p>contentionFactor may be used to tune performance. Only applies when algorithm is "Indexed" or "Range". libmongocrypt
returns an error if contentionFactor is set for a non-applicable algorithm.</p>
<h4 id="querytype"><a class="header" href="#querytype">queryType</a></h4>
<p>One of the strings:</p>
<ul>
<li>"equality"</li>
<li>"range"</li>
</ul>
<p>queryType only applies when algorithm is "Indexed" or "Range". libmongocrypt returns an error if queryType is set for a
non-applicable queryType.</p>
<h4 id="rangeopts"><a class="header" href="#rangeopts">rangeOpts</a></h4>
<p>rangeOpts only applies when algorithm is "Range". libmongocrypt returns an error if rangeOpts is set for a
non-applicable algorithm.</p>
<h2 id="user-facing-api-when-auto-encryption-fails"><a class="header" href="#user-facing-api-when-auto-encryption-fails">User facing API: When Auto Encryption Fails</a></h2>
<p>Auto encryption requires parsing the MongoDB query language client side (with the <a href="client-side-encryption/client-side-encryption.html#mongocryptd">mongocryptd</a> process or
<a href="client-side-encryption/client-side-encryption.html#crypt_shared">crypt_shared</a> library). For unsupported operations, an exception will propagate to prevent the
possibility of the client sending unencrypted data that should be encrypted. Drivers MUST include the following in the
documentation for MongoClient:</p>
<blockquote>
<p>If automatic encryption fails on an operation, use a MongoClient configured with bypassAutoEncryption=true and use
ClientEncryption.encrypt() to manually encrypt values.</p>
</blockquote>
<p>For example, currently an aggregate with <code>$lookup</code> into a foreign collection is unsupported (<a href="client-side-encryption/client-side-encryption.html#mongocryptd">mongocryptd</a>
and <a href="client-side-encryption/client-side-encryption.html#crypt_shared">crypt_shared</a> return errors):</p>
<pre><code class="language-python">opts = AutoEncryptionOpts (
   key_vault_namespace="keyvault.datakeys",
   kms_providers=kms)
client = MongoClient(auto_encryption_opts=opts)
accounts = client.db.accounts
results = accounts.aggregate([
   {
      "$lookup": {
      "from": "people",
      "pipeline": [
         {
            "$match": {
               "ssn": "457-55-5462"
            }
         }
      ],
      "as": "person"
   }
]) # Raises an error

print (next(results)["person"]["ssn"])
</code></pre>
<p>In this case, the user should use explicit encryption on a client configured to bypass auto encryption. (Note, automatic
decryption still occurs).</p>
<pre><code class="language-python">opts = AutoEncryptionOpts (
   key_vault_namespace="keyvault.datakeys",
   kms_providers=kms,
   bypass_auto_encryption=True)
client = MongoClient(auto_encryption_opts=opts)

opts = ClientEncryptionOpts (
   key_vault_client=client,
   key_vault_namespace="keyvault.datakeys",
   kms_providers=kms,
   bypass_auto_encryption=True)
client_encryption = ClientEncryption(opts)

accounts = client.db.accounts
results = accounts.aggregate([
   {
      "$lookup": {
      "from": "people",
      "pipeline": [
         {
            "$match": {
               "ssn": client_encryption.encrypt("457-55-5462", EncryptOpts(key_alt_name="ssn", algorithm="AEAD_AES_256_CBC_HMAC_SHA_512-Deterministic"))
            }
         }
      ],
      "as": "person"
   }
]) # Throws an exception

print (next(results)["person"]["ssn"])
</code></pre>
<h2 id="user-facing-api-view-limitations"><a class="header" href="#user-facing-api-view-limitations">User facing API: View limitations</a></h2>
<p>Users cannot use auto encryption with views. Attempting to do so results in an exception. Drivers do not need to
validate when the user is attempting to enable auto encryption on a view, but may defer to the underlying
implementation.</p>
<p>Although auto encryption does not work on views, users may still use explicit encrypt and decrypt functions on views on
a MongoClient without auto encryption enabled.</p>
<p>See <a href="client-side-encryption/client-side-encryption.html#why-do-operations-on-views-fail">Why do operations on views fail?</a></p>
<h2 id="implementation-2"><a class="header" href="#implementation-2">Implementation</a></h2>
<p>Drivers MUST integrate with libmongocrypt. libmongocrypt exposes a simple state machine to perform operations. Follow
<a href="https://github.com/mongodb/libmongocrypt/blob/master/integrating.md">the guide to integrating libmongocrypt</a>.</p>
<p>Drivers SHOULD take a best-effort approach to store sensitive data securely when interacting with KMS since responses
may include decrypted data key material (e.g. use secure malloc if available).</p>
<p>All errors from the MongoClient to <a href="client-side-encryption/client-side-encryption.html#mongocryptd">mongocryptd</a> or the <a href="client-side-encryption/client-side-encryption.html#crypt_shared">crypt_shared</a> error category MUST
be distinguished in some way (e.g. exception type) to make it easier for users to distinguish when a command fails due
to auto encryption limitations.</p>
<p>All errors from the MongoClient interacting with the key vault collection MUST be distinguished in some way (e.g.
exception type) to make it easier for users to distinguish when a command fails due to behind-the-scenes operations
required for encryption, decryption, or key management.</p>
<p>Drivers MUST apply timeouts to operations executed as part of client-side encryption per
<a href="client-side-encryption/../client-side-operations-timeout/client-side-operations-timeout.html#client-side-encryption">Client Side Operations Timeout: Client Side Encryption</a>.</p>
<h2 id="integrating-with-libmongocrypt"><a class="header" href="#integrating-with-libmongocrypt">Integrating with libmongocrypt</a></h2>
<p>Each ClientEncryption instance MUST have one <code>libmongocrypt_handle</code>.</p>
<p><a href="https://github.com/mongodb/libmongocrypt/blob/master/src/mongocrypt.h">The libmongocrypt C API documentation</a> For
information on how to initialize, encrypt, decrypt with libmongocrypt.</p>
<p><a href="https://github.com/mongodb/libmongocrypt/blob/master/integrating.md">The Guide to Integrating libmongocrypt</a> For
information about integrating the libmongocrypt library in a driver.</p>
<p>libmongocrypt exposes logging capabilities. If a driver provides a logging mechanism, it MUST enable this logging and
integrate. E.g. if your driver exposes a logging callback that a user can set, it SHOULD be possible to get log messages
from libmongocrypt.</p>
<p>Drivers MUST propagate errors from libmongocrypt in whatever way is idiomatic to the driver (exception, error object,
etc.). These errors MUST be distinguished in some way (e.g. exception type) to make it easier for users to distinguish
when a command fails due to client side encryption.</p>
<p><span id="enabling-crypt_shared"></span></p>
<h2 id="enabling-command-marking-with-the-crypt_shared-library"><a class="header" href="#enabling-command-marking-with-the-crypt_shared-library">Enabling Command Marking with the <code>crypt_shared</code> Library</a></h2>
<p>The MongoDB Enterprise distribution includes a dynamic library named <code>mongo_crypt_v1</code> (with the appropriate file
extension or filename suffix for the host platform). This library will be loaded by <a href="client-side-encryption/client-side-encryption.html#libmongocrypt">libmongocrypt</a> when
the <code>mongocrypt_init</code> function is invoked
<a href="https://github.com/mongodb/libmongocrypt/blob/master/src/mongocrypt.h">(from the libmongocrypt C API)</a> based on the
search criteria that are provided by the driver.</p>
<p><a href="client-side-encryption/client-side-encryption.html#libmongocrypt">libmongocrypt</a> allows the driver to specify an arbitrary list of directory
<a href="client-side-encryption/client-side-encryption.html#search-paths">search paths</a> in which to search for the <a href="client-side-encryption/client-side-encryption.html#crypt_shared">crypt_shared</a> dynamic library. The user-facing
API does not expose this full search path functionality. This extended search path customization is intended to
facilitate driver testing with <a href="client-side-encryption/client-side-encryption.html#crypt_shared">crypt_shared</a> (Refer:
<a href="client-side-encryption/client-side-encryption.html#search-paths-for-testing">Search Paths for Testing</a> and <a href="client-side-encryption/client-side-encryption.html#path-resolution-behavior">Path Resolution Behavior</a>).</p>
<blockquote>
<p>[!NOTE]
The driver MUST NOT manipulate or do any validation on the <a href="client-side-encryption/client-side-encryption.html#crypt_shared">crypt_shared</a> path options provided in
<a href="client-side-encryption/client-side-encryption.html#extraoptions">extraOptions</a>. They should be passed through to <a href="client-side-encryption/client-side-encryption.html#libmongocrypt">libmongocrypt</a> unchanged.</p>
</blockquote>
<p><span id="search-path"></span> <span id="search-paths"></span></p>
<h3 id="setting-search-paths"><a class="header" href="#setting-search-paths">Setting Search Paths</a></h3>
<p>For the user-facing API the driver MUST append the literal string - <code>"$SYSTEM"</code> to the search paths for the
<code>libmongocrypt_handle</code> if <code>bypassAutoEncryption</code> is not set to <code>true</code>, and MUST NOT append to the search path if it is
set to <code>true</code> or if the <a href="client-side-encryption/client-side-encryption.html#libmongocrypt">libmongocrypt</a> instance is used for explicit encryption only (i.e. on the
ClientEncryption class). For purposes of testing, a driver may use a different set of search paths.</p>
<p><strong>Explanation</strong></p>
<p>The <a href="client-side-encryption/client-side-encryption.html#search-paths">search paths</a> array in <a href="client-side-encryption/client-side-encryption.html#libmongocrypt">libmongocrypt</a> allows the driver to customize the way that
<a href="client-side-encryption/client-side-encryption.html#libmongocrypt">libmongocrypt</a> searches and loads the <a href="client-side-encryption/client-side-encryption.html#crypt_shared">crypt_shared</a> library. For testing purposes, the
driver may change the paths that it appends for <a href="client-side-encryption/client-side-encryption.html#crypt_shared">crypt_shared</a> searching to better isolate the test
execution from the ambient state of the host system.</p>
<p>Refer to: <a href="client-side-encryption/client-side-encryption.html#path-resolution-behavior">Path Resolution Behavior</a> and
<a href="client-side-encryption/client-side-encryption.html#search-paths-for-testing">Search Paths for Testing</a></p>
<p><span id="override-path"></span></p>
<h3 id="overriding-the-crypt_shared-library-path"><a class="header" href="#overriding-the-crypt_shared-library-path">Overriding the <code>crypt_shared</code> Library Path</a></h3>
<p>If <a href="client-side-encryption/client-side-encryption.html#extraoptions.cryptsharedlibpath">extraOptions.cryptSharedLibPath</a> was specified by the user, the driver MUST set
the <a href="client-side-encryption/client-side-encryption.html#crypt_shared">crypt_shared</a> path override on the <code>libmongocrypt_handle</code>.</p>
<blockquote>
<p>[!NOTE]
If a path override is set on a <code>libmongocrypt_handle</code> and <a href="client-side-encryption/client-side-encryption.html#libmongocrypt">libmongocrypt</a> fails to load
<a href="client-side-encryption/client-side-encryption.html#crypt_shared">crypt_shared</a> from that filepath, then that will result in a hard-error when initializing
<a href="client-side-encryption/client-side-encryption.html#libmongocrypt">libmongocrypt</a>.</p>
</blockquote>
<h3 id="path-resolution-behavior"><a class="header" href="#path-resolution-behavior">Path Resolution Behavior</a></h3>
<p>Drivers should include and note the following information regarding the behavior of <a href="client-side-encryption/client-side-encryption.html#crypt_shared">crypt_shared</a> path
options in <a href="client-side-encryption/client-side-encryption.html#extraoptions">extraOptions</a>:</p>
<ul>
<li>
<p>If used, the <a href="client-side-encryption/client-side-encryption.html#override-path">override path</a> must be given as a path to the <a href="client-side-encryption/client-side-encryption.html#crypt_shared">crypt_shared</a> dynamic
library file <em>itself</em>, and not simply the directory that contains it.</p>
</li>
<li>
<p>If the given <a href="client-side-encryption/client-side-encryption.html#override-path">override path</a> is a relative path and the first path component is the literal string
<code>"$ORIGIN"</code>, the <code>"$ORIGIN"</code> component will be replaced by the absolute path to the directory containing the
<a href="client-side-encryption/client-side-encryption.html#libmongocrypt">libmongocrypt</a> library that is performing the <a href="client-side-encryption/client-side-encryption.html#crypt_shared">crypt_shared</a> search. This behavior
mimics the <code>$ORIGIN</code> behavior of the <code>RUNPATH</code>/<code>RPATH</code> properties of ELF executable files. This permits bundling the
<a href="client-side-encryption/client-side-encryption.html#crypt_shared">crypt_shared</a> library along with <a href="client-side-encryption/client-side-encryption.html#libmongocrypt">libmongocrypt</a> for creating portable application
distributions without relying on a externally/globally available <a href="client-side-encryption/client-side-encryption.html#crypt_shared">crypt_shared</a> library.</p>
<blockquote>
<p>[!NOTE]
No other <code>RPATH</code>/<code>RUNPATH</code>-style substitutions are available.</p>
</blockquote>
</li>
<li>
<p>If the <a href="client-side-encryption/client-side-encryption.html#override-path">override path</a> is given as a relative path, that path will be resolved relative to the working
directory of the operating system process.</p>
</li>
<li>
<p>If an <a href="client-side-encryption/client-side-encryption.html#override-path">override path</a> was specified and <a href="client-side-encryption/client-side-encryption.html#libmongocrypt">libmongocrypt</a> fails to load
<a href="client-side-encryption/client-side-encryption.html#crypt_shared">crypt_shared</a> from that filepath, <a href="client-side-encryption/client-side-encryption.html#libmongocrypt">libmongocrypt</a> will fail to initialize with a
hard-error. <a href="client-side-encryption/client-side-encryption.html#libmongocrypt">libmongocrypt</a> will not attempt to search for <a href="client-side-encryption/client-side-encryption.html#crypt_shared">crypt_shared</a> in any other
locations.</p>
</li>
<li>
<p>If <a href="client-side-encryption/client-side-encryption.html#libmongocrypt">libmongocrypt</a> fails to load the <a href="client-side-encryption/client-side-encryption.html#crypt_shared">crypt_shared</a> library after searching the system
(and no <a href="client-side-encryption/client-side-encryption.html#override-path">override path</a> is specified), <a href="client-side-encryption/client-side-encryption.html#libmongocrypt">libmongocrypt</a> will proceed without error and
presume that <a href="client-side-encryption/client-side-encryption.html#crypt_shared">crypt_shared</a> is unavailable.</p>
</li>
</ul>
<h4 id="search-paths-for-testing"><a class="header" href="#search-paths-for-testing">Search Paths for Testing</a></h4>
<p>Drivers can make use of different <a href="client-side-encryption/client-side-encryption.html#search-paths">search paths</a> settings for testing purposes. These search paths use
the following behavior:</p>
<ul>
<li>
<p>For <a href="client-side-encryption/client-side-encryption.html#crypt_shared">crypt_shared</a> <a href="client-side-encryption/client-side-encryption.html#search-paths">search paths</a>, if a search path string is <code>"$SYSTEM"</code>, then —
instead of <a href="client-side-encryption/client-side-encryption.html#libmongocrypt">libmongocrypt</a> searching for <a href="client-side-encryption/client-side-encryption.html#crypt_shared">crypt_shared</a> in a directory named
"<code>$SYSTEM</code>" — <a href="client-side-encryption/client-side-encryption.html#libmongocrypt">libmongocrypt</a> will defer to the operating system's own dynamic-library resolution
mechanism when processing that search-path. For this reason, <code>"$SYSTEM"</code> is the only search path appended when the
driver is used via the user-facing API.</p>
</li>
<li>
<p>The <a href="client-side-encryption/client-side-encryption.html#search-paths">search paths</a> also support the <code>$ORIGIN</code> substitution string.</p>
</li>
<li>
<p>Like with the <a href="client-side-encryption/client-side-encryption.html#override-path">override path</a>, if a <a href="client-side-encryption/client-side-encryption.html#search-path">search path</a> is given as a relative path, that path
will be resolved relative to the working directory of the operating system process.</p>
</li>
<li>
<p>If no <a href="client-side-encryption/client-side-encryption.html#search-paths">search paths</a> are appended to the <code>libmongocrypt_handle</code>, the resulting search paths will be an
empty array, effectively <a href="client-side-encryption/client-side-encryption.html#disabling-crypt_shared">disabling crypt_shared</a> searching.</p>
<p>In this case, unless an <a href="client-side-encryption/client-side-encryption.html#override-path">override path</a> is specified, <a href="client-side-encryption/client-side-encryption.html#libmongocrypt">libmongocrypt</a> is guaranteed
not to load <a href="client-side-encryption/client-side-encryption.html#crypt_shared">crypt_shared</a>.</p>
</li>
</ul>
<h3 id="detecting-crypt_shared-availability"><a class="header" href="#detecting-crypt_shared-availability">Detecting <a href="client-side-encryption/client-side-encryption.html#crypt_shared">crypt_shared</a> Availability</a></h3>
<p><a href="client-side-encryption/client-side-encryption.html#crypt_shared">crypt_shared</a> availability can only be reliably detected <em>after</em> initializing the
<code>libmongocrypt_handle</code>.</p>
<p>After initializing the <code>libmongocrypt_handle</code>, the driver can detect whether <a href="client-side-encryption/client-side-encryption.html#crypt_shared">crypt_shared</a> was
successfully loaded by asking <a href="client-side-encryption/client-side-encryption.html#libmongocrypt">libmongocrypt</a> for the <a href="client-side-encryption/client-side-encryption.html#crypt_shared">crypt_shared</a> version string. If
the result is an empty string, <a href="client-side-encryption/client-side-encryption.html#libmongocrypt">libmongocrypt</a> did not load <a href="client-side-encryption/client-side-encryption.html#crypt_shared">crypt_shared</a> and the driver
must rely on <a href="client-side-encryption/client-side-encryption.html#mongocryptd">mongocryptd</a> to mark command documents for encryption.</p>
<p><span id="disabling-crypt_shared"></span></p>
<h3 id="disabling-crypt_shared"><a class="header" href="#disabling-crypt_shared">"Disabling" <code>crypt_shared</code></a></h3>
<p>For purposes of testing, a driver can "disable" <a href="client-side-encryption/client-side-encryption.html#crypt_shared">crypt_shared</a> searching to ensure that
<a href="client-side-encryption/client-side-encryption.html#mongocryptd">mongocryptd</a> is used instead, even if a <a href="client-side-encryption/client-side-encryption.html#crypt_shared">crypt_shared</a> library would be available.</p>
<p>As noted in <a href="client-side-encryption/client-side-encryption.html#path-resolution-behavior">Path Resolution Behavior</a>, <a href="client-side-encryption/client-side-encryption.html#crypt_shared">crypt_shared</a> can be "disabled" on a
<code>libmongocrypt_handle</code> by omission:</p>
<ol>
<li>Do not specify any <a href="client-side-encryption/client-side-encryption.html#search-paths">search paths</a>,</li>
<li>AND do not specify a <a href="client-side-encryption/client-side-encryption.html#crypt_shared">crypt_shared</a> library <a href="client-side-encryption/client-side-encryption.html#override-path">override path</a>
(<a href="client-side-encryption/client-side-encryption.html#extraoptions.cryptsharedlibpath">extraOptions.cryptSharedLibPath</a>).</li>
</ol>
<p>This will have the effect that <a href="client-side-encryption/client-side-encryption.html#libmongocrypt">libmongocrypt</a> will not attempt to search or load
<a href="client-side-encryption/client-side-encryption.html#crypt_shared">crypt_shared</a> during initialization.</p>
<p>At the current time, no user-facing API is exposed that allows users to opt-out of <a href="client-side-encryption/client-side-encryption.html#crypt_shared">crypt_shared</a>.</p>
<h3 id="loading-crypt_shared-multiple-times"><a class="header" href="#loading-crypt_shared-multiple-times">Loading <a href="client-side-encryption/client-side-encryption.html#crypt_shared">crypt_shared</a> Multiple Times</a></h3>
<p>Due to implementation restrictions, there must not be more than one <a href="client-side-encryption/client-side-encryption.html#crypt_shared">crypt_shared</a> dynamic library loaded
simultaneously in a single operating system process. <code>libmongocrypt</code> will do its best to enforce this at the time that
it loads <a href="client-side-encryption/client-side-encryption.html#crypt_shared">crypt_shared</a> while initializing a <code>libmongocrypt_handle</code>. <code>libmongocrypt</code> will keep track of
the open <a href="client-side-encryption/client-side-encryption.html#crypt_shared">crypt_shared</a> library globally, and any subsequent attempt to use a
<a href="client-side-encryption/client-side-encryption.html#crypt_shared">crypt_shared</a> library that does not exactly match the filepath of the already-loaded
<a href="client-side-encryption/client-side-encryption.html#crypt_shared">crypt_shared</a> will result in an error.</p>
<p>If at least one <code>libmongocrypt_handle</code> exists in an operating system process that has an open handle to a
<a href="client-side-encryption/client-side-encryption.html#crypt_shared">crypt_shared</a> library, subsequent attempts to initialize an additional <code>libmongocrypt_handle</code> will fail
if:</p>
<ol>
<li>The new <code>libmongocrypt_handle</code> wants <a href="client-side-encryption/client-side-encryption.html#crypt_shared">crypt_shared</a> (i.e. at least one <a href="client-side-encryption/client-side-encryption.html#search-path">search path</a> was
specified or an <a href="client-side-encryption/client-side-encryption.html#override-path">override path</a> was specified).</li>
<li>AND the initialization of that <code>libmongocrypt_handle</code> does not successfully find and load the same
<a href="client-side-encryption/client-side-encryption.html#crypt_shared">crypt_shared</a> library that was loaded by the existing <code>libmongocrypt_handle</code> that is already using
<a href="client-side-encryption/client-side-encryption.html#crypt_shared">crypt_shared</a>.</li>
</ol>
<p>Drivers MUST document this limitation for users along with the documentation on the <code>cryptShared*</code> options in
<a href="client-side-encryption/client-side-encryption.html#extraoptions">extraOptions</a> by including the following:</p>
<blockquote>
<p>All <code>MongoClient</code> objects in the same process should use the same setting for
<a href="client-side-encryption/client-side-encryption.html#extraoptions.cryptsharedlibpath">extraOptions.cryptSharedLibPath</a>, as it is an error to load more that one
<a href="client-side-encryption/client-side-encryption.html#crypt_shared">crypt_shared</a> dynamic library simultaneously in a single operating system process.</p>
</blockquote>
<p>Once all open handles to a <a href="client-side-encryption/client-side-encryption.html#crypt_shared">crypt_shared</a> library are closed, it is possible to load a different
<a href="client-side-encryption/client-side-encryption.html#crypt_shared">crypt_shared</a> library than was previously loaded. The restriction only applies to simultaneous open
handles within a single process.</p>
<h2 id="managing-mongocryptd"><a class="header" href="#managing-mongocryptd">Managing mongocryptd</a></h2>
<p>If the following conditions are met:</p>
<ul>
<li>The user's <code>MongoClient</code> is configured for client-side encryption (i.e. <code>bypassAutoEncryption</code> is not <code>false</code>)</li>
<li><strong>AND</strong> the user has not disabled <code>mongocryptd</code> spawning (i.e. by setting <code>extraOptions.mongocryptdBypassSpawn</code> to
<code>true</code>),</li>
<li><strong>AND</strong> the <a href="client-side-encryption/client-side-encryption.html#crypt_shared">crypt_shared</a> library is unavailable (Refer:
<a href="client-side-encryption/client-side-encryption.html#detecting-crypt_shared-availability">Detecting crypt_shared Availability</a>),</li>
<li><strong>AND</strong> the <a href="client-side-encryption/client-side-encryption.html#extraoptions.cryptsharedlibrequired">extraOptions.cryptSharedLibRequired</a> option is <code>false</code>.</li>
</ul>
<p><strong>then</strong> <code>mongocryptd</code> MUST be spawned by the driver.</p>
<p>If the <a href="client-side-encryption/client-side-encryption.html#extraoptions.cryptsharedlibrequired">extraOptions.cryptSharedLibRequired</a> option is <code>true</code> then the driver MUST
NOT attempt to spawn or connect to <code>mongocryptd</code>.</p>
<blockquote>
<p>[!NOTE]
Since spawning <a href="client-side-encryption/client-side-encryption.html#mongocryptd">mongocryptd</a> requires checking whether <a href="client-side-encryption/client-side-encryption.html#crypt_shared">crypt_shared</a> is loaded, and
checking whether <a href="client-side-encryption/client-side-encryption.html#crypt_shared">crypt_shared</a> is available can only be done <em>after</em> having initialized the
<code>libmongocrypt_handle</code>, drivers will need to defer spawning <a href="client-side-encryption/client-side-encryption.html#mongocryptd">mongocryptd</a> until <em>after</em> initializing
<a href="client-side-encryption/client-side-encryption.html#libmongocrypt">libmongocrypt</a> and checking for <a href="client-side-encryption/client-side-encryption.html#crypt_shared">crypt_shared</a>.</p>
</blockquote>
<h3 id="spawning-mongocryptd"><a class="header" href="#spawning-mongocryptd">Spawning <a href="client-side-encryption/client-side-encryption.html#mongocryptd">mongocryptd</a></a></h3>
<p>If a MongoClient is configured for Client Side Encryption (eg. <code>bypassAutoEncryption=false</code>), then by default (unless
<code>mongocryptdBypassSpawn=true</code>), mongocryptd MUST be spawned by the driver. Spawning MUST include the command line
argument <code>--idleShutdownTimeoutSecs</code>. If the user does not supply one through <code>extraOptions.mongocryptdSpawnArgs</code> (which
may be either in the form <code>--idleShutdownTimeoutSecs=60</code> or as two consecutive arguments
<code>["--idleShutdownTimeoutSecs", 60]</code>, then the driver MUST append <code>--idleShutdownTimeoutSecs=60</code> to the arguments. This
tells mongocryptd to automatically terminate after 60 seconds of non-use. The stdout and stderr of the spawned process
MUST not be exposed in the driver (e.g. redirect to <code>/dev/null</code>). Users can pass the argument <code>--logpath</code> to
<code>extraOptions.mongocryptdSpawnArgs</code> if they need to inspect mongocryptd logs.</p>
<p>Upon construction, the MongoClient MUST create a MongoClient to mongocryptd configured with
<code>serverSelectionTimeoutMS=10000</code>.</p>
<p>If spawning is necessary, the driver MUST spawn mongocryptd whenever server selection on the MongoClient to mongocryptd
fails. If the MongoClient fails to connect after spawning, the server selection error is propagated to the user.</p>
<h3 id="connecting-to-mongocryptd"><a class="header" href="#connecting-to-mongocryptd">Connecting to <a href="client-side-encryption/client-side-encryption.html#mongocryptd">mongocryptd</a></a></h3>
<p>If the <a href="client-side-encryption/client-side-encryption.html#crypt_shared">crypt_shared</a> library is loaded, the driver MUST NOT attempt to connect to
<a href="client-side-encryption/client-side-encryption.html#mongocryptd">mongocryptd</a>. (Refer: <a href="client-side-encryption/client-side-encryption.html#detecting-crypt_shared-availability">Detecting crypt_shared Availability</a>).</p>
<p>Single-threaded drivers MUST connect with
<a href="client-side-encryption/../server-selection/server-selection.html#serverselectiontryonce">serverSelectionTryOnce=false</a>,
<code>connectTimeoutMS=10000</code>, and MUST bypass
<a href="client-side-encryption/../server-discovery-and-monitoring/server-monitoring.html#cooldownms">cooldownMS</a> when connecting to mongocryptd. See
<a href="client-side-encryption/client-side-encryption.html#why-are-serverselectiontryonce-and-cooldownms-disabled-for-single-threaded-drivers-connecting-to-mongocryptd">Why are serverSelectionTryOnce and cooldownMS disabled for single-threaded drivers connecting to mongocryptd?</a></p>
<p>If the ClientEncryption is configured with <code>mongocryptdBypassSpawn=true</code>, then the driver is not responsible for
spawning mongocryptd. If server selection ever fails when connecting to mongocryptd, the server selection error is
propagated to the user.</p>
<blockquote>
<p>[!NOTE]
A correctly-behaving driver will never attempt to connect to <a href="client-side-encryption/client-side-encryption.html#mongocryptd">mongocryptd</a> when
<a href="client-side-encryption/client-side-encryption.html#extraoptions.cryptsharedlibrequired">extraOptions.cryptSharedLibRequired</a> is set to <code>true</code> or
<a href="client-side-encryption/client-side-encryption.html#crypt_shared">crypt_shared</a> is loaded.</p>
</blockquote>
<h2 id="clientencryption-1"><a class="header" href="#clientencryption-1">ClientEncryption</a></h2>
<p>The new ClientEncryption type interacts uses libmongocrypt to perform ClientEncryption operations. See the
<a href="https://github.com/mongodb/libmongocrypt/blob/master/src/mongocrypt.h">libmongocrypt API documentation</a> for more
information.</p>
<p>The ClientEncryption contains a MongoClient connected to the MongoDB cluster containing the key vault collection. It
does not contain a MongoClient to mongocryptd.</p>
<p>See
<a href="client-side-encryption/client-side-encryption.html#why-does-clientencryption-have-key-management-functions-when-drivers-can-use-existing-crud-operations-instead">Why does ClientEncryption have key management functions when Drivers can use existing CRUD operations instead?</a>.</p>
<h2 id="key-vault-collection"><a class="header" href="#key-vault-collection">Key Vault collection</a></h2>
<p>The key vault collection is the specially designated collection containing encrypted data keys. There is no default
collection (user must specify). The key vault collection is used for automatic and explicit encryption/decryption as
well as key management functions.</p>
<p>For key management functions that require creating, updating, or deleting key documents in the key vault collection, the
corresponding operations MUST be done with write concern majority.</p>
<p>For encryption/decryption and key management functions that require reading key documents from the key vault collection,
the corresponding operations MUST be done with read concern majority.</p>
<p>Some key management functions may require multiple commands to complete their operation. Key management functions
currently assume there is no concurrent access of the key vault collection being operated on. Concurrent access to a key
vault collection being operated on may result in unexpected or undefined behavior. Support for concurrent key management
may be considered for future work.</p>
<p>See <a href="client-side-encryption/client-side-encryption.html#support-sessions-in-key-management-functions">Support sessions in key management functions</a>.</p>
<h2 id="auto-encrypt-and-decrypt"><a class="header" href="#auto-encrypt-and-decrypt">Auto encrypt and decrypt</a></h2>
<p>An encrypted MongoClient automatically encrypts values for filtering and decrypts results.</p>
<p>The driver MUST use libmongocrypt to initiate auto encryption and decryption. Create the BSON command meant to be sent
over the wire, then pass that through the libmongocrypt state machine and use the returned BSON command in its place.
The state machine is created with the libmongocrypt function <code>mongocrypt_ctx_new</code> and initialized with a
<code>mongocrypt_ctx_encrypt_init</code> or <code>mongocrypt_ctx_decrypt_init</code>. See the
<a href="https://github.com/mongodb/libmongocrypt/blob/master/src/mongocrypt.h">libmongocrypt API documentation</a> for more
information.</p>
<p>An encrypted MongoClient configured with bypassAutoEncryption MUST NOT attempt automatic encryption for any command.</p>
<p>Otherwise, an encrypted MongoClient MUST attempt to auto encrypt all commands. Note, the underlying implementation may
determine no encryption is necessary, or bypass many checks if the command is deemed to not possibly contain any
encrypted data (e.g. ping). See the appendix section:
<a href="client-side-encryption/client-side-encryption.html#libmongocrypt-auto-encryption-allow-list">libmongocrypt: Auto Encryption Allow-List</a>.</p>
<p>An encrypted MongoClient MUST attempt to auto decrypt the results of all commands.</p>
<p>Drivers MUST raise an error when attempting to auto encrypt a command if the maxWireVersion is less than 8. The error
message MUST contain "Auto-encryption requires a minimum MongoDB version of 4.2".</p>
<p>Note, all client side features (including all of <code>ClientEncryption</code>) are only supported against 4.2 or higher servers.
However, errors are only raised for automatic encryption/decryption against older servers. See
<a href="client-side-encryption/client-side-encryption.html#why-is-a-42-server-required">Why is a 4.2 server required?</a></p>
<h2 id="interaction-with-command-monitoring"><a class="header" href="#interaction-with-command-monitoring">Interaction with Command Monitoring</a></h2>
<p>Unencrypted data MUST NOT appear in the data of any command monitoring events. Encryption MUST occur before generating a
CommandStartedEvent, and decryption MUST occur after generating a CommandSucceededEvent.</p>
<h2 id="size-limits-for-write-commands"><a class="header" href="#size-limits-for-write-commands">Size limits for Write Commands</a></h2>
<p>Automatic encryption requires the driver to serialize write commands as a single BSON document before automatically
encrypting with libmongocrypt (analogous to constructing <a href="client-side-encryption/../message/OP_MSG.html#sections">OP_MSG payload type 0</a>, not a
document sequence). Automatic encryption returns a single (possibly modified) BSON document as the command to send.</p>
<p>Because automatic encryption increases the size of commands, the driver MUST split bulk writes at a reduced size limit
before undergoing automatic encryption. The write payload MUST be split at 2MiB (2097152). Where batch splitting occurs
relative to automatic encryption is implementation-dependent.</p>
<p>Drivers MUST not reduce the size limits for a single write before automatic encryption. I.e. if a single document has
size larger than 2MiB (but less than <code>maxBsonObjectSize</code>) proceed with automatic encryption.</p>
<p>Drivers MUST document the performance limitation of enabling client side encryption by including the following
documentation in MongoClient:</p>
<blockquote>
<p>Enabling Client Side Encryption reduces the maximum write batch size and may have a negative performance impact.</p>
</blockquote>
<h2 id="appendix-1"><a class="header" href="#appendix-1">Appendix</a></h2>
<h3 id="appendix-terms"><a class="header" href="#appendix-terms">Appendix terms</a></h3>
<p><strong>intent-to-encrypt marking</strong></p>
<p>One of the data formats of BSON binary subtype 6, representing an encoded BSON document containing plaintext and
metadata.</p>
<h3 id="key-vault-collection-schema-for-data-keys"><a class="header" href="#key-vault-collection-schema-for-data-keys">Key vault collection schema for data keys</a></h3>
<p>Data keys are stored in the MongoDB key vault collection with the following schema:</p>
<div class="table-wrapper"><table><thead><tr><th></th><th></th><th></th></tr></thead><tbody>
<tr><td><strong>Name</strong></td><td><strong>Type</strong></td><td><strong>Description</strong></td></tr>
<tr><td>_id</td><td>UUID</td><td>A unique identifier for the key.</td></tr>
<tr><td>version</td><td>Int64</td><td>A numeric identifier for the schema version of this document. Implicitly 0 if unset.</td></tr>
<tr><td>keyAltNames</td><td>Array of strings</td><td>Alternate names to search for keys by. Used for a per-document key scenario in support of GDPR scenarios.</td></tr>
<tr><td>keyMaterial</td><td>BinData</td><td>Encrypted data key material, BinData type General</td></tr>
<tr><td>creationDate</td><td>Date</td><td>The datetime the wrapped data key material was imported into the Key Database.</td></tr>
<tr><td>updateDate</td><td>Date</td><td>The datetime the wrapped data key material was last modified. On initial import, this value will be set to creationDate.</td></tr>
<tr><td>status</td><td>Int</td><td>0 = enabled, 1 = disabled</td></tr>
<tr><td>masterKey</td><td>Document</td><td>Per provider master key definition, see below</td></tr>
</tbody></table>
</div>
<h4 id="masterkey-contents"><a class="header" href="#masterkey-contents">masterKey contents</a></h4>
<div class="table-wrapper"><table><thead><tr><th></th><th></th><th></th></tr></thead><tbody>
<tr><td><strong>Name</strong></td><td><strong>Type</strong></td><td><strong>Description</strong></td></tr>
<tr><td>provider</td><td>"aws"</td><td></td></tr>
<tr><td>key</td><td>String</td><td>AWS ARN. Only applicable for "aws" provider.</td></tr>
<tr><td>region</td><td>String</td><td>AWS Region that contains AWS ARN. Only applicable for "aws" provider.</td></tr>
<tr><td>endpoint</td><td>String</td><td>Alternate AWS endpoint (needed for FIPS endpoints)</td></tr>
</tbody></table>
</div><div class="table-wrapper"><table><thead><tr><th></th><th></th><th></th></tr></thead><tbody>
<tr><td><strong>Name</strong></td><td><strong>Type</strong></td><td><strong>Description</strong></td></tr>
<tr><td>provider</td><td>"azure"</td><td></td></tr>
<tr><td>keyVaultEndpoint</td><td>String</td><td>Required key vault endpoint. (e.g. "example.vault.azure.net")</td></tr>
<tr><td>keyName</td><td>String</td><td>Required key name.</td></tr>
<tr><td>keyVersion</td><td>String</td><td>Optional key version.</td></tr>
</tbody></table>
</div><div class="table-wrapper"><table><thead><tr><th></th><th></th><th></th></tr></thead><tbody>
<tr><td><strong>Name</strong></td><td><strong>Type</strong></td><td><strong>Description</strong></td></tr>
<tr><td>provider</td><td>"gcp"</td><td></td></tr>
<tr><td>projectId</td><td>String</td><td>Required project ID.</td></tr>
<tr><td>location</td><td>String</td><td>Required location name (e.g. "global")</td></tr>
<tr><td>keyRing</td><td>String</td><td>Required key ring name.</td></tr>
<tr><td>keyName</td><td>String</td><td>Required key name.</td></tr>
<tr><td>keyVersion</td><td>String</td><td>Optional key version.</td></tr>
<tr><td>endpoint</td><td>String</td><td>Optional, KMS URL, defaults to <a href="https://cloudkms.googleapis.com">https://cloudkms.googleapis.com</a></td></tr>
</tbody></table>
</div><div class="table-wrapper"><table><thead><tr><th></th><th></th><th></th></tr></thead><tbody>
<tr><td><strong>Name</strong></td><td><strong>Type</strong></td><td><strong>Description</strong></td></tr>
<tr><td>provider</td><td>"local"</td><td></td></tr>
</tbody></table>
</div><div class="table-wrapper"><table><thead><tr><th></th><th></th><th></th></tr></thead><tbody>
<tr><td><strong>Name</strong></td><td><strong>Type</strong></td><td><strong>Description</strong></td></tr>
<tr><td>provider</td><td>"kmip"</td><td></td></tr>
<tr><td>endpoint</td><td>String</td><td>Optional. Defaults to kmip.endpoint from KMS providers.</td></tr>
<tr><td>delegated</td><td>Boolean</td><td>Optional. Defaults to false.</td></tr>
<tr><td>keyId</td><td>String</td><td>Required. keyId is the Unique Identifier to a 96 byte KMIP Secret Data managed object.</td></tr>
</tbody></table>
</div>
<p>Data keys are needed for encryption and decryption. They are identified in the intent-to-encrypt marking and ciphertext.
Data keys may be retrieved by querying the "_id" with a UUID or by querying the "keyAltName" with a string.</p>
<p>Note, "status" is unused and is purely informational.</p>
<h4 id="example-data-key-document"><a class="header" href="#example-data-key-document">Example data key document</a></h4>
<pre><code>{
   "_id" : UUID("00000000-0000-0000-0000-000000000000"),
   "status" : 1,
   "masterKey" : {
      "provider" : "aws",
      "key" : "arn:aws...",
      "region" : "us-east-1"
   },
   "updateDate" : ISODate("2019-03-18T22:53:50.483Z"),
   "keyMaterial" : BinData(0,"AQICAH..."),
   "creationDate" : ISODate("2019-03-18T22:53:50.483Z"),
   "keyAltNames" : [
      "altname",
      "another_altname"
   ]
}
</code></pre>
<h3 id="bson-binary-subtype-6"><a class="header" href="#bson-binary-subtype-6">BSON binary subtype 6</a></h3>
<p>BSON Binary Subtype 6 has a one byte leading identifier. The following is a quick reference.</p>
<pre><code class="language-typescript">struct {
   uint8 subtype;
   [more data - see individual type definitions]
}
</code></pre>
<h4 id="type-0-intent-to-encrypt-marking"><a class="header" href="#type-0-intent-to-encrypt-marking">Type 0: Intent-to-encrypt marking</a></h4>
<pre><code class="language-typescript">struct {
   uint8 subtype = 0;
   [ bson ];
}
</code></pre>
<h4 id="types-1-and-2-ciphertext"><a class="header" href="#types-1-and-2-ciphertext">Types 1 and 2: Ciphertext</a></h4>
<pre><code class="language-typescript">struct {
   uint8 subtype = (1 or 2);
   uint8 key_uuid[16];
   uint8 original_bson_type;
   uint32 ciphertext_length;
   uint8 ciphertext[ciphertext_length];
}
</code></pre>
<p>See <a href="client-side-encryption/../bson-binary-encrypted/binary-encrypted.html">Driver Spec: BSON Binary Encrypted</a> for more information.</p>
<h3 id="jsonschema-encrypt"><a class="header" href="#jsonschema-encrypt">JSONSchema "encrypt"</a></h3>
<p>The additional support for encryption in JSONSchema will be documented in the MongoDB manual. But the following is an
example:</p>
<pre><code class="language-typescript">encrypt : {
   bsonType: "int"
   algorithm: "AEAD_AES_256_CBC_HMAC_SHA_512-Deterministic"
   keyId: [UUID(...)]
}
</code></pre>
<p>Each field is briefly described as follows:</p>
<div class="table-wrapper"><table><thead><tr><th>Name</th><th>Type</th><th>Description</th></tr></thead><tbody>
<tr><td>bsonType</td><td>string</td><td>The bsonType of the underlying encrypted field.</td></tr>
<tr><td>algorithm</td><td>string</td><td>"AEAD_AES_256_CBC_HMAC_SHA_512-Random" or <br>"AEAD_AES_256_CBC_HMAC_SHA_512-Deterministic"</td></tr>
<tr><td>keyId</td><td>string or array of UUID</td><td>If string, it is a JSON pointer to a field with a scalar value <br>identifying a key by keyAltName.<br>If array, an array of eligible keys.</td></tr>
</tbody></table>
</div>
<h3 id="libmongocrypt-prohibitions-and-warnings"><a class="header" href="#libmongocrypt-prohibitions-and-warnings">libmongocrypt: Prohibitions and warnings</a></h3>
<p>libmongocrypt MUST validate options. The following noteworthy cases are prohibited:</p>
<ul>
<li>Explicit encryption using the deterministic algorithm on any of the following types:
<ul>
<li>array</li>
<li>document</li>
<li>code with scope</li>
<li>single value types: undefined, MinKey, MaxKey, Null</li>
<li>decimal128</li>
<li>double</li>
<li>bool</li>
</ul>
</li>
<li>Explicit encryption on a BSON binary subtype 6.</li>
</ul>
<p>The following cases MUST warn:</p>
<ul>
<li>A local schema that does not include encrypted fields.</li>
</ul>
<h3 id="libmongocrypt-collection-info-caching"><a class="header" href="#libmongocrypt-collection-info-caching">libmongocrypt: Collection info caching</a></h3>
<p>libmongocrypt will cache the collection infos so encryption with remote schemas need not run listCollections every time.
Collection infos (or lack thereof) are cached for one minute. This is not configurable. After expiration, subsequent
attempts to encrypt will result in libmongocrypt requesting a new collection info.</p>
<p>A collection info result indicates if the collection is really a view. If it is, libmongocrypt returns an error since it
does not know the schema of the underlying collection.</p>
<p>A collection info with validators that aside from one top level <code>$jsonSchema</code> are considered an error.</p>
<h3 id="libmongocrypt-data-key-caching"><a class="header" href="#libmongocrypt-data-key-caching">libmongocrypt: Data key caching</a></h3>
<p>Data keys are cached in libmongocrypt for one minute. This is not configurable, and there is no maximum number of keys
in the cache. The data key material is stored securely. It will not be paged to disk and the memory will be properly
zero'ed out after freeing.</p>
<h3 id="libmongocrypt-crypto-implementation"><a class="header" href="#libmongocrypt-crypto-implementation">libmongocrypt: Crypto implementation</a></h3>
<p>libmongocrypt uses AEAD_SHA256_CBC_HMAC512 for both "randomized" and "deterministic" encryption algorithms. It is
described in this <a href="https://tools.ietf.org/html/draft-mcgrew-aead-aes-cbc-hmac-sha2-05">IETF document draft</a>. For
"randomized", libmongocrypt securely creates a random IV. For "deterministic", libmongocrypt securely creates a random
IV key and any given encryption operation will derive the IV from the IV key and the field plaintext data.</p>
<h3 id="libmongocrypt-auto-encryption-allow-list"><a class="header" href="#libmongocrypt-auto-encryption-allow-list">libmongocrypt: Auto Encryption Allow-List</a></h3>
<p>libmongocrypt determines whether or not the command requires encryption (i.e. is sent to mongocryptd) based on the table
below. Commands not listed in this table will result in an error returned by libmongocrypt.</p>
<div class="table-wrapper"><table><thead><tr><th></th><th></th></tr></thead><tbody>
<tr><td><strong>Command</strong></td><td><strong>Action</strong></td></tr>
<tr><td>aggregate (collection)</td><td>AUTOENCRYPT</td></tr>
<tr><td>count</td><td>AUTOENCRYPT</td></tr>
<tr><td>distinct</td><td>AUTOENCRYPT</td></tr>
<tr><td>delete</td><td>AUTOENCRYPT</td></tr>
<tr><td>find</td><td>AUTOENCRYPT</td></tr>
<tr><td>findAndModify</td><td>AUTOENCRYPT</td></tr>
<tr><td>getMore</td><td>BYPASS</td></tr>
<tr><td>insert</td><td>AUTOENCRYPT</td></tr>
<tr><td>update</td><td>AUTOENCRYPT</td></tr>
<tr><td>authenticate</td><td>BYPASS</td></tr>
<tr><td>getnonce</td><td>BYPASS</td></tr>
<tr><td>logout</td><td>BYPASS</td></tr>
<tr><td>hello</td><td>BYPASS</td></tr>
<tr><td>legacy hello</td><td>BYPASS</td></tr>
<tr><td>abortTransaction</td><td>BYPASS</td></tr>
<tr><td>commitTransaction</td><td>BYPASS</td></tr>
<tr><td>endSessions</td><td>BYPASS</td></tr>
<tr><td>startSession</td><td>BYPASS</td></tr>
<tr><td>create</td><td>BYPASS</td></tr>
<tr><td>createIndexes</td><td>BYPASS</td></tr>
<tr><td>createSearchIndexes</td><td>BYPASS</td></tr>
<tr><td>drop</td><td>BYPASS</td></tr>
<tr><td>dropDatabase</td><td>BYPASS</td></tr>
<tr><td>dropIndexes</td><td>BYPASS</td></tr>
<tr><td>dropSearchIndex</td><td>BYPASS</td></tr>
<tr><td>killCursors</td><td>BYPASS</td></tr>
<tr><td>listCollections</td><td>BYPASS</td></tr>
<tr><td>listDatabases</td><td>BYPASS</td></tr>
<tr><td>listIndexes</td><td>BYPASS</td></tr>
<tr><td>renameCollection</td><td>BYPASS</td></tr>
<tr><td>explain</td><td>AUTOENCRYPT</td></tr>
<tr><td>ping</td><td>BYPASS</td></tr>
<tr><td>killAllSessions</td><td>BYPASS</td></tr>
<tr><td>killSessions</td><td>BYPASS</td></tr>
<tr><td>killAllSessionsByPattern</td><td>BYPASS</td></tr>
<tr><td>refreshSessions</td><td>BYPASS</td></tr>
<tr><td>updateSearchIndex</td><td>BYPASS</td></tr>
</tbody></table>
</div>
<p>All AUTOENCRYPT commands are sent to mongocryptd, even if there is no JSONSchema. This is to ensure that commands that
reference other collections (e.g. aggregate with <code>$lookup</code>) are handled properly.</p>
<h2 id="test-plan-30"><a class="header" href="#test-plan-30">Test Plan</a></h2>
<p>See the <a href="client-side-encryption/tests/README.html">README.md</a> in the test directory.</p>
<h2 id="rationale-3"><a class="header" href="#rationale-3">Rationale</a></h2>
<h3 id="design-principles"><a class="header" href="#design-principles">Design Principles</a></h3>
<p>In addition to the <a href="https://github.com/mongodb/specifications#driver-mantras">Driver Mantras</a> there are design
principles specific to this project.</p>
<h3 id="1-make-encryption-easy-to-enable"><a class="header" href="#1-make-encryption-easy-to-enable">1. Make encryption easy to enable</a></h3>
<p>Users should be able to enable encryption with minimal application change.</p>
<h3 id="2-minimize-risk-of-exposing-sensitive-data"><a class="header" href="#2-minimize-risk-of-exposing-sensitive-data">2. Minimize risk of exposing sensitive data</a></h3>
<p>Storing or querying with unencrypted data can have dire consequences, because users may not be made aware immediately.
When in doubt, we should error. It should be clear to the user when an operation gets encrypted and when one doesn't.</p>
<h3 id="3-minimize-api"><a class="header" href="#3-minimize-api">3. Minimize API</a></h3>
<p>The first version of Client Side Encryption is to get signal. If it becomes popular, further improvements will be made
(removing mongocryptd process, support for more queries, better performance). But the public API we provide now will
stick around for the long-term. So let's keep it minimal to accomplish our goals.</p>
<h3 id="how-did-we-arrive-at-this-api"><a class="header" href="#how-did-we-arrive-at-this-api">How did we arrive at this API?</a></h3>
<p>The API for client side encryption underwent multiple iterations during the design process.</p>
<h4 id="why-is-client-side-encryption-configured-on-a-mongoclient"><a class="header" href="#why-is-client-side-encryption-configured-on-a-mongoclient">Why is client side encryption configured on a MongoClient?</a></h4>
<p>There is state that must be shared among all auto encrypted collections: the MongoClient to mongocryptd and the handle
to libmongocrypt (because key caching + JSONSchema caching occurs in libmongocrypt).</p>
<h4 id="why-not-make-auto-encryption-opt-in"><a class="header" href="#why-not-make-auto-encryption-opt-in">Why not make auto encryption "opt-in"?</a></h4>
<p>Because auto encryption is specified with a collection JSONSchema, we cannot auto encrypt database or client operations.
So we cannot know if the user is passing sensitive data as a filter to a database/client change stream or a currentOp
command for example. We also must always fail on view operations. We considered making auto encryption opt-in for
collections. But we decided against this. It is much simpler for users to enable auto encryption without enumerating all
collections with encryption in the common case of using remote JSONSchemas.</p>
<p>Note, this takes the trade-off of a better user experience over less safety. If a user mistakenly assumes that auto
encryption occurs on a database, or on a collection doing a <code>$(graph)lookup</code> on a collection with auto encryption, they
may end up sending unencrypted data.</p>
<h4 id="why-are-auto-encrypted-collections-configured-at-level-of-mongoclient"><a class="header" href="#why-are-auto-encrypted-collections-configured-at-level-of-mongoclient">Why are auto encrypted collections configured at level of MongoClient?</a></h4>
<p>In a previous iteration of the design, we proposed enabling auto encryption only in db.getCollection() for better
usability. But this better aligns with our design principles.</p>
<ul>
<li>Safer. Users won't forget to enable auto encryption on one call to db.getCollection()</li>
<li>Easier. It only requires changing MongoClient code instead of every db.getCollection()</li>
</ul>
<h4 id="why-do-we-have-a-separate-top-level-type-for-clientencryption"><a class="header" href="#why-do-we-have-a-separate-top-level-type-for-clientencryption">Why do we have a separate top level type for ClientEncryption?</a></h4>
<p>The encrypt/decrypt and createDataKey functions were originally placed on MongoClient. But, then we'd have API that
depends on optional configuration. A new top level type seemed warranted.</p>
<h4 id="why-not-pass-the-clientencryption-into-dbgetcollection-to-enable-auto-encryption"><a class="header" href="#why-not-pass-the-clientencryption-into-dbgetcollection-to-enable-auto-encryption">Why not pass the ClientEncryption into db.getCollection() to enable auto encryption?</a></h4>
<p>As it is now, a ClientEncryption and a MongoClient cannot share state (libmongocrypt handle or MongoClient to
mongocryptd). Foreseeably, they could share state if auto encryption was enabled by passing a ClientEncryption object
like:</p>
<pre><code class="language-javascript">db.getCollection("coll", { autoEncrypt: { clientEncryption: clientEncryption } })
</code></pre>
<p>But this would require a MongoCollection to peek into the internals of a ClientEncryption object. This is messy and
language dependent to implement and makes mocking out the ClientEncryption difficult for tests.</p>
<h4 id="why-do-we-need-to-pass-a-client-to-create-a-clientencryption"><a class="header" href="#why-do-we-need-to-pass-a-client-to-create-a-clientencryption">Why do we need to pass a client to create a ClientEncryption?</a></h4>
<p>We need to support an external key vault collection (i.e. on another MongoDB cluster).</p>
<h4 id="why-are-extraoptions-and-kmsproviders-maps"><a class="header" href="#why-are-extraoptions-and-kmsproviders-maps">Why are extraOptions and kmsProviders maps?</a></h4>
<p>Because we don't want AWS as part of the public types and we don't want to put <a href="client-side-encryption/client-side-encryption.html#mongocryptd">mongocryptd</a> and
<a href="client-side-encryption/client-side-encryption.html#crypt_shared">crypt_shared</a> options as types since mongocryptd is an implementation detail we'd like to hide as much
as possible.</p>
<h4 id="why-is-there-a-bypassautoencryption"><a class="header" href="#why-is-there-a-bypassautoencryption">Why is there a bypassAutoEncryption?</a></h4>
<p>bypassAutoEncryption still supports auto decryption. In cases where <a href="client-side-encryption/client-side-encryption.html#mongocryptd">mongocryptd</a> or
<a href="client-side-encryption/client-side-encryption.html#crypt_shared">crypt_shared</a> cannot analyze a query, it's still useful to provide auto decryption. Just like static
program analysis cannot always prove that a runtime invariant holds,
<a href="client-side-encryption/client-side-encryption.html#mongocryptd">mongocryptd</a>/<a href="client-side-encryption/client-side-encryption.html#crypt_shared">crypt_shared</a> cannot always prove that a query will be safe with respect to
encryption at runtime.</p>
<h3 id="why-not-require-compatibility-between-mongocryptd-and-the-server"><a class="header" href="#why-not-require-compatibility-between-mongocryptd-and-the-server">Why not require compatibility between mongocryptd and the server?</a></h3>
<p>It isn't necessary or unsafe if mongocryptd parses an old version of MQL. Consider what happens when we add a new
operator, <code>$newOperator</code>. If it properly encrypts a value in the <code>$newOperator</code> expression and sends it to an old server
that doesn't have <code>$newOperator</code>, that's a mistake but not a security hole. Also if the app passes a query with
<code>$newOperator</code> to mongocryptd, and mongocryptd doesn't know about <code>$newOperator</code>, then it will error,
<code>"Unrecognized operator $newOperator"</code> or something. Also a mistake, not a security hole.</p>
<p>So long as mongocryptd errors on unrecognized expressions, we don't need version compatibility between the mongocryptd
and server for the sake of security.</p>
<h3 id="why-cache-keys"><a class="header" href="#why-cache-keys">Why cache keys?</a></h3>
<p>We can't re-fetch the key on each operation, the performance goal for this project requires us to cache. We do need a
revocation mechanism, based upon periodic checking from the client. Initially this window will not be configurable.</p>
<h3 id="why-require-including-a-c-library"><a class="header" href="#why-require-including-a-c-library">Why require including a C library?</a></h3>
<ul>
<li>libmongocrypt deduplicates a lot of the work: JSONSchema cache, KMS message construction/parsing, key caching, and
encryption/decryption.</li>
<li>Our "best-effort" of storing decrypted key material securely is best accomplished with a C library.</li>
<li>Having crypto done in one centralized C library makes it much easier to audit the crypto code.</li>
</ul>
<h3 id="why-warn-if-a-local-schema-does-not-have-encrypted-fields"><a class="header" href="#why-warn-if-a-local-schema-does-not-have-encrypted-fields">Why warn if a local schema does not have encrypted fields?</a></h3>
<p>Because that is the only use of local schemas. No other JSONSchema validators have any function. It's likely the user
misconfigured encryption.</p>
<h3 id="why-limit-to-one-top-level-jsonschema"><a class="header" href="#why-limit-to-one-top-level-jsonschema">Why limit to one top-level <code>$jsonSchema</code>?</a></h3>
<ul>
<li>If we allow siblings, we can run into cases where the user specifies a top-level <code>$and/$or</code> or any arbitrary
match-expression that could have nested <code>$jsonSchema</code>'s.</li>
<li>Furthermore, the initial versions of <a href="client-side-encryption/client-side-encryption.html#mongocryptd">mongocryptd</a> and <a href="client-side-encryption/client-side-encryption.html#crypt_shared">crypt_shared</a> are only
implementing query analysis when the validator consists of a single <code>$jsonSchema</code> predicate. This helps to simplify
the <a href="client-side-encryption/client-side-encryption.html#mongocryptd">mongocryptd</a> and <a href="client-side-encryption/client-side-encryption.html#crypt_shared">crypt_shared</a> logic, and unifies it with the case where users
configure their schemas directly in the driver.</li>
</ul>
<h3 id="why-not-allow-schemas-to-be-configured-at-runtime"><a class="header" href="#why-not-allow-schemas-to-be-configured-at-runtime">Why not allow schemas to be configured at runtime?</a></h3>
<p>We could have something like Collection::setEncryptionSchema(), but users can simply recreate the client to set new
local schemas.</p>
<h3 id="why-not-support-other-aws-auth-mechanisms"><a class="header" href="#why-not-support-other-aws-auth-mechanisms">Why not support other AWS auth mechanisms?</a></h3>
<p>We could potentially authenticate against AWS in a more sophisticated way, like read credentials from ~/.aws/credentials
or assuming a role with EC2 instance metadata. But we've decided to implement the simplest authentication mechanism for
v1, and defer more sophisticated ones as future work.</p>
<h3 id="why-not-pass-a-uri-for-external-key-vault-collections-instead-of-a-mongoclient"><a class="header" href="#why-not-pass-a-uri-for-external-key-vault-collections-instead-of-a-mongoclient">Why not pass a URI for external key vault collections instead of a MongoClient?</a></h3>
<p>Some configuration on a MongoClient can only be done programmatically. E.g. in Java TLS configuration can only be done
at runtime since it is abstracted in an SSLContext which cannot be accessed or altered by the driver.</p>
<h3 id="what-happened-to-multiple-key-vault-collections"><a class="header" href="#what-happened-to-multiple-key-vault-collections">What happened to multiple key vault collections?</a></h3>
<p>An earlier revision of this specification supported multiple active key vaults with the notion of a "key vault
collection alias". The key vault collection alias identified one of possibly many key vault collections that stored the
key to decrypt the ciphertext. However, enforcing one key vault collection is a reasonable restriction for users. There
isn't clear value in having multiple key vault collections. And having active multiple key vault collections is not
necessary to migrate key vault collections.</p>
<h3 id="why-auto-encrypt-a-command-instead-of-a-wire-protocol-message"><a class="header" href="#why-auto-encrypt-a-command-instead-of-a-wire-protocol-message">Why auto encrypt a command instead of a wire protocol message?</a></h3>
<ul>
<li>It is significantly easier to implement communication in drivers if libmongocrypt gives back BSON object that can be
passed to run command.</li>
<li>mongocryptd cannot return document sequences, so it will return an array of documents anyway.</li>
<li>Though it is foreseeable that a driver can take the final result of encryption and turn it into an OP_MSG document
sequence, it does not seem worthwhile to impose extra complexity in this case.</li>
</ul>
<h3 id="why-is-a-failure-to-decrypt-always-an-error"><a class="header" href="#why-is-a-failure-to-decrypt-always-an-error">Why is a failure to decrypt always an error?</a></h3>
<p>In the original design we proposed <em>not</em> to error if decryption failed due to a missing key. But, it's not clear this is
a needed functionality, it goes against our principle of "Minimize API", and there's a simple recourse for users: bypass
mongocryptd and explicitly decrypt instead.</p>
<h3 id="why-are-there-no-apm-events-for-mongocryptd"><a class="header" href="#why-are-there-no-apm-events-for-mongocryptd">Why are there no APM events for mongocryptd?</a></h3>
<p>Though it may be helpful for debugging to expose APM events for mongocryptd, mongocryptd is an implementation detail
we'd like to have the freedom to remove in the future. So we want to expose mongocryptd as little as possible.</p>
<h3 id="why-arent-we-creating-a-unique-index-in-the-key-vault-collection"><a class="header" href="#why-arent-we-creating-a-unique-index-in-the-key-vault-collection">Why aren't we creating a unique index in the key vault collection?</a></h3>
<p>There should be a unique index on the <code>keyAltNames</code> field with a partial index filter for only documents where
<code>keyAltNames</code> exists. Although GridFS automatically creates indexes as a convenience upon first write, it has been
problematic before due to requiring the <code>createIndex</code> privilege, which a user might not have if they are just querying
the key vault collection with find and adding keys with insert.</p>
<p>See also <a href="https://www.mongodb.com/docs/manual/reference/privilege-actions/#mongodb-authaction-createIndex">https://www.mongodb.com/docs/manual/reference/privilege-actions/#mongodb-authaction-createIndex</a>.</p>
<h3 id="why-do-operations-on-views-fail"><a class="header" href="#why-do-operations-on-views-fail">Why do operations on views fail?</a></h3>
<p>Currently, the driver does not resolve the entire view pipeline, which would be necessary to know the schema of the
underlying collection. But, the driver does know whether or not a namespace is a view based on the response to
listCollections. And the driver will run listCollections on all namespaces omitted from the schemaMap.</p>
<h3 id="why-is-a-42-server-required"><a class="header" href="#why-is-a-42-server-required">Why is a 4.2 server required?</a></h3>
<p>Limiting to 4.2 reduces testing complexity. Additionally The <code>encrypt</code> subdocument in JSON schema is only supported on
4.2 or higher servers. Although not technically necessary for client side encryption, it does provide a fallback against
accidentally sending unencrypted data from misconfigured clients.</p>
<h3 id="why-are-serverselectiontryonce-and-cooldownms-disabled-for-single-threaded-drivers-connecting-to-mongocryptd"><a class="header" href="#why-are-serverselectiontryonce-and-cooldownms-disabled-for-single-threaded-drivers-connecting-to-mongocryptd">Why are serverSelectionTryOnce and cooldownMS disabled for single-threaded drivers connecting to mongocryptd?</a></h3>
<p>By default, single threaded clients set serverSelectionTryOnce to true, which means server selection fails if a topology
scan fails the first time (i.e. it will not make repeat attempts until serverSelectionTimeoutMS expires). This behavior
is overridden since there may be a small delay between spawning mongocryptd (which the driver may be responsible for)
and for mongocryptd to listen on sockets. See the Server Selection spec description of
<a href="client-side-encryption/../server-selection/server-selection.html#serverselectiontryonce">serverSelectionTryOnce</a>.</p>
<p>Similarly, single threaded clients will by default wait for 5 second cooldown period after failing to connect to a
server before making another attempt. Meaning if the first attempt to mongocryptd fails to connect, then the user would
observe a 5 second delay. This is not configurable in the URI, so this must be overridden internally. Since mongocryptd
is a local process, there should only be a very short delay after spawning mongocryptd for it to start listening on
sockets. See the SDAM spec description of
<a href="client-side-encryption/../server-discovery-and-monitoring/server-monitoring.html#cooldownms">cooldownMS</a>.</p>
<p>Because single threaded drivers may exceed <code>serverSelectionTimeoutMS</code> by the duration of the topology scan,
<code>connectTimeoutMS</code> is also reduced.</p>
<h3 id="whats-the-deal-with-metadataclient-keyvaultclient-and-the-internal-client"><a class="header" href="#whats-the-deal-with-metadataclient-keyvaultclient-and-the-internal-client">What's the deal with metadataClient, keyVaultClient, and the internal client?</a></h3>
<p>When automatically encrypting a command, the driver runs:</p>
<ul>
<li>a <code>listCollections</code> command to determine if the target collection has a remote schema. This uses the <code>metadataClient</code>.</li>
<li>a <code>find</code> against the key vault collection to fetch keys. This uses the <code>keyVaultClient</code>.</li>
</ul>
<h4 id="why-not-reuse-the-parent-mongoclient-when-maxpoolsize-is-limited"><a class="header" href="#why-not-reuse-the-parent-mongoclient-when-maxpoolsize-is-limited">Why not reuse the parent MongoClient when maxPoolSize is limited?</a></h4>
<p>These operations MUST NOT reuse the same connection pool as the parent <code>MongoClient</code> configured with automatic
encryption to avoid possible deadlock situations.</p>
<p>Drivers supporting a connection pool (see
<a href="client-side-encryption/../connection-monitoring-and-pooling/connection-monitoring-and-pooling.html">CMAP specification</a>) support an option for
limiting the connection pool size: <code>maxPoolSize</code>.</p>
<p>Drivers need to check out a connection before serializing the command. If the <code>listCollections</code> or <code>find</code> command during
automatic encryption uses the same connection pool as the parent MongoClient, the application is susceptible to
deadlocks.</p>
<p>Using the same connection pool causes automatic encryption to check out multiple connections from the pool when
processing a single command. If maxPoolSize=1, this is an immediate deadlock. If maxPoolSize=2, and two threads check
out the first connection, they will deadlock attempting to check out the second.</p>
<h4 id="why-is-keyvaultclient-an-exposed-option-but-metadataclient-private"><a class="header" href="#why-is-keyvaultclient-an-exposed-option-but-metadataclient-private">Why is keyVaultClient an exposed option, but metadataClient private?</a></h4>
<p>The <code>keyVaultClient</code> supports the use case where the key vault collection is stored on a MongoDB cluster separate from
the data-bearing cluster.</p>
<p>The <code>metadataClient</code> is only used for <code>listCollections</code> against the data-bearing cluster.</p>
<p><code>listCollections</code> responses are cached by libmongocrypt for one minute.</p>
<p>The use pattern of the <code>metadataClient</code> will likely greatly differ from the parent <code>MongoClient</code>. So it is configured
with <code>minPoolSize=0</code>.</p>
<p>The <code>metadataClient</code> is not an exposed option because a user could misconfigure it to point to another MongoDB cluster,
which could be a security risk.</p>
<h4 id="why-is-the-metadataclient-not-needed-if-bypassautoencryptiontrue"><a class="header" href="#why-is-the-metadataclient-not-needed-if-bypassautoencryptiontrue">Why is the metadataClient not needed if bypassAutoEncryption=true</a></h4>
<p>JSON schema data is only needed for automatic encryption but not for automatic decryption. <code>listCollections</code> is not run
when <code>bypassAutoEncryption</code> is <code>true</code>, making a metadataClient unnecessary.</p>
<h3 id="why-are-commands-sent-to-mongocryptd-on-collections-without-encrypted-fields"><a class="header" href="#why-are-commands-sent-to-mongocryptd-on-collections-without-encrypted-fields">Why are commands sent to mongocryptd on collections without encrypted fields?</a></h3>
<p>If a <code>MongoClient</code> is configured with automatic encryption, all commands on collections listed as <code>AUTOENCRYPT</code> in
<a href="client-side-encryption/client-side-encryption.html#libmongocrypt-auto-encryption-allow-list">libmongocrypt: Auto Encryption Allow-List</a> undergo the automatic encryption
process. Even if the collection does not have an associated schema, the command is sent to mongocryptd as a safeguard. A
collection may not have encrypted fields, but a command on the collection may could have sensitive data as part of the
command arguments. For example:</p>
<pre><code class="language-javascript">db.publicData.aggregate([
   {$lookup: {from: "privateData", localField: "_id", foreignField: "_id", as: "privateData"}},
   {$match: {"privateData.ssn": "123-45-6789"}},
])
</code></pre>
<p>The <code>publicData</code> collection does not have encrypted fields, but the <code>privateData</code> collection does. mongocryptd rejects
an aggregate with <code>$lookup</code> since there is no mechanism to determine encrypted fields of joined collections.</p>
<h3 id="why-do-kms-providers-require-tls-options"><a class="header" href="#why-do-kms-providers-require-tls-options">Why do KMS providers require TLS options?</a></h3>
<p>Drivers authenticate to KMIP servers with the client certificate presented in TLS connections.</p>
<p>This specification assumes that TLS connections to KMIP servers may require different TLS options than TLS connections
to MongoDB servers.</p>
<p>KMIP support in the MongoDB server is a precedent. The server supports <code>--kmipServerCAFile</code> and
<code>--kmipClientCertificateFile</code> to configure the encrypted storage engine KMIP. See
<a href="https://www.mongodb.com/docs/manual/tutorial/configure-encryption/">https://www.mongodb.com/docs/manual/tutorial/configure-encryption/</a>.</p>
<p>TLS options may be useful for the AWS, Azure, and GCP KMS providers in a case where the default trust store does not
include the needed CA certificates.</p>
<h3 id="why-is-it-an-error-to-have-an-fle-1-and-queryable-encryption-field-in-the-same-collection"><a class="header" href="#why-is-it-an-error-to-have-an-fle-1-and-queryable-encryption-field-in-the-same-collection">Why is it an error to have an FLE 1 and Queryable Encryption field in the same collection?</a></h3>
<p>There is no technical limitation to having a separate FLE field and Queryable Encryption field in the same collection.
Prohibiting FLE and Queryable Encryption in the same collection reduces complexity. From the product perspective, a
random FLE field and a non-queryable Queryable Encryption field have the same behavior and similar security guarantees.
A deterministic FLE field leaks more information then a deterministic Queryable Encryption field. There is not a
compelling use case to use both FLE and Queryable Encryption in the same collection.</p>
<h3 id="is-it-an-error-to-set-schemamap-and-encryptedfieldsmap"><a class="header" href="#is-it-an-error-to-set-schemamap-and-encryptedfieldsmap">Is it an error to set schemaMap and encryptedFieldsMap?</a></h3>
<p>No. FLE and Queryable Encryption fields can coexist in different collections. The same collection cannot be in the
<code>encryptedFieldsMap</code> and <code>schemaMap</code>. <a href="client-side-encryption/client-side-encryption.html#libmongocrypt">libmongocrypt</a> will error if the same collection is specified in
a <code>schemaMap</code> and <code>encryptedFieldsMap</code>.</p>
<h3 id="why-is-bypassqueryanalysis-needed"><a class="header" href="#why-is-bypassqueryanalysis-needed">Why is bypassQueryAnalysis needed?</a></h3>
<p>Commands containing payloads for encrypted indexed fields require a top-level "encryptionInformation" field for the
server processing. <code>bypassQueryAnalysis</code> enables the use case of Explicit Encryption without the MongoDB Enterprise
Advanced licensed <a href="client-side-encryption/client-side-encryption.html#crypt_shared">crypt_shared</a> library or mongocryptd process.</p>
<p>Here is an example:</p>
<pre><code class="language-go">// No MongoDB Enterprise Advanced licensed 'crypt_shared' shared library.
aeo := options.AutoEncryption().
   SetKeyVaultNamespace("keyvault.datakeys").
   SetEncryptedFieldsMap(efcMap).
   SetKmsProviders(kmsProviders).
   SetBypassQueryAnalysis(true)

co := options.Client().
   ApplyURI(uri).
   SetAutoEncryptionOptions(aeo)

encryptedClient, err := mongo.Connect(ctx, co)
defer encryptedClient.Disconnect(ctx)
if err != nil {
   log.Fatalf("error in Connect: %v", err)
}

coll := encryptedClient.Database("foo").Collection("bar")
// Explicit Encrypt an Queryable Encryption Indexed Field.
eo := options.Encrypt().
   SetEncryptIndexType(options.EncryptIndexEquality)
ciphertext, err := ce.Encrypt(ctx, val, eo)
// In InsertOne, libmongocrypt appends "encryptionInformation" to the insert command.
_, err = coll.InsertOne(ctx, bson.D{{"encryptedIndexed", ciphertext}})
if err != nil {
   log.Fatalf("error in InsertOne: %v", err)
}
</code></pre>
<p>A rejected alternative to adding <code>bypassQueryAnalysis</code> is to change the behavior of <code>bypassAutoEncryption</code>.
<code>bypassQueryAnalysis</code> is distinct from <code>bypassAutoEncryption</code>. <code>bypassAutoEncryption</code> bypasses all of libmongocrypt for
commands. Changing the behavior of <code>bypassAutoEncryption</code> could harm performance (e.g. by serializing as smaller
documents).</p>
<h3 id="why-does-rewrapmanydatakey-return-rewrapmanydatakeyresult-instead-of-bulkwriteresult"><a class="header" href="#why-does-rewrapmanydatakey-return-rewrapmanydatakeyresult-instead-of-bulkwriteresult">Why does rewrapManyDataKey return RewrapManyDataKeyResult instead of BulkWriteResult?</a></h3>
<p><code>rewrapManyDataKey</code> is risky as it performs both a find and an update on the key vault collection. Using
<code>RewrapManyDataKeyResult</code> allows new fields to be added in the future and more easily deprecate the wrapped
<code>BulkWriteResult</code> if necessary.</p>
<h3 id="why-does-clientencryption-have-key-management-functions-when-drivers-can-use-existing-crud-operations-instead"><a class="header" href="#why-does-clientencryption-have-key-management-functions-when-drivers-can-use-existing-crud-operations-instead">Why does ClientEncryption have key management functions when Drivers can use existing CRUD operations instead?</a></h3>
<p>The key management functions are added for parity with mongosh to reduce friction between conducting operations using
mongosh and a Driver. Their inclusion assumes their value for users outweighs their cost of implementation and
maintenance.</p>
<h3 id="why-are-the-querytype-and-algorithm-options-a-string"><a class="header" href="#why-are-the-querytype-and-algorithm-options-a-string">Why are the QueryType and Algorithm options a String?</a></h3>
<p>Using an enum to represent QueryType was considered and rejected in
<a href="https://jira.mongodb.org/browse/DRIVERS-2352">DRIVERS-2352</a>.</p>
<p>A string value helps with future compatibility. When new values of QueryType and IndexType are added in libmongocrypt,
users would only need to upgrade libmongocrypt, and not the driver, to use the new values.</p>
<h3 id="why-is-there-an-encryptexpression-helper"><a class="header" href="#why-is-there-an-encryptexpression-helper">Why is there an encryptExpression helper?</a></h3>
<p>Querying a range index requires encrypting a lower bound (value for <code>$gt</code> or <code>$gte</code>) and upper bound (value for <code>$lt</code> or
<code>$lte</code>) payload. A rejected alternative API is to encrypt the lower and upper bound payloads separately. The lower and
upper bound payloads must have a unique matching UUID. The lower and upper bound payloads are unique. This API requires
handling the UUID and distinguishing the upper and lower bounds. Here are examples showing possible errors:</p>
<pre><code class="language-javascript">uuid = UUID()
lOpts = EncryptOpts(
   keyId=keyId, algorithm="range", queryType="range", uuid=uuid, bound="lower")
lower = clientEncryption.encrypt (value=30, lOpts)
uOpts = EncryptOpts(
   keyId=keyId, algorithm="range", queryType="range", uuid=uuid, bound="upper")
upper = clientEncryption.encrypt (value=40, uOpts)

# Both bounds match UUID ... OK
db.coll.find_one ({"age": {"$gt": lower, "$lt": upper }})

# Upper bound is used as a lower bound ... ERROR!
db.coll.find_one ({"age": {"$gt": upper }})

lower2 = clientEncryption.encrypt (value=35, lOpts)

# UUID is re-used ... ERROR!
db.coll.find_one ({ "$or": [
   {"age": {"$gt": lower, "$lt": upper }},
   {"age": {"$gt": lower2 }}
]})

# UUID does not match between lower and upper bound ... ERROR!
db.coll.find_one ({ "age": {"$gt": lower2, "$lt": upper }})
</code></pre>
<p>Requiring an Aggregate Expression or Match Expression hides the UUID and handles both bounds.</p>
<p>Returning an Aggregate Expression or Match Expression as a BSON document motivated adding a new
<code>ClientEncryption.encryptExpression()</code> helper. <code>ClientEncryption.encrypt()</code> cannot be reused since it returns a Binary.</p>
<p>To limit scope, only <code>$and</code> is supported. Support for other operators <code>($eq, $in)</code> can be added in the future if
desired.</p>
<h3 id="why-do-on-demand-kms-credentials-not-support-named-kms-providers"><a class="header" href="#why-do-on-demand-kms-credentials-not-support-named-kms-providers">Why do on-demand KMS credentials not support named KMS providers?</a></h3>
<p>libmongocrypt supports supplying KMS providers credentials on-demand. This enables obtaining credentials from the host
machine. Supporting on-demand credentials was added as part of these projects:
<a href="https://jira.mongodb.org/browse/DRIVERS-2280">DRIVERS-2280</a> ("aws"),
<a href="https://jira.mongodb.org/browse/DRIVERS-2377">DRIVERS-2377</a> ("gcp"),
<a href="https://jira.mongodb.org/browse/DRIVERS-2411">DRIVERS-2411</a> ("azure").</p>
<p>On-demand credentials are primarily intended to support passing credentials assigned in an environment. Supporting
on-demand credentials for more than one KMS provider of the same type is not expected to be useful. Supporting on-demand
KMS credentials would require added work in drivers inspecting the KMS providers when obtaining credentials, as well as
additional test coverage. Supporting on-demand KMS credentials for named KMS providers can be considered as future work
if needed.</p>
<h3 id="what-is-the-kmip-delegated-option"><a class="header" href="#what-is-the-kmip-delegated-option">What is the KMIP <code>delegated</code> option?</a></h3>
<p>By default, the KMS will retrieve the key encryption key from the KMIP server and use it to encrypt the data key. If the
<code>delegated</code> option is set to true (recommended), the KMIP server will instead perform encryption and decryption locally,
ensuring that the key encryption key never leaves the server.</p>
<h2 id="future-work-16"><a class="header" href="#future-work-16">Future work</a></h2>
<h3 id="make-libmonogocrypt-cache-window-configurable"><a class="header" href="#make-libmonogocrypt-cache-window-configurable">Make libmonogocrypt cache window configurable</a></h3>
<p>There's a principle at MongoDB, "no knobs", that we should honor wherever possible. Configurability is bad, mandating
one well-chosen value is good. But if our default caching behavior is discovered unsuitable for some use cases we may
add configuration as part of future work.</p>
<h3 id="apm-events-for-encryption-or-key-service-interaction"><a class="header" href="#apm-events-for-encryption-or-key-service-interaction">APM events for encryption or key service interaction</a></h3>
<p>APM events include the encrypted data before it is sent to the server, or before it is decrypted in a reply. Therefore,
app developers can determine whether or not encryption occurred by inspecting the values in their command monitoring
events. However, it might be useful to offer separate "encryption" and "decryption" events, as well as interactions with
the key service.</p>
<h3 id="remove-mongocryptd"><a class="header" href="#remove-mongocryptd">Remove mongocryptd</a></h3>
<p>A future version plans to remove the <a href="client-side-encryption/client-side-encryption.html#mongocryptd">mongocryptd</a> process and fold the logic into <code>libmongocrypt</code> using
the <a href="client-side-encryption/client-side-encryption.html#crypt_shared">crypt_shared</a> library. Therefore, this spec mandates that drivers use <code>libmongocrypt</code> to abstract
encryption logic, deduplicate work, and to provide a simpler future path to removing <a href="client-side-encryption/client-side-encryption.html#mongocryptd">mongocryptd</a>.</p>
<h3 id="support-external-key-vault-collection-discovery"><a class="header" href="#support-external-key-vault-collection-discovery">Support external key vault collection discovery</a></h3>
<p>The only way to configure an external key vault collection is by passing a MongoClient.</p>
<p>For apps like Compass, where it may not be possible for users to configure this app side, there should ideally be enough
information in the database to decrypt data. (Excluding KMS credentials, which are still passed as MongoClient options).</p>
<p>We may want to store a URI to the external key vault collection somewhere in the data bearing cluster, so clients can
connect to the external key vault collection without additional user supplied configuration.</p>
<h3 id="batch-listcollections-requests-on-expired-schema-cache-entries"><a class="header" href="#batch-listcollections-requests-on-expired-schema-cache-entries">Batch listCollections requests on expired schema cache entries</a></h3>
<p>Currently libmongocrypt will refresh schemas one at a time.</p>
<h3 id="add-a-maximum-size-for-the-jsonschemakey-cache"><a class="header" href="#add-a-maximum-size-for-the-jsonschemakey-cache">Add a maximum size for the JSONSchema/key cache.</a></h3>
<p>They're unbounded currently.</p>
<h3 id="recalculate-message-size-bounds-dynamically"><a class="header" href="#recalculate-message-size-bounds-dynamically">Recalculate message size bounds dynamically</a></h3>
<p>Instead of using one reduced maxMessageSizeBytes, libmongocrypt could hide the complexity of properly resplitting bulk
writes after encryption. It could use a simple back-off algorithm: try marking a command with maxMessageSizeBytes=24MB.
If after marking we determine that's too large, try again with maxMessageSizeBytes=12MB and so on. And in the end
libmongocrypt would create multiple OP_MSGs to send.</p>
<h3 id="support-sessions-in-key-management-functions"><a class="header" href="#support-sessions-in-key-management-functions">Support sessions in key management functions</a></h3>
<p>Key management functions currently assume there are no concurrent accesses of the key vault collection being operated
on. To support concurrent access of the key vault collection, the key management functions may be overloaded to take an
explicit session parameter as described in the <a href="client-side-encryption/../sessions/driver-sessions.html">Drivers Sessions Specification</a>.</p>
<h2 id="changelog-41"><a class="header" href="#changelog-41">Changelog</a></h2>
<ul>
<li>
<p>2024-07-29: Document range as stable.</p>
</li>
<li>
<p>2024-07-22: Make <code>trimFactor</code> and <code>sparsity</code> optional.</p>
</li>
<li>
<p>2024-06-13: Document range as unstable.</p>
</li>
<li>
<p>2024-05-31: Replace rangePreview with range.</p>
</li>
<li>
<p>2024-03-20: Add <code>delegated</code> option to "kmip" KMS provider</p>
</li>
<li>
<p>2024-02-27: Migrated from reStructuredText to Markdown.</p>
</li>
<li>
<p>2024-01-10: Add named KMS providers</p>
</li>
<li>
<p>2023-03-30: Remove ECC collection</p>
</li>
<li>
<p>2023-02-01: Replace <code>DataKeyOpts</code> with <code>masterKey</code> in <code>createEncryptedCollection</code>.</p>
</li>
<li>
<p>2023-01-31: <code>createEncryptedCollection</code> does not check AutoEncryptionOptions for the encryptedFieldsMap.</p>
</li>
<li>
<p>2023-01-30: Return <code>encryptedFields</code> on <code>CreateCollection</code> error.</p>
</li>
<li>
<p>2023-01-26: Use <a href="client-side-encryption/client-side-encryption.html#GetEncryptedFields">GetEncryptedFields</a> in more helpers.</p>
</li>
<li>
<p>2022-11-30: Add <code>Range</code>.</p>
</li>
<li>
<p>2022-11-28: Permit <code>tlsDisableOCSPEndpointCheck</code> in KMS TLS options.</p>
</li>
<li>
<p>2022-11-27: Fix typo for references to <code>cryptSharedLibRequired</code> option.</p>
</li>
<li>
<p>2022-11-10: Defined a <code>CreateEncryptedCollection</code> helper for creating new encryption keys automatically for the
queryable encrypted fields in a new collection.</p>
</li>
<li>
<p>2022-11-07: Reformat changelog.</p>
</li>
<li>
<p>2022-11-04: Permit global cache for Azure credentials.</p>
</li>
<li>
<p>2022-10-26: Do not connect to <code>mongocryptd</code> if shared library is loaded.</p>
</li>
<li>
<p>2022-10-11: Specify a timeout on Azure IMDS HTTP requests and fix the resource URL</p>
</li>
<li>
<p>2022-10-05: Remove spec front matter and <code>versionadded</code> RST macros (since spec version was removed)</p>
</li>
<li>
<p>2022-09-26: Add behavior for automatic Azure KeyVault credentials for <code>kmsProviders</code>.</p>
</li>
<li>
<p>2022-09-09: Prohibit <code>rewrapManyDataKey</code> with libmongocrypt &lt;= 1.5.1.</p>
</li>
<li>
<p>2022-07-20: Add behavior for automatic GCP credential loading in <code>kmsProviders</code>.</p>
</li>
<li>
<p>2022-06-30: Add behavior for automatic AWS credential loading in <code>kmsProviders</code>.</p>
</li>
<li>
<p>2022-06-29: Clarify bulk write operation expectations for <code>rewrapManyDataKey()</code>.</p>
</li>
<li>
<p>2022-06-27: Remove <code>createKey</code>.</p>
</li>
<li>
<p>2022-06-24: Clean up kmsProviders to use more TypeScript-like type definitions.</p>
</li>
<li>
<p>2022-06-23: Make <code>RewrapManyDataKeyResult.bulkWriteResult</code> optional.</p>
</li>
<li>
<p>2022-06-16: Change <code>QueryType</code> to a string.</p>
</li>
<li>
<p>2022-06-15: Clarify description of date fields in key documents.</p>
</li>
<li>
<p>2022-06-08: Add <code>Queryable Encryption</code> to abstract.</p>
</li>
<li>
<p>2022-06-02: Rename <code>FLE 2</code> to <code>Queryable Encryption</code></p>
</li>
<li>
<p>2022-05-31: Rename <code>csfle</code> to <code>crypt_shared</code></p>
</li>
<li>
<p>2022-05-27: Define ECC, ECOC, and ESC acronyms within encryptedFields</p>
</li>
<li>
<p>2022-05-26: Clarify how <code>encryptedFields</code> interacts with <code>create</code> and <code>drop</code> commands</p>
</li>
<li>
<p>2022-05-24: Add key management API functions</p>
</li>
<li>
<p>2022-05-18: Add createKey and rewrapManyDataKey</p>
</li>
<li>
<p>2022-05-11: Update create state collections to use clustered collections. Drop data collection after state collection.</p>
</li>
<li>
<p>2022-05-03: Add queryType, contentionFactor, and "Indexed" and "Unindexed" to algorithm.</p>
</li>
<li>
<p>2022-04-29: Add bypassQueryAnalysis option</p>
</li>
<li>
<p>2022-04-11: Document the usage of the new <code>csfle</code> library (Note: Later renamed to <code>crypt_shared</code>)</p>
</li>
<li>
<p>2022-02-24: Rename Versioned API to Stable API</p>
</li>
<li>
<p>2022-01-19: Require that timeouts be applied per the CSOT spec</p>
</li>
<li>
<p>2021-11-04: Add "kmip" KMS provider</p>
</li>
<li>
<p>2021-04-08: Updated to use hello and legacy hello</p>
</li>
<li>
<p>2021-01-22: Add sessionToken option to "aws" KMS provider</p>
</li>
<li>
<p>2020-12-12: Add metadataClient option and internal client</p>
</li>
<li>
<p>2020-10-19: Add "azure" and "gcp" KMS providers</p>
</li>
<li>
<p>2019-10-11: Add "endpoint" to AWS masterkey</p>
</li>
<li>
<p>2019-12-17: Clarified <code>bypassAutoEncryption</code> and managing <code>mongocryptd</code></p>
</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="bson-binary-encrypted"><a class="header" href="#bson-binary-encrypted">BSON Binary Encrypted</a></h1>
<ul>
<li>Status: Accepted</li>
<li>Minimum Server Version: 4.2</li>
</ul>
<hr />
<h2 id="abstract-40"><a class="header" href="#abstract-40">Abstract</a></h2>
<p>Client side encryption requires a new binary subtype to store (1) encrypted ciphertext with metadata, and (2) binary
markings indicating what values must be encrypted in a document. (1) is stored in the server, but (2) is only used in
the communication protocol between libmongocrypt and mongocryptd described in
<a href="bson-binary-encrypted/../client-side-encryption/client-side-encryption.html">Driver Spec: Client Side Encryption Encryption</a>.</p>
<h2 id="meta-40"><a class="header" href="#meta-40">META</a></h2>
<p>The keywords "MUST", "MUST NOT", "REQUIRED", "SHALL", "SHALL NOT", "SHOULD", "SHOULD NOT", "RECOMMENDED", "MAY", and
"OPTIONAL" in this document are to be interpreted as described in <a href="https://www.ietf.org/rfc/rfc2119.txt">RFC 2119</a>.</p>
<h2 id="specification-37"><a class="header" href="#specification-37">Specification</a></h2>
<p>This spec introduces a new BSON binary subtype with value 6. The binary has multiple formats determined by the first
byte, but are all related to client side encryption. The first byte indicates the type and layout of the remaining data.</p>
<p>All values are represented in little endian. The payload is generally optimized for storage size. The exception is the
intent-to-encrypt markings which are only used between libmongocrypt and mongocryptd and never persisted.</p>
<pre><code class="language-typescript">struct {
   uint8 subtype;
   [more data - see individual type definitions]
}
</code></pre>
<div class="table-wrapper"><table><thead><tr><th></th><th></th><th></th></tr></thead><tbody>
<tr><td><strong>Name</strong></td><td><strong>Type</strong></td><td><strong>Description</strong></td></tr>
<tr><td>subtype</td><td>uint8</td><td>Type of blob format.</td></tr>
</tbody></table>
</div><div class="table-wrapper"><table><thead><tr><th></th><th></th><th></th></tr></thead><tbody>
<tr><td><strong>Type</strong></td><td><strong>Name</strong></td><td><strong>Blob Description</strong></td></tr>
<tr><td>0</td><td>Intent-to-encrypt marking.</td><td>Contains unencrypted data that will be encrypted (by libmongocrypt) along with metadata describing how to encrypt it.</td></tr>
<tr><td>1</td><td>AEAD_AES_CBC_HMAC_SHA512 deterministic ciphertext.</td><td>The metadata and encrypted data for deterministic encrypted data.</td></tr>
<tr><td>2</td><td>AEAD_AES_CBC_HMAC_SHA512 randomized ciphertext.</td><td>The metadata and encrypted data for random encrypted data.</td></tr>
</tbody></table>
</div>
<h3 id="type-0-intent-to-encrypt-marking-1"><a class="header" href="#type-0-intent-to-encrypt-marking-1">Type 0: Intent-to-encrypt marking</a></h3>
<pre><code class="language-typescript">struct {
   uint8 subtype = 0;
   [ bson ];
}
</code></pre>
<p>bson is the raw bytes of the following BSON document:</p>
<div class="table-wrapper"><table><thead><tr><th></th><th></th><th></th><th></th></tr></thead><tbody>
<tr><td><strong>Name</strong></td><td><strong>Long Name</strong></td><td><strong>Type</strong></td><td><strong>Description</strong></td></tr>
<tr><td>v</td><td>value</td><td>any</td><td>Value to encrypt.</td></tr>
<tr><td>a</td><td>algorithm</td><td>int32</td><td>Encryption algorithm to use. Same as fle_blob_subtype: 1 for deterministic, 2 for randomized.</td></tr>
<tr><td>ki</td><td>keyId</td><td>UUID</td><td>Optional. Used to query the key vault by _id. If omitted, then "ka" must be specified.</td></tr>
<tr><td>ka</td><td>keyAltName</td><td>string</td><td>Optional. Used to query the key vault by keyAltName. If omitted, then "ki" must be specified.</td></tr>
</tbody></table>
</div>
<h3 id="types-1-and-2-ciphertext-1"><a class="header" href="#types-1-and-2-ciphertext-1">Types 1 and 2: Ciphertext</a></h3>
<pre><code class="language-typescript">struct {
   uint8 subtype = (1 or 2);
   uint8 key_uuid[16];
   uint8 original_bson_type;
   uint8 ciphertext[ciphertext_length];
}
</code></pre>
<div class="table-wrapper"><table><thead><tr><th></th><th></th></tr></thead><tbody>
<tr><td><strong>Name</strong></td><td><strong>Description</strong></td></tr>
<tr><td>subtype</td><td>Type of blob format and encryption algorithm used.</td></tr>
<tr><td>key_uuid[16]</td><td>The value of _id for the key used to decrypt the ciphertext.</td></tr>
<tr><td>original_bson_type</td><td>The byte representing the original BSON type of the encrypted data.</td></tr>
<tr><td>ciphertext[]</td><td>The encrypted ciphertext (includes IV prepended).</td></tr>
</tbody></table>
</div>
<h2 id="test-plan-31"><a class="header" href="#test-plan-31">Test Plan</a></h2>
<p>Covered in <a href="bson-binary-encrypted/../client-side-encryption/client-side-encryption.html">Driver Spec: Client Side Encryption Encryption</a>.</p>
<h2 id="design-rationale-26"><a class="header" href="#design-rationale-26">Design Rationale</a></h2>
<h3 id="why-not-use-a-new-bson-type"><a class="header" href="#why-not-use-a-new-bson-type">Why not use a new BSON type?</a></h3>
<p>An alternative to using a new binary subtype would be introducing a new BSON type. This would be a needless backwards
breaking change. Since FLE is largely a client side feature, it should be possible to store encrypted data in old
servers.</p>
<p>Plus, encrypted ciphertext is inherently a binary blob. Packing metadata inside isolates all of the encryption related
data into one BSON value that can be treated as an opaque blob in most contexts.</p>
<h3 id="why-not-use-separate-bson-binary-subtypes-instead-of-a-nested-subtype"><a class="header" href="#why-not-use-separate-bson-binary-subtypes-instead-of-a-nested-subtype">Why not use separate BSON binary subtypes instead of a nested subtype?</a></h3>
<p>If we used separate subtypes, we'd need to reserve three (and possibly more in the future) of our 124 remaining
subtypes.</p>
<p><span id="intent-to-encrypt"></span></p>
<h3 id="why-are-intent-to-encrypt-markings-needed"><a class="header" href="#why-are-intent-to-encrypt-markings-needed">Why are intent-to-encrypt markings needed?</a></h3>
<p>Intent-to-encrypt markings provide a simple way for mongocryptd to communicate what values need to be encrypted to
libmongocrypt. Alternatively, mongocryptd could respond with a list of field paths. But field paths are difficult to
make unambiguous, and even the query language is not always consistent.</p>
<h3 id="what-happened-to-the-key-vault-alias"><a class="header" href="#what-happened-to-the-key-vault-alias">What happened to the "key vault alias"?</a></h3>
<p>In an earlier revision of this specification the notion of a "key vault alias". The key vault alias identified one of
possibly many key vaults that stored the key to decrypt the ciphertext. However, enforcing one key vault is a reasonable
restriction for users. Users can migrate from one key vault to another without ciphertext data including a key vault
alias. If we find a future need for multiple key vaults, we can easily introduce a new format with the fle_blob_subtype.</p>
<p>Why distinguish between "deterministic" and "randomized" when they contain the same fields?</p>
<p>Deterministic and randomized ciphertext supports different behavior. Deterministic ciphertext supports exact match
queries but randomized does not.</p>
<h3 id="why-is-the-original-bson-type-not-encrypted"><a class="header" href="#why-is-the-original-bson-type-not-encrypted">Why is the original BSON type not encrypted?</a></h3>
<p>Exposing the underlying BSON type gives some validation of the data that is encrypted. A JSONSchema on the server can
validate that the underlying encrypted BSON type is correct.</p>
<h2 id="reference-implementation-22"><a class="header" href="#reference-implementation-22">Reference Implementation</a></h2>
<p>libmongocrypt and mongocryptd will be the reference implementation of how BSON binary subtype 6 is used.</p>
<h2 id="security-implication-3"><a class="header" href="#security-implication-3">Security Implication</a></h2>
<p>It would be a very bad security flaw if intent-to-encrypt markings were confused with ciphertexts. This could lead to a
marking inadvertently being stored on a server – meaning that plaintext is stored where ciphertext should have been.</p>
<p>Therefore, the leading byte of the BSON binary subtype distinguishes between marking and ciphertext.</p>
<h2 id="changelog-42"><a class="header" href="#changelog-42">Changelog</a></h2>
<ul>
<li>2024-03-04: Migrated from reStructuredText to Markdown.</li>
<li>2022-10-05: Remove spec front matter and create changelog.</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="command-logging-and-monitoring"><a class="header" href="#command-logging-and-monitoring">Command Logging and Monitoring</a></h1>
<ul>
<li>Status: Accepted</li>
<li>Minimum Server Version: 2.4</li>
</ul>
<hr />
<h2 id="specification-38"><a class="header" href="#specification-38">Specification</a></h2>
<p>The command logging and monitoring specification defines a set of behaviour in the drivers for providing runtime
information about commands in log messages as well as in events which users can consume programmatically, either
directly or by integrating with third-party APM libraries.</p>
<h3 id="definitions-10"><a class="header" href="#definitions-10">Definitions</a></h3>
<h4 id="meta-41"><a class="header" href="#meta-41">META</a></h4>
<p>The keywords "MUST", "MUST NOT", "REQUIRED", "SHALL", "SHALL NOT", "SHOULD", "SHOULD NOT", "RECOMMENDED", "MAY", and
"OPTIONAL" in this document are to be interpreted as described in <a href="https://www.ietf.org/rfc/rfc2119.txt">RFC 2119</a>.</p>
<h4 id="terms-27"><a class="header" href="#terms-27">Terms</a></h4>
<p><strong>Document</strong></p>
<p>The term <code>Document</code> refers to the implementation in the driver's language of a BSON document.</p>
<h3 id="guidance-5"><a class="header" href="#guidance-5">Guidance</a></h3>
<h4 id="documentation-6"><a class="header" href="#documentation-6">Documentation</a></h4>
<p>The documentation provided in code below is merely for driver authors and SHOULD NOT be taken as required documentation
for the driver.</p>
<h4 id="messages-and-events"><a class="header" href="#messages-and-events">Messages and Events</a></h4>
<p>All drivers MUST implement the specified event types as well as log messages.</p>
<p>Implementation details are noted in the comments when a specific implementation is required. Within each event and log
message, all properties are REQUIRED unless noted otherwise.</p>
<h4 id="naming-4"><a class="header" href="#naming-4">Naming</a></h4>
<p>All drivers MUST name types, properties, and log message values as defined in the following sections. Exceptions to this
rule are noted in the appropriate section. Class and interface names may vary according to the driver and language best
practices.</p>
<h4 id="publishing--subscribing"><a class="header" href="#publishing--subscribing">Publishing &amp; Subscribing</a></h4>
<p>The driver SHOULD publish events in a manner that is standard to the driver's language publish/subscribe patterns and is
not strictly mandated in this specification.</p>
<p>Similarly, as described in the <a href="command-logging-and-monitoring/../logging/logging.html#implementation-requirements">logging specification</a> the driver
SHOULD emit log messages in a manner that is standard for the language.</p>
<h4 id="guarantees"><a class="header" href="#guarantees">Guarantees</a></h4>
<p>The driver MUST guarantee that every <code>CommandStartedEvent</code> has either a correlating <code>CommandSucceededEvent</code> or
<code>CommandFailedEvent</code>, and that every "command started" log message has either a correlating "command succeeded" log
message or "command failed" log message.</p>
<p>The driver MUST guarantee that the <code>requestId</code> of the <code>CommandStartedEvent</code> and the corresponding
<code>CommandSucceededEvent</code> or <code>CommandFailedEvent</code> is the same, and that the <code>requestId</code> of the "command started" log
message and the corresponding "command succeeded" or "command failed" log message is the same.</p>
<h4 id="unacknowledgedacknowledged-writes"><a class="header" href="#unacknowledgedacknowledged-writes">Unacknowledged/Acknowledged Writes</a></h4>
<p>Unacknowledged writes must provide a <code>CommandSucceededEvent</code> and a "command succeeded" log message with a <code>{ ok: 1 }</code>
reply.</p>
<p>A non-default write concern MUST be included in the published command. The default write concern is not required to be
included.</p>
<h4 id="succeeded-or-failed"><a class="header" href="#succeeded-or-failed">Succeeded or Failed</a></h4>
<p>Commands that executed on the server and return a status of <code>{ ok: 1.0 }</code> are considered successful commands and MUST
generate a <code>CommandSucceededEvent</code> and "command succeeded" log message. Commands that have write errors are included
since the actual command did succeed, only writes failed.</p>
<h4 id="error-handling-4"><a class="header" href="#error-handling-4">Error Handling</a></h4>
<p>If an exception occurs while sending the operation to the server, the driver MUST generate a <code>CommandFailedEvent</code> and
"command failed" log message with the exception or message, and re-raise the exception.</p>
<h4 id="bulk-writes"><a class="header" href="#bulk-writes">Bulk Writes</a></h4>
<p>This specification defines the monitoring and logging of individual commands and in that respect MUST generate events
and log messages for each command a bulk write executes. Each of these commands, however, must be linked together via
the same <code>operationId</code>.</p>
<h4 id="implementation-notes-5"><a class="header" href="#implementation-notes-5">Implementation Notes</a></h4>
<p>When a driver sends an OP_MSG with a document sequence, it MUST include the document sequence as a BSON array in
<code>CommandStartedEvent.command</code>. The array's field name MUST be the OP_MSG sequence identifier. For example, if the driver
sends an <code>update</code> command using OP_MSG, and sends a document sequence as a separate section of payload type 1 with
identifier <code>updates</code>, the driver MUST include the documents as a BSON array in <code>CommandStartedEvent.command</code> with field
name <code>updates</code>.</p>
<p>See "Why are document sequences included as BSON arrays?" in the <a href="command-logging-and-monitoring/command-logging-and-monitoring.html#rationale">rationale</a>.</p>
<h3 id="rationale-4"><a class="header" href="#rationale-4">Rationale</a></h3>
<p><em>1. Why are commands with</em> <code>{ ok: 1 }</code> <em>treated as successful and</em> <code>{ ok: 0 }</code> <em>as failed?</em></p>
<p>The specification is consistent with what the server deems as a successful or failed command and reports this as so.
This also allows for server changes around this behaviour in the future to require no change in the drivers to continue
to be compliant.</p>
<p>The command listener API is responsible only for receiving and handling events sent from the lowest level of the driver,
and is only about informing listeners about what commands are sent and what replies are received. As such, it would be
innappropiate at this level for a driver to execute custom logic around particular commands to determine what failure or
success means for a particular command. Implementers of the API are free to handle these events as they see fit, which
may include code that further interprets replies to specific commands based on the presence or absence of other fields
in the reply beyond the <code>ok</code> field.</p>
<p><em>2. Why are document sequences included as BSON arrays?</em></p>
<p>The OP_MSG wire protocol was introduced in MongoDB 3.6, with document sequences as an optimization for bulk writes. We
have chosen to represent these OP_MSGs as single command documents for now, until a need for a more accurate (and
perhaps better-performing) command monitoring API for document sequences has been demonstrated.</p>
<p><em>3. Why is BSON serialization and deserialization optional to include in durations?</em></p>
<p>Different drivers will serialize and deserialize BSON at different levels of the driver architecture. For example, some
parts of a command (e.g. inserted document structs) could be pre-encoded early into a "raw" BSON form and the final
command with late additions like a session ID could encoded just before putting it on the wire.</p>
<p>Rather than specify a duration rule that would be hard to satisfy consistently, we allow duration to include BSON
serialization/deserialization or not based on the architecture needs of each driver.</p>
<h3 id="security"><a class="header" href="#security">Security</a></h3>
<p>Some commands and replies will contain sensitive data relating to authentication.</p>
<p>In order to not risk leaking this data to external sources or logs, for these commands:</p>
<ul>
<li>
<p>The "command" field in <code>CommandStartedEvent</code> and "command started" log messages MUST be replaced with an empty BSON
document.</p>
</li>
<li>
<p>The "reply" field in <code>CommandSucceededEvent</code> and "command succeeded" log messages MUST be replaced with an empty BSON
document.</p>
</li>
<li>
<p>If the error is a server-side error, the "failure" field in <code>CommandFailedEvent</code> and "command failed" log messages
MUST have all fields besides the following redacted:</p>
<ul>
<li><code>code</code></li>
<li><code>codeName</code></li>
<li><code>errorLabels</code></li>
</ul>
<p>The exact implementation of redaction is flexible depending on the type the driver uses to represent a failure in
these events and log messages. For example, a driver could choose to set all properties besides these on an error
object to null. Alternatively, a driver that uses strings to represent failures could replace relevant portions of the
string with "REDACTED".</p>
</li>
</ul>
<p>The list of sensitive commands is as follows:</p>
<div class="table-wrapper"><table><thead><tr><th>Command</th></tr></thead><tbody>
<tr><td><code>authenticate</code></td></tr>
<tr><td><code>saslStart</code></td></tr>
<tr><td><code>saslContinue</code></td></tr>
<tr><td><code>getnonce</code></td></tr>
<tr><td><code>createUser</code></td></tr>
<tr><td><code>updateUser</code></td></tr>
<tr><td><code>copydbgetnonce</code></td></tr>
<tr><td><code>copydbsaslstart</code></td></tr>
<tr><td><code>copydb</code></td></tr>
<tr><td><code>hello</code> (or legacy hello) when <code>speculativeAuthenticate</code> is present</td></tr>
</tbody></table>
</div>
<p>See the <a href="command-logging-and-monitoring/../mongodb-handshake/handshake.html">MongoDB Handshake spec</a> for more information on <code>hello</code> and legacy hello.
Note that legacy hello has two different letter casings that must be taken into account. See the previously mentioned
MongoDB Handshake spec for details.</p>
<h3 id="events-api"><a class="header" href="#events-api">Events API</a></h3>
<p>See the <a href="command-logging-and-monitoring/../load-balancers/load-balancers.html#events">Load Balancer Specification</a> for details on the <code>serviceId</code> field.</p>
<pre><code class="language-typescript">interface CommandStartedEvent {

  /**
   * Returns the command.
   */
  command: Document;

  /**
   * Returns the database name.
   */
  databaseName: String;

  /**
   * Returns the command name.
   */
  commandName: String;

  /**
   * Returns the driver generated request id.
   */
  requestId: Int64;

  /**
   * Returns the driver generated operation id. This is used to link events together such
   * as bulk write operations. OPTIONAL.
   */
  operationId: Int64;

  /**
   * Returns the connection id for the command. For languages that do not have this,
   * this MUST return the driver equivalent which MUST include the server address and port.
   * The name of this field is flexible to match the object that is returned from the driver.
   */
  connectionId: ConnectionId;

  /**
   * Returns the server connection id for the command. The server connection id is distinct from
   * the connection id and is returned by the hello or legacy hello response as "connectionId"
   * from the server on 4.2+. Drivers MUST use an Int64 to represent the server connection ID value.
   */
  serverConnectionId: Optional&lt;Int64&gt;;

  /**
   * Returns the service id for the command when the driver is in load balancer mode.
   * For drivers that wish to include this in their ConnectionId object, this field is
   * optional.
   */
  serviceId: Optional&lt;ObjectId&gt;;
}

interface CommandSucceededEvent {

  /**
   * Returns the execution time of the event in the highest possible resolution for the platform.
   * The calculated value MUST be the time to send the message and receive the reply from the server
   * and MAY include BSON serialization and/or deserialization. The name can imply the units in which the
   * value is returned, i.e. durationMS, durationNanos.
   */
  duration: Int64;

  /**
   * Returns the command reply.
   */
  reply: Document;

  /**
   * Returns the command name.
   */
  commandName: String;

  /**
   * Returns the database name.
   */
  databaseName: String;

  /**
   * Returns the driver generated request id.
   */
  requestId: Int64;

  /**
   * Returns the driver generated operation id. This is used to link events together such
   * as bulk write operations. OPTIONAL.
   */
  operationId: Int64;

  /**
   * Returns the connection id for the command. For languages that do not have this,
   * this MUST return the driver equivalent which MUST include the server address and port.
   * The name of this field is flexible to match the object that is returned from the driver.
   */
  connectionId: ConnectionId;

  /**
   * Returns the server connection id for the command. The server connection id is distinct from
   * the connection id and is returned by the hello or legacy hello response as "connectionId"
   * from the server on 4.2+. Drivers MUST use an Int64 to represent the server connection ID value.
   */
  serverConnectionId: Optional&lt;Int64&gt;;

  /**
   * Returns the service id for the command when the driver is in load balancer mode.
   * For drivers that wish to include this in their ConnectionId object, this field is
   * optional.
   */
  serviceId: Optional&lt;ObjectId&gt;;
}

interface CommandFailedEvent {

  /**
   * Returns the execution time of the event in the highest possible resolution for the platform.
   * The calculated value MUST be the time to send the message and receive the reply from the server
   * and MAY include BSON serialization and/or deserialization. The name can imply the units in which the
   * value is returned, i.e. durationMS, durationNanos.
   */
  duration: Int64;

  /**
   * Returns the command name.
   */
  commandName: String;

  /**
   * Returns the database name.
   */
  databaseName: String;

  /**
   * Returns the failure. Based on the language, this SHOULD be a message string, exception
   * object, or error document.
   */
  failure: String,Exception,Document;

  /**
   * Returns the client generated request id.
   */
  requestId: Int64;

  /**
   * Returns the driver generated operation id. This is used to link events together such
   * as bulk write operations. OPTIONAL.
   */
  operationId: Int64;

  /**
   * Returns the connection id for the command. For languages that do not have this,
   * this MUST return the driver equivalent which MUST include the server address and port.
   * The name of this field is flexible to match the object that is returned from the driver.
   */
  connectionId: ConnectionId;

  /**
   * Returns the server connection id for the command. The server connection id is distinct from
   * the connection id and is returned by the hello or legacy hello response as "connectionId"
   * from the server on 4.2+. Drivers MUST use an Int64 to represent the server connection ID value.
   */
  serverConnectionId: Optional&lt;Int64&gt;;

  /**
   * Returns the service id for the command when the driver is in load balancer mode.
   * For drivers that wish to include this in their ConnectionId object, this field is
   * optional.
   */
  serviceId: Optional&lt;ObjectId&gt;;
}
</code></pre>
<h3 id="log-messages-1"><a class="header" href="#log-messages-1">Log Messages</a></h3>
<p>Please refer to the <a href="command-logging-and-monitoring/../logging/logging.html">logging specification</a> for details on logging implementations in general,
including log levels, log components, and structured versus unstructured logging.</p>
<p>Drivers MUST support logging of command information via the following types of log messages. These messages MUST be
logged at <code>Debug</code> level and use the <code>command</code> log component.</p>
<p>The log messages are intended to match the information contained in the events above. Drivers MAY implement command
logging support via an event subscriber if it is convenient to do so.</p>
<p>The types used in the structured message definitions below are demonstrative, and drivers MAY use similar types instead
so long as the information is present (e.g. a double instead of an integer, or a string instead of an integer if the
structured logging framework does not support numeric types.)</p>
<p>Drivers MUST not emit command log messages for commands issued as part of the handshake with the server, or heartbeat
commands issued by server monitors.</p>
<h4 id="common-fields-2"><a class="header" href="#common-fields-2">Common Fields</a></h4>
<p>The following key-value pairs MUST be included in all command messages:</p>
<div class="table-wrapper"><table><thead><tr><th>Key</th><th>Suggested Type</th><th>Value</th></tr></thead><tbody>
<tr><td>commandName</td><td>String</td><td>The command name.</td></tr>
<tr><td>databaseName</td><td>String</td><td>The database name.</td></tr>
<tr><td>requestId</td><td>Int</td><td>The driver-generated request ID.</td></tr>
<tr><td>operationId</td><td>Int</td><td>The driver-generated operation ID. Optional; only present if the driver generated operation IDs and this command has one.</td></tr>
<tr><td>driverConnectionId</td><td>Int64</td><td>The driver's ID for the connection used for the command. Note this is NOT the same as <code>CommandStartedEvent.connectionId</code> defined above, but refers to the <code>connectionId</code> defined in the <a href="command-logging-and-monitoring/../connection-monitoring-and-pooling/connection-monitoring-and-pooling.html">connection monitoring and pooling specification</a>. Unlike <code>CommandStartedEvent.connectionId</code> this field MUST NOT contain the host/port; that information MUST be in the following fields, <code>serverHost</code> and <code>serverPort</code>. This field is optional for drivers that do not implement CMAP if they do have an equivalent concept of a connection ID.</td></tr>
<tr><td>serverHost</td><td>String</td><td>The hostname or IP address for the server the command is being run on.</td></tr>
<tr><td>serverPort</td><td>Int</td><td>The port for the server the command is being run on. Optional; not present for Unix domain sockets. When the user does not specify a port and the default (27017) is used, the driver SHOULD include it here.</td></tr>
<tr><td>serverConnectionId</td><td>Int64</td><td>The server's ID for the connection used for the command. Optional; only present for server versions 4.2+. NOTE: Existing drivers may represent this as an Int32 already. For strongly-typed languages, you may have to introduce a new Int64 field and deprecate the old Int32 field. The next major version should remove the old Int32 field.</td></tr>
<tr><td>serviceId</td><td>String</td><td>The hex string representation of the service ID for the command. Optional; only present when the driver is in load balancer mode.</td></tr>
</tbody></table>
</div>
<h4 id="command-started-message"><a class="header" href="#command-started-message">Command Started Message</a></h4>
<p>In addition to the common fields, command started messages MUST contain the following key-value pairs:</p>
<div class="table-wrapper"><table><thead><tr><th>Key</th><th>Suggested Type</th><th>Value</th></tr></thead><tbody>
<tr><td>message</td><td>String</td><td>"Command started"</td></tr>
<tr><td>command</td><td>String</td><td>Relaxed extJSON representation of the command. This document MUST be truncated appropriately according to rules defined in the <a href="command-logging-and-monitoring/../logging/logging.html#configurable-max-document-length">logging specification</a>, and MUST be replaced with an empty document "{ }" if the command is considered sensitive.</td></tr>
</tbody></table>
</div>
<p>The unstructured form SHOULD be as follows, using the values defined in the structured format above to fill in
placeholders as appropriate:</p>
<blockquote>
<p>Command "{{commandName}}" started on database "{{databaseName}}" using a connection with driver-generated ID
{{driverConnectionId}} and server-generated ID {{serverConnectionId}} to {{serverHost}}:{{serverPort}} with service ID
{{serviceId}}. The requestID is {{requestId}} and the operation ID is {{operationId}}. Command: {{command}}</p>
</blockquote>
<h4 id="command-succeeded-message"><a class="header" href="#command-succeeded-message">Command Succeeded Message</a></h4>
<p>In addition to the common fields, command succeeded messages MUST contain the following key-value pairs:</p>
<div class="table-wrapper"><table><thead><tr><th>Key</th><th>Suggested Type</th><th>Value</th></tr></thead><tbody>
<tr><td>message</td><td>String</td><td>"Command succeeded"</td></tr>
<tr><td>durationMS</td><td>Int</td><td>The execution time for the command in milliseconds. The calculated value MUST be the time to send the message and receive the reply from the server and MAY include BSON serialization and/or deserialization.</td></tr>
<tr><td>reply</td><td>String</td><td>Relaxed extJSON representation of the reply. This document MUST be truncated appropriately according to rules defined in the <a href="command-logging-and-monitoring/../logging/logging.html#configurable-max-document-length">logging specification</a>, and MUST be replaced with an empty document "{ }" if the command is considered sensitive.</td></tr>
</tbody></table>
</div>
<p>The unstructured form SHOULD be as follows, using the values defined in the structured format above to fill in
placeholders as appropriate:</p>
<blockquote>
<p>Command "{{commandName}}" succeeded on database "{{databaseName}}" in {{durationMS}} ms using a connection with
driver-generated ID {{driverConnectionId}} and server-generated ID {{serverConnectionId}} to
{{serverHost}}:{{serverPort}} with service ID {{serviceId}}. The requestID is {{requestId}} and the operation ID is
{{operationId}}. Command reply: {{command}}</p>
</blockquote>
<h4 id="command-failed-message"><a class="header" href="#command-failed-message">Command Failed Message</a></h4>
<p>In addition to the common fields, command failed messages MUST contain the following key-value pairs:</p>
<div class="table-wrapper"><table><thead><tr><th>Key</th><th>Suggested Type</th><th>Value</th></tr></thead><tbody>
<tr><td>message</td><td>String</td><td>"Command failed"</td></tr>
<tr><td>durationMS</td><td>Int</td><td>The execution time for the command in milliseconds. The calculated value MUST be the time to send the message and receive the reply from the server and MAY include BSON serialization and/or deserialization.</td></tr>
<tr><td>failure</td><td>Flexible</td><td>The error. The type and format of this value is flexible; see the <a href="command-logging-and-monitoring/../logging/logging.html#representing-errors-in-log-messages">logging specification</a> for details on representing errors in log messages. If the command is considered sensitive, the error MUST be redacted and replaced with a language-appropriate alternative for a redacted error, e.g. an empty string, empty document, or null.</td></tr>
</tbody></table>
</div>
<p>The unstructured form SHOULD be as follows, using the values defined in the structured format above to fill in
placeholders as appropriate:</p>
<blockquote>
<p>Command "{{commandName}}" failed on database "{{databaseName}}" in {{durationMS}} ms using a connection with
driver-generated ID {{driverConnectionId}} and server-generated ID {{serverConnectionId}} to
{{serverHost}}:{{serverPort}} with service ID {{serviceId}}. The requestID is {{requestId}} and the operation ID is
{{operationId}}. Error: {{error}}</p>
</blockquote>
<h3 id="testing"><a class="header" href="#testing">Testing</a></h3>
<p>See the README in the test directory for requirements and guidance.</p>
<h2 id="qa-12"><a class="header" href="#qa-12">Q&amp;A</a></h2>
<h3 id="why-is-the-command-document-only-available-in-the-commandstartevent"><a class="header" href="#why-is-the-command-document-only-available-in-the-commandstartevent">Why is the command document only available in the <code>CommandStartEvent</code>?</a></h3>
<p>Some drivers may realize the command document as raw BSON, treating it as a component of the message transmitted to the
server and stored in an internal buffer. By the time the server's response is received, this buffer may have been
released. Requiring the retention of this buffer until command completion could result in unacceptable performance
penalties, particularly when event listeners are introduced.</p>
<h2 id="changelog-43"><a class="header" href="#changelog-43">Changelog</a></h2>
<ul>
<li>
<p>2024-09-11: Migrated from reStructuredText to Markdown.</p>
</li>
<li>
<p>2015-09-16: Removed <code>limit</code> from find test with options to support 3.2.<br />
Changed find test read preference to
<code>primaryPreferred</code>.</p>
</li>
<li>
<p>2015-10-01: Changed find test with a kill cursors to not run on server versions<br />
greater than 3.0. Added a find test
with no kill cursors command which only runs on 3.1 and higher. Added notes on which tests should run based on server
versions.</p>
</li>
<li>
<p>2015-10-19: Changed batchSize in the 3.2 find tests to expect the remaining value.</p>
</li>
<li>
<p>2015-10-31: Changed find test on 3.1 and higher to ignore being run on sharded clusters.</p>
</li>
<li>
<p>2015-11-22: Specify how to merge OP_MSG document sequences into command-started events.</p>
</li>
<li>
<p>2016-03-29: Added note on guarantee of the request ids.</p>
</li>
<li>
<p>2016-11-02: Added clause for not upconverting commands larger than maxBsonSize.</p>
</li>
<li>
<p>2018-04-16: Made inclusion of BSON serialization/deserialization in command<br />
durations to be optional.</p>
</li>
<li>
<p>2020-02-12: Added legacy hello <code>speculativeAuthenticate</code> to the list of<br />
values that should be redacted.</p>
</li>
<li>
<p>2021-04-15: Added <code>serviceId</code> field to events.</p>
</li>
<li>
<p>2021-05-05: Updated to use hello and legacy hello.</p>
</li>
<li>
<p>2021-08-30: Added <code>serverConnectionId</code> field to <code>CommandStartedEvent</code>,<br />
<code>CommandSucceededEvent</code> and
<code>CommandFailedEvent</code>.</p>
</li>
<li>
<p>2022-05-18: Converted legacy tests to the unified test format.</p>
</li>
<li>
<p>2022-09-02: Remove material that only applies to MongoDB versions &lt; 3.6.</p>
</li>
<li>
<p>2022-10-05: Remove spec front matter and reformat changelog.</p>
</li>
<li>
<p>2022-10-11: Add command logging information and tests.</p>
</li>
<li>
<p>2022-11-16: Update sensitive command tests to only run on server versions where the commands are supported.</p>
</li>
<li>
<p>2022-12-13: Updated log message <code>serverPort</code> field description to clarify drivers should populate it with the<br />
default
port 27017 when relevant. Updated suggested unstructured forms of log messages to more clearly label connection IDs
and use more readable server address representations.</p>
</li>
<li>
<p>2023-03-23: Updated <code>serverConnectionId</code> field to be Int64 as long-running servers can return Int64.</p>
</li>
<li>
<p>2023-06-13: Added <code>databaseName</code> field to <code>CommandFailedEvent</code> and <code>CommandSucceededEvent</code>.<br />
Updated suggested
unstructured forms of log messages reflecting the changes.</p>
</li>
<li>
<p>2023-10-19: Add Q&amp;A section</p>
</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="sdam-logging-and-monitoring-specification"><a class="header" href="#sdam-logging-and-monitoring-specification">SDAM Logging and Monitoring Specification</a></h1>
<ul>
<li>Status: Accepted</li>
<li>Minimum Server Version: 2.4</li>
</ul>
<hr />
<h2 id="abstract-41"><a class="header" href="#abstract-41">Abstract</a></h2>
<p>The SDAM logging and monitoring specification defines a set of behaviors in the driver for providing runtime information
about server discovery and monitoring (SDAM) in log messages, as well as in events that users can consume
programmatically, either directly or by integrating with third-party APM libraries.</p>
<h3 id="definitions-11"><a class="header" href="#definitions-11">Definitions</a></h3>
<h4 id="meta-42"><a class="header" href="#meta-42">META</a></h4>
<p>The keywords "MUST", "MUST NOT", "REQUIRED", "SHALL", "SHALL NOT", "SHOULD", "SHOULD NOT", "RECOMMENDED", "MAY", and
"OPTIONAL" in this document are to be interpreted as described in <a href="https://www.ietf.org/rfc/rfc2119.txt">RFC 2119</a>.</p>
<h4 id="terms-28"><a class="header" href="#terms-28">Terms</a></h4>
<p><code>ServerAddress</code></p>
<blockquote>
<p>The term <code>ServerAddress</code> refers to the implementation in the driver's language of a server host/port pair. This may be
an object or a string. The name of this object is NOT REQUIRED.</p>
</blockquote>
<p><code>TopologyType</code></p>
<blockquote>
<p>The term <code>TopologyType</code> refers to the implementation in the driver's language of a topology type (standalone, sharded,
etc.). This may be a string or object. The name of the object is NOT REQUIRED.</p>
</blockquote>
<p><code>Server</code></p>
<blockquote>
<p>The term <code>Server</code> refers to the implementation in the driver's language of an abstraction of a mongod or mongos
process, or a load balancer, as defined by the <a href="server-discovery-and-monitoring/server-discovery-and-monitoring.html#server">SDAM specification</a>.</p>
</blockquote>
<h3 id="specification-39"><a class="header" href="#specification-39">Specification</a></h3>
<h3 id="guidance-6"><a class="header" href="#guidance-6">Guidance</a></h3>
<h4 id="documentation-7"><a class="header" href="#documentation-7">Documentation</a></h4>
<p>The documentation provided in the code below is merely for driver authors and SHOULD NOT be taken as required
documentation for the driver.</p>
<h4 id="messages-and-events-1"><a class="header" href="#messages-and-events-1">Messages and Events</a></h4>
<p>All drivers MUST implement the specified event types as well as log messages.</p>
<p>Implementation details are noted below when a specific implementation is required. Within each event and log message,
all properties are REQUIRED unless noted otherwise.</p>
<h4 id="naming-5"><a class="header" href="#naming-5">Naming</a></h4>
<p>All drivers MUST name types, properties, and log message values as defined in the following sections. Exceptions to this
rule are noted in the appropriate section. Class and interface names may vary according to the driver and language best
practices.</p>
<h4 id="publishing-and-subscribing"><a class="header" href="#publishing-and-subscribing">Publishing and Subscribing</a></h4>
<p>The driver SHOULD publish events in a manner that is standard to the driver's language publish/subscribe patterns and is
not strictly mandated in this specification.</p>
<p>Similarly, as described in the <a href="server-discovery-and-monitoring/../logging/logging.html#implementation-requirements">logging specification</a> the driver
SHOULD emit log messages in a manner that is standard for the language.</p>
<h3 id="guarantees-1"><a class="header" href="#guarantees-1">Guarantees</a></h3>
<h4 id="event-order-and-concurrency"><a class="header" href="#event-order-and-concurrency">Event Order and Concurrency</a></h4>
<p>Events and log messages MUST be published in the order that their corresponding changes are processed in the driver.
Events MUST NOT be published concurrently for the same topology ID or server ID, but MAY be published concurrently for
differing topology IDs and server IDs.</p>
<h4 id="heartbeats"><a class="header" href="#heartbeats">Heartbeats</a></h4>
<p>The driver MUST guarantee that every <code>ServerHeartbeatStartedEvent</code> has either a correlating
<code>ServerHeartbeatSucceededEvent</code> or <code>ServerHeartbeatFailedEvent</code>, and that every "server heartbeat started" log message
has either a correlating "server heartbeat succeeded" or "server heartbeat failed" log message.</p>
<p>Drivers that use the streaming heartbeat protocol MUST publish a <code>ServerHeartbeatStartedEvent</code> and "server heartbeat
started" log message before attempting to read the next <code>hello</code> or legacy hello exhaust response.</p>
<h4 id="error-handling-5"><a class="header" href="#error-handling-5">Error Handling</a></h4>
<p>If an exception occurs while sending the <code>hello</code> or legacy hello operation to the server, the driver MUST generate a
<code>ServerHeartbeatFailedEvent</code> and "server heartbeat failed" log message with the exception or message and re-raise the
exception. The SDAM mandated retry of the <code>hello</code> or legacy hello call should be visible to consumers.</p>
<h4 id="topology-ids"><a class="header" href="#topology-ids">Topology IDs</a></h4>
<p>These MUST be a unique value that is specific to the Topology for which the events and log messages are emitted. The
language may decide how to generate the value and what type the value is, as long as it is unique to the Topology. The
ID MUST be created once when the Topology is created and remain the same until the Topology is destroyed.</p>
<h4 id="initial-server-description"><a class="header" href="#initial-server-description">Initial Server Description</a></h4>
<p><code>ServerDescription</code> objects MUST be initialized with a default description in an "unknown" state, guaranteeing that the
previous description in the events and log messages will never be null.</p>
<h4 id="initial-topology-description"><a class="header" href="#initial-topology-description">Initial Topology Description</a></h4>
<p>The first <code>TopologyDescriptionChangedEvent</code> to be emitted from a monitored Topology MUST set its <code>previousDescription</code>
property to be a <code>TopologyDescription</code> object in the "unknown" state.</p>
<h3 id="events-api-1"><a class="header" href="#events-api-1">Events API</a></h3>
<p>The first <code>TopologyDescriptionChangedEvent</code> to be emitted from a monitored Topology MUST set its <code>previousDescription</code>
property to be a <code>TopologyDescription</code> object in the "unknown" state.</p>
<h2 id="closing-topology-description"><a class="header" href="#closing-topology-description">Closing Topology Description</a></h2>
<p>When a <code>Topology</code> object or equivalent is being shut-down or closed, the driver MUST change the <code>TopologyDescription</code> to
an "unknown" state.</p>
<hr />
<h2 id="events-api-2"><a class="header" href="#events-api-2">Events API</a></h2>
<p>This specification defines 9 main events that MUST be published in the scenarios described. 6 of these events are the
core behaviour within the cluster lifecycle, and the remaining 3 server heartbeat events are fired from the server
monitor and follow the guidelines for publishing in the command monitoring specification.</p>
<p>Events that MUST be published (with their conditions) are as follows.</p>
<div class="table-wrapper"><table><thead><tr><th>Event Type</th><th>Condition</th></tr></thead><tbody>
<tr><td><code>TopologyOpeningEvent</code></td><td>When a topology description is initialized - this MUST be the first SDAM event fired.</td></tr>
<tr><td><code>ServerOpeningEvent</code></td><td>Published when the server description is instantiated with its defaults, and MUST be the first operation to happen after the defaults are set. This is before the Monitor is created and the Monitor socket connection is opened.</td></tr>
<tr><td><code>ServerDescriptionChangedEvent</code></td><td>When the old server description is not equal to the new server description</td></tr>
<tr><td><code>TopologyDescriptionChangedEvent</code></td><td>When the old topology description is not equal to the new topology description.</td></tr>
<tr><td><code>ServerClosedEvent</code></td><td>Published when the server monitor's connection is closed and the server is shutdown.</td></tr>
<tr><td><code>TopologyClosedEvent</code></td><td>When a topology is shut down - this MUST be the last SDAM event fired.</td></tr>
<tr><td><code>ServerHeartbeatStartedEvent</code></td><td>Published when the server monitor sends its <code>hello</code> or legacy hello call to the server. When the monitor is creating a new connection, this event MUST be published just before the socket is created.</td></tr>
<tr><td><code>ServerHeartbeatSucceededEvent</code></td><td>Published on successful completion of the server monitor's <code>hello</code> or legacy hello call.</td></tr>
<tr><td><code>ServerHeartbeatFailedEvent</code></td><td>Published on failure of the server monitor's <code>hello</code> or legacy hello call, either with an ok: 0 result or a socket exception from the connection.</td></tr>
</tbody></table>
</div>
<pre><code class="language-typescript">/**
 * Published when server description changes, but does NOT include changes to the RTT.
 */
interface ServerDescriptionChangedEvent {

  /**
   * Returns the address (host/port pair) of the server.
   */
  address: ServerAddress;

  /**
   * Returns a unique identifier for the topology.
   */
  topologyId: Object;

  /**
   * Returns the previous server description.
   */
  previousDescription: ServerDescription;

  /**
   * Returns the new server description.
   */
  newDescription: ServerDescription;
}

/**
 * Published when server is initialized.
 */
interface ServerOpeningEvent {

  /**
   * Returns the address (host/port pair) of the server.
   */
  address: ServerAddress;

  /**
   * Returns a unique identifier for the topology.
   */
  topologyId: Object;
}

/**
 * Published when server is closed.
 */
interface ServerClosedEvent {

  /**
   * Returns the address (host/port pair) of the server.
   */
  address: ServerAddress;

  /**
   * Returns a unique identifier for the topology.
   */
  topologyId: Object;
}

/**
 * Published when topology description changes.
 */
interface TopologyDescriptionChangedEvent {

  /**
   * Returns a unique identifier for the topology.
   */
  topologyId: Object;

  /**
   * Returns the old topology description.
   */
  previousDescription: TopologyDescription;

  /**
   * Returns the new topology description.
   */
  newDescription: TopologyDescription;
}

/**
 * Published when topology is initialized.
 */
interface TopologyOpeningEvent {

  /**
   * Returns a unique identifier for the topology.
   */
  topologyId: Object;
}

/**
 * Published when topology is closed.
 */
interface TopologyClosedEvent {

  /**
   * Returns a unique identifier for the topology.
   */
  topologyId: Object;
}

/**
 * Fired when the server monitor's ``hello`` or legacy hello command is started - immediately before
 * the ``hello`` or legacy hello command is serialized into raw BSON and written to the socket.
 * When the monitor is creating a new monitoring connection, this event is fired just before the
 * socket is opened.
 */
interface ServerHeartbeatStartedEvent {

 /**
   * Returns the connection id for the command. The connection id is the unique
   * identifier of the driver's Connection object that wraps the socket. For languages that
   * do not have this object, this MUST a string of "hostname:port" or an object that
   * that contains the hostname and port as attributes.
   *
   * The name of this field is flexible to match the object that is returned from the driver.
   * Examples are, but not limited to, 'address', 'serverAddress', 'connectionId',
   */
  connectionId: ConnectionId;

 /**
   * Determines if this heartbeat event is for an awaitable ``hello`` or legacy hello.
   */
  awaited: Boolean;

}

/**
 * Fired when the server monitor's ``hello`` or legacy hello succeeds.
 */
interface ServerHeartbeatSucceededEvent {

 /**
   * Returns the execution time of the event in the highest possible resolution for the platform.
   * The calculated value MUST be the time to send the message and receive the reply from the server,
   * including BSON serialization and deserialization. The name can imply the units in which the
   * value is returned, i.e. durationMS, durationNanos.
   *
   * When the awaited field is false, the time measurement used MUST be the
   * same measurement used for the RTT calculation. When the awaited field is
   * true, the time measurement is not used for RTT calculation.
   */
  duration: Int64;

  /**
   * Returns the command reply.
   */
  reply: Document;

 /**
   * Returns the connection id for the command. For languages that do not have this,
   * this MUST return the driver equivalent which MUST include the server address and port.
   * The name of this field is flexible to match the object that is returned from the driver.
   */
  connectionId: ConnectionId;

 /**
   * Determines if this heartbeat event is for an awaitable ``hello`` or legacy hello. If
   * true, then the duration field cannot be used for RTT calculation
   * because the command blocks on the server.
   */
  awaited: Boolean;

}

/**
 * Fired when the server monitor's ``hello`` or legacy hello fails, either with an "ok: 0" or a socket exception.
 */
interface ServerHeartbeatFailedEvent {

 /**
   * Returns the execution time of the event in the highest possible resolution for the platform.
   * The calculated value MUST be the time to send the message and receive the reply from the server,
   * including BSON serialization and deserialization. The name can imply the units in which the
   * value is returned, i.e. durationMS, durationNanos.
   */
  duration: Int64;

 /**
   * Returns the failure. Based on the language, this SHOULD be a message string,
   * exception object, or error document.
   */
  failure: String,Exception,Document;

 /**
   * Returns the connection id for the command. For languages that do not have this,
   * this MUST return the driver equivalent which MUST include the server address and port.
   * The name of this field is flexible to match the object that is returned from the driver.
   */
  connectionId: ConnectionId;

 /**
   * Determines if this heartbeat event is for an awaitable ``hello`` or legacy hello. If
   * true, then the duration field cannot be used for RTT calculation
   * because the command blocks on the server.
   */
  awaited: Boolean;
}
</code></pre>
<p>The <code>TopologyDescription</code> object MUST expose the new methods defined in the API below, in order for subscribers to take
action on certain conditions based on the driver options.</p>
<p><code>TopologyDescription</code> objects MAY have additional methods and properties.</p>
<pre><code class="language-typescript">/**
 * Describes the current topology.
 */
interface TopologyDescription {

  /**
   * Determines if the topology has a readable server available. See the table in the
   * following section for behaviour rules.
   */
  hasReadableServer(readPreference: Optional&lt;ReadPreference&gt;): Boolean

  /**
   * Determines if the topology has a writable server available. See the table in the
   * following section for behaviour rules.
   */
  hasWritableServer(): Boolean
}
</code></pre>
<h3 id="determining-if-a-topology-has-readablewritable-servers"><a class="header" href="#determining-if-a-topology-has-readablewritable-servers">Determining If A Topology Has Readable/Writable Servers</a></h3>
<p>The following table describes the rules for determining if a topology type has readable or writable servers. If no read
preference is passed to <code>hasReadableServer</code>, the driver MUST default the value to the default read preference,
<code>primary</code>, or treat the call as if <code>primary</code> was provided.</p>
<div class="table-wrapper"><table><thead><tr><th>Topology Type</th><th><code>hasReadableServer</code></th><th><code>hasWritableServer</code></th></tr></thead><tbody>
<tr><td>Unknown</td><td><code>false</code></td><td><code>false</code></td></tr>
<tr><td>Single</td><td><code>true</code> if the server is available</td><td><code>true</code> if the server is available</td></tr>
<tr><td>ReplicaSetNoPrimary</td><td>Called with <code>primary</code>: <code>false</code>  <br>Called with any other option: uses the read preference to determine if any server in the cluster is suitable for reading.  <br>Called with no option: <code>false</code></td><td><code>false</code></td></tr>
<tr><td>ReplicaSetWithPrimary</td><td>Called with any valid option: uses the read preference to determine if any server in the cluster is suitable for reading.  <br>Called with no option: <code>true</code></td><td><code>true</code></td></tr>
<tr><td>Sharded</td><td><code>true</code> if 1+ servers are available</td><td><code>true</code> if 1+ servers are available</td></tr>
<tr><td>LoadBalanced</td><td><code>true</code></td><td><code>true</code></td></tr>
</tbody></table>
</div>
<h3 id="log-messages-2"><a class="header" href="#log-messages-2">Log Messages</a></h3>
<p>Please refer to the <a href="server-discovery-and-monitoring/../logging/logging.html">logging specification</a> for details on logging implementations in general,
including log levels, log components, and structured versus unstructured logging.</p>
<p>Drivers MUST support logging of SDAM information via the following types of log messages. These messages MUST be logged
at <code>Debug</code> level and use the <code>topology</code> log component.</p>
<p>A number of the log messages are intended to match the information contained in the events above. However, note that a
log message regarding a server description change (which would correspond to <code>ServerDescriptionChangedEvent</code>) has been
intentionally omitted since the information it would contain is redundant with <code>TopologyDescriptionChangedEvent</code> and the
equivalent log message.</p>
<p>Drivers MAY implement SDAM logging support via an event subscriber if it is convenient to do so.</p>
<p>The types used in the structured message definitions below are demonstrative, and drivers MAY use similar types instead
so long as the information is present (e.g. a double instead of an integer, or a string instead of an integer if the
structured logging framework does not support numeric types.)</p>
<h4 id="common-fields-3"><a class="header" href="#common-fields-3">Common Fields</a></h4>
<p>The following key-value pairs are common to all or several log messages and MUST be included in the "applicable
messages":</p>
<div class="table-wrapper"><table><thead><tr><th>Key</th><th>Applicable Messages</th><th>Suggested Type</th><th>Value</th></tr></thead><tbody>
<tr><td>topologyId</td><td>All messages</td><td>Flexible</td><td>The driver's unique ID for this topology as discussed in <a href="server-discovery-and-monitoring/server-discovery-and-monitoring-logging-and-monitoring.html#topology-ids">Topology IDs</a>. The type is flexible depending on the driver's choice of type for topology ID.</td></tr>
<tr><td>serverHost</td><td>Log messages specific to a particular server, including heartbeat-related messages</td><td>String</td><td>The hostname, IP address, or Unix domain socket path for the endpoint the pool is for.</td></tr>
<tr><td>serverPort</td><td>Log messages specific to a particular server, including heartbeat-related messages</td><td>Int</td><td>(Only present for server-specific log messages) The port for the endpoint the pool is for. Optional; not present for Unix domain sockets. When the user does not specify a port and the default (27017) is used, the driver SHOULD include it here.</td></tr>
<tr><td>driverConnectionId</td><td>Heartbeat-related log messages</td><td>Int</td><td>The driver-generated ID for the monitoring connection as defined in the <a href="server-discovery-and-monitoring/../connection-monitoring-and-pooling/connection-monitoring-and-pooling.html">connection monitoring and pooling specification</a>. Unlike <code>connectionId</code> in the above events, this field MUST NOT contain the host/port; that information MUST be in the above fields, <code>serverHost</code> and <code>serverPort</code>. This field is optional for drivers that do not implement CMAP if they do have an equivalent concept of a connection ID.</td></tr>
<tr><td>serverConnectionId</td><td>Heartbeat-related log messages</td><td>Int</td><td>The server's ID for the monitoring connection, if known. This value will be unknown and can be omitted in certain cases, e.g. the first "heartbeat started" message for a monitoring connection. Only present on server versions 4.2+.</td></tr>
</tbody></table>
</div>
<h4 id="starting-topology-monitoring-log-message"><a class="header" href="#starting-topology-monitoring-log-message">"Starting Topology Monitoring" Log Message</a></h4>
<p>This message MUST be published under the same circumstances as a <code>TopologyOpeningEvent</code> as detailed in
<a href="server-discovery-and-monitoring/server-discovery-and-monitoring-logging-and-monitoring.html#events-api">Events API</a>.</p>
<p>In addition to the relevant common fields, these messages MUST contain the following key-value pair:</p>
<div class="table-wrapper"><table><thead><tr><th>Key</th><th>Suggested Type</th><th>Value</th></tr></thead><tbody>
<tr><td>message</td><td>String</td><td>"Starting topology monitoring"</td></tr>
</tbody></table>
</div>
<p>The unstructured form SHOULD be as follows, using the values defined in the structured format above to fill in
placeholders as appropriate:</p>
<blockquote>
<p>Starting monitoring for topology with ID {{topologyId}}</p>
</blockquote>
<h4 id="stopped-topology-monitoring-log-message"><a class="header" href="#stopped-topology-monitoring-log-message">"Stopped Topology Monitoring" Log Message</a></h4>
<p>This message MUST be published under the same circumstances as a <code>TopologyClosedEvent</code> as detailed in
<a href="server-discovery-and-monitoring/server-discovery-and-monitoring-logging-and-monitoring.html#events-api">Events API</a>.</p>
<p>In addition to the relevant common fields, these messages MUST contain the following key-value pair:</p>
<div class="table-wrapper"><table><thead><tr><th>Key</th><th>Suggested Type</th><th>Value</th></tr></thead><tbody>
<tr><td>message</td><td>String</td><td>"Stopped topology monitoring"</td></tr>
</tbody></table>
</div>
<p>The unstructured form SHOULD be as follows, using the values defined in the structured format above to fill in
placeholders as appropriate:</p>
<blockquote>
<p>Stopped monitoring for topology with ID {{topologyId}}</p>
</blockquote>
<h4 id="starting-server-monitoring-log-message"><a class="header" href="#starting-server-monitoring-log-message">"Starting Server Monitoring" Log Message</a></h4>
<p>This message MUST be published under the same circumstances as a <code>ServerOpeningEvent</code> as detailed in
<a href="server-discovery-and-monitoring/server-discovery-and-monitoring-logging-and-monitoring.html#events-api">Events API</a>.</p>
<p>In addition to the relevant common fields, these messages MUST contain the following key-value pair:</p>
<div class="table-wrapper"><table><thead><tr><th>Key</th><th>Suggested Type</th><th>Value</th></tr></thead><tbody>
<tr><td>message</td><td>String</td><td>"Starting server monitoring"</td></tr>
</tbody></table>
</div>
<p>The unstructured form SHOULD be as follows, using the values defined in the structured format above to fill in
placeholders as appropriate:</p>
<blockquote>
<p>Starting monitoring for server {{serverHost}}:{{serverPort}} in topology with ID {{topologyId}}</p>
</blockquote>
<h4 id="stopped-server-monitoring-log-message"><a class="header" href="#stopped-server-monitoring-log-message">"Stopped Server Monitoring" Log Message</a></h4>
<p>This message MUST be published under the same circumstances as a <code>ServerClosedEvent</code> as detailed in
<a href="server-discovery-and-monitoring/server-discovery-and-monitoring-logging-and-monitoring.html#events-api">Events API</a>.</p>
<p>In addition to the relevant common fields, these messages MUST contain the following key-value pair:</p>
<div class="table-wrapper"><table><thead><tr><th>Key</th><th>Suggested Type</th><th>Value</th></tr></thead><tbody>
<tr><td>message</td><td>String</td><td>"Stopped server monitoring"</td></tr>
</tbody></table>
</div>
<p>The unstructured form SHOULD be as follows, using the values defined in the structured format above to fill in
placeholders as appropriate:</p>
<blockquote>
<p>Stopped monitoring for server {{serverHost}}:{{serverPort}} in topology with ID {{topologyId}}</p>
</blockquote>
<h4 id="topology-description-changed-log-message"><a class="header" href="#topology-description-changed-log-message">"Topology Description Changed" Log Message</a></h4>
<p>This message MUST be published under the same circumstances as a <code>TopologyDescriptionChangedEvent</code> as detailed in
<a href="server-discovery-and-monitoring/server-discovery-and-monitoring-logging-and-monitoring.html#events-api">Events API</a>.</p>
<p>In addition to the relevant common fields, these messages MUST contain the following key-value pairs:</p>
<div class="table-wrapper"><table><thead><tr><th>Key</th><th>Suggested Type</th><th>Value</th></tr></thead><tbody>
<tr><td>message</td><td>String</td><td>"Topology description changed"</td></tr>
<tr><td>previousDescription</td><td>String</td><td>A string representation of the previous description of the topology. The format is flexible and could be e.g. the <code>toString()</code> implementation for a driver's topology description type, or an extended JSON representation of the topology object.</td></tr>
<tr><td>newDescription</td><td>String</td><td>A string representation of the new description of the server. The format is flexible and could be e.g. the <code>toString()</code> implementation for a driver's topology description type, or an extended JSON representation of the topology object.</td></tr>
</tbody></table>
</div>
<p>The unstructured form SHOULD be as follows, using the values defined in the structured format above to fill in
placeholders as appropriate:</p>
<blockquote>
<p>Description changed for topology with ID {{topologyId}}. Previous description: {{previousDescription}}. New
description: {{newDescription}}</p>
</blockquote>
<h4 id="server-heartbeat-started-log-message"><a class="header" href="#server-heartbeat-started-log-message">"Server Heartbeat Started" Log Message</a></h4>
<p>This message MUST be published under the same circumstances as a <code>ServerHeartbeatStartedEvent</code> as detailed in
<a href="server-discovery-and-monitoring/server-discovery-and-monitoring-logging-and-monitoring.html#events-api">Events API</a>.</p>
<p>In addition to the relevant common fields, these messages MUST contain the following key-value pairs:</p>
<div class="table-wrapper"><table><thead><tr><th>Key</th><th>Suggested Type</th><th>Value</th></tr></thead><tbody>
<tr><td>message</td><td>String</td><td>"Server heartbeat started"</td></tr>
<tr><td>awaited</td><td>Boolean</td><td>Whether this log message is for an awaitable hello or legacy "hello".</td></tr>
</tbody></table>
</div>
<p>The unstructured form SHOULD be as follows, using the values defined in the structured format above to fill in
placeholders as appropriate:</p>
<blockquote>
<p>Heartbeat started for {{serverHost}}:{{serverPort}} on connection with driver-generated ID {{driverConnectionId}} and
server-generated ID {{serverConnectionId}} in topology with ID {{topologyId}}. Awaited: {{awaited}}</p>
</blockquote>
<h4 id="server-heartbeat-succeeded-log-message"><a class="header" href="#server-heartbeat-succeeded-log-message">"Server Heartbeat Succeeded" Log Message</a></h4>
<p>This message MUST be published under the same circumstances as a <code>ServerHeartbeatSucceededEvent</code> as detailed in
<a href="server-discovery-and-monitoring/server-discovery-and-monitoring-logging-and-monitoring.html#events-api">Events API</a>.</p>
<p>In addition to the relevant common fields, these messages MUST contain the following key-value pairs:</p>
<div class="table-wrapper"><table><thead><tr><th>Key</th><th>Suggested Type</th><th>Value</th></tr></thead><tbody>
<tr><td>message</td><td>String</td><td>"Server heartbeat succeeded"</td></tr>
<tr><td>awaited</td><td>Boolean</td><td>Whether this log message is for an awaitable hello or legacy "hello".</td></tr>
<tr><td>durationMS</td><td>Int</td><td>The execution time for the heartbeat in milliseconds. See <code>ServerHeartbeatSucceededEvent</code> in <a href="server-discovery-and-monitoring/server-discovery-and-monitoring-logging-and-monitoring.html#events-api">Events API</a> for details on calculating this value.</td></tr>
<tr><td>reply</td><td>String</td><td>Relaxed extended JSON representation of the reply to the heartbeat command.</td></tr>
</tbody></table>
</div>
<p>The unstructured form SHOULD be as follows, using the values defined in the structured format above to fill in
placeholders as appropriate:</p>
<blockquote>
<p>Heartbeat succeeded in {{durationMS}} ms for {{serverHost}}:{{serverPort}} on connection with driver-generated ID
{{driverConnectionId}} and server-generated ID {{serverConnectionId}} in topology with ID {{topologyId}}. Awaited:
{{awaited}}. Reply: {{reply}}</p>
</blockquote>
<h4 id="server-heartbeat-failed-log-message"><a class="header" href="#server-heartbeat-failed-log-message">"Server Heartbeat Failed" Log Message</a></h4>
<p>This message MUST be published under the same circumstances as a <code>ServerHeartbeatFailedEvent</code> as detailed in
<a href="server-discovery-and-monitoring/server-discovery-and-monitoring-logging-and-monitoring.html#events-api">Events API</a>.</p>
<p>In addition to the relevant common fields, these messages MUST contain the following key-value pairs:</p>
<div class="table-wrapper"><table><thead><tr><th>Key</th><th>Suggested Type</th><th>Value</th></tr></thead><tbody>
<tr><td>message</td><td>String</td><td>"Server heartbeat failed"</td></tr>
<tr><td>awaited</td><td>Boolean</td><td>Whether this log message is for an awaitable hello or legacy "hello".</td></tr>
<tr><td>durationMS</td><td>Int</td><td>The execution time for the heartbeat in milliseconds. See <code>ServerHeartbeatFailedEvent</code> in <a href="server-discovery-and-monitoring/server-discovery-and-monitoring-logging-and-monitoring.html#events-api">Events API</a> for details on calculating this value.</td></tr>
<tr><td>failure</td><td>Flexible</td><td>The error. The type and format of this value is flexible; see the <a href="server-discovery-and-monitoring/../logging/logging.html#representing-errors-in-log-messages">logging specification</a> for details on representing errors in log messages. If the command is considered sensitive, the error MUST be redacted and replaced with a language-appropriate alternative for a redacted error, e.g. an empty string, empty document, or null.</td></tr>
</tbody></table>
</div>
<p>The unstructured form SHOULD be as follows, using the values defined in the structured format above to fill in
placeholders as appropriate:</p>
<blockquote>
<p>Heartbeat failed in {{durationMS}} ms for {{serverHost}}:{{serverPort}} on connection with driver-generated ID
{{driverConnectionId}} and server-generated ID {{serverConnectionId}} in topology with ID {{topologyId}}. Awaited:
{{awaited}}. Failure: {{failure}}</p>
</blockquote>
<h3 id="tests-2"><a class="header" href="#tests-2">Tests</a></h3>
<p>See the <a href="server-discovery-and-monitoring/tests/monitoring/README.html">README</a>.</p>
<h2 id="changelog-44"><a class="header" href="#changelog-44">Changelog</a></h2>
<ul>
<li>
<p>2024-05-02: Migrated from reStructuredText to Markdown.</p>
</li>
<li>
<p>2024-03-29: Updated to clarify expected initial value of TopologyDescriptionChangedEvent's previousDescription field</p>
</li>
<li>
<p>2024-01-04: Updated to clarify when ServerHeartbeatStartedEvent should be emitted</p>
</li>
<li>
<p>2023-03-31: Renamed to include "logging" in the title. Reorganized contents and made consistent with CLAM spec, and
added requirements for SDAM log messages.</p>
</li>
<li>
<p>2022-10-05: Remove spec front matter and reformat changelog.</p>
</li>
<li>
<p>2021-05-06: Updated to use modern terminology.</p>
</li>
<li>
<p>2020-04-20: Add rules for streaming heartbeat protocol and add "awaited" field to heartbeat events.</p>
</li>
<li>
<p>2018-12-12: Clarified table of rules for readable/writable servers</p>
</li>
<li>
<p>2016-08-31: Added table of rules for determining if topology has readable/writable servers.</p>
</li>
<li>
<p>2016-10-11: TopologyDescription objects MAY have additional methods and properties.</p>
</li>
</ul>
<hr />
<div style="break-before: page; page-break-before: always;"></div><h1 id="logging-1"><a class="header" href="#logging-1">Logging</a></h1>
<ul>
<li>Title: Logging</li>
<li>Status: Accepted</li>
<li>Minimum Server Version: N/A</li>
</ul>
<hr />
<h2 id="abstract-42"><a class="header" href="#abstract-42">Abstract</a></h2>
<p>This specification defines requirements for drivers' logging configuration and behavior.</p>
<h2 id="meta-43"><a class="header" href="#meta-43">META</a></h2>
<p>The keywords "MUST", "MUST NOT", "REQUIRED", "SHALL", "SHALL NOT", "SHOULD", "SHOULD NOT", "RECOMMENDED", "MAY", and
"OPTIONAL" in this document are to be interpreted as described in <a href="https://www.ietf.org/rfc/rfc2119.txt">RFC 2119</a>.</p>
<h2 id="specification-40"><a class="header" href="#specification-40">Specification</a></h2>
<h3 id="terms-29"><a class="header" href="#terms-29">Terms</a></h3>
<p><strong>Structured logging</strong></p>
<p>Structured logging refers to producing log messages in a structured format, i.e. a series of key-value pairs, which can
be converted to external formats such as JSON.</p>
<p><strong>Unstructured logging</strong></p>
<p>Unstructured logging refers to producing string log messages which embed all attached information within that string.</p>
<h3 id="implementation-requirements-1"><a class="header" href="#implementation-requirements-1">Implementation requirements</a></h3>
<p>Drivers SHOULD implement support for logging in a manner that is idiomatic for their language and ecosystem.</p>
<h4 id="minimizing-required-code-changes"><a class="header" href="#minimizing-required-code-changes">Minimizing Required Code Changes</a></h4>
<p>If possible, drivers SHOULD support the following configuration requirements in a manner that does not require any
changes to an application's source code, and in the case of compiled languages, does not require recompilation. However,
if that is impossible to do without conflicting with idiomatic logging patterns for the language ecosystem, it is
acceptable for a driver to require minimal changes to enable logging, such as recompiling with a feature flag specified,
or passing a logging configuration to a <code>MongoClient</code> constructor. In that case, drivers SHOULD strive to minimize the
amount of code change needed.</p>
<p>Drivers SHOULD take advantage of built-in support for logging configuration within logging frameworks or their language
ecosystem if available. If unavailable, drivers MUST support configuration via the listed fallback implementation
methods.</p>
<p>In addition to supporting configuration without code changes/recompilation, drivers MAY additionally provide support for
enabling and configuring logging via their API in a manner that does require code changes, and MAY support additional
configuration options beyond those defined in this specification.</p>
<p>For languages/ecosystems where libraries depend on only a logging interface (for example, the Java driver and
<a href="https://www.slf4j.org/">SLF4J</a>) and application developers must choose a log handler, the requirements MAY be
considered satisfied if there is a log handler available in the ecosystem which users can select that satisfies the
requirements. Similarly, the requirements MAY be considered satisfied if the driver provides an integration with a
logging framework which satisfies the requirements.</p>
<h4 id="per-component-configuration-of-log-levels"><a class="header" href="#per-component-configuration-of-log-levels">Per-Component Configuration of Log Levels</a></h4>
<p>Drivers MUST support enabling logging and specifying the minimum severity level for emitted messages on a per-component
level, for each component defined below in the <a href="logging/logging.html#components">Components</a> section.</p>
<blockquote>
<p><strong>Fallback implementation method</strong>: Support configuration via environment variables corresponding to each component,
as defined in <a href="logging/logging.html#components">Components</a>, as well as via the environment variable <code>MONGODB_LOG_ALL</code>.</p>
<p>Each of these variables may be set to any of the values defined below in <a href="logging/logging.html#log-severity-levels">Log Severity Levels</a>
to indicate the minimum severity level at which messages should be emitted for the corresponding component, or in the
case of <code>MONGODB_LOG_ALL</code>, all components. Setting a value for <code>MONGODB_LOG_ALL</code> is equivalent to setting that value
for all of the per-component variables.</p>
<p>If <code>MONGODB_LOG_ALL</code> is specified in addition to one or more component variables, the component variable(s) MUST take
precedence.</p>
<p>The default is to not log anything.</p>
<p>If a variable is set to an invalid value, it MUST be treated as if it were not specified at all, and the driver MAY
attempt to warn the user about the misconfiguration via a log message or otherwise but MUST NOT throw an exception.</p>
</blockquote>
<h4 id="configurable-log-destination"><a class="header" href="#configurable-log-destination">Configurable Log Destination</a></h4>
<p>Drivers MUST support configuring where log messages should be output, including the options:</p>
<ul>
<li>
<p>stdout</p>
</li>
<li>
<p>stderr</p>
</li>
<li>
<p>Output file (path MUST be configurable). For languages that are not relying on a logging interface or framework to
handle file support, the driver can choose to either support this directly (i.e. the driver allows the user to specify
a path and itself handles writing to that path), or to instead provide a straightforward, idiomatic way to
programmatically consume the messages and in turn write them to a file, e.g. via a Node.js
<a href="https://nodejs.org/api/stream.html">stream</a>, along with a documentation example of how to do this.</p>
<blockquote>
<p><strong>Fallback implementation method</strong>: If the environment variable <code>MONGODB_LOG_PATH</code> is provided:</p>
<ul>
<li>If the value is "stdout" (case-insensitive), log to stdout.</li>
<li>If the value is "stderr" (case-insensitive), log to stderr.</li>
<li>Else, if direct logging to files is supported, log to a file at the specified path. If the file already exists, it
MUST be appended to.</li>
</ul>
<p>If the variable is not provided or is set to an invalid value (which could be invalid for any reason, e.g. the path
does not exist or is not writeable), the driver MUST log to stderr and the driver MAY attempt to warn the user about
the misconfiguration via a log message or otherwise but MUST NOT throw an exception.</p>
</blockquote>
</li>
</ul>
<h4 id="configurable-max-document-length"><a class="header" href="#configurable-max-document-length">Configurable Max Document Length</a></h4>
<p>Drivers MUST support configuring the maximum logged length for extended JSON documents in log messages. The unit here is
flexible and can be bytes, Unicode code points, code units, or graphemes, depending on what a driver is able to
accomplish with its language's string APIs. The default max length is 1000 of whichever unit is selected. If the chosen
unit is anything other than a Unicode code point, the driver MUST ensure that it gracefully handles cases where the
truncation length falls mid code point, by either rounding the length up or down to the closest code point boundary or
using the Unicode replacement character, to avoid producing invalid Unicode data. Drivers MUST implement truncation
naively by simply truncating the output at the required length; i.e. do not attempt to implement truncation such that
the output is still valid JSON. Truncated extended JSON MUST have a trailing ellipsis <code>...</code> appended to indicate to the
user that truncation occurred. The ellipsis MUST NOT count toward the max length.</p>
<blockquote>
<p><strong>Fallback Implementation method</strong>: Environment variable <code>MONGOB_LOG_MAX_DOCUMENT_LENGTH</code>. When unspecified, any
extended JSON representation of a document which is longer than the default max length MUST be truncated to that
length. When set to an integer value, any extended JSON document longer than that value MUST be truncated to that
length. If a variable is set to an invalid value, it MUST be treated as if it were not specified at all, and the
driver MAY attempt to warn the user about the misconfiguration via a log message or otherwise but MUST NOT throw an
exception.</p>
</blockquote>
<h4 id="components"><a class="header" href="#components">Components</a></h4>
<p>Drivers MUST support configuring minimum log severity levels on a per-component level. The below components currently
exist and correspond to the listed specifications. This list is expected to grow over time as logging is added to more
specifications.</p>
<p>Drivers SHOULD specify the component names in whatever the idiomatic way is for their language. For example, the Java
command component could be named <code>org.mongodb.driver.protocol.command</code>.</p>
<p>Drivers MAY define additional language-specific components in addition to these for any driver-specific messages they
produce.</p>
<div class="table-wrapper"><table><thead><tr><th>Component Name</th><th>Specification(s)</th><th>Environment Variable</th></tr></thead><tbody>
<tr><td>command</td><td><a href="logging/../command-logging-and-monitoring/command-logging-and-monitoring.html">Command Logging and Monitoring</a></td><td><code>MONGODB_LOG_COMMAND</code></td></tr>
<tr><td>topology</td><td><a href="logging/../server-discovery-and-monitoring/server-discovery-and-monitoring.html">Server Discovery and Monitoring</a></td><td><code>MONGODB_LOG_TOPOLOGY</code></td></tr>
<tr><td>serverSelection</td><td><a href="logging/../server-selection/server-selection.html">Server Selection</a></td><td><code>MONGODB_LOG_SERVER_SELECTION</code></td></tr>
<tr><td>connection</td><td><a href="logging/../connection-monitoring-and-pooling/connection-monitoring-and-pooling.html">Connection Monitoring and Pooling</a></td><td><code>MONGODB_LOG_CONNECTION</code></td></tr>
</tbody></table>
</div>
<h4 id="log-severity-levels"><a class="header" href="#log-severity-levels">Log Severity Levels</a></h4>
<p>Driver specifications defining log messages MUST use log levels from the following list, inspired by the Syslog Protocol
as described in <a href="https://www.rfc-editor.org/rfc/rfc5424">RFC 5424</a>:</p>
<div class="table-wrapper"><table><thead><tr><th>Code</th><th>Level Name</th><th>Meaning</th><th>Environment Variable value (case-insensitive)</th></tr></thead><tbody>
<tr><td>-</td><td>Off</td><td>Nothing is logged.</td><td><code>off</code></td></tr>
<tr><td>0</td><td>Emergency</td><td>-</td><td><code>emergency</code></td></tr>
<tr><td>1</td><td>Alert</td><td>-</td><td><code>alert</code></td></tr>
<tr><td>2</td><td>Critical</td><td>-</td><td><code>critical</code></td></tr>
<tr><td>3</td><td>Error</td><td>Any error that we are unable to report to the user via driver API.</td><td><code>error</code></td></tr>
<tr><td>4</td><td>Warning</td><td>Indicates a situation where undesirable application behavior may occur. Example: The driver ignores an unrecognized option in a connection string.</td><td><code>warn</code></td></tr>
<tr><td>5</td><td>Notice</td><td>Indicates an event that is unusual but not problematic. Example: a change stream is automatically resumed.</td><td><code>notice</code></td></tr>
<tr><td>6</td><td>Informational</td><td>High-level information about normal driver behavior. Example: <code>MongoClient</code> creation or close.</td><td><code>info</code></td></tr>
<tr><td>7</td><td>Debug</td><td>Detailed information that may be helpful when debugging an application. Example: A command starting.</td><td><code>debug</code></td></tr>
<tr><td>8</td><td>Trace</td><td>Very fine-grained details related to logic flow. Example: entering and exiting function bodies.</td><td><code>trace</code></td></tr>
</tbody></table>
</div>
<p>Note that the Emergency, Alert, and Critical levels have been intentionally left undefined. At the time of writing this
specification, we do not expect any driver specifications to need to log at these levels, but we have included them in
the list of permitted levels for consistency with Syslog.</p>
<p>The levels above are defined in order from most to least severe. Not all logging frameworks will necessarily support all
of these levels. If an equivalent level is not available, drivers MUST emit messages for that level at the closest, less
severe level if one is available, or the closest more severe level otherwise.</p>
<p>For example:</p>
<ul>
<li>If an Informational level is not available and Debug is, messages defined as Informational in a specification MUST be
emitted at Debug level.</li>
<li>If a Trace level is not available, Trace messages MUST be emitted at Debug level.</li>
</ul>
<h4 id="structured-versus-unstructured-logging"><a class="header" href="#structured-versus-unstructured-logging">Structured versus Unstructured Logging</a></h4>
<p>If structured logging is available in and idiomatic for the driver's language/ecosystem, the driver SHOULD produce
structured log messages. Note that some ecosystems with structured logging support may also have support available to
convert structured output to traditional unstructured messages for users who want it (for example, the
<a href="https://docs.rs/tracing/latest/tracing/#emitting-log-records">log feature</a> in Rust's
<a href="https://docs.rs/tracing/latest/tracing/">tracing</a> crate). If such support is available, drivers SHOULD utilize it to
support both types of logging.</p>
<p>Note that drivers implementing unstructured logging MUST still support some internal way to intercept the data contained
in messages in a structured form, as this is required to implement the unified tests for logging conformance. See the
<a href="logging/../unified-test-format/unified-test-format.html#expectedlogmessage">unified test format specification</a> for details.</p>
<h4 id="representing-documents-in-log-messages"><a class="header" href="#representing-documents-in-log-messages">Representing Documents in Log Messages</a></h4>
<p>BSON documents MUST be represented in relaxed extended JSON when they appear in log messages to improve readability.</p>
<h4 id="representing-errors-in-log-messages"><a class="header" href="#representing-errors-in-log-messages">Representing Errors in Log Messages</a></h4>
<p>Drivers MAY represent errors in log messages in whatever format is idiomatic for their language and existing error
types. For example, if a driver's error classes have existing <code>toString()</code> implementations, those MAY be used.
Alternatively, if a driver emits structured log messages, a structured format containing error data could be used. Any
information which a driver reports via its error classes MUST be included in the log representations. Note that if the
driver includes full server responses in its errors these MUST be truncated in accordance with the max document length
option.</p>
<h4 id="logging-failures"><a class="header" href="#logging-failures">Logging Failures</a></h4>
<p>Specifications MAY define log messages that correspond to failures which also are reported via exceptions in the API,
for example a "command failed" log message. Such messages MUST NOT use log levels more severe than <code>debug</code>.</p>
<p>While it might seem natural that such messages would be logged at <code>error</code> level, not all failures that the driver
considers worthy of an error will be considered a true error by the application. For example, consider an application
that unconditionally creates a collection on startup, and ignores any <code>NamespaceExists</code> errors received in response: it
would be undesirable for those failures to show up in application logs at <code>error</code> level.</p>
<p>Additionally, some applications will already have infrastructure in place to log any unhandled exceptions at <code>error</code>
level. If the driver were to log exception-related messages at <code>error</code> level, such applications would end up with
duplicate, <code>error</code>-level messages for these exceptions. On the other hand, some applications may not log exceptions at
all, or might not include all of the relevant information about an encountered exception in their custom log messages;
for these applications, there is value in a driver emitting such log messages.</p>
<p>Given this, logging such messages at <code>debug</code> level strikes the best balance between making the diagnostic information
available, but not overloading users with overly severe and/or duplicative messages. Users who do not log exceptions
will have a way to see driver exceptions, by turning on <code>debug</code> logging, while users who do log exceptions can filter
for the true exceptions by only looking at more severe log levels.</p>
<h4 id="omitting-null-values-from-log-messages"><a class="header" href="#omitting-null-values-from-log-messages">Omitting Null Values from Log Messages</a></h4>
<p>Some log messages will include fields that are only present under particular circumstances, for example on certain
server versions. When such a field is not present:</p>
<ul>
<li>If the driver does structured logging, the field MUST be omitted from the message altogether, i.e. the field MUST not
be present with an explicit null value.</li>
<li>If the driver does unstructured logging, the corresponding segment of the message string MUST be omitted altogether.</li>
</ul>
<h4 id="performance-considerations"><a class="header" href="#performance-considerations">Performance Considerations</a></h4>
<p>The computation required to generate certain log messages can be significant, e.g. if extended JSON serialization is
required. If possible, drivers SHOULD check whether a log message would actually be emitted and consumed based on the
users' configuration before doing such computation. For example, this can be checked in Rust via
<a href="https://docs.rs/log/latest/log/macro.log_enabled.html">log::log_enabled</a>.</p>
<p>Drivers SHOULD optimize extended JSON generation to avoid generating JSON strings longer than will be emitted, such that
the complexity is O(N) where N = <code>&lt;max document length&gt;</code>, rather than N = <code>&lt;actual document length&gt;</code>.</p>
<h4 id="standard-naming-in-structured-log-messages"><a class="header" href="#standard-naming-in-structured-log-messages">Standard Naming in Structured Log Messages</a></h4>
<p>Driver specifications typically allow for language-appropriate naming variations, e.g. using snakecase or camelcase to
name a property. However, for log messages, drivers doing structured logging MUST use the exact names and casing
specified for the names of fields included in messages. This will be easier for our support team since the names will be
consistent across languages, and will simplify writing language-agnostic tooling to search through and parse structured
logs.</p>
<h4 id="including-timestamps-in-log-messages"><a class="header" href="#including-timestamps-in-log-messages">Including Timestamps in Log Messages</a></h4>
<p>Drivers MAY add timestamps to their log messages if one will not be added automatically by the logging framework(s) they
use.</p>
<h4 id="supporting-both-programmatic-and-environment-variable-configuration"><a class="header" href="#supporting-both-programmatic-and-environment-variable-configuration">Supporting Both Programmatic and Environment Variable Configuration</a></h4>
<p>If a driver supports configuration via both environment variables and programmatically via API, programmatic
configuration MUST take precedence over environment variables. Drivers supporting both forms of configuration MUST
document this behavior and MUST provide an example of how users can implement custom logic to allow an environment
variable to override a programmatic default, so that users who prefer the opposite behavior have a way to achieve it.</p>
<h2 id="test-plan-32"><a class="header" href="#test-plan-32">Test Plan</a></h2>
<p>Tests for logging behavior are defined in each corresponding specification. The
<a href="logging/../unified-test-format/unified-test-format.html">unified test runner specification</a> has support for specifying logging
expectations in tests.</p>
<h2 id="motivation-for-change-17"><a class="header" href="#motivation-for-change-17">Motivation for Change</a></h2>
<p>A common complaint from our support team is that they don't know how to easily get debugging information from drivers.
Some drivers provide debug logging, but others do not. For drivers that do provide it, the log messages produced and the
mechanisms for enabling debug logging are inconsistent.</p>
<p>Although users can implement their own debug logging support via existing driver events (SDAM, APM, etc), this requires
code changes. It is often difficult to quickly implement and deploy such changes in production at the time they are
needed, and to remove the changes afterward. Additionally, there are useful scenarios to log that do not correspond to
existing events. Standardizing on debug log messages that drivers produce and how to enable/configure logging will
provide TSEs, CEs, and MongoDB users an easier way to get debugging information out of our drivers, facilitate support
of drivers for our internal teams, and improve our documentation around troubleshooting.</p>
<h2 id="design-rationale-27"><a class="header" href="#design-rationale-27">Design Rationale</a></h2>
<h3 id="truncation-of-large-documents"><a class="header" href="#truncation-of-large-documents">Truncation of large documents</a></h3>
<ol>
<li>
<p>Why have an option?</p>
<p>We considered a number of approaches for dealing with documents of potentially very large size in log messages, e.g.
command documents, including 1) always logging the full document, 2) only logging documents with the potential to be
large when the user opts in, and 3) truncating large documents by default, but allowing the user to adjust the
maximum length logged. We chose the third option as we felt it struck the best balance between concerns around
readability and usability of log messages. In the case where data is sufficiently small, the default behavior will
show the user the full data. In the case where data is large, the user will receive a readable message with truncated
data, but have the option to see more or all of the data.</p>
</li>
<li>
<p>Why are the units for max document length flexible?</p>
<p>String APIs vary across languages, and not all drivers will be able to easily and efficiently truncate strings in the
same exact manner. The important thing is that the option exists and that its default value is reasonable, and for
all possible unit choices (byte, code point, code unit, or grapheme) we felt 1000 was a reasonable default. See
<a href="https://exploringjs.com/impatient-js/ch_unicode.html">here</a> for a helpful primer on related Unicode concepts.</p>
</li>
<li>
<p>Why do we implement naive truncation rather than truncating the JSON so it is still valid?</p>
<p>Designing and implementing a truncation algorithm for JSON that outputs valid JSON, but fits in as much of the
original JSON as possible, would be non-trivial. The server team wrote an entire separate truncation design document
when they implemented this for their log messages. This is more of a necessity for the server where the entire log
message is JSON, but we don't know if parsing the documents included in log messages is something that users will
actually need to do. Furthermore, any users who want parseable documents have an escape hatch to do so: they can set
the max document length to a very large value. If we hear of use cases in the future for parsing the documents in log
messages, we could make an additive change to this specification to permit a smarter truncation algorithm.</p>
</li>
</ol>
<h3 id="structured-versus-unstructured-logging-1"><a class="header" href="#structured-versus-unstructured-logging-1">Structured versus Unstructured Logging</a></h3>
<p>The MongoDB server produces structured logs as of 4.4, so it seems natural that MongoDB drivers might too. However,
structured logging is not idiomatic or common in some language ecosystems, so we have chosen not to require it.</p>
<h3 id="omitting-null-values-from-log-messages-1"><a class="header" href="#omitting-null-values-from-log-messages-1">Omitting Null Values from Log Messages</a></h3>
<p>We considered alternatives such as allowing, or requiring, drivers to explicitly include null values in log messages.
While this might make it easier to identify cases where a value is unexpectedly null, we decided against it because
there are a number of values that will often be null, or even always be null for certain applications (e.g. <code>serviceId</code>
when not connected to a load-balanced topology) and their inclusion may confuse users and lead them to think the null
value is meaningful. Additionally, always including null values would increase the size of log messages. The omission of
null values is left to the drivers' discretion for any driver-specific logs not covered by common specification
components.</p>
<h3 id="invalid-values-of-environment-variables"><a class="header" href="#invalid-values-of-environment-variables">Invalid Values of Environment Variables</a></h3>
<p>For drivers supporting configuration via environment variables, the spec requires that if an environment variable is set
to an invalid value the driver behaves as if the value were not specified at all, and optionally warns the user but does
not throw an error. We considered the following alternatives:</p>
<ol>
<li>
<p>Drivers could be required to throw an exception if a value is invalid: This was rejected because of concerns around
the implications for environments/applications where multiple versions of the driver or multiple drivers may be
present and where the validation logic may not match, meaning a value considered valid for one driver/version might
not be by another. Additionally, there is no obvious place to throw an exception from about invalid environment
variables; <code>MongoClient</code> constructors would be one possibility, but not all languages will support per-client
configuration so throwing there regarding an environment variable might be surprising to users.</p>
<p>Note that these same concerns do not apply to logging options that are specified via driver API: there is no risk of
such options propagating to other drivers/driver versions present, and drivers can report exceptions at the point the
options are specified, either globally or per-client. Therefore, drivers MUST validate programmatic logging options
in a manner consistent with how they validate all other programmatic options, and if possible SHOULD prefer to throw
exceptions for invalid configuration.</p>
</li>
<li>
<p>Drivers could be required to log a warning if a value is invalid: While drivers MAY do this, requiring it was
rejected because depending on the language/framework log messages may not be a viable way to communicate a warning:
if a language's default behavior is to log nothing, or only log messages at a more severe level than <code>warn</code>, the user
will not actually receive the message unless it is logged at a level and component they have successfully enabled.</p>
</li>
</ol>
<h3 id="programmatic-configuration-taking-precedence"><a class="header" href="#programmatic-configuration-taking-precedence">Programmatic Configuration Taking Precedence</a></h3>
<p>We chose to have programmatic configuration win out over environment variables because:</p>
<ol>
<li>This allows applications built atop drivers (e.g. mongosh) to fully control the driver's logging behavior by setting
options for it programmatically.</li>
<li>This is consistent with how many drivers treat options specified both in a connection string and programmatically:
programmatic options win out.</li>
<li>It is straightforward for users to override this behavior (by writing logic to read in environment variables and
override programmatic defaults), but if we went with the opposite default, it would be more complicated for users to
override: not all languages will necessarily have an easy way to override/unset an environment variable from within
application code.</li>
</ol>
<h2 id="backwards-compatibility-26"><a class="header" href="#backwards-compatibility-26">Backwards Compatibility</a></h2>
<p>This specification takes the stance that the contents of log messages (both structured and unstructured) are <em>not</em>
covered by semantic versioning, but that logging components <em>are</em>, since changing the name of a component or removing a
component altogether has the potential to break user logging configuration and cause users to silently miss log
messages.</p>
<p>As a result, any drivers that already support logging should be free to update the messages they log to match those
defined in various specifications. However, drivers should take care to avoid removing or renaming existing logging
components except in major version releases.</p>
<p>Since this specification defines no particular API, drivers are free to keep any existing programmatic APIs they have
for configuring logging. If such APIs are incompatible with the logging specification requirements (for example, the
driver defines its own set of log levels in a public type, which do not match the spec-defined levels), changes to match
the specification should be staged in via semantic versioning.</p>
<h2 id="reference-implementation-23"><a class="header" href="#reference-implementation-23">Reference Implementation</a></h2>
<p>Links to be added once Rust and C# implementations have been merged.</p>
<h2 id="security-implication-4"><a class="header" href="#security-implication-4">Security Implication</a></h2>
<p>Drivers must take care to avoid exposing sensitive information (e.g. authentication credentials) in log messages. It
will be up to each individual specification that defines log messages to define which information should be redacted and
add tests confirming its redaction.</p>
<h2 id="future-work-17"><a class="header" href="#future-work-17">Future work</a></h2>
<h3 id="additional-log-components"><a class="header" href="#additional-log-components">Additional Log Components</a></h3>
<p>Additional log components may be added as logging is added to more specifications.</p>
<h3 id="preventing-recursion-when-using-mongodb-as-a-log-sink"><a class="header" href="#preventing-recursion-when-using-mongodb-as-a-log-sink">Preventing Recursion When Using MongoDB as a Log Sink</a></h3>
<p>If a user chooses to store log messages produced by a driver in MongoDB, it may be possible for them to end up recursing
infinitely if each write to store a log message generates additional log messages. This has historically not been an
issue in drivers that already produce log messages, or with the command monitoring API, but if users start to run into
this issue, we could try to address it at the specification level by e.g. requiring drivers to support disabling logging
on individual clients or for particular namespaces.</p>
<h2 id="changelog-45"><a class="header" href="#changelog-45">Changelog</a></h2>
<ul>
<li>
<p>2024-03-06: Migrated from reStructuredText to Markdown.</p>
</li>
<li>
<p>2022-11-16: Add policy on severity level for log messages corresponding to driver exceptions.</p>
</li>
<li>
<p>2022-11-11: Clarify that guidance around null values only strictly applies to spec-defined log messages.</p>
</li>
<li>
<p>2022-10-26: Allow drivers to add timestamps to log messages.</p>
</li>
<li>
<p>2022-11-10: Clarify driver-specific null omission.</p>
</li>
<li>
<p>2022-12-29: Fix typo in trace log level example</p>
</li>
<li>
<p>2023-01-04: Elaborate on treatment of invalid values of environment variables. Permit drivers to omit direct support
for logging to file so long as they provide a straightforward way for users to consume the log messages
programmatically and write to a file themselves. Require that programmatic configuration take precedence over
environment variables.</p>
</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="connection-monitoring-and-pooling-1"><a class="header" href="#connection-monitoring-and-pooling-1">Connection Monitoring and Pooling</a></h1>
<ul>
<li>Status: Accepted</li>
<li>Minimum Server Version: N/A</li>
</ul>
<h2 id="abstract-43"><a class="header" href="#abstract-43">Abstract</a></h2>
<p>Drivers currently support a variety of options that allow users to configure connection pooling behavior. Users are
confused by drivers supporting different subsets of these options. Additionally, drivers implement their connection
pools differently, making it difficult to design cross-driver pool functionality. By unifying and codifying pooling
options and behavior across all drivers, we will increase user comprehension and code base maintainability.</p>
<p>This specification does not apply to drivers that do not support multitasking.</p>
<h2 id="meta-44"><a class="header" href="#meta-44">META</a></h2>
<p>The keywords "MUST", "MUST NOT", "REQUIRED", "SHALL", "SHALL NOT", "SHOULD", "SHOULD NOT", "RECOMMENDED", "MAY", and
"OPTIONAL" in this document are to be interpreted as described in <a href="https://www.ietf.org/rfc/rfc2119.txt">RFC 2119</a>.</p>
<h2 id="definitions-12"><a class="header" href="#definitions-12">Definitions</a></h2>
<h3 id="connection-2"><a class="header" href="#connection-2">Connection</a></h3>
<p>A Connection (when linked) refers to the <code>Connection</code> type defined in the
<a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection-pool-members">Connection Pool Members</a> section of this specification. It does not refer to an actual TCP
connection to an Endpoint. A <code>Connection</code> will attempt to create and wrap such a TCP connection over the course of its
existence, but it is not equivalent to one nor does it wrap an active one at all times.</p>
<p>For the purposes of testing, a mocked <code>Connection</code> type could be used with the pool that never actually creates a TCP
connection or performs any I/O.</p>
<h3 id="endpoint-1"><a class="header" href="#endpoint-1">Endpoint</a></h3>
<p>For convenience, an Endpoint refers to either a <strong>mongod</strong> or <strong>mongos</strong> instance.</p>
<h3 id="thread-1"><a class="header" href="#thread-1">Thread</a></h3>
<p>For convenience, a Thread refers to:</p>
<ul>
<li>A shared-address-space process (a.k.a. a thread) in multi-threaded drivers</li>
<li>An Execution Frame / Continuation in asynchronous drivers</li>
<li>A goroutine in Go</li>
</ul>
<h2 id="behavioral-description-1"><a class="header" href="#behavioral-description-1">Behavioral Description</a></h2>
<h3 id="which-drivers-this-applies-to-1"><a class="header" href="#which-drivers-this-applies-to-1">Which Drivers this applies to</a></h3>
<p>This specification is solely concerned with drivers that implement a connection pool. A driver SHOULD implement a
connection pool, but is not required to.</p>
<h3 id="connection-pool-options-2"><a class="header" href="#connection-pool-options-2">Connection Pool Options</a></h3>
<p>All drivers that implement a connection pool MUST implement and conform to the same MongoClient options. There can be
slight deviation in naming to make the options idiomatic to the driver language.</p>
<h3 id="connection-pool-behaviors-2"><a class="header" href="#connection-pool-behaviors-2">Connection Pool Behaviors</a></h3>
<p>All driver connection pools MUST provide an API that allows the driver to check out a connection, check in a connection
back to the pool, and clear all connections in the pool. This API is for internal use only, and SHOULD NOT be documented
as a public API.</p>
<h3 id="connection-pool-monitoring-2"><a class="header" href="#connection-pool-monitoring-2">Connection Pool Monitoring</a></h3>
<p>All drivers that implement a connection pool MUST provide an API that allows users to subscribe to events emitted from
the pool. Conceptually, event emission is instantaneous, i.e., one may talk about the instant an event is emitted, and
represents the start of an activity of delivering the event to a subscribed user.</p>
<h2 id="detailed-design-1"><a class="header" href="#detailed-design-1">Detailed Design</a></h2>
<h3 id="connection-pool-options-3"><a class="header" href="#connection-pool-options-3">Connection Pool Options</a></h3>
<p>Drivers that implement a Connection Pool MUST support the following ConnectionPoolOptions:</p>
<pre><code class="language-typescript">interface ConnectionPoolOptions {
  /**
   *  The maximum number of Connections that may be associated
   *  with a pool at a given time. This includes in use and
   *  available connections.
   *  If specified, MUST be an integer &gt;= 0.
   *  A value of 0 means there is no limit.
   *  Defaults to 100.
   */
  maxPoolSize?: number;

  /**
   *  The minimum number of Connections that MUST exist at any moment
   *  in a single connection pool.
   *  If specified, MUST be an integer &gt;= 0. If maxPoolSize is &gt; 0
   *  then minPoolSize must be &lt;= maxPoolSize
   *  Defaults to 0.
   */
  minPoolSize?: number;

  /**
   *  The maximum amount of time a Connection should remain idle
   *  in the connection pool before being marked idle.
   *  If specified, MUST be a number &gt;= 0.
   *  A value of 0 means there is no limit.
   *  Defaults to 0.
   */
  maxIdleTimeMS?: number;

  /**
   *  The maximum number of Connections a Pool may be establishing concurrently.
   *  Establishment of a Connection is a part of its life cycle
   *  starting after a ConnectionCreatedEvent and ending before a ConnectionReadyEvent.
   *  If specified, MUST be a number &gt; 0.
   *  Defaults to 2.
   */
  maxConnecting?: number;
}
</code></pre>
<p>Additionally, Drivers that implement a Connection Pool MUST support the following ConnectionPoolOptions UNLESS that
driver meets ALL of the following conditions:</p>
<ul>
<li>The driver/language currently has an idiomatic timeout mechanism implemented</li>
<li>The timeout mechanism conforms to <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#waitqueue">the aggressive requirement of timing out a thread in the WaitQueue</a></li>
</ul>
<pre><code class="language-typescript">interface ConnectionPoolOptions {
  /**
   *  NOTE: This option has been deprecated in favor of timeoutMS.
   *
   *  The maximum amount of time a thread can wait for
   *  either an available non-perished connection (limited by `maxPoolSize`),
   *  or a pending connection (limited by `maxConnecting`).
   *  If specified, MUST be a number &gt;= 0.
   *  A value of 0 means there is no limit.
   *  Defaults to 0.
   */
  waitQueueTimeoutMS?: number;
}
</code></pre>
<p>These options MUST be specified at the MongoClient level, and SHOULD be named in a manner idiomatic to the driver's
language. All connection pools created by a MongoClient MUST use the same ConnectionPoolOptions.</p>
<p>When parsing a mongodb connection string, a user MUST be able to specify these options using the default names specified
above.</p>
<h4 id="deprecated-options-1"><a class="header" href="#deprecated-options-1">Deprecated Options</a></h4>
<p>The following ConnectionPoolOptions are considered deprecated. They MUST NOT be implemented if they do not already exist
in a driver, and they SHOULD be deprecated and removed from drivers that implement them as early as possible:</p>
<pre><code class="language-typescript">interface ConnectionPoolOptions {
  /**
   *  The maximum number of threads that can simultaneously wait
   *  for a Connection to become available.
   */
  waitQueueSize?: number;

  /**
   *  An alternative way of setting waitQueueSize, it specifies
   *  the maximum number of threads that can wait per connection.
   *  waitQueueSize === waitQueueMultiple * maxPoolSize
   */
  waitQueueMultiple?: number
}
</code></pre>
<h3 id="connection-pool-members-1"><a class="header" href="#connection-pool-members-1">Connection Pool Members</a></h3>
<h4 id="connection-3"><a class="header" href="#connection-3">Connection</a></h4>
<p>A driver-defined wrapper around a single TCP connection to an Endpoint. A <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connection</a> has the following
properties:</p>
<ul>
<li><strong>Single Endpoint:</strong> A <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connection</a> MUST be associated with a single Endpoint. A
<a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connection</a> MUST NOT be associated with multiple Endpoints.</li>
<li><strong>Single Lifetime:</strong> A <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connection</a> MUST NOT be used after it is closed.</li>
<li><strong>Single Owner:</strong> A <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connection</a> MUST belong to exactly one Pool, and MUST NOT be shared across multiple
pools</li>
<li><strong>Single Track:</strong> A <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connection</a> MUST limit itself to one request / response at a time. A
<a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connection</a> MUST NOT multiplex/pipeline requests to an Endpoint.</li>
<li><strong>Monotonically Increasing ID:</strong> A <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connection</a> MUST have an ID number associated with it.
<a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connection</a> IDs within a Pool MUST be assigned in order of creation, starting at 1 and increasing by 1
for each new Connection.</li>
<li><strong>Valid Connection:</strong> A connection MUST NOT be checked out of the pool until it has successfully and fully completed a
MongoDB Handshake and Authentication as specified in the <a href="connection-monitoring-and-pooling/../mongodb-handshake/handshake.html">Handshake</a>,
<a href="connection-monitoring-and-pooling/../compression/OP_COMPRESSED.html">OP_COMPRESSED</a>, and <a href="connection-monitoring-and-pooling/../auth/auth.html">Authentication</a> specifications.</li>
<li><strong>Perishable</strong>: it is possible for a <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connection</a> to become <strong>Perished</strong>. A <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connection</a> is
considered perished if any of the following are true:
<ul>
<li><strong>Stale:</strong> The <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connection</a> 's generation does not match the generation of the parent pool</li>
<li><strong>Idle:</strong> The <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connection</a> is currently "available" (as defined below) and has been for longer than
<strong>maxIdleTimeMS</strong>.</li>
<li><strong>Errored:</strong> The <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connection</a> has experienced an error that indicates it is no longer recommended for
use. Examples include, but are not limited to:
<ul>
<li>Network Error</li>
<li>Network Timeout</li>
<li>Endpoint closing the connection</li>
<li>Driver-Side Timeout</li>
<li>Wire-Protocol Error</li>
</ul>
</li>
</ul>
</li>
</ul>
<pre><code class="language-typescript">interface Connection {
  /**
   *  An id number associated with the Connection
   */
  id: number;

  /**
   *  The address of the pool that owns this Connection
   */
  address: string;

  /**
   *  An integer representing the "generation" of the pool
   *  when this Connection was created.
   */
  generation: number;

  /**
   * The current state of the Connection.
   *
   * Possible values are the following:
   *   - "pending":       The Connection has been created but has not yet been established. Contributes to
   *                      totalConnectionCount and pendingConnectionCount.
   *
   *   - "available":     The Connection has been established and is waiting in the pool to be checked
   *                      out. Contributes to both totalConnectionCount and availableConnectionCount.
   *
   *   - "in use":        The Connection has been established, checked out from the pool, and has yet
   *                      to be checked back in. Contributes to totalConnectionCount.
   *
   *   - "closed":        The Connection has had its socket closed and cannot be used for any future
   *                      operations. Does not contribute to any connection counts.
   *
   * Note: this field is mainly used for the purposes of describing state
   * in this specification. It is not required that drivers
   * actually include this field in their implementations of Connection.
   */
  state: "pending" | "available" | "in use" | "closed";
}
</code></pre>
<h4 id="waitqueue-1"><a class="header" href="#waitqueue-1">WaitQueue</a></h4>
<p>A concept that represents pending requests for <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connections</a>. When a thread requests a
<a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connection</a> from a Pool, the thread enters the Pool's WaitQueue. A thread stays in the WaitQueue until it
either receives a <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connection</a> or times out. A WaitQueue has the following traits:</p>
<ul>
<li><strong>Thread-Safe</strong>: When multiple threads attempt to enter or exit a WaitQueue, they do so in a thread-safe manner.</li>
<li><strong>Ordered/Fair</strong>: When <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connections</a> are made available, they are issued out to threads in the order that
the threads entered the WaitQueue.</li>
<li><strong>Timeout aggressively:</strong> Members of a WaitQueue MUST timeout if they are enqueued for longer than the computed
timeout and MUST leave the WaitQueue immediately in this case.</li>
</ul>
<p>The implementation details of a WaitQueue are left to the driver. Example implementations include:</p>
<ul>
<li>A fair Semaphore</li>
<li>A Queue of callbacks</li>
</ul>
<h4 id="connection-pool-1"><a class="header" href="#connection-pool-1">Connection Pool</a></h4>
<p>A driver-defined entity that encapsulates all non-monitoring <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connections</a> associated with a single
Endpoint. The pool has the following properties:</p>
<ul>
<li><strong>Thread Safe:</strong> All Pool behaviors MUST be thread safe.</li>
<li><strong>Not Fork-Safe:</strong> A Pool is explicitly not fork-safe. If a Pool detects that is it being used by a forked process, it
MUST immediately clear itself and update its pid</li>
<li><strong>Single Owner:</strong> A Pool MUST be associated with exactly one Endpoint, and MUST NOT be shared between Endpoints.</li>
<li><strong>Emit Events and Log Messages:</strong> A Pool MUST emit pool events and log messages when dictated by this spec (see
<a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection-pool-monitoring">Connection Pool Monitoring</a>). Users MUST be able to subscribe to emitted events and log
messages in a manner idiomatic to their language and driver.</li>
<li><strong>Closeable:</strong> A Pool MUST be able to be manually closed. When a Pool is closed, the following behaviors change:
<ul>
<li>Checking in a <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connection</a> to the Pool automatically closes the <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connection</a></li>
<li>Attempting to check out a <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connection</a> from the Pool results in an Error</li>
</ul>
</li>
<li><strong>Clearable:</strong> A Pool MUST be able to be cleared. Clearing the pool marks all pooled and checked out
<a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connections</a> as stale and lazily closes them as they are checkedIn or encountered in checkOut.
Additionally, all requests are evicted from the WaitQueue and return errors that are considered non-timeout network
errors.</li>
<li><strong>Pausable:</strong> A Pool MUST be able to be paused and resumed. A Pool is paused automatically when it is cleared, and it
can be resumed by being marked as "ready". While the Pool is paused, it exhibits the following behaviors:
<ul>
<li>Attempting to check out a <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connection</a> from the Pool results in a non-timeout network error</li>
<li>Connections are not created in the background to satisfy minPoolSize</li>
</ul>
</li>
<li><strong>Capped:</strong> a pool is capped if <strong>maxPoolSize</strong> is set to a non-zero value. If a pool is capped, then its total number
of <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connections</a> (including available and in use) MUST NOT exceed <strong>maxPoolSize</strong></li>
<li><strong>Rate-limited:</strong> A Pool MUST limit the number of <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connections</a> being
<a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#establishing-a-connection-internal-implementation">established</a> concurrently via the <strong>maxConnecting</strong>
<a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection-pool-options">pool option</a>.</li>
</ul>
<pre><code class="language-typescript">interface ConnectionPool {
  /**
   *  The Queue of threads waiting for a Connection to be available
   */
  waitQueue: WaitQueue;

  /**
   *  A generation number representing the SDAM generation of the pool.
   */
  generation: number;

  /**
   * A map representing the various generation numbers for various services
   * when in load balancer mode.
   */
  serviceGenerations: Map&lt;ObjectId, [number, number]&gt;;

  /**
   * The state of the pool.
   *
   * Possible values are the following:
   *   - "paused":        The initial state of the pool. Connections may not be checked out nor can they
   *                      be established in the background to satisfy minPoolSize. Clearing a pool
   *                      transitions it to this state.
   *
   *   - "ready":         The healthy state of the pool. It can service checkOut requests and create
   *                      connections in the background. The pool can be set to this state via the
   *                      ready() method.
   *
   *   - "closed":        The pool is destroyed. No more Connections may ever be checked out nor any
   *                      created in the background. The pool can be set to this state via the close()
   *                      method. The pool cannot transition to any other state after being closed.
   */
  state: "paused" | "ready" | "closed";

  // Any of the following connection counts may be computed rather than
  // actually stored on the pool.

  /**
   *  An integer expressing how many total Connections
   *  ("pending" + "available" + "in use") the pool currently has
   */
  totalConnectionCount: number;

  /**
   *  An integer expressing how many Connections are currently
   *  available in the pool.
   */
  availableConnectionCount: number;

  /**
   *  An integer expressing how many Connections are currently
   *  being established.
   */
  pendingConnectionCount: number;

  /**
   *  Returns a Connection for use
   */
  checkOut(): Connection;

  /**
   *  Check in a Connection back to the Connection pool
   */
  checkIn(connection: Connection): void;

  /**
   *  Mark all current Connections as stale, clear the WaitQueue, and mark the pool as "paused".
   *  No connections may be checked out or created in this pool until ready() is called again.
   *  interruptInUseConnections specifies whether the pool will force interrupt "in use" connections as part of the clear. 
   *  Default false.
   */
  clear(interruptInUseConnections: Optional&lt;Boolean&gt;): void;

  /**
   *  Mark the pool as "ready", allowing checkOuts to resume and connections to be created in the background.
   *  A pool can only transition from "paused" to "ready". A "closed" pool
   *  cannot be marked as "ready" via this method.
   */
  ready(): void;

  /**
   *  Marks the pool as "closed", preventing the pool from creating and returning new Connections
   */
  close(): void;
}
</code></pre>
<h3 id="connection-pool-behaviors-3"><a class="header" href="#connection-pool-behaviors-3">Connection Pool Behaviors</a></h3>
<h4 id="creating-a-connection-pool-1"><a class="header" href="#creating-a-connection-pool-1">Creating a Connection Pool</a></h4>
<p>This specification does not define how a pool is to be created, leaving it up to the driver. Creation of a connection
pool is generally an implementation detail of the driver, i.e., is not a part of the public API of the driver. The SDAM
specification defines
<a href="connection-monitoring-and-pooling/../server-discovery-and-monitoring/server-discovery-and-monitoring.html#connection-pool-management">when</a> the driver
should create connection pools.</p>
<p>When a pool is created, its state MUST initially be set to "paused". Even if minPoolSize is set, the pool MUST NOT begin
being <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#populating-the-pool-with-a-connection-internal-implementation">populated</a> with <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connections</a> until
it has been marked as "ready". SDAM will mark the pool as "ready" on each successful check. See
<a href="connection-monitoring-and-pooling/../server-discovery-and-monitoring/server-discovery-and-monitoring.html#connection-pool-management">Connection Pool Management</a>
section in the SDAM specification for more information.</p>
<pre><code>set generation to 0
set state to "paused"
emit PoolCreatedEvent and equivalent log message
</code></pre>
<h4 id="closing-a-connection-pool-1"><a class="header" href="#closing-a-connection-pool-1">Closing a Connection Pool</a></h4>
<p>When a pool is closed, it MUST first close all available <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connections</a> in that pool. This results in the
following behavior changes:</p>
<ul>
<li>In use <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connections</a> MUST be closed when they are checked in to the closed pool.</li>
<li>Attempting to check out a <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connection</a> MUST result in an error.</li>
</ul>
<pre><code>mark pool as "closed"
for connection in availableConnections:
  close connection
emit PoolClosedEvent and equivalent log message
</code></pre>
<h4 id="marking-a-connection-pool-as-ready-1"><a class="header" href="#marking-a-connection-pool-as-ready-1">Marking a Connection Pool as Ready</a></h4>
<p>Connection Pools start off as "paused", and they are marked as "ready" by monitors after they perform successful server
checks. Once a pool is "ready", it can start checking out <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connections</a> and populating them in the
background.</p>
<p>If the pool is already "ready" when this method is invoked, then this method MUST immediately return and MUST NOT emit a
PoolReadyEvent.</p>
<pre><code>mark pool as "ready"
emit PoolReadyEvent and equivalent log message
allow background thread to create connections
</code></pre>
<p>Note that the PoolReadyEvent MUST be emitted before the background thread is allowed to resume creating new connections,
and it must be the case that no observer is able to observe actions of the background thread related to creating new
connections before observing the PoolReadyEvent event.</p>
<h4 id="creating-a-connection-internal-implementation-1"><a class="header" href="#creating-a-connection-internal-implementation-1">Creating a Connection (Internal Implementation)</a></h4>
<p>When creating a <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connection</a>, the initial <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connection</a> is in a "pending" state. This only
creates a "virtual" <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connection</a>, and performs no I/O.</p>
<pre><code>connection = new Connection()
increment totalConnectionCount
increment pendingConnectionCount
set connection state to "pending"
tConnectionCreated = current instant (use a monotonic clock if possible)
emit ConnectionCreatedEvent and equivalent log message
return connection
</code></pre>
<h4 id="establishing-a-connection-internal-implementation-1"><a class="header" href="#establishing-a-connection-internal-implementation-1">Establishing a Connection (Internal Implementation)</a></h4>
<p>Before a <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connection</a> can be marked as either "available" or "in use", it must be established. This process
involves performing the initial handshake, handling OP_COMPRESSED, and performing authentication.</p>
<pre><code>try:
  connect connection via TCP / TLS
  perform connection handshake
  handle OP_COMPRESSED
  perform connection authentication
  tConnectionReady = current instant (use a monotonic clock if possible)
  emit ConnectionReadyEvent(duration = tConnectionReady - tConnectionCreated) and equivalent log message
  return connection
except error:
  close connection
  throw error # Propagate error in manner idiomatic to language.
</code></pre>
<h4 id="closing-a-connection-internal-implementation-1"><a class="header" href="#closing-a-connection-internal-implementation-1">Closing a Connection (Internal Implementation)</a></h4>
<p>When a <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connection</a> is closed, it MUST first be marked as "closed", removing it from being counted as
"available" or "in use". Once that is complete, the <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connection</a> can perform whatever teardown is necessary
to close its underlying socket. The Driver SHOULD perform this teardown in a non-blocking manner, such as via the use of
a background thread or async I/O.</p>
<pre><code>original state = connection state
set connection state to "closed"

if original state is "available":
  decrement availableConnectionCount
else if original state is "pending":
  decrement pendingConnectionCount

decrement totalConnectionCount
emit ConnectionClosedEvent and equivalent log message

# The following can happen at a later time (i.e. in background
# thread) or via non-blocking I/O.
connection.socket.close()
</code></pre>
<h4 id="marking-a-connection-as-available-internal-implementation-1"><a class="header" href="#marking-a-connection-as-available-internal-implementation-1">Marking a Connection as Available (Internal Implementation)</a></h4>
<p>A <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connection</a> is "available" if it is able to be checked out. A <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connection</a> MUST NOT be
marked as "available" until it has been established. The pool MUST keep track of the number of currently available
<a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connections</a>.</p>
<pre><code>increment availableConnectionCount
set connection state to "available"
add connection to availableConnections
</code></pre>
<h4 id="populating-the-pool-with-a-connection-internal-implementation-1"><a class="header" href="#populating-the-pool-with-a-connection-internal-implementation-1">Populating the Pool with a Connection (Internal Implementation)</a></h4>
<p>"Populating" the pool involves preemptively creating and establishing a <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connection</a> which is marked as
"available" for use in future operations.</p>
<p>Populating the pool MUST NOT block any application threads. For example, it could be performed on a background thread or
via the use of non-blocking/async I/O. Populating the pool MUST NOT be performed unless the pool is "ready".</p>
<p>If an error is encountered while populating a connection, it MUST be handled via the SDAM machinery according to the
<a href="connection-monitoring-and-pooling/../server-discovery-and-monitoring/server-discovery-and-monitoring.html#application-errors">Application Errors</a> section
in the SDAM specification.</p>
<p>If minPoolSize is set, the <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connection</a> Pool MUST be populated until it has at least minPoolSize total
<a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connections</a>. This MUST occur only while the pool is "ready". If the pool implements a background thread,
it can be used for this. If the pool does not implement a background thread, the checkOut method is responsible for
ensuring this requirement is met.</p>
<p>When populating the Pool, pendingConnectionCount has to be decremented after establishing a <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connection</a>
similarly to how it is done in <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#checking-out-a-connection">Checking Out a Connection</a> to signal that another
<a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connection</a> is allowed to be established. Such a signal MUST become observable to any <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#thread">Thread</a>
after the action that
<a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#marking-a-connection-as-available-internal-implementation">marks the established Connection as "available"</a> becomes
observable to the <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#thread">Thread</a>. Informally, this order guarantees that no <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#thread">Thread</a> tries to start
establishing a <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connection</a> when there is an "available" <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connection</a> established as a result
of populating the Pool.</p>
<pre><code>wait until pendingConnectionCount &lt; maxConnecting and pool is "ready"
create connection
try:
  establish connection
  mark connection as available
except error:
  # Defer error handling to SDAM.
  topology.handle_pre_handshake_error(error)
</code></pre>
<h4 id="checking-out-a-connection-1"><a class="header" href="#checking-out-a-connection-1">Checking Out a Connection</a></h4>
<p>A Pool MUST have a method that allows the driver to check out a <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connection</a>. Checking out a
<a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connection</a> involves submitting a request to the WaitQueue and, once that request reaches the front of the
queue, having the Pool find or create a <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connection</a> to fulfill that request. Requests MUST be subject to a
timeout which is computed per the rules in
<a href="connection-monitoring-and-pooling/../client-side-operations-timeout/client-side-operations-timeout.html#server-selection">Client Side Operations Timeout: Server Selection</a>.</p>
<p>To service a request for a <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connection</a>, the Pool MUST first iterate over the list of available
<a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connections</a>, searching for a non-perished one to be returned. If a perished <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connection</a> is
encountered, such a <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connection</a> MUST be closed (as described in
<a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#closing-a-connection-internal-implementation">Closing a Connection</a>) and the iteration of available
<a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connections</a> MUST continue until either a non-perished available <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connection</a> is found or the
list of available <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connections</a> is exhausted.</p>
<p>If the list is exhausted, the total number of <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connections</a> is less than maxPoolSize, and
pendingConnectionCount &lt; maxConnecting, the pool MUST create a <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connection</a>, establish it, mark it as "in
use" and return it. If totalConnectionCount == maxPoolSize or pendingConnectionCount == maxConnecting, then the pool
MUST wait to service the request until neither of those two conditions are met or until a <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connection</a>
becomes available, re-entering the checkOut loop in either case. This waiting MUST NOT prevent
<a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connections</a> from being checked into the pool. Additionally, the Pool MUST NOT service any newer checkOut
requests before fulfilling the original one which could not be fulfilled. For drivers that implement the WaitQueue via a
fair semaphore, a condition variable may also be needed to to meet this requirement. Waiting on the condition variable
SHOULD also be limited by the WaitQueueTimeout, if the driver supports one and it was specified by the user.</p>
<p>If the pool is "closed" or "paused", any attempt to check out a <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connection</a> MUST throw an Error. The error
thrown as a result of the pool being "paused" MUST be considered a retryable error and MUST NOT be an error that marks
the SDAM state unknown.</p>
<p>If the pool does not implement a background thread, the checkOut method is responsible for ensuring that the pool is
<a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#populating-the-pool-with-a-connection-internal-implementation">populated</a> with at least minPoolSize
<a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connections</a>.</p>
<p>A <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connection</a> MUST NOT be checked out until it is established. In addition, the Pool MUST NOT prevent
other threads from checking out <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connections</a> while establishing a <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connection</a>.</p>
<p>Before a given <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connection</a> is returned from checkOut, it must be marked as "in use", and the pool's
availableConnectionCount MUST be decremented.</p>
<pre><code class="language-python">connection = Null
tConnectionCheckOutStarted = current instant (use a monotonic clock if possible)
emit ConnectionCheckOutStartedEvent and equivalent log message
try:
  enter WaitQueue
  wait until at top of wait queue
  # Note that in a lock-based implementation of the wait queue would
  # only allow one thread in the following block at a time
  while connection is Null:
    if a connection is available:
      while connection is Null and a connection is available:
        connection = next available connection
        if connection is perished:
          close connection
          connection = Null
    else if totalConnectionCount &lt; maxPoolSize:
      if pendingConnectionCount &lt; maxConnecting:
        connection = create connection
      else:
        # this waiting MUST NOT prevent other threads from checking Connections
        # back in to the pool.
        wait until pendingConnectionCount &lt; maxConnecting or a connection is available
        continue

except pool is "closed":
  tConnectionCheckOutFailed = current instant (use a monotonic clock if possible)
  emit ConnectionCheckOutFailedEvent(reason="poolClosed", duration = tConnectionCheckOutFailed - tConnectionCheckOutStarted) and equivalent log message
  throw PoolClosedError
except pool is "paused":
  tConnectionCheckOutFailed = current instant (use a monotonic clock if possible)
  emit ConnectionCheckOutFailedEvent(reason="connectionError", duration = tConnectionCheckOutFailed - tConnectionCheckOutStarted) and equivalent log message
  throw PoolClearedError
except timeout:
  tConnectionCheckOutFailed = current instant (use a monotonic clock if possible)
  emit ConnectionCheckOutFailedEvent(reason="timeout", duration = tConnectionCheckOutFailed - tConnectionCheckOutStarted) and equivalent log message
  throw WaitQueueTimeoutError
finally:
  # This must be done in all drivers
  leave wait queue

# If the Connection has not been established yet (TCP, TLS,
# handshake, compression, and auth), it must be established
# before it is returned.
# This MUST NOT block other threads from acquiring connections.
if connection state is "pending":
  try:
    establish connection
  except connection establishment error:
    tConnectionCheckOutFailed = current instant (use a monotonic clock if possible)
    emit ConnectionCheckOutFailedEvent(reason="connectionError", duration = tConnectionCheckOutFailed - tConnectionCheckOutStarted) and equivalent log message
    decrement totalConnectionCount
    throw
  finally:
    decrement pendingConnectionCount
else:
    decrement availableConnectionCount
set connection state to "in use"

# If there is no background thread, the pool MUST ensure that
# there are at least minPoolSize total connections.
do asynchronously:
  while totalConnectionCount &lt; minPoolSize:
    populate the pool with a connection

tConnectionCheckedOut = current instant (use a monotonic clock if possible)
emit ConnectionCheckedOutEvent(duration = tConnectionCheckedOut - tConnectionCheckOutStarted) and equivalent log message
return connection
</code></pre>
<h4 id="checking-in-a-connection-1"><a class="header" href="#checking-in-a-connection-1">Checking In a Connection</a></h4>
<p>A Pool MUST have a method of allowing the driver to check in a <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connection</a>. The driver MUST NOT be allowed
to check in a <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connection</a> to a Pool that did not create that <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connection</a>, and MUST throw an
Error if this is attempted.</p>
<p>When the <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connection</a> is checked in, it MUST be <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#closing-a-connection-internal-implementation">closed</a> if
any of the following are true:</p>
<ul>
<li>The <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connection</a> is perished.</li>
<li>The pool has been closed.</li>
</ul>
<p>Otherwise, the <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connection</a> is marked as available.</p>
<pre><code>emit ConnectionCheckedInEvent and equivalent log message
if connection is perished OR pool is closed:
  close connection
else:
  mark connection as available
</code></pre>
<h4 id="clearing-a-connection-pool-1"><a class="header" href="#clearing-a-connection-pool-1">Clearing a Connection Pool</a></h4>
<p>Clearing the pool involves different steps depending on whether the pool is in load balanced mode or not. The
traditional / non-load balanced clearing behavior MUST NOT be used by pools in load balanced mode, and the load balanced
pool clearing behavior MUST NOT be used in non-load balanced pools.</p>
<h5 id="clearing-a-non-load-balanced-pool-1"><a class="header" href="#clearing-a-non-load-balanced-pool-1">Clearing a non-load balanced pool</a></h5>
<p>A Pool MUST have a method of clearing all <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connections</a> when instructed. Rather than iterating through
every <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connection</a>, this method should simply increment the generation of the Pool, implicitly marking all
current <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connections</a> as stale. It should also transition the pool's state to "paused" to halt the creation
of new connections until it is marked as "ready" again. The checkOut and checkIn algorithms will handle clearing out
stale <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connections</a>. If a user is subscribed to Connection Monitoring events and/or connection log
messages, a PoolClearedEvent and log message MUST be emitted after incrementing the generation / marking the pool as
"paused". If the pool is already "paused" when it is cleared, then the pool MUST NOT emit a PoolCleared event or log
message.</p>
<p>As part of clearing the pool, the WaitQueue MUST also be cleared, meaning all requests in the WaitQueue MUST fail with
errors indicating that the pool was cleared while the checkOut was being performed. The error returned as a result of
the pool being cleared MUST be considered a retryable error and MUST NOT be an error that marks the SDAM state unknown.
Clearing the WaitQueue MUST happen eagerly so that any operations waiting on <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connections</a> can retry as
soon as possible. The pool MUST NOT rely on WaitQueueTimeoutMS to clear requests from the WaitQueue.</p>
<p>The clearing method MUST provide the option to interrupt any in-use connections as part of the clearing (henceforth
referred to as the interruptInUseConnections flag in this specification). "Interrupting a Connection" is defined as
canceling whatever task the Connection is currently performing and marking the Connection as perished (e.g. by closing
its underlying socket). The interrupting of these Connections MUST be performed as soon as possible but MUST NOT block
the pool or prevent it from processing further requests. If the pool has a background thread, and it is responsible for
interrupting in-use connections, its next run MUST be scheduled as soon as possible.</p>
<p>The pool MUST only interrupt in-use Connections whose generation is less than or equal to the generation of the pool at
the moment of the clear (before the increment) that used the interruptInUseConnections flag. Any operations that have
their Connections interrupted in this way MUST fail with a retryable error. If possible, the error SHOULD be a
PoolClearedError with the following message: "Connection to <pool address> interrupted due to server monitor timeout".</p>
<h5 id="clearing-a-load-balanced-pool-1"><a class="header" href="#clearing-a-load-balanced-pool-1">Clearing a load balanced pool</a></h5>
<p>A Pool MUST also have a method of clearing all <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connections</a> for a specific <code>serviceId</code> for use when in
load balancer mode. This method increments the generation of the pool for that specific <code>serviceId</code> in the generation
map. A PoolClearedEvent and log message MUST be emitted after incrementing the generation. Note that this method MUST
NOT transition the pool to the "paused" state and MUST NOT clear the WaitQueue.</p>
<h4 id="load-balancer-mode-2"><a class="header" href="#load-balancer-mode-2">Load Balancer Mode</a></h4>
<p>For load-balanced deployments, pools MUST maintain a map from <code>serviceId</code> to a tuple of (generation, connection count)
where the connection count refers to the total number of connections that exist for a specific <code>serviceId</code>. The pool
MUST remove the entry for a <code>serviceId</code> once the connection count reaches 0. Once the MongoDB handshake is done, the
connection MUST get the generation number that applies to its <code>serviceId</code> from the map and update the map to increment
the connection count for this <code>serviceId</code>.</p>
<p>See the <a href="connection-monitoring-and-pooling/../load-balancers/load-balancers.html#connection-pooling">Load Balancer Specification</a> for details.</p>
<h4 id="forking-1"><a class="header" href="#forking-1">Forking</a></h4>
<p>A <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connection</a> is explicitly not fork-safe. The proper behavior in the case of a fork is to ResetAfterFork
by:</p>
<ul>
<li>clear all Connection Pools in the child process</li>
<li>closing all <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connections</a> in the child-process.</li>
</ul>
<p>Drivers that support forking MUST document that <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connections</a> to an Endpoint are not fork-safe, and
document the proper way to ResetAfterFork in the driver.</p>
<p>Drivers MAY aggressively ResetAfterFork if the driver detects it has been forked.</p>
<h4 id="optional-behaviors-1"><a class="header" href="#optional-behaviors-1">Optional Behaviors</a></h4>
<p>The following features of a Connection Pool SHOULD be implemented if they make sense in the driver and driver's
language.</p>
<h5 id="background-thread-1"><a class="header" href="#background-thread-1">Background Thread</a></h5>
<p>A Pool SHOULD have a background Thread that is responsible for monitoring the state of all available
<a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connections</a>. This background thread SHOULD</p>
<ul>
<li>Populate <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connections</a> to ensure that the pool always satisfies minPoolSize.</li>
<li>Remove and close perished available <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connections</a> including "in use" connections if
<code>interruptInUseConnections</code> option was set to true in the most recent pool clear.</li>
<li>Apply timeouts to connection establishment per
<a href="connection-monitoring-and-pooling/../client-side-operations-timeout/client-side-operations-timeout.html#background-connection-pooling">Client Side Operations Timeout: Background Connection Pooling</a>.</li>
</ul>
<p>A pool SHOULD allow immediate scheduling of the next background thread iteration after a clear is performed.</p>
<p>Conceptually, the aforementioned activities are organized into sequential Background Thread Runs. A Run MUST do as much
work as readily available and then end instead of waiting for more work. For example, instead of waiting for
pendingConnectionCount to become less than maxConnecting when satisfying minPoolSize, a Run MUST either proceed with the
rest of its duties, e.g., closing available perished connections, or end.</p>
<p>The duration of intervals between the end of one Run and the beginning of the next Run is not specified, but the
<a href="connection-monitoring-and-pooling/../connection-monitoring-and-pooling/tests/README.html">Test Format and Runner Specification</a> may restrict this duration,
or introduce other restrictions to facilitate testing.</p>
<h5 id="withconnection-1"><a class="header" href="#withconnection-1">withConnection</a></h5>
<p>A Pool SHOULD implement a scoped resource management mechanism idiomatic to their language to prevent
<a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connections</a> from not being checked in. Examples include
<a href="https://docs.python.org/3/whatsnew/2.6.html#pep-343-the-with-statement">Python's "with" statement</a> and
<a href="https://docs.microsoft.com/en-us/dotnet/csharp/language-reference/keywords/using-statement">C#'s "using" statement</a>. If
implemented, drivers SHOULD use this method as the default method of checking out and checking in
<a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connections</a>.</p>
<h3 id="connection-pool-monitoring-3"><a class="header" href="#connection-pool-monitoring-3">Connection Pool Monitoring</a></h3>
<p>All drivers that implement a connection pool MUST provide an API that allows users to subscribe to events emitted from
the pool. If a user subscribes to Connection Monitoring events, these events MUST be emitted when specified in
"Connection Pool Behaviors". Events SHOULD be created and subscribed to in a manner idiomatic to their language and
driver.</p>
<p><span id="events"></span></p>
<h4 id="events-3"><a class="header" href="#events-3">Events</a></h4>
<p>See the <a href="connection-monitoring-and-pooling/../load-balancers/load-balancers.html#events">Load Balancer Specification</a> for details on the <code>serviceId</code> field.</p>
<pre><code class="language-typescript">/**
 *  Emitted when a Connection Pool is created
 */
interface PoolCreatedEvent {
  /**
   *  The ServerAddress of the Endpoint the pool is attempting to connect to.
   */
  address: string;

  /**
   *  Any non-default pool options that were set on this Connection Pool.
   */
  options: {...}
}

/**
 *  Emitted when a Connection Pool is marked as ready.
 */
interface PoolReadyEvent {
  /**
   *  The ServerAddress of the Endpoint the pool is attempting to connect to.
   */
  address: string;
}

/**
 *  Emitted when a Connection Pool is cleared
 */
interface PoolClearedEvent {
  /**
   *  The ServerAddress of the Endpoint the pool is attempting to connect to.
   */
  address: string;

  /**
   * The service id for which the pool was cleared for in load balancing mode.
   * See load balancer specification for more information about this field.
   */
  serviceId: Optional&lt;ObjectId&gt;;

  /**
   * A flag whether the pool forced interrupting "in use" connections as part of the clear.
  */
  interruptInUseConnections: Optional&lt;Boolean&gt;;
}

/**
 *  Emitted when a Connection Pool is closed
 */
interface PoolClosedEvent {
  /**
   *  The ServerAddress of the Endpoint the pool is attempting to connect to.
   */
  address: string;
}

/**
 *  Emitted when a Connection Pool creates a Connection object.
 *  NOTE: This does not mean that the Connection is ready for use.
 */
interface ConnectionCreatedEvent { 
  /**
   *  The ServerAddress of the Endpoint the pool is attempting to connect to.
   */
  address: string;

  /**
   *  The ID of the Connection
   */
  connectionId: int64;
}

/**
 *  Emitted when a Connection has finished its setup, and is now ready to use
 */
interface ConnectionReadyEvent {
  /**
   *  The ServerAddress of the Endpoint the pool is attempting to connect to.
   */
  address: string;

  /**
   *  The ID of the Connection
   */
  connectionId: int64;

  /**
   * The time it took to establish the connection.
   * In accordance with the definition of establishment of a connection
   * specified by `ConnectionPoolOptions.maxConnecting`,
   * it is the time elapsed between emitting a `ConnectionCreatedEvent`
   * and emitting this event as part of the same checking out.
   *
   * Naturally, when establishing a connection is part of checking out,
   * this duration is not greater than
   * `ConnectionCheckedOutEvent`/`ConnectionCheckOutFailedEvent.duration`.
   *
   * A driver MAY choose the type idiomatic to the driver.
   * If the type chosen does not convey units, e.g., `int64`,
   * then the driver MAY include units in the name, e.g., `durationMS`.
   */
  duration: Duration;
}

/**
 *  Emitted when a Connection Pool closes a Connection
 */
interface ConnectionClosedEvent {
  /**
   *  The ServerAddress of the Endpoint the pool is attempting to connect to.
   */
  address: string;

  /**
   *  The ID of the Connection
   */
  connectionId: int64;

  /**
   * A reason explaining why this Connection was closed.
   * Can be implemented as a string or enum.
   * Current valid values are:
   *   - "stale":           The pool was cleared, making the Connection no longer valid
   *   - "idle":            The Connection became stale by being available for too long
   *   - "error":           The Connection experienced an error, making it no longer valid
   *   - "poolClosed":      The pool was closed, making the Connection no longer valid
   */
  reason: string|Enum;
}

/**
 *  Emitted when the driver starts attempting to check out a Connection
 */
interface ConnectionCheckOutStartedEvent {
  /**
   * The ServerAddress of the Endpoint the pool is attempting
   * to connect to.
   */
  address: string;
}

/**
 *  Emitted when the driver's attempt to check out a Connection fails
 */
interface ConnectionCheckOutFailedEvent {
  /**
   *  The ServerAddress of the Endpoint the pool is attempting to connect to.
   */
  address: string;

  /**
   *  A reason explaining why Connection check out failed.
   *  Can be implemented as a string or enum.
   *  Current valid values are:
   *   - "poolClosed":      The pool was previously closed, and cannot provide new Connections
   *   - "timeout":         The Connection check out attempt exceeded the specified timeout
   *   - "connectionError": The Connection check out attempt experienced an error while setting up a new Connection
   */
  reason: string|Enum;

  /**
   * See `ConnectionCheckedOutEvent.duration`.
   */
  duration: Duration;
}

/**
 *  Emitted when the driver successfully checks out a Connection
 */
interface ConnectionCheckedOutEvent {
  /**
   *  The ServerAddress of the Endpoint the pool is attempting to connect to.
   */
  address: string;

  /**
   *  The ID of the Connection
   */
  connectionId: int64;

  /**
   * The time it took to check out the connection.
   * More specifically, the time elapsed between
   * emitting a `ConnectionCheckOutStartedEvent`
   * and emitting this event as part of the same checking out.
   *
   * Naturally, if a new connection was not created (`ConnectionCreatedEvent`)
   * and established (`ConnectionReadyEvent`) as part of checking out,
   * this duration is usually
   * not greater than `ConnectionPoolOptions.waitQueueTimeoutMS`,
   * but MAY occasionally be greater than that,
   * because a driver does not provide hard real-time guarantees.
   *
   * A driver MAY choose the type idiomatic to the driver.
   * If the type chosen does not convey units, e.g., `int64`,
   * then the driver MAY include units in the name, e.g., `durationMS`.
   */
  duration: Duration;
}

/**
 *  Emitted when the driver checks in a Connection back to the Connection Pool
 */
interface ConnectionCheckedInEvent {
  /**
   * The ServerAddress of the Endpoint the pool is attempting to connect to.
   */
  address: string;

  /**
   *  The ID of the Connection
   */
  connectionId: int64;
}
</code></pre>
<h3 id="connection-pool-logging-1"><a class="header" href="#connection-pool-logging-1">Connection Pool Logging</a></h3>
<p>Please refer to the <a href="connection-monitoring-and-pooling/../logging/logging.html">logging specification</a> for details on logging implementations in general,
including log levels, log components, handling of null values in log messages, and structured versus unstructured
logging.</p>
<p>Drivers MUST support logging of connection pool information via the following types of log messages. These messages MUST
be logged at <code>Debug</code> level and use the <code>connection</code> log component. These messages MUST be emitted when specified in
"Connection Pool Behaviors".</p>
<p>The log messages are intended to match the information contained in the events above. Drivers MAY implement connection
logging support via an event subscriber if it is convenient to do so.</p>
<p>The types used in the structured message definitions below are demonstrative, and drivers MAY use similar types instead
so long as the information is present (e.g. a double instead of an integer, or a string instead of an integer if the
structured logging framework does not support numeric types).</p>
<h4 id="common-fields-4"><a class="header" href="#common-fields-4">Common Fields</a></h4>
<p>All connection log messages MUST contain the following key-value pairs:</p>
<div class="table-wrapper"><table><thead><tr><th>Key</th><th>Suggested Type</th><th>Value</th></tr></thead><tbody>
<tr><td>serverHost</td><td>String</td><td>the hostname, IP address, or Unix domain socket path for the endpoint the pool is for.</td></tr>
<tr><td>serverPort</td><td>Int</td><td>The port for the endpoint the pool is for. Optional; not present for Unix domain sockets. When the user does not specify a port and the default (27017) is used, the driver SHOULD include it here.</td></tr>
</tbody></table>
</div>
<h4 id="pool-created-message-1"><a class="header" href="#pool-created-message-1">Pool Created Message</a></h4>
<p>In addition to the common fields defined above, this message MUST contain the following key-value pairs:</p>
<div class="table-wrapper"><table><thead><tr><th>Key</th><th>Suggested Type</th><th>Value</th></tr></thead><tbody>
<tr><td>message</td><td>String</td><td>"Connection pool created"</td></tr>
<tr><td>maxIdleTimeMS</td><td>Int</td><td>The maxIdleTimeMS value for this pool. Optional; only required to include if the user specified a value.</td></tr>
<tr><td>minPoolSize</td><td>Int</td><td>The minPoolSize value for this pool. Optional; only required to include if the user specified a value.</td></tr>
<tr><td>maxPoolSize</td><td>Int</td><td>The maxPoolSize value for this pool. Optional; only required to include if the user specified a value.</td></tr>
<tr><td>maxConnecting</td><td>Int</td><td>The maxConnecting value for this pool. Optional; only required to include if the driver supports this option and the user specified a value.</td></tr>
<tr><td>waitQueueTimeoutMS</td><td>Int</td><td>The waitQueueTimeoutMS value for this pool. Optional; only required to include if the driver supports this option and the user specified a value.</td></tr>
<tr><td>waitQueueSize</td><td>Int</td><td>The waitQueueSize value for this pool. Optional; only required to include if the driver supports this option and the user specified a value.</td></tr>
<tr><td>waitQueueMultiple</td><td>Int</td><td>The waitQueueMultiple value for this pool. Optional; only required to include if the driver supports this option and the user specified a value.</td></tr>
</tbody></table>
</div>
<p>The unstructured form SHOULD be as follows, using the values defined in the structured format above to fill in
placeholders as appropriate:</p>
<blockquote>
<p>Connection pool created for {{serverHost}}:{{serverPort}} using options maxIdleTimeMS={{maxIdleTimeMS}},
minPoolSize={{minPoolSize}}, maxPoolSize={{maxPoolSize}}, maxConnecting={{maxConnecting}},
waitQueueTimeoutMS={{waitQueueTimeoutMS}}, waitQueueSize={{waitQueueSize}}, waitQueueMultiple={{waitQueueMultiple}}</p>
</blockquote>
<h4 id="pool-ready-message-1"><a class="header" href="#pool-ready-message-1">Pool Ready Message</a></h4>
<p>In addition to the common fields defined above, this message MUST contain the following key-value pairs:</p>
<div class="table-wrapper"><table><thead><tr><th>Key</th><th>Suggested Type</th><th>Value</th></tr></thead><tbody>
<tr><td>message</td><td>String</td><td>"Connection pool ready"</td></tr>
</tbody></table>
</div>
<p>The unstructured form SHOULD be as follows, using the values defined in the structured format above to fill in
placeholders as appropriate:</p>
<blockquote>
<p>Connection pool ready for {{serverHost}}:{{serverPort}}</p>
</blockquote>
<h4 id="pool-cleared-message-1"><a class="header" href="#pool-cleared-message-1">Pool Cleared Message</a></h4>
<p>In addition to the common fields defined above, this message MUST contain the following key-value pairs:</p>
<div class="table-wrapper"><table><thead><tr><th>Key</th><th>Suggested Type</th><th>Value</th></tr></thead><tbody>
<tr><td>message</td><td>String</td><td>"Connection pool cleared"</td></tr>
<tr><td>serviceId</td><td>String</td><td>The hex string representation of the service ID which the pool was cleared for. Optional; only present in load balanced mode.</td></tr>
</tbody></table>
</div>
<p>The unstructured form SHOULD be as follows, using the values defined in the structured format above to fill in
placeholders as appropriate:</p>
<blockquote>
<p>Connection pool for {{serverHost}}:{{serverPort}} cleared for serviceId {{serviceId}}</p>
</blockquote>
<h4 id="pool-closed-message-1"><a class="header" href="#pool-closed-message-1">Pool Closed Message</a></h4>
<p>In addition to the common fields defined above, this message MUST contain the following key-value pairs:</p>
<div class="table-wrapper"><table><thead><tr><th>Key</th><th>Suggested Type</th><th>Value</th></tr></thead><tbody>
<tr><td>message</td><td>String</td><td>"Connection pool closed"</td></tr>
</tbody></table>
</div>
<p>The unstructured form SHOULD be as follows, using the values defined in the structured format above to fill in
placeholders as appropriate:</p>
<blockquote>
<p>Connection pool closed for {{serverHost}}:{{serverPort}}</p>
</blockquote>
<h4 id="connection-created-message-1"><a class="header" href="#connection-created-message-1">Connection Created Message</a></h4>
<p>In addition to the common fields defined above, this message MUST contain the following key-value pairs:</p>
<div class="table-wrapper"><table><thead><tr><th>Key</th><th>Suggested Type</th><th>Value</th></tr></thead><tbody>
<tr><td>message</td><td>String</td><td>"Connection created"</td></tr>
<tr><td>driverConnectionId</td><td>Int64</td><td>The driver-generated ID for the connection as defined in <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connection</a>.</td></tr>
</tbody></table>
</div>
<p>The unstructured form SHOULD be as follows, using the values defined in the structured format above to fill in
placeholders as appropriate:</p>
<blockquote>
<p>Connection created: address={{serverHost}}:{{serverPort}}, driver-generated ID={{driverConnectionId}}</p>
</blockquote>
<h4 id="connection-ready-message-1"><a class="header" href="#connection-ready-message-1">Connection Ready Message</a></h4>
<p>In addition to the common fields defined above, this message MUST contain the following key-value pairs:</p>
<div class="table-wrapper"><table><thead><tr><th>Key</th><th>Suggested Type</th><th>Value</th></tr></thead><tbody>
<tr><td>message</td><td>String</td><td>"Connection ready"</td></tr>
<tr><td>driverConnectionId</td><td>Int64</td><td>The driver-generated ID for the connection as defined in <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connection</a>.</td></tr>
<tr><td>durationMS</td><td>Int64</td><td><code>ConnectionReadyEvent.duration</code> converted to milliseconds.</td></tr>
</tbody></table>
</div>
<p>The unstructured form SHOULD be as follows, using the values defined in the structured format above to fill in
placeholders as appropriate:</p>
<blockquote>
<p>Connection ready: address={{serverHost}}:{{serverPort}}, driver-generated ID={{driverConnectionId}}, established
in={{durationMS}} ms</p>
</blockquote>
<h4 id="connection-closed-message-1"><a class="header" href="#connection-closed-message-1">Connection Closed Message</a></h4>
<p>In addition to the common fields defined above, this message MUST contain the following key-value pairs:</p>
<div class="table-wrapper"><table><thead><tr><th>Key</th><th>Suggested Type</th><th>Value</th></tr></thead><tbody>
<tr><td>message</td><td>String</td><td>"Connection closed"</td></tr>
<tr><td>driverConnectionId</td><td>Int64</td><td>The driver-generated ID for the connection as defined in a <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connection</a>.</td></tr>
<tr><td>reason</td><td>String</td><td>A string describing the reason the connection was closed. The following strings MUST be used for each possible reason as defined in <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#events">Events</a> above:<br>- Stale: "Connection became stale because the pool was cleared<br>- Idle: "Connection has been available but unused for longer than the configured max idle time"<br>- Error: "An error occurred while using the connection"<br>- Pool closed: "Connection pool was closed"</td></tr>
<tr><td>error</td><td>Flexible</td><td>If <code>reason</code> is <code>Error</code>, the associated error.<br>The type and format of this value is flexible; see the <a href="connection-monitoring-and-pooling/../logging/logging.html#representing-errors-in-log-messages">logging specification</a> for details on representing errors in log messages.</td></tr>
</tbody></table>
</div>
<p>The unstructured form SHOULD be as follows, using the values defined in the structured format above to fill in
placeholders as appropriate:</p>
<blockquote>
<p>Connection closed: address={{serverHost}}:{{serverPort}}, driver-generated ID={{driverConnectionId}}. Reason:
{{reason}}. Error: {{error}}</p>
</blockquote>
<h4 id="connection-checkout-started-message-1"><a class="header" href="#connection-checkout-started-message-1">Connection Checkout Started Message</a></h4>
<p>In addition to the common fields defined above, this message MUST contain the following key-value pairs:</p>
<div class="table-wrapper"><table><thead><tr><th>Key</th><th>Suggested Type</th><th>Value</th></tr></thead><tbody>
<tr><td>message</td><td>String</td><td>"Connection checkout started"</td></tr>
</tbody></table>
</div>
<p>The unstructured form SHOULD be as follows, using the values defined in the structured format above to fill in
placeholders as appropriate:</p>
<blockquote>
<p>Checkout started for connection to {{serverHost}}:{{serverPort}}</p>
</blockquote>
<h4 id="connection-checkout-failed-message-1"><a class="header" href="#connection-checkout-failed-message-1">Connection Checkout Failed Message</a></h4>
<p>In addition to the common fields defined above, this message MUST contain the following key-value pairs:</p>
<div class="table-wrapper"><table><thead><tr><th>Key</th><th>Suggested Type</th><th>Value</th></tr></thead><tbody>
<tr><td>message</td><td>String</td><td>"Connection checkout failed"</td></tr>
<tr><td>reason</td><td>String</td><td>A string describing the reason checkout. The following strings MUST be used for each possible reason as defined in <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#events">Events</a> above:<br>- Timeout: "Wait queue timeout elapsed without a connection becoming available"<br>- ConnectionError: "An error occurred while trying to establish a new connection"<br>- Pool closed: "Connection pool was closed"</td></tr>
<tr><td>error</td><td>Flexible</td><td>If <code>reason</code> is <code>ConnectionError</code>, the associated error. The type and format of this value is flexible; see the <a href="connection-monitoring-and-pooling/../logging/logging.html#representing-errors-in-log-messages">logging specification</a> for details on representing errors in log messages.</td></tr>
<tr><td>durationMS</td><td>Int64</td><td><code>ConnectionCheckOutFailedEvent.duration</code> converted to milliseconds.</td></tr>
</tbody></table>
</div>
<p>The unstructured form SHOULD be as follows, using the values defined in the structured format above to fill in
placeholders as appropriate:</p>
<blockquote>
<p>Checkout failed for connection to {{serverHost}}:{{serverPort}}. Reason: {{reason}}. Error: {{error}}. Duration:
{{durationMS}} ms</p>
</blockquote>
<h4 id="connection-checked-out-1"><a class="header" href="#connection-checked-out-1">Connection Checked Out</a></h4>
<p>In addition to the common fields defined above, this message MUST contain the following key-value pairs:</p>
<div class="table-wrapper"><table><thead><tr><th>Key</th><th>Suggested Type</th><th>Value</th></tr></thead><tbody>
<tr><td>message</td><td>String</td><td>"Connection checked out"</td></tr>
<tr><td>driverConnectionId</td><td>Int64</td><td>The driver-generated ID for the connection as defined in <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connection</a>.</td></tr>
<tr><td>durationMS</td><td>Int64</td><td><code>ConnectionCheckedOutEvent.duration</code> converted to milliseconds.</td></tr>
</tbody></table>
</div>
<p>The unstructured form SHOULD be as follows, using the values defined in the structured format above to fill in
placeholders as appropriate:</p>
<blockquote>
<p>Connection checked out: address={serverHost}}:{{serverPort}}, driver-generated ID={{driverConnectionId}},
duration={{durationMS}} ms</p>
</blockquote>
<h4 id="connection-checked-in-1"><a class="header" href="#connection-checked-in-1">Connection Checked In</a></h4>
<p>In addition to the common fields defined above, this message MUST contain the following key-value pairs:</p>
<div class="table-wrapper"><table><thead><tr><th>Key</th><th>Suggested Type</th><th>Value</th></tr></thead><tbody>
<tr><td>message</td><td>String</td><td>"Connection checked in"</td></tr>
<tr><td>driverConnectionId</td><td>Int64</td><td>The driver-generated ID for the connection as defined in <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connection</a>.</td></tr>
</tbody></table>
</div>
<p>The unstructured form SHOULD be as follows, using the values defined in the structured format above to fill in
placeholders as appropriate:</p>
<blockquote>
<p>Connection checked in: address={{serverHost}}:{{serverPort}}, driver-generated ID={{driverConnectionId}}</p>
</blockquote>
<h3 id="connection-pool-errors-1"><a class="header" href="#connection-pool-errors-1">Connection Pool Errors</a></h3>
<p>A connection pool throws errors in specific circumstances. These Errors MUST be emitted by the pool. Errors SHOULD be
created and dispatched in a manner idiomatic to the Driver and Language.</p>
<pre><code class="language-typescript">/**
 *  Thrown when the driver attempts to check out a
 *  Connection from a closed Connection Pool
 */
interface PoolClosedError {
  message: 'Attempted to check out a Connection from closed connection pool';
  address: &lt;pool address&gt;;
}

/**
 *  Thrown when the driver attempts to check out a
 *  Connection from a paused Connection Pool
 */
interface PoolClearedError extends RetryableError {
  message: 'Connection pool for &lt;pool address&gt; was cleared because another operation failed with: &lt;original error which cleared the pool&gt;';
  address: &lt;pool address&gt;;
}

/**
 *  Thrown when a driver times out when attempting to check out
 *  a Connection from a Pool
 */
interface WaitQueueTimeoutError {
  message: 'Timed out while checking out a Connection from connection pool';
  address: &lt;pool address&gt;;
}
</code></pre>
<h2 id="test-plan-33"><a class="header" href="#test-plan-33">Test Plan</a></h2>
<p>See <a href="connection-monitoring-and-pooling/tests/README.html">tests/README</a></p>
<h2 id="design-rationale-28"><a class="header" href="#design-rationale-28">Design Rationale</a></h2>
<h3 id="why-do-we-set-minpoolsize-across-all-members-of-a-replicaset-when-most-traffic-will-be-against-a-primary-1"><a class="header" href="#why-do-we-set-minpoolsize-across-all-members-of-a-replicaset-when-most-traffic-will-be-against-a-primary-1">Why do we set minPoolSize across all members of a replicaSet, when most traffic will be against a Primary?</a></h3>
<p>Currently, we are attempting to codify our current pooling behavior with minimal changes, and minPoolSize is currently
uniform across all members of a replicaSet. This has the benefit of offsetting connection swarming during a Primary
Step-Down, which will be further addressed in our <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#advanced-pooling-behaviors">Advanced Pooling Behaviors</a>.</p>
<h3 id="why-do-we-have-separate-connectioncreated-and-connectionready-events-but-only-one-connectionclosed-event-1"><a class="header" href="#why-do-we-have-separate-connectioncreated-and-connectionready-events-but-only-one-connectionclosed-event-1">Why do we have separate ConnectionCreated and ConnectionReady events, but only one ConnectionClosed event?</a></h3>
<p>ConnectionCreated and ConnectionReady each involve different state changes in the pool.</p>
<ul>
<li>ConnectionCreated adds a new "pending" <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connection</a>, meaning the totalConnectionCount and
pendingConnectionCount increase by one</li>
<li>ConnectionReady establishes that the <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connection</a> is ready for use, meaning the availableConnectionCount
increases by one</li>
</ul>
<p>ConnectionClosed indicates that the <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connection</a> is no longer a member of the pool, decrementing
totalConnectionCount and potentially availableConnectionCount. After this point, the <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connection</a> is no
longer a part of the pool. Further hypothetical events would not indicate a change to the state of the pool, so they are
not specified here.</p>
<h3 id="why-are-waitqueuesize-and-waitqueuemultiple-deprecated-1"><a class="header" href="#why-are-waitqueuesize-and-waitqueuemultiple-deprecated-1">Why are waitQueueSize and waitQueueMultiple deprecated?</a></h3>
<p>These options were originally only implemented in three drivers (Java, C#, and Python), and provided little value. While
these fields would allow for faster diagnosis of issues in the connection pool, they would not actually prevent an error
from occurring.</p>
<p>Additionally, these options have the effect of prioritizing older requests over newer requests, which is not necessarily
the behavior that users want. They can also result in cases where queue access oscillates back and forth between full
and not full. If a driver has a full waitQueue, then all requests for <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connections</a> will be rejected. If
the client is continually spammed with requests, you could wind up with a scenario where as soon as the waitQueue is no
longer full, it is immediately filled. It is not a favorable situation to be in, partially b/c it violates the fairness
guarantee that the waitQueue normally provides.</p>
<p>Because of these issues, it does not make sense to
<a href="connection-monitoring-and-pooling/../driver-mantras.html#">go against driver mantras and provide an additional knob</a>. We may eventually pursue an
alternative configuration to address wait queue size in <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#advanced-pooling-behaviors">Advanced Pooling Behaviors</a>.</p>
<p>Users that wish to have this functionality can achieve similar results by utilizing other methods to limit concurrency.
Examples include implementing either a thread pool or an operation queue with a capped size in the user application.
Drivers that need to deprecate <code>waitQueueSize</code> and/or <code>waitQueueMultiple</code> SHOULD refer users to these examples.</p>
<h3 id="why-is-waitqueuetimeoutms-optional-for-some-drivers-1"><a class="header" href="#why-is-waitqueuetimeoutms-optional-for-some-drivers-1">Why is waitQueueTimeoutMS optional for some drivers?</a></h3>
<p>We are anticipating eventually introducing a single client-side timeout mechanism, making us hesitant to introduce
another granular timeout control. Therefore, if a driver/language already has an idiomatic way to implement their
timeouts, they should leverage that mechanism over implementing waitQueueTimeoutMS.</p>
<h3 id="why-must-populating-the-pool-require-the-use-of-a-background-thread-or-async-io-1"><a class="header" href="#why-must-populating-the-pool-require-the-use-of-a-background-thread-or-async-io-1">Why must populating the pool require the use of a background thread or async I/O?</a></h3>
<p>Without the use of a background thread, the pool is
<a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#populating-the-pool-with-a-connection-internal-implementation">populated</a> with enough connections to satisfy
minPoolSize during checkOut. <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connections</a> are established as part of populating the pool though, so if
<a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connection</a> establishment were done in a blocking fashion, the first operations after a clearing of the
pool would experience unacceptably high latency, especially for larger values of minPoolSize. Thus, populating the pool
must occur on a background thread (which is acceptable to block) or via the usage of non-blocking (async) I/O.</p>
<h3 id="why-should-closing-a-connection-be-non-blocking-1"><a class="header" href="#why-should-closing-a-connection-be-non-blocking-1">Why should closing a connection be non-blocking?</a></h3>
<p>Because idle and perished <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connections</a> are cleaned up as part of checkOut, performing blocking I/O while
closing such <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connections</a> would block application threads, introducing unnecessary latency. Once a
<a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connection</a> is marked as "closed", it will not be checked out again, so ensuring the socket is torn down
does not need to happen immediately and can happen at a later time, either via async I/O or a background thread.</p>
<h3 id="why-can-the-pool-be-paused-1"><a class="header" href="#why-can-the-pool-be-paused-1">Why can the pool be paused?</a></h3>
<p>The distinction between the "paused" state and the "ready" state allows the pool to determine whether or not the
endpoint it is associated with is available or not. This enables the following behaviors:</p>
<ol>
<li>The pool can halt the creation of background connection establishments until the endpoint becomes available again.
Without the "paused" state, the pool would have no way of determining when to begin establishing background
connections again, so it would just continually attempt, and often fail, to create connections until minPoolSize was
satisfied, even after repeated failures. This could unnecessarily waste resources both server and driver side.</li>
<li>The pool can evict requests that enter the WaitQueue after the pool was cleared but before the server was in a known
state again. Such requests can occur when a server is selected at the same time as it becomes marked as Unknown in
highly concurrent workloads. Without the "paused" state, the pool would attempt to service these requests, since it
would assume they were routed to the pool because its endpoint was available, not because of a race between SDAM and
Server Selection. These requests would then likely fail with potentially high latency, again wasting resources both
server and driver side.</li>
</ol>
<h3 id="why-not-emit-poolcleared-events-and-log-messages-when-clearing-a-paused-pool-1"><a class="header" href="#why-not-emit-poolcleared-events-and-log-messages-when-clearing-a-paused-pool-1">Why not emit PoolCleared events and log messages when clearing a paused pool?</a></h3>
<p>If a pool is already paused when it is cleared, that means it was previously cleared and no new connections have been
created since then. Thus, clearing the pool in this case is essentially a no-op, so there is no need to notify any
listeners that it has occurred. The generation is still incremented, however, to ensure future errors that caused the
duplicate clear will stop attempting to clear the pool again. This situation is possible if the pool is cleared by the
background thread after it encounters an error establishing a connection, but the ServerDescription for the endpoint was
not updated accordingly yet.</p>
<h3 id="why-does-the-pool-need-to-support-interrupting-in-use-connections-as-part-of-its-clear-logic-1"><a class="header" href="#why-does-the-pool-need-to-support-interrupting-in-use-connections-as-part-of-its-clear-logic-1">Why does the pool need to support interrupting in use connections as part of its clear logic?</a></h3>
<p>If a SDAM monitor has observed a network timeout, we assume that all connections including "in use" connections are no
longer healthy. In some cases connections will fail to detect the network timeout fast enough. For example, a server
request can hang at the OS level in TCP retry loop up for 17 minutes before failing. Therefore these connections MUST be
proactively interrupted in the case of a server monitor network timeout. Requesting an immediate background thread run
will speed up this process.</p>
<h3 id="why-dont-we-configure-tcp_user_timeout-1"><a class="header" href="#why-dont-we-configure-tcp_user_timeout-1">Why don't we configure TCP_USER_TIMEOUT?</a></h3>
<p>Ideally, a reasonable TCP_USER_TIMEOUT can help with detecting stale connections as an alternative to
<code>interruptInUseConnections</code> in Clear. Unfortunately this approach is platform dependent and not each driver allows
easily configuring it. For example, C# driver can configure this socket option on linux only with target frameworks
higher or equal to .net 5.0. On macOS, there is no straight equivalent for this option, it's possible that we can find
some equivalent configuration, but this configuration will also require target frameworks higher than or equal to .net
5.0. The advantage of using Background Thread to manage perished connections is that it will work regardless of
environment setup.</p>
<h2 id="backwards-compatibility-27"><a class="header" href="#backwards-compatibility-27">Backwards Compatibility</a></h2>
<p>As mentioned in <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#deprecated-options">Deprecated Options</a>, some drivers currently implement the options <code>waitQueueSize</code>
and/or <code>waitQueueMultiple</code>. These options will need to be deprecated and phased out of the drivers that have implemented
them.</p>
<h2 id="reference-implementations-5"><a class="header" href="#reference-implementations-5">Reference Implementations</a></h2>
<ul>
<li>JAVA (JAVA-3079)</li>
<li>RUBY (RUBY-1560)</li>
</ul>
<h2 id="future-development-1"><a class="header" href="#future-development-1">Future Development</a></h2>
<h3 id="sdam-2"><a class="header" href="#sdam-2">SDAM</a></h3>
<p>This specification does not dictate how SDAM Monitoring connections are managed. SDAM specifies that "A monitor SHOULD
NOT use the client's regular Connection pool". Some possible solutions for this include:</p>
<ul>
<li>Having each Endpoint representation in the driver create and manage a separate dedicated <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connection</a> for
monitoring purposes</li>
<li>Having each Endpoint representation in the driver maintain a separate pool of maxPoolSize 1 for monitoring purposes.</li>
<li>Having each Pool maintain a dedicated <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connection</a> for monitoring purposes, with an API to expose that
Connection.</li>
</ul>
<h3 id="advanced-pooling-behaviors-1"><a class="header" href="#advanced-pooling-behaviors-1">Advanced Pooling Behaviors</a></h3>
<p>This spec does not address all advanced pooling behaviors like predictive pooling or aggressive
<a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connection</a> creation. Future work may address this.</p>
<h3 id="add-support-for-op_msg-exhaustallowed-1"><a class="header" href="#add-support-for-op_msg-exhaustallowed-1">Add support for OP_MSG exhaustAllowed</a></h3>
<p>Exhaust Cursors may require changes to how we close <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connections</a> in the future, specifically to add a way
to close and remove from its pool a <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#connection">Connection</a> which has unread exhaust messages.</p>
<h2 id="changelog-46"><a class="header" href="#changelog-46">Changelog</a></h2>
<ul>
<li>
<p>2024-01-23: Migrated from reStructuredText to Markdown.</p>
</li>
<li>
<p>2019-06-06: Add "connectionError" as a valid reason for ConnectionCheckOutFailedEvent</p>
</li>
<li>
<p>2020-09-03: Clarify Connection states and definition. Require the use of a background thread and/or async I/O. Add
tests to ensure ConnectionReadyEvents are fired after ConnectionCreatedEvents.</p>
</li>
<li>
<p>2020-09-24: Introduce maxConnecting requirement</p>
</li>
<li>
<p>2020-12-17: Introduce "paused" and "ready" states. Clear WaitQueue on pool clear.</p>
</li>
<li>
<p>2021-01-12: Clarify "clear" method behavior in load balancer mode.</p>
</li>
<li>
<p>2021-01-19: Require that timeouts be applied per the client-side operations timeout specification.</p>
</li>
<li>
<p>2021-04-12: Adding in behaviour for load balancer mode.</p>
</li>
<li>
<p>2021-06-02: Formalize the behavior of a <a href="connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#background-thread">Background Thread</a>.</p>
</li>
<li>
<p>2021-11-08: Make maxConnecting configurable.</p>
</li>
<li>
<p>2022-04-05: Preemptively cancel in progress operations when SDAM heartbeats timeout.</p>
</li>
<li>
<p>2022-10-05: Remove spec front matter and reformat changelog.</p>
</li>
<li>
<p>2022-10-14: Add connection pool log messages and associated tests.</p>
</li>
<li>
<p>2023-04-17: Fix duplicate logging test description.</p>
</li>
<li>
<p>2023-08-04: Add durations to connection pool events.</p>
</li>
<li>
<p>2023-10-04: Commit to the currently specified requirements regarding durations in events.</p>
</li>
</ul>
<hr />
<div style="break-before: page; page-break-before: always;"></div><h1 id="unified-test-format"><a class="header" href="#unified-test-format">Unified Test Format</a></h1>
<ul>
<li>Status: Accepted</li>
<li>Minimum Server Version: N/A</li>
<li>Current Schema Version: 1.19.0</li>
</ul>
<hr />
<h2 id="abstract-44"><a class="header" href="#abstract-44">Abstract</a></h2>
<p>This project defines a unified schema for YAML and JSON specification tests, which run operations against a MongoDB
deployment. By conforming various spec tests to a single schema, drivers can implement a single test runner to execute
acceptance tests for multiple specifications, thereby reducing maintenance of existing specs and implementation time for
new specifications.</p>
<h2 id="meta-45"><a class="header" href="#meta-45">META</a></h2>
<p>The keywords "MUST", "MUST NOT", "REQUIRED", "SHALL", "SHALL NOT", "SHOULD", "SHOULD NOT", "RECOMMENDED", "MAY", and
"OPTIONAL" in this document are to be interpreted as described in <a href="https://www.ietf.org/rfc/rfc2119.txt">RFC 2119</a>.</p>
<p>This document tends to use "SHOULD" more frequently than other specifications, but mainly in the context of providing
guidance on writing test files. This is discussed in more detail in <a href="unified-test-format/unified-test-format.html#design-rationale">Design Rationale</a>.</p>
<h2 id="goals-2"><a class="header" href="#goals-2">Goals</a></h2>
<p>This test format can be used to define tests for the following specifications:</p>
<ul>
<li><a href="unified-test-format/../change-streams/change-streams.html">Change Streams</a></li>
<li><a href="unified-test-format/../command-logging-and-monitoring/command-logging-and-monitoring.html">Command Logging and Monitoring</a></li>
<li><a href="unified-test-format/../crud/crud.html">CRUD</a></li>
<li><a href="unified-test-format/../gridfs/gridfs-spec.html">GridFS</a></li>
<li><a href="unified-test-format/../retryable-reads/retryable-reads.html">Retryable Reads</a></li>
<li><a href="unified-test-format/../retryable-writes/retryable-writes.html">Retryable Writes</a></li>
<li><a href="unified-test-format/../sessions/driver-sessions.html">Sessions</a></li>
<li><a href="unified-test-format/../transactions/transactions.html">Transactions</a></li>
<li><a href="unified-test-format/../transactions-convenient-api/transactions-convenient-api.html">Convenient API for Transactions</a></li>
<li><a href="unified-test-format/../server-discovery-and-monitoring/server-discovery-and-monitoring.html">Server Discovery and Monitoring</a></li>
</ul>
<p>This is not an exhaustive list. Specifications that are known to not be supported by this format may be discussed under
<a href="unified-test-format/unified-test-format.html#future-work">Future Work</a>.</p>
<h2 id="specification-41"><a class="header" href="#specification-41">Specification</a></h2>
<h3 id="terms-30"><a class="header" href="#terms-30">Terms</a></h3>
<p><strong>Entity</strong> Any object or value that is indexed by a unique name and stored in the <a href="unified-test-format/unified-test-format.html#entity-map">Entity Map</a>. This will
typically be a driver object (e.g. client, session) defined in <a href="unified-test-format/unified-test-format.html#createentities">createEntities</a> but may also be a
<a href="unified-test-format/unified-test-format.html#operation_saveResultAsEntity">saved operation result</a>. A exhaustive list of supported types is presented in
<a href="unified-test-format/unified-test-format.html#supported-entity-types">Supported Entity Types</a>. Entities are referenced by name throughout the test file (e.g.
<a href="unified-test-format/unified-test-format.html#entity-test-operations">Entity Test Operations</a>).</p>
<p><strong>Internal MongoClient</strong> A MongoClient created specifically for use with internal test operations, such as inserting
collection data before a test, performing special assertions during a test, or asserting collection data after a test.</p>
<p><strong>Iterable</strong> This term is used by various specifications as the return type for operations that return a sequence of
items, which may be iterated. For example, the CRUD spec uses this as the return value for <code>find</code> and permit API
flexibility rather than stipulate that a cursor object be returned directly.</p>
<h3 id="server-compatibility"><a class="header" href="#server-compatibility">Server Compatibility</a></h3>
<p>The unified test format is intended to only run against enterprise servers. Additionally, many tests make use of
<a href="unified-test-format/unified-test-format.html#server-fail-points">Server Fail Points</a>, so servers MUST be launched with the <code>enableTestCommands</code> parameter enabled.</p>
<h3 id="schema-version"><a class="header" href="#schema-version">Schema Version</a></h3>
<p>This specification and the <a href="unified-test-format/unified-test-format.html#test-format">Test Format</a> follow <a href="https://semver.org/">semantic versioning</a>. The version is
primarily used to validate test files with a <a href="https://json-schema.org/">JSON schema</a> and also allow test runners to
determine whether a particular test file is supported.</p>
<p>New tests files SHOULD always be written using the latest major version of this specification; however, test files
SHOULD be conservative in the minor version they specify (as noted in <a href="unified-test-format/unified-test-format.html#schemaVersion">schemaVersion</a>).</p>
<h4 id="json-schema-validation"><a class="header" href="#json-schema-validation">JSON Schema Validation</a></h4>
<p>Each major or minor version that changes the <a href="unified-test-format/unified-test-format.html#test-format">Test Format</a> SHALL have a corresponding JSON schema. When a
new schema file is introduced, any existing schema files MUST remain in place since they may be needed for validation.
For example: if an additive change is made to version 1.0 of the spec, the <code>schema-1.0.json</code> file will be copied to
<code>schema-1.1.json</code> and modified accordingly. A new or existing test file using <a href="unified-test-format/unified-test-format.html#schemaVersion">schemaVersion</a> "1.0"
would then be expected to validate against both schema files. Schema version bumps MUST be noted in the
<a href="unified-test-format/unified-test-format.html#changelog">Changelog</a>.</p>
<p>A particular minor version MUST be capable of validating any and all test files in that major version series up to and
including the minor version. For example, <code>schema-2.1.json</code> should validate test files with
<a href="unified-test-format/unified-test-format.html#schemaVersion">schemaVersion</a> "2.0" and "2.1", but would not be expected to validate files specifying "1.0", "2.2", or
"3.0".</p>
<p>The JSON schema MUST remain consistent with the <a href="unified-test-format/unified-test-format.html#test-format">Test Format</a> section. If and when a new major version is
introduced, the <a href="unified-test-format/unified-test-format.html#breaking-changes">Breaking Changes</a> section MUST be updated.</p>
<p><a href="https://ajv.js.org/">Ajv</a> MAY be used to programmatically validate both YAML and JSON files using the JSON schema. The
JSON schema MUST NOT use syntax that is unsupported by this tool, which bears mentioning because there are multiple
versions of the <a href="https://json-schema.org/specification.html">JSON schema specification</a>.</p>
<h4 id="test-runner-support"><a class="header" href="#test-runner-support">Test Runner Support</a></h4>
<p>Each test file defines a <a href="unified-test-format/unified-test-format.html#schemaVersion">schemaVersion</a>, which test runners will use to determine compatibility (i.e.
whether and how the test file will be interpreted). Test files are considered compatible with a test runner if their
<a href="unified-test-format/unified-test-format.html#schemaVersion">schemaVersion</a> is less than or equal to a supported version in the test runner, given the same major
version component. For example:</p>
<ul>
<li>A test runner supporting version 1.5.1 could execute test files with versions 1.0 and 1.5 but <em>not</em> 1.6 and 2.0.</li>
<li>A test runner supporting version 2.1 could execute test files with versions 2.0 and 2.1 but <em>not</em> 1.0 and 1.5.</li>
<li>A test runner supporting <em>both</em> versions 1.5.1 and 2.0 could execute test files with versions 1.4, 1.5, and 2.0, but
<em>not</em> 1.6, 2.1, or 3.0.</li>
<li>A test runner supporting version 2.0.1 could execute test files with versions 2.0 and 2.0.1 but <em>not</em> 2.0.2 or 2.1.
This example is provided for completeness, but test files SHOULD NOT need to refer to patch versions (as previously
mentioned).</li>
</ul>
<p>Test runners MUST NOT process incompatible files and MUST raise an error if they encounter an incompatible file (as
discussed in <a href="unified-test-format/unified-test-format.html#executing-a-test-file">Executing a Test File</a>). Test runners MAY support multiple schema versions (as
demonstrated in the example above).</p>
<h4 id="impact-of-spec-changes-on-schema-version"><a class="header" href="#impact-of-spec-changes-on-schema-version">Impact of Spec Changes on Schema Version</a></h4>
<p>Backwards-breaking changes SHALL warrant a new major version. These changes include, but are not limited to:</p>
<ul>
<li>Subtractive changes, such as removing a field, operation, or type of supported entity or event</li>
<li>Changing an existing field from optional to required</li>
<li>Introducing a new, required field in the test format</li>
<li>Significant changes to test file execution (not BC)</li>
</ul>
<p>Backwards-compatible changes SHALL warrant a new minor version. These changes include, but are not limited to:</p>
<ul>
<li>Additive changes, such as a introducing a new <a href="unified-test-format/unified-test-format.html#special-test-operations">Special Test Operations</a> or type of supported
entity or event</li>
<li>Changing an existing field from required to optional</li>
<li>Introducing a new, optional field in the test format</li>
<li>Minor changes to test file execution (BC)</li>
</ul>
<p>Small fixes and internal spec changes (e.g. grammar, adding clarifying text to the spec) MAY warrant a new patch
version; however, patch versions SHOULD NOT alter the structure of the test format and thus SHOULD NOT be relevant to
test files (as noted in <a href="unified-test-format/unified-test-format.html#schemaVersion">schemaVersion</a>).</p>
<h3 id="entity-map"><a class="header" href="#entity-map">Entity Map</a></h3>
<p>The entity map indexes arbitrary objects and values by unique names, so that they can be referenced from test constructs
(e.g. <a href="unified-test-format/unified-test-format.html#operation_object">operation.object</a>). To ensure each test is executed in isolation, test runners MUST NOT share
entity maps between tests. Most entities will be driver objects created by the <a href="unified-test-format/unified-test-format.html#createentities">createEntities</a>
directive during test setup, but the entity map may also be modified during test execution via the
<a href="unified-test-format/unified-test-format.html#operation_saveResultAsEntity">operation.saveResultAsEntity</a> directive.</p>
<p>Test runners MAY choose to implement the entity map in a fashion most suited to their language, but implementations MUST
enforce both uniqueness of entity names and referential integrity when fetching an entity. Test runners MUST raise an
error if an attempt is made to store an entity with a name that already exists in the map and MUST raise an error if an
entity is not found for a name or is found but has an unexpected type.</p>
<p>Test runners MUST provide a mechanism to retrieve entities from the entity map prior to the clearing of the entity map,
as discussed in <a href="unified-test-format/unified-test-format.html#executing-a-test">Executing a Test</a>. There MUST be a way to retrieve an entity by its name (for
example, to support retrieving the iteration count stored by the <code>storeIterationsAsEntity</code> option).</p>
<p>Test runners MAY restrict access to driver objects (e.g. MongoClient, ChangeStream) and only allow access to BSON types
(see: <a href="unified-test-format/unified-test-format.html#supported-entity-types">Supported Entity Types</a>). This restriction may be necessary if the test runner needs to
ensure driver objects in its entity map are properly freed/destroyed between tests.</p>
<p>The entity map MUST be implemented in a way that allows for safe concurrent access, since a test may include multiple
thread entities that all need to access the map concurrently. See <a href="unified-test-format/unified-test-format.html#entity_thread">entity_thread</a> for more information
on test runner threads.</p>
<p>Consider the following examples:</p>
<pre><code># Error due to a duplicate name (client0 was already defined)
createEntities:
  - client: { id: client0 }
  - client: { id: client0 }

# Error due to a missing entity (client1 is undefined)
createEntities:
  - client: { id: client0 }
  - session: { id: session0, client: client1 }

# Error due to an unexpected entity type (session instead of client)
createEntities:
  - client: { id: client0 }
  - session: { id: session0, client: client0 }
  - session: { id: session1, client: session0 }
</code></pre>
<h4 id="supported-entity-types"><a class="header" href="#supported-entity-types">Supported Entity Types</a></h4>
<p>Test runners MUST support the following types of entities:</p>
<ul>
<li>MongoClient. See <a href="unified-test-format/unified-test-format.html#entity_client">entity_client</a> and <a href="unified-test-format/unified-test-format.html#client-operations">Client Operations</a>.</li>
<li>ClientEncryption. See <a href="unified-test-format/unified-test-format.html#entity_clientEncryption">entity_clientEncryption</a> and
<a href="unified-test-format/unified-test-format.html#clientencryption-operations">ClientEncryption Operations</a>.</li>
<li>Database. See <a href="unified-test-format/unified-test-format.html#entity_database">entity_database</a> and <a href="unified-test-format/unified-test-format.html#database-operations">Database Operations</a>.</li>
<li>Collection. See <a href="unified-test-format/unified-test-format.html#entity_collection">entity_collection</a> and <a href="unified-test-format/unified-test-format.html#collection-operations">Collection Operations</a></li>
<li>ClientSession. See <a href="unified-test-format/unified-test-format.html#entity_session">entity_session</a> and <a href="unified-test-format/unified-test-format.html#session-operations">Session Operations</a>.</li>
<li>GridFS Bucket. See <a href="unified-test-format/unified-test-format.html#entity_bucket">entity_bucket</a> and <a href="unified-test-format/unified-test-format.html#bucket-operations">Bucket Operations</a>.</li>
</ul>
<p><span id="entity_changestream"></span></p>
<ul>
<li>
<p>ChangeStream. Change stream entities are special in that they are not defined in <a href="unified-test-format/unified-test-format.html#createentities">createEntities</a> but
are instead created by using <a href="unified-test-format/unified-test-format.html#operation_saveResultAsEntity">operation.saveResultAsEntity</a> with a
<a href="unified-test-format/unified-test-format.html#client_createChangeStream">client_createChangeStream</a>, <a href="unified-test-format/unified-test-format.html#database_createChangeStream">database_createChangeStream</a>,
or <a href="unified-test-format/unified-test-format.html#collection_createChangeStream">collection_createChangeStream</a> operation.</p>
<p>Test files SHOULD NOT use a <code>watch</code> operation to create a change stream, as the implementation of that method may vary
among drivers. For example, some implementations of <code>watch</code> immediately execute <code>aggregate</code> and construct the
server-side cursor, while others may defer <code>aggregate</code> until the change stream object is iterated.</p>
<p>See <a href="unified-test-format/unified-test-format.html#cursor-operations">Cursor Operations</a> for a list of operations.</p>
</li>
<li>
<p>FindCursor. These entities are not defined in <a href="unified-test-format/unified-test-format.html#createentities">createEntities</a> but are instead created by using
<a href="unified-test-format/unified-test-format.html#operation_saveResultAsEntity">operation.saveResultAsEntity</a> with a
<a href="unified-test-format/unified-test-format.html#collection_createFindCursor">collection_createFindCursor</a> operation.</p>
<p>See <a href="unified-test-format/unified-test-format.html#cursor-operations">Cursor Operations</a> for a list of operations.</p>
</li>
<li>
<p>CommandCursor. These entities are not defined in <a href="unified-test-format/unified-test-format.html#createentities">createEntities</a> but are instead created by using
<a href="unified-test-format/unified-test-format.html#operation_saveResultAsEntity">operation.saveResultAsEntity</a> with a <a href="unified-test-format/unified-test-format.html#createcommandcursor">createCommandCursor</a>
operation.</p>
<p>See <a href="unified-test-format/unified-test-format.html#cursor-operations">Cursor Operations</a> for a list of operations.</p>
</li>
<li>
<p>Event list. See <a href="unified-test-format/unified-test-format.html#entity_client_storeEventsAsEntities">storeEventsAsEntities</a>. The event list MUST store BSON
documents. The type of the list itself is not prescribed by this specification. Test runner MAY use a BSON array or a
thread-safe list data structure to implement the event list.</p>
</li>
<li>
<p>All known BSON types and/or equivalent language types for the target driver. For the present version of the spec, the
following BSON types are known: 0x01-0x13, 0x7F, 0xFF.</p>
<p>Tests SHOULD NOT utilize deprecated types (e.g. 0x0E: Symbol), since they may not be supported by all drivers and
could yield runtime errors (e.g. while loading a test file with an Extended JSON parser).</p>
</li>
</ul>
<p><span id="entity_thread"></span></p>
<ul>
<li>Test runner thread. An entity representing a "thread" that can be used to concurrently execute operations. Thread
entities MUST be able to run concurrently with the main test runner thread and other thread entities, but they do not
have to be implemented as actual OS threads (e.g. they can be goroutines or async tasks). See
<a href="unified-test-format/unified-test-format.html#entity_thread_object">entity_thread_object</a> for more information on how they are created.</li>
</ul>
<p><span id="entity_topologydescription"></span></p>
<ul>
<li>TopologyDescription. An entity representing a client's
<a href="unified-test-format/../server-discovery-and-monitoring/server-discovery-and-monitoring.html#topologydescription">TopologyDescription</a> at a
certain point in time. These entities are not defined in <a href="unified-test-format/unified-test-format.html#createentities">createEntities</a> but are instead created via
<a href="unified-test-format/unified-test-format.html#recordtopologydescription">recordTopologyDescription</a> test runner operations.</li>
</ul>
<p>This is an exhaustive list of supported types for the entity map. Test runners MUST raise an error if an attempt is made
to store an unsupported type in the entity map.</p>
<p>Adding new entity types (including known BSON types) to this list will require a minor version bump to the spec and
schema version. Removing entity types will require a major version bump. See
<a href="unified-test-format/unified-test-format.html#impact-of-spec-changes-on-schema-version">Impact of Spec Changes on Schema Version</a> for more information.</p>
<h3 id="test-format"><a class="header" href="#test-format">Test Format</a></h3>
<p>Each specification test file can define one or more tests, which inherit some top-level configuration (e.g. namespace,
initial data). YAML and JSON test files are parsed as an object by the test runner. This section defines the top-level
keys for that object and links to various sub-sections for definitions of nested structures (e.g. individual
<a href="unified-test-format/unified-test-format.html#test">test</a>, <a href="unified-test-format/unified-test-format.html#operation">operation</a>).</p>
<p>Although test runners are free to process YAML or JSON files, YAML is the canonical format for writing tests. YAML files
may be converted to JSON using a tool such as <a href="https://github.com/nodeca/js-yaml">js-yaml</a> .</p>
<h4 id="top-level-fields"><a class="header" href="#top-level-fields">Top-level Fields</a></h4>
<p>The top-level fields of a test file are as follows:</p>
<ul>
<li>
<p><code>description</code>: Required string. The name of the test file.</p>
<p>This SHOULD describe the common purpose of tests in this file and MAY refer to the filename (e.g. "updateOne-hint").</p>
</li>
</ul>
<p><span id="schemaVersion"></span></p>
<ul>
<li>
<p><code>schemaVersion</code>: Required string. Version of this specification with which the test file complies.</p>
<p>Test files SHOULD be conservative when specifying a schema version. For example, if the latest schema version is 1.1
but the test file complies with schema version 1.0, the test file should specify 1.0.</p>
<p>Test runners will use this to determine compatibility (i.e. whether and how the test file will be interpreted). The
format of this string is defined in <a href="unified-test-format/unified-test-format.html#version-string">Version String</a>; however, test files SHOULD NOT need to refer to
specific patch versions since patch-level changes SHOULD NOT alter the structure of the test format (as previously
noted in <a href="unified-test-format/unified-test-format.html#schema-version">Schema Version</a>).</p>
</li>
</ul>
<p><span id="runOnRequirements"></span></p>
<ul>
<li><code>runOnRequirements</code>: Optional array of one or more <a href="unified-test-format/unified-test-format.html#runonrequirement">runOnRequirement</a> objects. List of server
version and/or topology requirements for which the tests in this file can be run. If no requirements are met, the test
runner MUST skip this test file.</li>
</ul>
<p><span id="createEntities"></span></p>
<ul>
<li>
<p><code>createEntities</code>: Optional array of one or more <a href="unified-test-format/unified-test-format.html#entity">entity</a> objects. List of entities (e.g. client, collection,
session objects) that SHALL be created before each test case is executed.</p>
<p>Test files SHOULD define entities in dependency order, such that all referenced entities (e.g. client) are defined
before any of their dependent entities (e.g. database, session).</p>
</li>
</ul>
<p><span id="initialData"></span></p>
<ul>
<li><code>initialData</code>: Optional array of one or more <a href="unified-test-format/unified-test-format.html#collectiondata">collectionData</a> objects. Data that will exist in
collections before each test case is executed.</li>
</ul>
<p><span id="tests"></span></p>
<ul>
<li><code>tests</code>: Required array of one or more <a href="unified-test-format/unified-test-format.html#test">test</a> objects. List of test cases to be executed independently of each
other.</li>
<li><code>_yamlAnchors</code>: Optional object containing arbitrary data. This is only used to define anchors within the YAML files
and MUST NOT be used by test runners.</li>
</ul>
<h4 id="runonrequirement"><a class="header" href="#runonrequirement">runOnRequirement</a></h4>
<p>A combination of server version and/or topology requirements for running the test(s).</p>
<p>The format of server version strings is defined in <a href="unified-test-format/unified-test-format.html#version-string">Version String</a>. When comparing server version
strings, each component SHALL be compared numerically. For example, "4.0.10" is greater than "4.0.9" and "3.6" and less
than "4.2.0".</p>
<p>The structure of this object is as follows:</p>
<ul>
<li>
<p><code>minServerVersion</code>: Optional string. The minimum server version (inclusive) required to successfully run the tests. If
this field is omitted, there is no lower bound on the required server version. The format of this string is defined in
<a href="unified-test-format/unified-test-format.html#version-string">Version String</a>.</p>
</li>
<li>
<p><code>maxServerVersion</code>: Optional string. The maximum server version (inclusive) against which the tests can be run
successfully. If this field is omitted, there is no upper bound on the required server version. The format of this
string is defined in <a href="unified-test-format/unified-test-format.html#version-string">Version String</a>.</p>
</li>
<li>
<p><code>topologies</code>: Optional array of one or more strings. Server topologies against which the tests can be run
successfully. Valid topologies are "single", "replicaset", "sharded", "load-balanced", and "sharded-replicaset" (i.e.
sharded cluster backed by replica sets). If this field is omitted, there is no topology requirement for the test.</p>
<p>When matching a "sharded-replicaset" topology, test runners MUST ensure that all shards are backed by a replica set.
The process for doing so is described in
<a href="unified-test-format/unified-test-format.html#determining-if-a-sharded-cluster-uses-replica-sets">Determining if a Sharded Cluster Uses Replica Sets</a>. When
matching a "sharded" topology, test runners MUST accept any type of sharded cluster (i.e. "sharded" implies
"sharded-replicaset", but not vice versa).</p>
<p>The "sharded-replicaset" topology type is deprecated. MongoDB 3.6+ requires that all shard servers be replica sets.
Therefore, tests SHOULD use "sharded" instead of "sharded-replicaset" when targeting 3.6+ server versions in order to
avoid unnecessary overhead.</p>
<p>Note: load balancers were introduced in MongoDB 5.0. Therefore, any sharded cluster behind a load balancer implicitly
uses replica sets for its shards.</p>
</li>
<li>
<p><code>serverless</code>: Optional string. Whether or not the test should be run on Atlas Serverless instances. Valid values are
"require", "forbid", and "allow". If "require", the test MUST only be run on Atlas Serverless instances. If "forbid",
the test MUST NOT be run on Atlas Serverless instances. If omitted or "allow", this option has no effect.</p>
<p>The test runner MUST be informed whether or not Atlas Serverless is being used in order to determine if this
requirement is met (e.g. through an environment variable or configuration option).</p>
<p>Note: the Atlas Serverless proxy imitates mongos, so the test runner is not capable of determining if Atlas Serverless
is in use by issuing commands such as <code>buildInfo</code> or <code>hello</code>. Furthermore, connections to Atlas Serverless use a load
balancer, so the topology will appear as "load-balanced".</p>
</li>
<li>
<p><code>serverParameters</code>: Optional object of server parameters to check against. To check server parameters, drivers send a
<code>{ getParameter: 1, &lt;parameter&gt;: 1 }</code> command to the server using an internal MongoClient. Drivers MAY also choose to
send a <code>{ getParameter: '*' }</code> command and fetch all parameters at once. The result SHOULD be cached to avoid repeated
calls to fetch the same parameter. Test runners MUST apply the rules specified in
<a href="unified-test-format/unified-test-format.html#flexible-numeric-comparisons">Flexible Numeric Comparisons</a> when comparing values. If a server does not support a
parameter, test runners MUST treat the comparison as not equal and skip the test. This includes errors that occur when
fetching a single parameter using <code>getParameter</code>.</p>
</li>
</ul>
<p><span id="runOnRequirement_auth"></span></p>
<ul>
<li>
<p><code>auth</code>: Optional boolean. If true, the tests MUST only run if authentication is enabled. If false, tests MUST NOT run
if authentication is enabled. If this field is omitted, there is no authentication requirement.</p>
</li>
<li>
<p><code>authMechanism</code>: Optional string. Specifies an authentication mechanism that the server needs to support for the test.
If set, tests MUST only run if the given string matches (case-insensitive) one of the strings in the
<a href="https://www.mongodb.com/docs/manual/reference/parameters/#mongodb-parameter-param.authenticationMechanisms">authenticationMechanisms</a>
server parameter. If this field is omitted, there is no authentication mechanism requirement.</p>
</li>
<li>
<p><code>csfle</code>: Optional boolean. If true, the tests MUST only run if the driver and server support Client-Side Field Level
Encryption. CSFLE is supported when all of the following are true:</p>
<ul>
<li>Server version is 4.2.0 or higher</li>
<li>Driver has libmongocrypt enabled</li>
<li>At least one of <a href="unified-test-format/../client-side-encryption/client-side-encryption.html#crypt_shared">crypt_shared</a> and/or
<a href="unified-test-format/../client-side-encryption/client-side-encryption.html#mongocryptd">mongocryptd</a> is available</li>
</ul>
<p>If false, tests MUST NOT run if CSFLE is supported. If this field is omitted, there is no CSFLE requirement.</p>
</li>
</ul>
<p>Test runners MAY evaluate these conditions in any order. For example, it may be more efficient to evaluate <code>serverless</code>
or <code>auth</code> before communicating with a server to check its version.</p>
<h4 id="entity"><a class="header" href="#entity">entity</a></h4>
<p>An entity (e.g. client, collection, session object) that will be created in the <a href="unified-test-format/unified-test-format.html#entity-map">Entity Map</a> before each
test is executed.</p>
<p>This object MUST contain <strong>exactly one</strong> top-level key that identifies the entity type and maps to a nested object,
which specifies a unique name for the entity (<code>id</code> key) and any other parameters necessary for its construction. Tests
SHOULD use sequential names based on the entity type (e.g. "session0", "session1").</p>
<p>When defining an entity object in YAML, a <a href="https://yaml.org/spec/1.2/spec.html#id2785586">node anchor</a> SHOULD be created
on the entity's <code>id</code> key. This anchor will allow the unique name to be referenced with an
<a href="https://yaml.org/spec/1.2/spec.html#id2786196">alias node</a> later in the file (e.g. from another entity or
<a href="unified-test-format/unified-test-format.html#operation">operation</a> object) and also leverage YAML's parser for reference validation.</p>
<p>The structure of this object is as follows:</p>
<p><span id="entity_client"></span></p>
<ul>
<li>
<p><code>client</code>: Optional object. Defines a MongoClient object. In addition to the configuration defined below, test runners
for drivers that implement connection pooling MUST track the number of connections checked out at any given time for
the constructed MongoClient. This can be done using a single counter and
<a href="unified-test-format/../connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#events">CMAP events</a>. Each
<code>ConnectionCheckedOutEvent</code> should increment the counter and each <code>ConnectionCheckedInEvent</code> should decrement it.</p>
<p>The structure of this object is as follows:</p>
<ul>
<li>
<p><code>id</code>: Required string. Unique name for this entity. The YAML file SHOULD define a
<a href="https://yaml.org/spec/1.2/spec.html#id2785586">node anchor</a> for this field (e.g. <code>id: &amp;client0 client0</code>).</p>
</li>
<li>
<p><code>uriOptions</code>: Optional object. Additional URI options to apply to the test suite's connection string that is used to
create this client. Any keys in this object MUST override conflicting keys in the connection string.</p>
<p>Documentation for supported options may be found in the <a href="unified-test-format/../uri-options/uri-options.html">URI Options</a> spec, with one
notable exception: if <code>readPreferenceTags</code> is specified in this object, the key will map to an array of strings,
each representing a tag set, since it is not feasible to define multiple <code>readPreferenceTags</code> keys in the object.</p>
<p>Note also that when specifying <code>directConnection</code> as true, the connection string used to instantiate a client MUST
only have a single seed and MUST NOT specify the <code>replicaSet</code> option. See the
<a href="unified-test-format/../uri-options/uri-options.html#directconnection-uri-option-with-multiple-seeds-or-srv-uri">URI Options spec</a> for
more information.</p>
<p>Any field in <code>uriOptions</code> may be a <a href="unified-test-format/unified-test-format.html#placeholder">$$placeholder</a> document and the test runner MUST support replacing
the placeholder document with values loaded from the test environment. For example:</p>
<pre><code>uriOptions:
  authMechanism: "MONGODB-OIDC"
  authMechanismProperties:
    ENVIRONMENT: { $$placeholder: 1 }
</code></pre>
</li>
</ul>
<p><span id="entity_client_useMultipleMongoses"></span></p>
<ul>
<li>
<p><code>useMultipleMongoses</code>: Optional boolean. If true and the topology is a sharded cluster, the test runner MUST assert
that this MongoClient connects to multiple mongos hosts (e.g. by inspecting the connection string). If false and the
topology is a sharded cluster, the test runner MUST ensure that this MongoClient connects to only a single mongos
host (e.g. by modifying the connection string).</p>
<p>If this option is not specified and the topology is a sharded cluster, the test runner MUST NOT enforce any limit on
the number of mongos hosts in the connection string and any tests using this client SHOULD NOT depend on a
particular number of mongos hosts.</p>
<p>This option SHOULD be set to true in test files if the resulting entity is used to conduct transactions against a
sharded cluster. This is advised because connecting to multiple mongos servers is necessary to test session pinning.</p>
<p>If the topology type is <code>LoadBalanced</code> and Atlas Serverless is not being used, the test runner MUST use one of the
two load balancer URIs described in <a href="unified-test-format/unified-test-format.html#initializing-the-test-runner">Initializing the Test Runner</a> to configure the
MongoClient. If <code>useMultipleMongoses</code> is true or unset, the test runner MUST use the URI of the load balancer
fronting multiple servers. Otherwise, the test runner MUST use the URI of the load balancer fronting a single
server.</p>
<p>If the topology type is <code>LoadBalanced</code> and Atlas Serverless is being used, this option has no effect. This is
because provisioning an Atlas Serverless instance yields a single URI (i.e. a load balancer fronting a single Atlas
Serverless proxy).</p>
<p>This option has no effect for topologies that are not sharded or load balanced.</p>
</li>
</ul>
<p><span id="entity_client_observeEvents"></span></p>
<ul>
<li>
<p><code>observeEvents</code>: Optional array of one or more strings. Types of events that can be observed for this client.
Unspecified event types MUST be ignored by this client's event listeners and SHOULD NOT be included in
<a href="unified-test-format/unified-test-format.html#test_expectEvents">test.expectEvents</a> for this client.</p>
<p>Supported types correspond to the top-level keys (strings) documented in <a href="unified-test-format/unified-test-format.html#expectedevent">expectedEvent</a> and are as
follows:</p>
<ul>
<li><a href="unified-test-format/unified-test-format.html#expectedEvent_commandStartedEvent">commandStartedEvent</a></li>
<li><a href="unified-test-format/unified-test-format.html#expectedEvent_commandSucceededEvent">commandSucceededEvent</a></li>
<li><a href="unified-test-format/unified-test-format.html#expectedEvent_commandFailedEvent">commandFailedEvent</a></li>
<li><a href="unified-test-format/unified-test-format.html#expectedEvent_poolCreatedEvent">poolCreatedEvent</a></li>
<li><a href="unified-test-format/unified-test-format.html#expectedEvent_poolReadyEvent">poolReadyEvent</a></li>
<li><a href="unified-test-format/unified-test-format.html#expectedEvent_poolClearedEvent">poolClearedEvent</a></li>
<li><a href="unified-test-format/unified-test-format.html#expectedEvent_poolClosedEvent">poolClosedEvent</a></li>
<li><a href="unified-test-format/unified-test-format.html#expectedEvent_connectionCreatedEvent">connectionCreatedEvent</a></li>
<li><a href="unified-test-format/unified-test-format.html#expectedEvent_connectionReadyEvent">connectionReadyEvent</a></li>
<li><a href="unified-test-format/unified-test-format.html#expectedEvent_connectionClosedEvent">connectionClosedEvent</a></li>
<li><a href="unified-test-format/unified-test-format.html#expectedEvent_connectionCheckOutStartedEvent">connectionCheckOutStartedEvent</a></li>
<li><a href="unified-test-format/unified-test-format.html#expectedEvent_connectionCheckOutFailedEvent">connectionCheckOutFailedEvent</a></li>
<li><a href="unified-test-format/unified-test-format.html#expectedEvent_connectionCheckedOutEvent">connectionCheckedOutEvent</a></li>
<li><a href="unified-test-format/unified-test-format.html#expectedEvent_connectionCheckedInEvent">connectionCheckedInEvent</a></li>
<li><a href="unified-test-format/unified-test-format.html#expectedEvent_serverDescriptionChangedEvent">serverDescriptionChangedEvent</a></li>
<li><a href="unified-test-format/unified-test-format.html#expectedEvent_serverHeartbeatStartedEvent">serverHeartbeatStartedEvent</a></li>
<li><a href="unified-test-format/unified-test-format.html#expectedEvent_serverHeartbeatSucceededEvent">serverHeartbeatSucceededEvent</a></li>
<li><a href="unified-test-format/unified-test-format.html#expectedEvent_serverHeartbeatFailedEvent">serverHeartbeatFailedEvent</a></li>
<li><a href="unified-test-format/unified-test-format.html#expectedEvent_topologyDescriptionChangedEvent">topologyDescriptionChangedEvent</a></li>
</ul>
</li>
</ul>
<p><span id="entity_client_ignoreCommandMonitoringEvents"></span></p>
<ul>
<li>
<p><code>ignoreCommandMonitoringEvents</code>: Optional array of one or more strings. Command names for which the test runner MUST
ignore any observed command monitoring events. The command(s) will be ignored in addition to <code>configureFailPoint</code>
and any commands containing sensitive information (per the
<a href="unified-test-format/../command-logging-and-monitoring/command-logging-and-monitoring.html#security">Command Logging and Monitoring</a> spec)
unless <code>observeSensitiveCommands</code> is true.</p>
<p>Test files SHOULD NOT use this option unless one or more command monitoring events are specified in
<a href="unified-test-format/unified-test-format.html#entity_client_observeEvents">observeEvents</a>.</p>
</li>
</ul>
<p><span id="entity_client_observeSensitiveCommands"></span></p>
<ul>
<li><code>observeSensitiveCommands</code>: Optional boolean. If true, events associated with sensitive commands (per the
<a href="unified-test-format/../command-logging-and-monitoring/command-logging-and-monitoring.html#security">Command Logging and Monitoring</a> spec)
will be observed for this client. Note that the command and replies for such events will already have been redacted
by the driver. If false or not specified, events for commands containing sensitive information MUST be ignored.
Authentication SHOULD be disabled when this property is true, i.e. <a href="unified-test-format/unified-test-format.html#runOnRequirement_auth">auth</a> should be false
for each <code>runOnRequirement</code>. See <a href="unified-test-format/unified-test-format.html#rationale_observeSensitiveCommands">rationale_observeSensitiveCommands</a>.</li>
</ul>
<p><span id="entity_client_storeEventsAsEntities"></span></p>
<ul>
<li>
<p><code>storeEventsAsEntities</code>: Optional array of one or more <a href="unified-test-format/unified-test-format.html#storeeventsasentity">storeEventsAsEntity</a> objects. Each
object denotes an entity name and one or more events to be collected and stored in that entity. See
<a href="unified-test-format/unified-test-format.html#storeeventsasentity">storeEventsAsEntity</a> for implementation details.</p>
<p>Note: the implementation of <code>storeEventsAsEntities</code> is wholly independent from <code>observeEvents</code> and
<code>ignoreCommandMonitoringEvents</code>.</p>
<p>Example option value:</p>
<pre><code>storeEventsAsEntities:
  - id: client0_events
    events: [PoolCreatedEvent, ConnectionCreatedEvent, CommandStartedEvent]
</code></pre>
</li>
</ul>
<p><span id="entity_client_observeLogMessages"></span></p>
<ul>
<li><code>observeLogMessages</code>: Optional object where the key names are log <a href="unified-test-format/../logging/logging.html#components">components</a> and
the values are minimum <a href="unified-test-format/../logging/logging.html#log-severity-levels">log severity levels</a> indicating which components
to collect log messages for and what the minimum severity level of collected messages should be. Messages for
unspecified components and/or with lower severity levels than those specified MUST be ignored by this client's log
collector(s) and SHOULD NOT be included in <a href="unified-test-format/unified-test-format.html#test_expectLogMessages">test.expectLogMessages</a> for this client.</li>
<li><code>serverApi</code>: Optional <a href="unified-test-format/unified-test-format.html#serverapi">serverApi</a> object.</li>
</ul>
</li>
</ul>
<p><span id="entity_clientEncryption"></span></p>
<ul>
<li>
<p><code>clientEncryption</code>: Optional object. Defines a ClientEncryption object.</p>
<p>The structure of this object is as follows:</p>
<ul>
<li>
<p><code>id</code>: Required string. Unique name for this entity. The YAML file SHOULD define a
<a href="https://yaml.org/spec/1.2/spec.html#id2785586">node anchor</a> for this field (e.g.
<code>id: &amp;clientEncryption0 clientEncryption0</code>).</p>
</li>
<li>
<p><code>clientEncryptionOpts</code>: Required document. A value corresponding to a
<a href="unified-test-format/../client-side-encryption/client-side-encryption.html#clientencryption">ClientEncryptionOpts</a>.</p>
<p>Note: the <code>tlsOptions</code> document is intentionally omitted from the test format. However, drivers MAY internally
configure TLS options as needed to satisfy the requirements of configured KMS providers.</p>
<p>The structure of this document is as follows:</p>
<ul>
<li>
<p><code>keyVaultClient</code>: Required string. Client entity from which this ClientEncryption will be created. The YAML file
SHOULD use an <a href="https://yaml.org/spec/1.2/spec.html#id2786196">alias node</a> for a client entity's <code>id</code> field (e.g.
<code>client: *client0</code>).</p>
</li>
<li>
<p><code>keyVaultNamespace</code>: Required string. The database and collection to use as the key vault collection for this
clientEncryption. The namespace takes the form <code>database.collection</code> (e.g.
<code>keyVaultNamespace: keyvault.datakeys</code>).</p>
</li>
<li>
<p><code>kmsProviders</code>: Required document. Drivers MUST NOT configure a KMS provider if it is not given. This is to permit
testing conditions where a required KMS provider is not configured. If a KMS provider is given as an empty
document (e.g. <code>kmsProviders: { aws: {} }</code>), drivers MUST configure the KMS provider without credentials to permit
testing conditions where KMS credentials are needed. If a KMS credentials field has a placeholder value (e.g.
<code>kmsProviders: { aws: { accessKeyId: { $$placeholder: 1 }, secretAccessKey: { $$placeholder: 1 } } }</code>), drivers
MUST replace the field with credentials that satisfy the operations required by the unified test files. Drivers
MAY load the credentials from the environment or a configuration file as needed to satisfy the requirements of the
given KMS provider and tests. If a KMS credentials field is not given (e.g. the required field <code>secretAccessKey</code>
is omitted in: <code>kmsProviders: { aws: { accessKeyId: { $$placeholder: 1 } }</code>), drivers MUST NOT include the field
during KMS configuration. This is to permit testing conditions where required KMS credentials fields are not
provided. Otherwise, drivers MUST configure the KMS provider with the explicit value of KMS credentials field
given in the test file (e.g. <code>kmsProviders: { aws: { accessKeyId: abc, secretAccessKey: def } }</code>). This is to
permit testing conditions where invalid KMS credentials are provided.</p>
<p>Tests may also reference named KMS providers. KMS providers with the name <code>name1</code> are expected to be configured
exactly as the unnamed KMS providers. The <code>aws:name2</code> KMS provider and <code>aws:name1</code> KMS providers deliberately use
separate AWS accounts that do not have permission to the other's keys.</p>
<p>See the <a href="unified-test-format/../client-side-encryption/tests/README.html#credentials">Client-Side Encryption test README</a> for
instructions to obtain test credentials.</p>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><span id="entity_database"></span></p>
<ul>
<li>
<p><code>database</code>: Optional object. Defines a Database object.</p>
<p>The structure of this object is as follows:</p>
<ul>
<li><code>id</code>: Required string. Unique name for this entity. The YAML file SHOULD define a
<a href="https://yaml.org/spec/1.2/spec.html#id2785586">node anchor</a> for this field (e.g. <code>id: &amp;database0 database0</code>).</li>
<li><code>client</code>: Required string. Client entity from which this database will be created. The YAML file SHOULD use an
<a href="https://yaml.org/spec/1.2/spec.html#id2786196">alias node</a> for a client entity's <code>id</code> field (e.g.
<code>client: *client0</code>).</li>
<li><code>databaseName</code>: Required string. Database name. The YAML file SHOULD define a
<a href="https://yaml.org/spec/1.2/spec.html#id2785586">node anchor</a> for this field (e.g.
<code>databaseName: &amp;database0Name foo</code>).</li>
<li><code>databaseOptions</code>: Optional <a href="unified-test-format/unified-test-format.html#collectionordatabaseoptions">collectionOrDatabaseOptions</a> object.</li>
</ul>
</li>
</ul>
<p><span id="entity_collection"></span></p>
<ul>
<li>
<p><code>collection</code>: Optional object. Defines a Collection object.</p>
<p>The structure of this object is as follows:</p>
<ul>
<li><code>id</code>: Required string. Unique name for this entity. The YAML file SHOULD define a
<a href="https://yaml.org/spec/1.2/spec.html#id2785586">node anchor</a> for this field (e.g. <code>id: &amp;collection0 collection0</code>).</li>
<li><code>database</code>: Required string. Database entity from which this collection will be created. The YAML file SHOULD use an
<a href="https://yaml.org/spec/1.2/spec.html#id2786196">alias node</a> for a database entity's <code>id</code> field (e.g.
<code>database: *database0</code>).</li>
<li><code>collectionName</code>: Required string. Collection name. The YAML file SHOULD define a
<a href="https://yaml.org/spec/1.2/spec.html#id2785586">node anchor</a> for this field (e.g.
<code>collectionName: &amp;collection0Name foo</code>).</li>
<li><code>collectionOptions</code>: Optional <a href="unified-test-format/unified-test-format.html#collectionordatabaseoptions">collectionOrDatabaseOptions</a> object.</li>
</ul>
</li>
</ul>
<p><span id="entity_session"></span></p>
<ul>
<li>
<p><code>session</code>: Optional object. Defines an explicit ClientSession object.</p>
<p>The structure of this object is as follows:</p>
<ul>
<li>
<p><code>id</code>: Required string. Unique name for this entity. The YAML file SHOULD define a
<a href="https://yaml.org/spec/1.2/spec.html#id2785586">node anchor</a> for this field (e.g. <code>id: &amp;session0 session0</code>).</p>
</li>
<li>
<p><code>client</code>: Required string. Client entity from which this session will be created. The YAML file SHOULD use an
<a href="https://yaml.org/spec/1.2/spec.html#id2786196">alias node</a> for a client entity's <code>id</code> field (e.g.
<code>client: *client0</code>).</p>
</li>
<li>
<p><code>sessionOptions</code>: Optional object. Map of parameters to pass to
<a href="unified-test-format/../sessions/driver-sessions.html#startsession">MongoClient.startSession</a> when creating the session. Supported options
are defined in the following specifications:</p>
<ul>
<li><a href="unified-test-format/../causal-consistency/causal-consistency.html#sessionoptions-changes">Causal Consistency</a></li>
<li><a href="unified-test-format/../sessions/snapshot-sessions.html#sessionoptions-changes">Snapshot Reads</a></li>
<li><a href="unified-test-format/../transactions/transactions.html#sessionoptions-changes">Transactions</a></li>
<li><a href="unified-test-format/../client-side-operations-timeout/client-side-operations-timeout.html#sessions">Client Side Operations Timeout</a></li>
</ul>
<p>When specifying TransactionOptions for <code>defaultTransactionOptions</code>, the transaction options MUST remain nested under
<code>defaultTransactionOptions</code> and MUST NOT be flattened into <code>sessionOptions</code>.</p>
</li>
</ul>
</li>
</ul>
<p><span id="entity_bucket"></span></p>
<ul>
<li>
<p><code>bucket</code>: Optional object. Defines a Bucket object, as defined in the <a href="unified-test-format/../gridfs/gridfs-spec.html">GridFS</a> spec.</p>
<p>The structure of this object is as follows:</p>
<ul>
<li><code>id</code>: Required string. Unique name for this entity. The YAML file SHOULD define a
<a href="https://yaml.org/spec/1.2/spec.html#id2785586">node anchor</a> for this field (e.g. <code>id: &amp;bucket0 bucket0</code>).</li>
<li><code>database</code>: Required string. Database entity from which this bucket will be created. The YAML file SHOULD use an
<a href="https://yaml.org/spec/1.2/spec.html#id2786196">alias node</a> for a database entity's <code>id</code> field (e.g.
<code>database: *database0</code>).</li>
<li><code>bucketOptions</code>: Optional object. Additional options used to construct the bucket object. Supported options are
defined in the <a href="unified-test-format/../gridfs/gridfs-spec.html#configurable-gridfsbucket-class">GridFS</a> specification. The <code>readConcern</code>,
<code>readPreference</code>, and <code>writeConcern</code> options use the same structure as defined in <a href="unified-test-format/unified-test-format.html#common-options">Common Options</a>.</li>
</ul>
</li>
</ul>
<p><span id="entity_thread_object"></span></p>
<ul>
<li>
<p><code>thread</code>: Optional object. Defines a test runner "thread". Once the "thread" has been created, it should be idle and
waiting for operations to be dispatched to it later on by <a href="unified-test-format/unified-test-format.html#runonthread">runOnThread</a> operations.</p>
<p>The structure of this object is as follows:</p>
<ul>
<li><code>id</code>: Required string. Unique name for this entity. The YAML file SHOULD define a
<a href="https://yaml.org/spec/1.2/spec.html#id2785586">node anchor</a> for this field (e.g. <code>id: &amp;thread0 thread0</code>).</li>
</ul>
</li>
</ul>
<h4 id="storeeventsasentity"><a class="header" href="#storeeventsasentity">storeEventsAsEntity</a></h4>
<p>A list of one or more events that will be observed on a client and collectively stored within an entity. This object is
used within <a href="unified-test-format/unified-test-format.html#entity_client_storeEventsAsEntities">storeEventsAsEntities</a>.</p>
<p>The structure of this object is as follows:</p>
<ul>
<li><code>id</code>: Required string. Unique name for this entity.</li>
<li><code>events</code>: Required array of one or more strings, which denote the events to be collected. Currently, only the
following <a href="unified-test-format/../connection-monitoring-and-pooling/connection-monitoring-and-pooling.html">CMAP</a> and
<a href="unified-test-format/../command-logging-and-monitoring/command-logging-and-monitoring.html">command monitoring</a> events MUST be supported:
<ul>
<li>PoolCreatedEvent</li>
<li>PoolReadyEvent</li>
<li>PoolClearedEvent</li>
<li>PoolClosedEvent</li>
<li>ConnectionCreatedEvent</li>
<li>ConnectionReadyEvent</li>
<li>ConnectionClosedEvent</li>
<li>ConnectionCheckOutStartedEvent</li>
<li>ConnectionCheckOutFailedEvent</li>
<li>ConnectionCheckedOutEvent</li>
<li>ConnectionCheckedInEvent</li>
<li>CommandStartedEvent</li>
<li>CommandSucceededEvent</li>
<li>CommandFailedEvent</li>
</ul>
</li>
</ul>
<p>For the specified entity name, the test runner MUST create the respective entity with a type of "event list", as
described in <a href="unified-test-format/unified-test-format.html#supported-entity-types">Supported Entity Types</a>. If the entity already exists (such as from a previous
<a href="unified-test-format/unified-test-format.html#storeeventsasentity">storeEventsAsEntity</a> object) the test runner MUST raise an error.</p>
<p>The test runner MUST set up an event subscriber for each event named. The event subscriber MUST serialize the events it
receives into a document, using the documented properties of the event as field names, and append the document to the
list stored in the specified entity. Additionally, the following fields MUST be stored with each event document:</p>
<ul>
<li><code>name</code>: The name of the event (e.g. <code>PoolCreatedEvent</code>). The name of the event MUST be the name used in the respective
specification that defines the event in question.</li>
<li><code>observedAt</code>: The time, as the floating-point number of seconds since the Unix epoch, when the event was observed by
the test runner.</li>
</ul>
<p>The test runner MAY omit the <code>command</code> field for CommandStartedEvent and <code>reply</code> field for CommandSucceededEvent.</p>
<p>If an event field in the driver is of a type that does not directly map to a BSON type (e.g. <code>Exception</code> for the
<code>failure</code> field of CommandFailedEvent) the test runner MUST convert values of that field to one of the BSON types. For
example, a test runner MAY store the exception's error message string as the <code>failure</code> field of CommandFailedEvent.</p>
<p>If the specification defining an event permits deviation in field names, such as <code>connectionId</code> field for
CommandStartedEvent, the test runner SHOULD use the field names used in the specification when serializing events to
documents even if the respective field name is different in the driver's event object.</p>
<h4 id="serverapi"><a class="header" href="#serverapi">serverApi</a></h4>
<p>Declares an API version for a <a href="unified-test-format/unified-test-format.html#entity_client">client entity</a>.</p>
<p>The structure of this object is as follows:</p>
<ul>
<li>
<p><code>version</code>: Required string. Test runners MUST fail if the given version string is not supported by the driver.</p>
<p>Note: the format of this string is unrelated to <a href="unified-test-format/unified-test-format.html#version-string">Version String</a>.</p>
</li>
<li>
<p><code>strict</code>: Optional boolean.</p>
</li>
<li>
<p><code>deprecationErrors</code>: Optional boolean.</p>
</li>
</ul>
<p>See the <a href="unified-test-format/../versioned-api/versioned-api.html">Stable API</a> spec for more details on these fields.</p>
<h4 id="collectiondata"><a class="header" href="#collectiondata">collectionData</a></h4>
<p>List of documents corresponding to the contents of a collection. This structure is used by both
<a href="unified-test-format/unified-test-format.html#initialData">initialData</a> and <a href="unified-test-format/unified-test-format.html#test_outcome">test.outcome</a>, which insert and read documents, respectively.</p>
<p>The structure of this object is as follows:</p>
<ul>
<li><code>collectionName</code>: Required string. See <a href="unified-test-format/unified-test-format.html#commonOptions_collectionName">commonOptions_collectionName</a>.</li>
<li><code>databaseName</code>: Required string. See <a href="unified-test-format/unified-test-format.html#commonOptions_databaseName">commonOptions_databaseName</a>.</li>
<li><code>createOptions</code>: Optional object. When used in <a href="unified-test-format/unified-test-format.html#initialData">initialData</a>, these options MUST be passed to the
<a href="https://docs.mongodb.com/manual/reference/command/create/">create</a> command when creating the collection. Test files
MUST NOT specify <code>writeConcern</code> in this options document as that could conflict with the use of the <code>majority</code> write
concern when the collection is created during test execution.</li>
<li><code>documents</code>: Required array of objects. List of documents corresponding to the contents of the collection. This list
may be empty.</li>
</ul>
<h4 id="test"><a class="header" href="#test">test</a></h4>
<p>Test case consisting of a sequence of operations to be executed.</p>
<p>The structure of this object is as follows:</p>
<ul>
<li>
<p><code>description</code>: Required string. The name of the test.</p>
<p>This SHOULD describe the purpose of this test (e.g. "insertOne is retried").</p>
</li>
</ul>
<p><span id="test_runOnRequirements"></span></p>
<ul>
<li>
<p><code>runOnRequirements</code>: Optional array of one or more <a href="unified-test-format/unified-test-format.html#runonrequirement">runOnRequirement</a> objects. List of server
version and/or topology requirements for which this test can be run. If specified, these requirements are evaluated
independently and in addition to any top-level <a href="unified-test-format/unified-test-format.html#runOnRequirements">runOnRequirements</a>. If no requirements in this
array are met, the test runner MUST skip this test.</p>
<p>These requirements SHOULD be more restrictive than those specified in the top-level
<a href="unified-test-format/unified-test-format.html#runOnRequirements">runOnRequirements</a> (if any) and SHOULD NOT be more permissive. This is advised because both sets
of requirements MUST be satisfied in order for a test to be executed and more permissive requirements at the
test-level could be taken out of context on their own.</p>
</li>
</ul>
<p><span id="test_skipReason"></span></p>
<ul>
<li><code>skipReason</code>: Optional string. If set, the test will be skipped. The string SHOULD explain the reason for skipping the
test (e.g. JIRA ticket).</li>
</ul>
<p><span id="test_operations"></span></p>
<ul>
<li><code>operations</code>: Required array of one or more <a href="unified-test-format/unified-test-format.html#operation">operation</a> objects. List of operations to be executed for the
test case.</li>
</ul>
<p><span id="test_expectEvents"></span></p>
<ul>
<li>
<p><code>expectEvents</code>: Optional array of one or more <a href="unified-test-format/unified-test-format.html#expectedeventsforclient">expectedEventsForClient</a> objects. For one or
more clients, a list of events that are expected to be observed in a particular order.</p>
<p>If a driver only supports configuring event listeners globally (for all clients), the test runner SHOULD associate
each observed event with a client in order to perform these assertions.</p>
<p>Tests SHOULD NOT specify multiple <a href="unified-test-format/unified-test-format.html#expectedeventsforclient">expectedEventsForClient</a> objects for a single client
entity with the same <code>eventType</code> field. For example, a test containing two
<a href="unified-test-format/unified-test-format.html#expectedeventsforclient">expectedEventsForClient</a> objects with the <code>eventType</code> set to <code>cmap</code> for both would either
be redundant (if the <code>events</code> arrays were identical) or likely to fail (if the <code>events</code> arrays differed).</p>
</li>
</ul>
<p><span id="test_expectLogMessages"></span></p>
<ul>
<li>
<p><code>expectLogMessages</code>: Optional array of one or more <a href="unified-test-format/unified-test-format.html#expectedlogmessagesforclient">expectedLogMessagesForClient</a>
objects. For one or more clients, a list of log messages that are expected to be observed in a particular order.</p>
<p>If a driver only supports configuring log collectors globally (for all clients), the test runner SHOULD associate each
observed message with a client in order to perform these assertions. One possible implementation is to add a test-only
option to MongoClient which enables the client to store its entity name and add the entity name to each log message to
enable filtering messages by client.</p>
<p>Tests SHOULD NOT specify multiple <a href="unified-test-format/unified-test-format.html#expectedlogmessagesforclient">expectedLogMessagesForClient</a> objects for a single
client entity.</p>
</li>
</ul>
<p><span id="test_outcome"></span></p>
<ul>
<li>
<p><code>outcome</code>: Optional array of one or more <a href="unified-test-format/unified-test-format.html#collectiondata">collectionData</a> objects. Data that is expected to exist in
collections after each test case is executed.</p>
<p>The list of documents herein SHOULD be sorted ascendingly by the <code>_id</code> field to allow for deterministic comparisons.
The procedure for asserting collection contents is discussed in <a href="unified-test-format/unified-test-format.html#executing-a-test">Executing a Test</a>.</p>
</li>
</ul>
<h4 id="operation"><a class="header" href="#operation">operation</a></h4>
<p>An operation to be executed as part of the test.</p>
<p>The structure of this object is as follows:</p>
<p><span id="operation_name"></span></p>
<ul>
<li><code>name</code>: Required string. Name of the operation (e.g. method) to perform on the object.</li>
</ul>
<p><span id="operation_object"></span></p>
<ul>
<li><code>object</code>: Required string. Name of the object on which to perform the operation. This SHOULD correspond to either an
<a href="unified-test-format/unified-test-format.html#entity">entity</a> name (for <a href="unified-test-format/unified-test-format.html#entity-test-operations">Entity Test Operations</a>) or "testRunner" (for
<a href="unified-test-format/unified-test-format.html#special-test-operations">Special Test Operations</a>). If the object is an entity, The YAML file SHOULD use an
<a href="https://yaml.org/spec/1.2/spec.html#id2786196">alias node</a> for its <code>id</code> field (e.g. <code>object: *collection0</code>).</li>
</ul>
<p><span id="operation_arguments"></span></p>
<ul>
<li>
<p><code>arguments</code>: Optional object. Map of parameter names and values for the operation. The structure of this object will
vary based on the operation. See <a href="unified-test-format/unified-test-format.html#entity-test-operations">Entity Test Operations</a> and
<a href="unified-test-format/unified-test-format.html#special-test-operations">Special Test Operations</a>.</p>
<p>The <code>session</code> parameter is handled specially (see <a href="unified-test-format/unified-test-format.html#commonOptions_session">commonOptions_session</a>).</p>
</li>
</ul>
<p><span id="operation_ignoreResultAndError"></span></p>
<ul>
<li>
<p><code>ignoreResultAndError</code>: Optional boolean. If true, both the error and result for the operation MUST be ignored.</p>
<p>This field is mutually exclusive with <a href="unified-test-format/unified-test-format.html#operation_expectResult">expectResult</a>, <a href="unified-test-format/unified-test-format.html#operation_expectError">expectError</a>,
and <a href="unified-test-format/unified-test-format.html#operation_saveResultAsEntity">saveResultAsEntity</a>.</p>
<p>This field SHOULD NOT be used for <a href="unified-test-format/unified-test-format.html#special-test-operations">Special Test Operations</a> (i.e. <code>object: testRunner</code>).</p>
</li>
</ul>
<p><span id="operation_expectError"></span></p>
<ul>
<li>
<p><code>expectError</code>: Optional <a href="unified-test-format/unified-test-format.html#expectederror">expectedError</a> object. One or more assertions for an error expected to be
raised by the operation.</p>
<p>This field is mutually exclusive with <a href="unified-test-format/unified-test-format.html#operation_expectResult">expectResult</a> and
<a href="unified-test-format/unified-test-format.html#operation_saveResultAsEntity">saveResultAsEntity</a>.</p>
<p>This field SHOULD NOT be used for <a href="unified-test-format/unified-test-format.html#special-test-operations">Special Test Operations</a> (i.e. <code>object: testRunner</code>).</p>
</li>
</ul>
<p><span id="operation_expectResult"></span></p>
<ul>
<li>
<p><code>expectResult</code>: Optional mixed type. A value corresponding to the expected result of the operation. This field may be
a scalar value, a single document, or an array of values. Test runners MUST follow the rules in
<a href="unified-test-format/unified-test-format.html#evaluating-matches">Evaluating Matches</a> when processing this assertion.</p>
<p>This field is mutually exclusive with <a href="unified-test-format/unified-test-format.html#operation_expectError">expectError</a>.</p>
<p>This field SHOULD NOT be used for <a href="unified-test-format/unified-test-format.html#special-test-operations">Special Test Operations</a> (i.e. <code>object: testRunner</code>).</p>
</li>
</ul>
<p><span id="operation_saveResultAsEntity"></span></p>
<ul>
<li>
<p><code>saveResultAsEntity</code>: Optional string. If specified, the actual result returned by the operation (if any) will be
saved with this name in the <a href="unified-test-format/unified-test-format.html#entity-map">Entity Map</a>. The test runner MUST raise an error if the name is already in
use or if the result does not comply with <a href="unified-test-format/unified-test-format.html#supported-entity-types">Supported Entity Types</a>.</p>
<p>This field is mutually exclusive with <a href="unified-test-format/unified-test-format.html#operation_expectError">expectError</a>.</p>
<p>This field SHOULD NOT be used for <a href="unified-test-format/unified-test-format.html#special-test-operations">Special Test Operations</a> (i.e. <code>object: testRunner</code>).</p>
</li>
</ul>
<h4 id="expectederror"><a class="header" href="#expectederror">expectedError</a></h4>
<p>One or more assertions for an error/exception, which is expected to be raised by an executed operation. At least one key
is required in this object.</p>
<p>The structure of this object is as follows:</p>
<ul>
<li>
<p><code>isError</code>: Optional boolean. If true, the test runner MUST assert that an error was raised. This is primarily used
when no other error assertions apply but the test still needs to assert an expected error. Test files MUST NOT specify
false, as <a href="unified-test-format/unified-test-format.html#expectederror">expectedError</a> is only applicable when an operation is expected to raise an error.</p>
</li>
<li>
<p><code>isClientError</code>: Optional boolean. If true, the test runner MUST assert that the error originates from the client
(i.e. it is not derived from a server response). If false, the test runner MUST assert that the error does not
originate from the client.</p>
<p>Client errors include, but are not limited to: parameter validation errors before a command is sent to the server;
network errors.</p>
</li>
<li>
<p><code>isTimeoutError</code>: Optional boolean. If true, the test runner MUST assert that the error represents a timeout due to
use of the <code>timeoutMS</code> option. If false, the test runner MUST assert that the error does not represent a timeout.</p>
</li>
<li>
<p><code>errorContains</code>: Optional string. A substring of the expected error message (e.g. "errmsg" field in a server error
document). The test runner MUST assert that the error message contains this string using a case-insensitive match.</p>
<p>See <a href="unified-test-format/unified-test-format.html#bulkwrite">bulkWrite</a> for special considerations for BulkWriteExceptions.</p>
</li>
<li>
<p><code>errorCode</code>: Optional integer. The expected "code" field in the server-generated error response. The test runner MUST
assert that the error includes a server-generated response whose "code" field equals this value. In the interest of
readability, YAML files SHOULD use a comment to note the corresponding code name (e.g.
<code>errorCode: 26 # NamespaceNotFound</code>).</p>
<p>Server error codes are defined in
<a href="https://github.com/mongodb/mongo/blob/master/src/mongo/base/error_codes.yml">error_codes.yml</a>.</p>
<p>Test files SHOULD NOT assert error codes for client errors, as specifications do not define standardized codes for
client errors.</p>
</li>
<li>
<p><code>errorCodeName</code>: Optional string. The expected "codeName" field in the server-generated error response. The test
runner MUST assert that the error includes a server-generated response whose "codeName" field equals this value using
a case-insensitive comparison.</p>
<p>See <a href="unified-test-format/unified-test-format.html#bulkwrite">bulkWrite</a> for special considerations for BulkWriteExceptions.</p>
<p>Server error codes are defined in
<a href="https://github.com/mongodb/mongo/blob/master/src/mongo/base/error_codes.yml">error_codes.yml</a>.</p>
<p>Test files SHOULD NOT assert error codes for client errors, as specifications do not define standardized codes for
client errors.</p>
</li>
<li>
<p><code>errorLabelsContain</code>: Optional array of one or more strings. A list of error label strings that the error is expected
to have. The test runner MUST assert that the error contains all of the specified labels (e.g. using the
<code>hasErrorLabel</code> method).</p>
</li>
<li>
<p><code>errorLabelsOmit</code>: Optional array of one or more strings. A list of error label strings that the error is expected not
to have. The test runner MUST assert that the error does not contain any of the specified labels (e.g. using the
<code>hasErrorLabel</code> method).</p>
</li>
<li>
<p><code>writeErrors</code>: Optional document. The write errors expected to be present in the error. The <code>writeErrors</code> document
contains numeric keys representing the index of the write that failed and <code>writeError</code> object values. The test runner
MUST assert that the error contains a <code>writeError</code> for each index present in <code>writeErrors</code> and MUST assert that the
<code>writeError</code>s match as root-level documents according to the rules in <a href="unified-test-format/unified-test-format.html#evaluating-matches">Evaluating Matches</a>. The
test runner MUST assert that the error does not contain any additional <code>writeError</code>s. This field is only intended for
use with the <a href="unified-test-format/unified-test-format.html#clientbulkwrite">clientBulkWrite</a> operation.</p>
</li>
<li>
<p><code>writeConcernErrors</code>: Optional array of one or more objects. An ordered list of write concern errors expected to be
present in the error. The test runner MUST assert that each <code>writeConcernError</code> in this list matches the
<code>writeConcernError</code> present at the same index in the error's list of <code>writeConcernError</code>s as a root-level document
according to the rules in <a href="unified-test-format/unified-test-format.html#evaluating-matches">Evaluating Matches</a>. The test runner MUST assert that the error does
not contain any additional <code>writeConcernErrors</code>s. This field is only intended for use with the
<a href="unified-test-format/unified-test-format.html#clientbulkwrite">clientBulkWrite</a> operation.</p>
</li>
</ul>
<p><span id="expectedError_errorResponse"></span></p>
<ul>
<li>
<p><code>errorResponse</code>: Optional document. A value corresponding to the expected server response. The test runner MUST assert
that the error includes a server response that matches this value as a root-level document according to the rules in
<a href="unified-test-format/unified-test-format.html#evaluating-matches">Evaluating Matches</a>.</p>
<p>Note that some drivers may not be able to evaluate <code>errorResponse</code> for write commands (i.e. insert, update, delete)
and bulk write operations. For example, a BulkWriteException is derived from potentially multiple server responses and
may not provide direct access to a single response. Tests SHOULD avoid using <code>errorResponse</code> for such operations if
possible; otherwise, affected drivers SHOULD skip such tests if necessary.</p>
</li>
</ul>
<p><span id="expectedError_expectResult"></span></p>
<ul>
<li><code>expectResult</code>: Optional mixed type. This field follows the same rules as
<a href="unified-test-format/unified-test-format.html#operation_expectResult">operation.expectResult</a> and is only used in cases where the error includes a result (e.g.
<a href="unified-test-format/unified-test-format.html#bulkwrite">bulkWrite</a>). If specified, the test runner MUST assert that the error includes a result and that it
matches this value. If the result is optional (e.g. BulkWriteResult reported through the <code>writeResult</code> property of a
BulkWriteException), this assertion SHOULD utilize the <a href="unified-test-format/unified-test-format.html#unsetormatches">$$unsetOrMatches</a> operator.</li>
</ul>
<h4 id="expectedeventsforclient"><a class="header" href="#expectedeventsforclient">expectedEventsForClient</a></h4>
<p>A list of events that are expected to be observed (in that order) for a client while executing
<a href="unified-test-format/unified-test-format.html#test_operations">operations</a>.</p>
<p>The structure of each object is as follows:</p>
<ul>
<li><code>client</code>: Required string. Client entity on which the events are expected to be observed. See
<a href="unified-test-format/unified-test-format.html#commonOptions_client">commonOptions_client</a>.</li>
<li><code>eventType</code>: Optional string. Specifies the type of the monitor which captured the events. Valid values are <code>command</code>
for <a href="unified-test-format/../command-logging-and-monitoring/command-logging-and-monitoring.html#events-api">Command Monitoring</a> events,
<code>cmap</code> for <a href="unified-test-format/../connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#events">CMAP</a> events, and <code>sdam</code>
for <a href="unified-test-format/../server-discovery-and-monitoring/server-discovery-and-monitoring-logging-and-monitoring.html#events-api">SDAM</a>
events. Defaults to <code>command</code> if omitted.</li>
<li><code>events</code>: Required array of <a href="unified-test-format/unified-test-format.html#expectedevent">expectedEvent</a> objects. List of events, which are expected to be observed
(in this order) on the corresponding client while executing <a href="unified-test-format/unified-test-format.html#test_operations">operations</a>. If the array is empty, the
test runner MUST assert that no events were observed on the client (excluding ignored events).</li>
<li><code>ignoreExtraEvents</code>: Optional boolean. Specifies how the <code>events</code> array is matched against the observed events. If
<code>false</code>, observed events after all specified events have matched MUST cause a test failure; if <code>true</code>, observed events
after all specified events have been matched MUST NOT cause a test failure. Defaults to <code>false</code>.</li>
</ul>
<h4 id="expectedevent"><a class="header" href="#expectedevent">expectedEvent</a></h4>
<p>An event (e.g. APM), which is expected to be observed while executing the test's operations.</p>
<p>This object MUST contain <strong>exactly one</strong> top-level key that identifies the event type and maps to a nested object, which
contains one or more assertions for the event's properties.</p>
<p>Some event properties are omitted in the following structures because they cannot be reliably tested. Taking command
monitoring events as an example, <code>requestId</code> and <code>operationId</code> are nondeterministic and types for <code>connectionId</code> and
<code>failure</code> can vary by implementation.</p>
<p>The events allowed in an <code>expectedEvent</code> object depend on the value of <code>eventType</code> in the corresponding
<a href="unified-test-format/unified-test-format.html#expectedeventsforclient">expectedEventsForClient</a> object, which can have one of the following values:</p>
<ul>
<li><code>command</code> or omitted: only the event types defined in <a href="unified-test-format/unified-test-format.html#expectedcommandevent">expectedCommandEvent</a> are allowed.</li>
<li><code>cmap</code>: only the event types defined in <a href="unified-test-format/unified-test-format.html#expectedcmapevent">expectedCmapEvent</a> are allowed.</li>
<li><code>sdam</code>: only the event types defined in <a href="unified-test-format/unified-test-format.html#expectedsdamevent">expectedSdamEvent</a> are allowed.</li>
</ul>
<h5 id="expectedcommandevent"><a class="header" href="#expectedcommandevent">expectedCommandEvent</a></h5>
<p>The structure of this object is as follows:</p>
<p><span id="expectedEvent_commandStartedEvent"></span></p>
<ul>
<li>
<p><code>commandStartedEvent</code>: Optional object. Assertions for one or more
<a href="unified-test-format/../command-logging-and-monitoring/command-logging-and-monitoring.html#events-api">CommandStartedEvent</a> fields.</p>
<p>The structure of this object is as follows:</p>
<ul>
<li><code>command</code>: Optional document. A value corresponding to the expected command document. Test runners MUST follow the
rules in <a href="unified-test-format/unified-test-format.html#evaluating-matches">Evaluating Matches</a> when processing this assertion.</li>
<li><code>commandName</code>: Optional string. Test runners MUST assert that the command name matches this value.</li>
<li><code>databaseName</code>: Optional string. Test runners MUST assert that the database name matches this value. The YAML file
SHOULD use an <a href="https://yaml.org/spec/1.2/spec.html#id2786196">alias node</a> for this value (e.g.
<code>databaseName: *database0Name</code>).</li>
<li><code>hasServiceId</code>: Defined in <a href="unified-test-format/unified-test-format.html#hasserviceid">hasServiceId</a>.</li>
<li><code>hasServerConnectionId</code>: Defined in <a href="unified-test-format/unified-test-format.html#hasserverconnectionid">hasServerConnectionId</a>.</li>
</ul>
</li>
</ul>
<p><span id="expectedEvent_commandSucceededEvent"></span></p>
<ul>
<li>
<p><code>commandSucceededEvent</code>: Optional object. Assertions for one or more
<a href="unified-test-format/../command-logging-and-monitoring/command-logging-and-monitoring.html#events-api">CommandSucceededEvent</a> fields.</p>
<p>The structure of this object is as follows:</p>
<ul>
<li><code>reply</code>: Optional document. A value corresponding to the expected reply document. Test runners MUST follow the rules
in <a href="unified-test-format/unified-test-format.html#evaluating-matches">Evaluating Matches</a> when processing this assertion.</li>
<li><code>commandName</code>: Optional string. Test runners MUST assert that the command name matches this value.</li>
<li><code>databaseName</code>: Optional string. Test runners MUST assert that the database name matches this value. The YAML file
SHOULD use an <a href="https://yaml.org/spec/1.2/spec.html#id2786196">alias node</a> for this value (e.g.
<code>databaseName: *database0Name</code>).</li>
<li><code>hasServiceId</code>: Defined in <a href="unified-test-format/unified-test-format.html#hasserviceid">hasServiceId</a>.</li>
<li><code>hasServerConnectionId</code>: Defined in <a href="unified-test-format/unified-test-format.html#hasserverconnectionid">hasServerConnectionId</a>.</li>
</ul>
</li>
</ul>
<p><span id="expectedEvent_commandFailedEvent"></span></p>
<ul>
<li>
<p><code>commandFailedEvent</code>: Optional object. Assertions for one or more
<a href="unified-test-format/../command-logging-and-monitoring/command-logging-and-monitoring.html#events-api">CommandFailedEvent</a> fields.</p>
<p>The structure of this object is as follows:</p>
<ul>
<li><code>commandName</code>: Optional string. Test runners MUST assert that the command name matches this value.</li>
<li><code>databaseName</code>: Optional string. Test runners MUST assert that the database name matches this value. The YAML file
SHOULD use an <a href="https://yaml.org/spec/1.2/spec.html#id2786196">alias node</a> for this value (e.g.
<code>databaseName: *database0Name</code>).</li>
<li><code>hasServiceId</code>: Defined in <a href="unified-test-format/unified-test-format.html#hasserviceid">hasServiceId</a>.</li>
<li><code>hasServerConnectionId</code>: Defined in <a href="unified-test-format/unified-test-format.html#hasserverconnectionid">hasServerConnectionId</a>.</li>
</ul>
</li>
</ul>
<h5 id="expectedcmapevent"><a class="header" href="#expectedcmapevent">expectedCmapEvent</a></h5>
<p><span id="expectedEvent_poolCreatedEvent"></span></p>
<ul>
<li><code>poolCreatedEvent</code>: Optional object. If present, this object MUST be an empty document as all fields in this event are
non-deterministic.</li>
</ul>
<p><span id="expectedEvent_poolReadyEvent"></span></p>
<ul>
<li><code>poolReadyEvent</code>: Optional object. If present, this object MUST be an empty document as all fields in this event are
non-deterministic.</li>
</ul>
<p><span id="expectedEvent_poolClearedEvent"></span></p>
<ul>
<li>
<p><code>poolClearedEvent</code>: Optional object. Assertions for one or more
<a href="unified-test-format/../connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#events">PoolClearedEvent</a> fields.</p>
<p>The structure of this object is as follows:</p>
<ul>
<li><code>hasServiceId</code>: Defined in <a href="unified-test-format/unified-test-format.html#hasserviceid">hasServiceId</a>.</li>
<li><code>interruptInUseConnections</code>: Optional boolean. If specified, test runners MUST assert that the field is set and
matches this value.</li>
</ul>
</li>
</ul>
<p><span id="expectedEvent_poolClosedEvent"></span></p>
<ul>
<li><code>poolClosedEvent</code>: Optional object. If present, this object MUST be an empty document as all fields in this event are
non-deterministic.</li>
</ul>
<p><span id="expectedEvent_connectionCreatedEvent"></span></p>
<ul>
<li><code>connectionCreatedEvent</code>: Optional object. If present, this object MUST be an empty document as all fields in this
event are non-deterministic.</li>
</ul>
<p><span id="expectedEvent_connectionReadyEvent"></span></p>
<ul>
<li><code>connectionReadyEvent</code>: Optional object. If present, this object MUST be an empty document as all fields in this event
are non-deterministic.</li>
</ul>
<p><span id="expectedEvent_connectionClosedEvent"></span></p>
<ul>
<li>
<p><code>connectionClosedEvent</code>: Optional object. Assertions for one or more
<a href="unified-test-format/../connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#events">ConnectionClosedEvent</a> fields.</p>
<p>The structure of this object is as follows:</p>
<ul>
<li><code>reason</code>: Optional string. Test runners MUST assert that the reason in the published event matches this value. Valid
values for this field are defined in the CMAP spec.</li>
</ul>
</li>
</ul>
<p><span id="expectedEvent_connectionCheckOutStartedEvent"></span></p>
<ul>
<li><code>connectionCheckOutStartedEvent</code>: Optional object. If present, this object MUST be an empty document as all fields in
this event are non-deterministic.</li>
</ul>
<p><span id="expectedEvent_connectionCheckOutFailedEvent"></span></p>
<ul>
<li>
<p><code>connectionCheckOutFailedEvent</code>: Optional object. Assertions for one or more
<a href="unified-test-format/../connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#events">ConnectionCheckOutFailedEvent</a>
fields.</p>
<p>The structure of this object is as follows:</p>
<ul>
<li><code>reason</code>: Optional string. Test runners MUST assert that the reason in the published event matches this value. Valid
values for this field are defined in the CMAP spec.</li>
</ul>
</li>
</ul>
<p><span id="expectedEvent_connectionCheckedOutEvent"></span></p>
<ul>
<li><code>connectionCheckedOutEvent</code>: Optional object. If present, this object MUST be an empty document as all fields in this
event are non-deterministic.</li>
</ul>
<p><span id="expectedEvent_connectionCheckedInEvent"></span></p>
<ul>
<li><code>connectionCheckedInEvent</code>: Optional object. If present, this object MUST be an empty document as all fields in this
event are non-deterministic.</li>
</ul>
<h5 id="expectedsdamevent"><a class="header" href="#expectedsdamevent">expectedSdamEvent</a></h5>
<p>The structure of this object is as follows:</p>
<p><span id="expectedEvent_serverDescriptionChangedEvent"></span></p>
<ul>
<li>
<p><code>serverDescriptionChangedEvent</code>: Optional object. Assertions for one or more
<a href="unified-test-format/../server-discovery-and-monitoring/server-discovery-and-monitoring-logging-and-monitoring.html#events-api">ServerDescriptionChangedEvent</a>
fields.</p>
<p>The structure of this object is as follows:</p>
<ul>
<li><code>previousDescription</code>: Optional object. A value corresponding to the server description as it was before the change
that triggered this event.</li>
<li><code>newDescription</code>: Optional object. A value corresponding to the server description as it was after the change that
triggered this event.</li>
</ul>
<p>The structure of a server description object (which the <code>previousDescription</code> and <code>newDescription</code> fields contain) is
as follows:</p>
<ul>
<li><code>type</code>: Optional string. The type of the server in the description. Test runners MUST assert that the type in the
published event matches this value. See
<a href="unified-test-format/../server-discovery-and-monitoring/server-discovery-and-monitoring.html#servertype">SDAM: ServerType</a> for a list of
valid values.</li>
</ul>
</li>
</ul>
<p><span id="expectedEvent_serverHeartbeatStartedEvent"></span></p>
<ul>
<li>
<p><code>serverHeartbeatStartedEvent</code>: Optional object. Assertions for one or more
<a href="unified-test-format/../server-discovery-and-monitoring/server-discovery-and-monitoring-logging-and-monitoring.html#events-api">ServerHeartbeatStartedEvent</a>
fields.</p>
<p>The structure of this object is as follows:</p>
<ul>
<li><code>awaited</code>: Optional boolean. If specified, test runners MUST assert that the field is set and matches this value.</li>
</ul>
</li>
</ul>
<p><span id="expectedEvent_serverHeartbeatSucceededEvent"></span></p>
<ul>
<li>
<p><code>serverHeartbeatSucceededEvent</code>: Optional object. Assertions for one or more
<a href="unified-test-format/../server-discovery-and-monitoring/server-discovery-and-monitoring-logging-and-monitoring.html#events-api">ServerHeartbeatSucceededEvent</a>
fields.</p>
<p>The structure of this object is as follows:</p>
<ul>
<li><code>awaited</code>: Optional boolean. If specified, test runners MUST assert that the field is set and matches this value.</li>
</ul>
</li>
</ul>
<p><span id="expectedEvent_serverHeartbeatFailedEvent"></span></p>
<ul>
<li>
<p><code>serverHeartbeatFailedEvent</code>: Optional object. Assertions for one or more
<a href="unified-test-format/../server-discovery-and-monitoring/server-discovery-and-monitoring-logging-and-monitoring.html#events-api">ServerHeartbeatFailedEvent</a>
fields.</p>
<p>The structure of this object is as follows:</p>
<ul>
<li><code>awaited</code>: Optional boolean. If specified, test runners MUST assert that the field is set and matches this value.</li>
</ul>
</li>
</ul>
<p><span id="expectedEvent_topologyDescriptionChangedEvent"></span></p>
<ul>
<li>
<p><code>topologyDescriptionChangedEvent</code>: Optional object. Assertions for one
<a href="unified-test-format/../server-discovery-and-monitoring/server-discovery-and-monitoring-logging-and-monitoring.html#events-api">TopologyDescriptionChangedEvent</a>
object.</p>
<p>The structure of this object is as follows:</p>
<ul>
<li>
<p><code>previousDescription</code>: Optional Object. A value corresponding to the topology description as it was before the
change that triggered the event.</p>
</li>
<li>
<p><code>newDescription</code> : Optional Object. A value corresponding to the topology description as it is after the change that
triggered the event.</p>
<p>Test runners SHOULD ignore any other fields than the <code>previousDescription</code> and <code>newDescription</code> fields.</p>
<p>The structure of a topology description object (which the <code>previousDescription</code> and <code>newDescription</code> fields contain
is as follows:</p>
<ul>
<li><code>type</code>: Optional string. The type of the topology in the description. Test runners MUST assert that the type in
the published event matches this value. See
<a href="unified-test-format/../server-discovery-and-monitoring/server-discovery-and-monitoring.html#topologytype">SDAM: TopologyType</a> for a
list of valid values.</li>
</ul>
<p>Test runners SHOULD ignore any other fields present on the <code>previousDescription</code> and <code>newDescription</code> fields of the
captured <code>topologyDescriptionChangedEvent</code>.</p>
</li>
</ul>
</li>
</ul>
<h5 id="hasserviceid"><a class="header" href="#hasserviceid">hasServiceId</a></h5>
<p>This field is an optional boolean that specifies whether or not the <code>serviceId</code> field of an event is set. If true, test
runners MUST assert that the field is set and is a non-empty BSON ObjectId (i.e. all bytes of the ObjectId are not 0).
If false, test runners MUST assert that the field is not set or is an empty BSON ObjectId.</p>
<h5 id="hasserverconnectionid"><a class="header" href="#hasserverconnectionid">hasServerConnectionId</a></h5>
<p>This field is an optional boolean that specifies whether or not the <code>serverConnectionId</code> field of an event is set. If
true, test runners MUST assert that the field is set and is a positive Int32. If false, test runners MUST assert that
the field is not set, or, if the driver uses a nonpositive Int32 value to indicate the field being unset, MUST assert
that <code>serverConnectionId</code> is a nonpositive Int32.</p>
<h4 id="expectedlogmessagesforclient"><a class="header" href="#expectedlogmessagesforclient">expectedLogMessagesForClient</a></h4>
<p>A list of log messages that are expected to be observed (in that order) for a client while executing
<a href="unified-test-format/unified-test-format.html#test_operations">operations</a>.</p>
<p>The structure of each object is as follows:</p>
<ul>
<li><code>client</code>: Required string. Client entity for which the messages are expected to be observed. See
<a href="unified-test-format/unified-test-format.html#commonOptions_client">commonOptions_client</a>.</li>
<li><code>messages</code>: Required array of <a href="unified-test-format/unified-test-format.html#expectedlogmessage">expectedLogMessage</a> objects. List of messages, which are expected
to be observed (in this order) on the corresponding client while executing <a href="unified-test-format/unified-test-format.html#test_operations">operations</a>. If the
array is empty, the test runner MUST assert that no messages were observed on the client. The driver MUST assert that
the messages produced are an exact match, i.e. that the expected and actual message counts are the same and that there
are no extra messages emitted by the client during the test run. Note: <code>ignoreMessages</code> and <code>ignoreExtraMessages</code> may
exclude log messages from this evaluation.</li>
<li><code>ignoreMessages</code>: Optional array of <a href="unified-test-format/unified-test-format.html#expectedlogmessage">expectedLogMessage</a> objects. Unordered set of messages,
which MUST be ignored on the corresponding client while executing <a href="unified-test-format/unified-test-format.html#test_operations">operations</a>. The test runner MUST
exclude all log messages from observed messages that match any of the messages in <code>ignoreMessages</code> array before
<code>messages</code> evaluation. Matching rules used to match messages in <code>ignoreMessages</code> are identical to match rules used for
<code>messages</code> matching.</li>
<li><code>ignoreExtraMessages</code>: Optional boolean. Specifies how the <code>messages</code> array is matched against the observed logs. If
<code>false</code>, observed logs after all specified logs have matched MUST cause a test failure; if <code>true</code>, observed logs after
all specified logs have been matched MUST NOT cause a test failure. Defaults to <code>false</code>.</li>
</ul>
<p><span id="expectedLogMessage"></span></p>
<h4 id="expectedlogmessage"><a class="header" href="#expectedlogmessage">expectedLogMessage</a></h4>
<p>A log message which is expected to be observed while executing the test's operations.</p>
<p>The structure of each object is as follows:</p>
<ul>
<li>
<p><code>level</code>: Required string. This MUST be one of the level names listed in
<a href="unified-test-format/../logging/logging.html#log-severity-levels">log severity levels</a>. This specifies the expected level for the log
message and corresponds to the level used for the message in the specification that defines it. Note that since not
all drivers will necessarily support all log levels, some driver may need to map the specified level to the
corresponding driver-supported level. Test runners MUST assert that the actual level matches this value.</p>
</li>
<li>
<p><code>component</code>: Required string. This MUST be one of the component names listed in
<a href="unified-test-format/../logging/logging.html#components">components</a>. This specifies the expected component for the log message. Note that
since naming variations are permitted for components, some drivers may need to map this to a corresponding
language-specific component name. Test runners MUST assert that the actual component matches this value.</p>
</li>
<li>
<p><code>failureIsRedacted</code>: Optional boolean. This field SHOULD only be specified when the log message data is expected to
contain a <code>failure</code> value.</p>
<p>When <code>failureIsRedacted</code> is present and its value is <code>true</code>, the test runner MUST assert that a failure is present and
that the failure has been redacted according to the rules defined for error redaction in the
<a href="unified-test-format/../command-logging-and-monitoring/command-logging-and-monitoring.html#security">command logging and monitoring specification</a>.</p>
<p>When <code>false</code>, the test runner MUST assert that a failure is present and that the failure has NOT been redacted.</p>
<p>The exact form of these assertions and how thorough they are will vary based on the driver's chosen error
representation in logs; e.g. drivers that use strings may only be able to assert on the presence/absence of
substrings.</p>
</li>
<li>
<p><code>data</code>: Required object. Contains key-value pairs that are expected to be attached to the log message. Test runners
MUST assert that the actual data contained in the log message matches the expected data, and MUST treat the log
message data as a root-level document.</p>
<p>A suggested implementation approach is to decode <code>data</code> as a BSON document and serialize the data attached to each log
message to a BSON document, and match those documents.</p>
<p>Note that for drivers that do not implement structured logging, this requires designing logging internals such that
data is first gathered in a structured form (e.g. a document or hashmap) which can be intercepted for testing
purposes.</p>
</li>
</ul>
<h4 id="collectionordatabaseoptions"><a class="header" href="#collectionordatabaseoptions">collectionOrDatabaseOptions</a></h4>
<p>Map of parameters used to construct a collection or database object.</p>
<p>The structure of this object is as follows:</p>
<ul>
<li><code>readConcern</code>: Optional object. See <a href="unified-test-format/unified-test-format.html#commonOptions_readConcern">commonOptions_readConcern</a>.</li>
<li><code>readPreference</code>: Optional object. See <a href="unified-test-format/unified-test-format.html#commonOptions_readPreference">commonOptions_readPreference</a>.</li>
<li><code>writeConcern</code>: Optional object. See <a href="unified-test-format/unified-test-format.html#commonOptions_writeConcern">commonOptions_writeConcern</a>.</li>
</ul>
<h3 id="common-options"><a class="header" href="#common-options">Common Options</a></h3>
<p>This section defines the structure of common options that are referenced from various contexts in the test format.
Comprehensive documentation for some of these types and their parameters may be found in the following specifications:</p>
<ul>
<li><a href="unified-test-format/../read-write-concern/read-write-concern.html">Read and Write Concern</a>.</li>
<li><a href="unified-test-format/../server-selection/server-selection.html#read-preference">Server Selection: Read Preference</a>.</li>
<li><a href="unified-test-format/../server-discovery-and-monitoring/server-discovery-and-monitoring.html#topologydescription">Server Discovery and Monitoring: TopologyDescription</a>.</li>
</ul>
<p>The structure of these common options is as follows:</p>
<p><span id="commonOptions_collectionName"></span></p>
<ul>
<li><code>collectionName</code>: String. Collection name. The YAML file SHOULD use an
<a href="https://yaml.org/spec/1.2/spec.html#id2786196">alias node</a> for a collection entity's <code>collectionName</code> field (e.g.
<code>collectionName: *collection0Name</code>).</li>
</ul>
<p><span id="commonOptions_databaseName"></span></p>
<ul>
<li><code>databaseName</code>: String. Database name. The YAML file SHOULD use an
<a href="https://yaml.org/spec/1.2/spec.html#id2786196">alias node</a> for a database entity's <code>databaseName</code> field (e.g.
<code>databaseName: *database0Name</code>).</li>
</ul>
<p><span id="commonOptions_readConcern"></span></p>
<ul>
<li>
<p><code>readConcern</code>: Object. Map of parameters to construct a read concern.</p>
<p>The structure of this object is as follows:</p>
<ul>
<li><code>level</code>: Required string.</li>
</ul>
</li>
</ul>
<p><span id="commonOptions_readPreference"></span></p>
<ul>
<li>
<p><code>readPreference</code>: Object. Map of parameters to construct a read preference.</p>
<p>The structure of this object is as follows:</p>
<ul>
<li><code>mode</code>: Required string.</li>
<li><code>tagSets</code>: Optional array of objects.</li>
<li><code>maxStalenessSeconds</code>: Optional integer.</li>
<li><code>hedge</code>: Optional object.</li>
</ul>
</li>
</ul>
<p><span id="commonOptions_client"></span></p>
<ul>
<li><code>client</code>: String. Client entity name, which the test runner MUST resolve to a MongoClient object. The YAML file SHOULD
use an <a href="https://yaml.org/spec/1.2/spec.html#id2786196">alias node</a> for a client entity's <code>id</code> field (e.g.
<code>client: *client0</code>).</li>
</ul>
<p><span id="commonOptions_session"></span></p>
<ul>
<li><code>session</code>: String. Session entity name, which the test runner MUST resolve to a ClientSession object. The YAML file
SHOULD use an <a href="https://yaml.org/spec/1.2/spec.html#id2786196">alias node</a> for a session entity's <code>id</code> field (e.g.
<code>session: *session0</code>).</li>
</ul>
<p><span id="commonOptions_writeConcern"></span></p>
<ul>
<li>
<p><code>writeConcern</code>: Object. Map of parameters to construct a write concern.</p>
<p>The structure of this object is as follows:</p>
<ul>
<li><code>journal</code>: Optional boolean.</li>
<li><code>w</code>: Optional integer or string.</li>
<li><code>wtimeoutMS</code>: Optional integer.</li>
</ul>
</li>
</ul>
<h3 id="version-string"><a class="header" href="#version-string">Version String</a></h3>
<p>Version strings, which are used for <a href="unified-test-format/unified-test-format.html#schemaVersion">schemaVersion</a> and <a href="unified-test-format/unified-test-format.html#runonrequirement">runOnRequirement</a>, MUST
conform to one of the following formats, where each component is a non-negative integer:</p>
<ul>
<li><code>&lt;major&gt;.&lt;minor&gt;.&lt;patch&gt;</code></li>
<li><code>&lt;major&gt;.&lt;minor&gt;</code> (<code>&lt;patch&gt;</code> is assumed to be zero)</li>
<li><code>&lt;major&gt;</code> (<code>&lt;minor&gt;</code> and <code>&lt;patch&gt;</code> are assumed to be zero)</li>
</ul>
<p>Any component other than <code>major</code>, <code>minor</code>, and <code>patch</code> MUST be discarded prior to comparing versions. This is necessary
to ensure that spec tests run on pre-release versions of the MongoDB server. As an example, when checking if a server
with the version <code>4.9.0-alpha4-271-g7d5cf02</code> passes the requirement for a test, only <code>4.9.0</code> is relevant for the
comparison. When reading the server version from the <code>buildInfo</code> command reply, the three elements of the <code>versionArray</code>
field MUST be used, and all other fields MUST be discarded for this comparison.</p>
<h3 id="entity-test-operations"><a class="header" href="#entity-test-operations">Entity Test Operations</a></h3>
<p>Entity operations correspond to an API method on a driver object. If <a href="unified-test-format/unified-test-format.html#operation_object">operation.object</a> refers to an
<a href="unified-test-format/unified-test-format.html#entity">entity</a> name (e.g. "collection0") then <a href="unified-test-format/unified-test-format.html#operation_name">operation.name</a> is expected to reference an API
method on that class.</p>
<p>Test files SHALL use camelCase when referring to API methods and parameters, even if the defining specifications use
other forms (e.g. snake_case in GridFS). Test files SHOULD use the exact API method names defined in specifications for
entity test operations. Test files MAY use a different descriptive name if a naming conflict occurs. For example, the
name "clientBulkWrite" is used for the client-level bulk write operation to differentiate it from the collection-level
bulk write operation.</p>
<p>This spec does not provide exhaustive documentation for all possible API methods that may appear in a test; however, the
following sections discuss all supported entities and their operations in some level of detail. Special handling for
certain operations is also discussed as needed.</p>
<h4 id="expressing-required-and-optional-parameters"><a class="header" href="#expressing-required-and-optional-parameters">Expressing Required and Optional Parameters</a></h4>
<p>Some specifications group optional parameters for API methods under an <code>options</code> parameter (e.g.
<code>options: Optional&lt;UpdateOptions&gt;</code> in the CRUD spec); however, driver APIs vary in how they accept options (e.g.
Python's keyword/named arguments, <code>session</code> as either an option or required parameter depending on whether a language
supports method overloading). Therefore, test files SHALL declare all required and optional parameters for an API method
directly within <a href="unified-test-format/unified-test-format.html#operation_arguments">operation.arguments</a> (e.g. <code>upsert</code> for <code>updateOne</code> is <em>not</em> nested under an
<code>options</code> key).</p>
<h4 id="special-handling-for-arguments"><a class="header" href="#special-handling-for-arguments">Special Handling for Arguments</a></h4>
<p>If <code>session</code> is specified in <a href="unified-test-format/unified-test-format.html#operation_arguments">operation.arguments</a>, it is defined according to
<a href="unified-test-format/unified-test-format.html#commonOptions_session">commonOptions_session</a>. Test runners MUST resolve the <code>session</code> argument to
<a href="unified-test-format/unified-test-format.html#entity_session">session</a> entity <em>before</em> passing it as a parameter to any API method.</p>
<p>If <code>readConcern</code>, <code>readPreference</code>, or <code>writeConcern</code> are specified in <a href="unified-test-format/unified-test-format.html#operation_arguments">operation.arguments</a>, test
runners MUST interpret them according to the corresponding definition in <a href="unified-test-format/unified-test-format.html#common-options">Common Options</a> and MUST
convert the value into the appropriate object <em>before</em> passing it as a parameter to any API method.</p>
<h4 id="converting-returned-model-objects-to-documents"><a class="header" href="#converting-returned-model-objects-to-documents">Converting Returned Model Objects to Documents</a></h4>
<p>For operations that return a model object (e.g. <code>BulkWriteResult</code> for <code>bulkWrite</code>), the test runner MUST convert the
model object to a document when evaluating <a href="unified-test-format/unified-test-format.html#operation_expectResult">expectResult</a> or
<a href="unified-test-format/unified-test-format.html#operation_saveResultAsEntity">saveResultAsEntity</a>. Similarly, for operations that may return iterables of model
objects (e.g. <code>DatabaseInfo</code> for <code>listDatabases</code>), the test runner MUST convert the iterable to an array of documents
when evaluating <a href="unified-test-format/unified-test-format.html#operation_expectResult">expectResult</a> or <a href="unified-test-format/unified-test-format.html#operation_saveResultAsEntity">saveResultAsEntity</a>.</p>
<h4 id="iterating-returned-iterables"><a class="header" href="#iterating-returned-iterables">Iterating Returned Iterables</a></h4>
<p>Unless otherwise stated by an operation below, test runners MUST fully iterate any iterable returned by an operation as
part of that operation's execution. This is necessary to ensure consistent behavior among drivers, as discussed in
<a href="unified-test-format/unified-test-format.html#collection_aggregate">collection_aggregate</a> and <a href="unified-test-format/unified-test-format.html#find">find</a>, and also ensures that error and event assertions can be
evaluated consistently.</p>
<h3 id="client-operations"><a class="header" href="#client-operations">Client Operations</a></h3>
<p>These operations and their arguments may be documented in the following specifications:</p>
<ul>
<li><a href="unified-test-format/../change-streams/change-streams.html">Change Streams</a></li>
<li><a href="unified-test-format/../enumerate-databases/enumerate-databases.html">Enumerating Databases</a></li>
</ul>
<p>Client operations that require special handling or are not documented by an existing specification are described below.</p>
<h4 id="close"><a class="header" href="#close">close</a></h4>
<p>Closes the client, i.e. close underlying connection pool(s) and cease monitoring the topology. For languages that rely
on built-in language mechanisms such as reference counting to automatically close/deinitialize clients once they go out
of scope, this may require implementing an abstraction to allow a client entity's underlying client to be set to null.
Because drivers do not consistently propagate errors encountered while closing a client, test files SHOULD NOT specify
<a href="unified-test-format/unified-test-format.html#operation_expectResult">expectResult</a> or <a href="unified-test-format/unified-test-format.html#operation_expectError">expectError</a> for this operation. Test files SHOULD
NOT specify any operations for a client entity or any entity descended from it following a <code>close</code> operation on it, as
driver behavior when an operation is attempted on a closed client or one of its descendant objects is not consistent.</p>
<p><span id="client_createChangeStream"></span></p>
<h4 id="createchangestream"><a class="header" href="#createchangestream">createChangeStream</a></h4>
<p>Creates a cluster-level change stream and ensures that the server-side cursor has been created.</p>
<p>This operation proxies the client's <code>watch</code> method and supports the same arguments and options. Test files SHOULD NOT
use the client's <code>watch</code> operation directly for reasons discussed in <a href="unified-test-format/unified-test-format.html#entity_changestream">ChangeStream</a>. Test runners
MUST ensure that the server-side cursor is created (i.e. <code>aggregate</code> is executed) as part of this operation and before
the resulting change stream might be saved with <a href="unified-test-format/unified-test-format.html#operation_saveResultAsEntity">operation.saveResultAsEntity</a>.</p>
<p>Test runners MUST NOT iterate the change stream when executing this operation and test files SHOULD NOT specify
<a href="unified-test-format/unified-test-format.html#operation_expectResult">operation.expectResult</a> for this operation.</p>
<h4 id="clientbulkwrite"><a class="header" href="#clientbulkwrite">clientBulkWrite</a></h4>
<p>These considerations only apply to the <code>MongoClient.bulkWrite</code> method. See <a href="unified-test-format/unified-test-format.html#bulkwrite">bulkWrite</a> for special
considerations for <code>MongoCollection.bulkWrite</code>.</p>
<p>The <code>models</code> parameter for <code>clientBulkWrite</code> is documented as a list of WriteModel interfaces. Each WriteModel
implementation (e.g. InsertOneModel) provides important context to the method, but that type information is not easily
expressed in YAML and JSON. To account for this, test files MUST nest each WriteModel object in a single-key object,
where the key identifies the request type (e.g. "insertOne") and its value is an object expressing the parameters, as in
the following example:</p>
<pre><code>arguments:
  models:
    - insertOne:
        document: { _id: 1, x: 1 }
    - replaceOne:
        filter: { _id: 2 }
        replacement: { x: 2 }
        upsert: true
    - updateOne:
        filter: { _id: 3 }
        update: { $set: { x: 3 } }
        upsert: true
    - updateMany:
        filter: { }
        update: { $inc: { x: 1 } }
    - deleteOne:
        filter: { x: 2 }
    - deleteMany:
        filter: { x: { $gt: 2 } }
  ordered: true
</code></pre>
<p>Because the <code>insertResults</code>, <code>updateResults</code>, and <code>deleteResults</code> may be absent or empty in the <code>BulkWriteResult</code>
returned from a summary-only bulk write, the <code>clientBulkWrite</code> operation SHOULD use the
<a href="unified-test-format/unified-test-format.html#unsetormatches">$$unsetOrMatches</a> operator for assertions on these fields when <code>verboseResults</code> is not set to true.
This also applies to result objects defined in the <code>expectedResult</code> field of <a href="unified-test-format/unified-test-format.html#expectederror">expectedError</a>.</p>
<p>The <code>BulkWriteException</code> thrown by <code>MongoClient.bulkWrite</code> contains an optional <code>error</code> field that stores a top-level
error that occurred during the bulk write. Test runners MUST inspect the contents of this field when making assertions
based on the contents of the <code>errorCode</code> and <code>errorContains</code> fields in <a href="unified-test-format/unified-test-format.html#expectederror">expectedError</a>.</p>
<p><code>BulkWriteException</code> also contains <code>writeErrors</code> and <code>writeConcernErrors</code> fields that define the individual write errors
and write concern errors that occurred during the bulk write. Unified tests SHOULD use <code>writeErrors</code> and
<code>writeConcernErrors</code> in <code>expectedError</code> to assert on the contents of these fields. Test runners MUST NOT inspect the
contents of these fields when making assertions based on any other fields defined in <code>expectedError</code>.</p>
<p>While operations typically raise an error <em>or</em> return a result, the <code>MongoClient.bulkWrite</code> operation may report both
via the <code>partialResult</code> property of a <code>BulkWriteException</code>. In this case, the intermediary write result may be matched
with <a href="unified-test-format/unified-test-format.html#expectedError_expectResult">expectedError_expectResult</a></p>
<h4 id="watch"><a class="header" href="#watch">watch</a></h4>
<p>This operation SHOULD NOT be used in test files. See <a href="unified-test-format/unified-test-format.html#client_createChangeStream">client_createChangeStream</a>.</p>
<h3 id="clientencryption-operations"><a class="header" href="#clientencryption-operations">ClientEncryption Operations</a></h3>
<p>These operations and their arguments may be documented in the following specifications:</p>
<ul>
<li><a href="unified-test-format/../client-side-encryption/client-side-encryption.html">Client Side Encryption</a></li>
</ul>
<p>Operations that require sending and receiving KMS requests to encrypt or decrypt data keys may require appropriate KMS
credentials to be loaded by the driver. Drivers MUST load appropriate KMS credentials (i.e. from the environment or a
configuration file) when prompted by a test providing a placeholder value in a corresponding <code>kmsProviders</code> field as
described under <a href="unified-test-format/unified-test-format.html#entity_clientEncryption">entity.clientEncryption</a>.</p>
<p>See the <a href="unified-test-format/../client-side-encryption/tests/README.html#credentials">Client-Side Encryption test README</a> for instructions to
obtain test credentials.</p>
<p>Drivers MUST be running the mock
<a href="https://github.com/mongodb-labs/drivers-evergreen-tools/blob/master/.evergreen/csfle/kms_kmip_server.py">KMS KMIP server</a>
when evaluating tests that require KMS requests to a KMIP KMS provider.</p>
<p>Drivers MAY enforce a unique index on <code>keyAltNames</code> as described in the
<a href="unified-test-format/../client-side-encryption/client-side-encryption.html#why-arent-we-creating-a-unique-index-in-the-key-vault-collection">Client Side Field Level Encryption spec</a>
when running key management operations on the key vault collection. Although unified tests are written assuming the
existence of the unique index, no unified test currently requires its implementation for correctness (e.g. no unified
test currently attempts to create a data key with an existing keyAltName or add an existing keyAltName to a data key).</p>
<h3 id="database-operations"><a class="header" href="#database-operations">Database Operations</a></h3>
<p>These operations and their arguments may be documented in the following specifications:</p>
<ul>
<li><a href="unified-test-format/../change-streams/change-streams.html">Change Streams</a></li>
<li><a href="unified-test-format/../crud/crud.html">CRUD</a></li>
<li><a href="unified-test-format/../enumerate-collections/enumerate-collections.html">Enumerating Collections</a></li>
</ul>
<p>Database operations that require special handling or are not documented by an existing specification are described
below.</p>
<h4 id="aggregate"><a class="header" href="#aggregate">aggregate</a></h4>
<p>When executing an <code>aggregate</code> operation, the test runner MUST fully iterate the result. This will ensure consistent
behavior between drivers that eagerly create a server-side cursor and those that do so lazily when iteration begins.</p>
<p><span id="database_createChangeStream"></span></p>
<h4 id="createchangestream-1"><a class="header" href="#createchangestream-1">createChangeStream</a></h4>
<p>Creates a database-level change stream and ensures that the server-side cursor has been created.</p>
<p>This operation proxies the database's <code>watch</code> method and supports the same arguments and options. Test files SHOULD NOT
use the database's <code>watch</code> operation directly for reasons discussed in <a href="unified-test-format/unified-test-format.html#entity_changestream">ChangeStream</a>. Test
runners MUST ensure that the server-side cursor is created (i.e. <code>aggregate</code> is executed) as part of this operation and
before the resulting change stream might be saved with <a href="unified-test-format/unified-test-format.html#operation_saveResultAsEntity">operation.saveResultAsEntity</a>.</p>
<p>Test runners MUST NOT iterate the change stream when executing this operation and test files SHOULD NOT specify
<a href="unified-test-format/unified-test-format.html#operation_expectResult">operation.expectResult</a> for this operation.</p>
<h4 id="listcollections"><a class="header" href="#listcollections">listCollections</a></h4>
<p>When executing a <code>listCollections</code> operation, the test runner MUST fully iterate the resulting cursor.</p>
<h4 id="runcommand-2"><a class="header" href="#runcommand-2">runCommand</a></h4>
<p>Generic command runner.</p>
<p>This method does not inherit a read preference (per the
<a href="unified-test-format/../server-selection/server-selection.html#use-of-read-preferences-with-commands">Server Selection</a> spec); however,
<code>readPreference</code> may be specified as an argument.</p>
<p>The following arguments are supported:</p>
<ul>
<li><code>command</code>: Required document. The command to be executed.</li>
<li><code>commandName</code>: Required string. The name of the command to run. This is used by languages that are unable preserve the
order of keys in the <code>command</code> argument when parsing YAML/JSON.</li>
<li><code>readPreference</code>: Optional object. See <a href="unified-test-format/unified-test-format.html#commonOptions_readPreference">commonOptions_readPreference</a>.</li>
<li><code>session</code>: Optional string. See <a href="unified-test-format/unified-test-format.html#commonOptions_session">commonOptions_session</a>.</li>
</ul>
<h4 id="runcursorcommand-1"><a class="header" href="#runcursorcommand-1">runCursorCommand</a></h4>
<p><a href="unified-test-format/../run-command/run-command.html">Generic cursor returning command runner</a>.</p>
<p>This method does not inherit a read preference (per the
<a href="unified-test-format/../server-selection/server-selection.html#use-of-read-preferences-with-commands">Server Selection</a> spec); however,
<code>readPreference</code> may be specified as an argument.</p>
<p>This operation proxies the database's <code>runCursorCommand</code> method and supports the same arguments and options (note:
handling for <code>getMore</code> options may vary by driver implementation).</p>
<p>When executing the provided command, the test runner MUST fully iterate the cursor. This will ensure consistent behavior
between drivers that eagerly create a server-side cursor and those that do so lazily when iteration begins.</p>
<p>The following arguments are supported:</p>
<ul>
<li><code>command</code>: Required document. The command to be executed.</li>
<li><code>commandName</code>: Required string. The name of the command to run. This is used by languages that are unable preserve the
order of keys in the <code>command</code> argument when parsing YAML/JSON.</li>
<li><code>readPreference</code>: Optional object. See <a href="unified-test-format/unified-test-format.html#commonOptions_readPreference">commonOptions_readPreference</a>.</li>
<li><code>session</code>: Optional string. See <a href="unified-test-format/unified-test-format.html#commonOptions_session">commonOptions_session</a>.</li>
<li><code>batchSize</code>: Optional positive integer value. Use this value to configure the <code>batchSize</code> option sent on subsequent
<code>getMore</code> commands.</li>
<li><code>maxTimeMS</code>: Optional non-negative integer value. Use this value to configure the <code>maxTimeMS</code> option sent on
subsequent <code>getMore</code> commands.</li>
<li><code>comment</code>: Optional BSON value. Use this value to configure the <code>comment</code> option sent on subsequent <code>getMore</code>
commands.</li>
<li><code>cursorType</code>: Optional string enum value, one of <code>'tailable' | 'tailableAwait' | 'nonTailable'</code>. Use this value to
configure the enum passed to the <code>cursorType</code> option.</li>
<li><code>timeoutMode</code>: Optional string enum value, one of <code>'iteration' | 'cursorLifetime'</code>. Use this value to configure the
enum passed to the <code>timeoutMode</code> option.</li>
</ul>
<h4 id="createcommandcursor"><a class="header" href="#createcommandcursor">createCommandCursor</a></h4>
<p>This operation proxies the database's <code>runCursorCommand</code> method and supports the same arguments and options (note:
handling for <code>getMore</code> options may vary by driver implementation). Test runners MUST ensure that the server-side cursor
is created (i.e. the command document has executed) as part of this operation and before the resulting cursor might be
saved with <a href="unified-test-format/unified-test-format.html#operation_saveResultAsEntity">operation.saveResultAsEntity</a>. Test runners for drivers that lazily execute
the command on the first iteration of the cursor MUST iterate the resulting cursor once. The result from this iteration
MUST be used as the result for the first iteration operation on the cursor.</p>
<p>Test runners MUST NOT iterate the resulting cursor when executing this operation and test files SHOULD NOT specify
<a href="unified-test-format/unified-test-format.html#operation_expectResult">operation.expectResult</a> for this operation.</p>
<h4 id="watch-1"><a class="header" href="#watch-1">watch</a></h4>
<p>This operation SHOULD NOT be used in test files. See <a href="unified-test-format/unified-test-format.html#database_createChangeStream">database_createChangeStream</a>.</p>
<h3 id="collection-operations"><a class="header" href="#collection-operations">Collection Operations</a></h3>
<p>These operations and their arguments may be documented in the following specifications:</p>
<ul>
<li><a href="unified-test-format/../change-streams/change-streams.html">Change Streams</a></li>
<li><a href="unified-test-format/../crud/crud.html">CRUD</a></li>
<li><a href="unified-test-format/../index-management/index-management.html">Index Management</a></li>
</ul>
<p>Collection operations that require special handling or are not documented by an existing specification are described
below.</p>
<p><span id="collection_aggregate"></span></p>
<h4 id="aggregate-1"><a class="header" href="#aggregate-1">aggregate</a></h4>
<p>When executing an <code>aggregate</code> operation, the test runner MUST fully iterate the result. This will ensure consistent
behavior between drivers that eagerly create a server-side cursor and those that do so lazily when iteration begins.</p>
<h4 id="bulkwrite"><a class="header" href="#bulkwrite">bulkWrite</a></h4>
<p>These considerations only apply to the <code>MongoCollection.bulkWrite</code> method. See <a href="unified-test-format/unified-test-format.html#clientbulkwrite">clientBulkWrite</a> for
special considerations for <code>MongoClient.bulkWrite</code>.</p>
<p>The <code>requests</code> parameter for <code>bulkWrite</code> is documented as a list of WriteModel interfaces. Each WriteModel
implementation (e.g. InsertOneModel) provides important context to the method, but that type information is not easily
expressed in YAML and JSON. To account for this, test files MUST nest each WriteModel object in a single-key object,
where the key identifies the request type (e.g. "insertOne") and its value is an object expressing the parameters, as in
the following example:</p>
<pre><code>arguments:
  requests:
    - insertOne:
        document: { _id: 1, x: 1 }
    - replaceOne:
        filter: { _id: 2 }
        replacement: { x: 2 }
        upsert: true
    - updateOne:
        filter: { _id: 3 }
        update: { $set: { x: 3 } }
        upsert: true
    - updateMany:
        filter: { }
        update: { $inc: { x: 1 } }
    - deleteOne:
        filter: { x: 2 }
    - deleteMany:
        filter: { x: { $gt: 2 } }
  ordered: true
</code></pre>
<p>Because the <code>insertedIds</code> field of BulkWriteResult is optional for drivers to implement, assertions for that field
SHOULD utilize the <a href="unified-test-format/unified-test-format.html#unsetormatches">$$unsetOrMatches</a> operator.</p>
<p>While operations typically raise an error <em>or</em> return a result, the <code>bulkWrite</code> operation is unique in that it may
report both via the <code>writeResult</code> property of a BulkWriteException. In this case, the intermediary write result may be
matched with <a href="unified-test-format/unified-test-format.html#expectedError_expectResult">expectedError_expectResult</a>. Because <code>writeResult</code> is optional for drivers to
implement, such assertions SHOULD utilize the <a href="unified-test-format/unified-test-format.html#unsetormatches">$$unsetOrMatches</a> operator.</p>
<p>Additionally, BulkWriteException is unique in that it aggregates one or more server errors in its <code>writeConcernError</code>
and <code>writeErrors</code> properties. When test runners evaluate <a href="unified-test-format/unified-test-format.html#expectederror">expectedError</a> assertions for <code>errorContains</code>
and <code>errorCodeName</code>, they MUST examine the aggregated errors and consider any match therein to satisfy the assertion(s).
Drivers that concatenate all write and write concern error messages into the BulkWriteException message MAY optimize the
check for <code>errorContains</code> by examining the concatenated message. Drivers that expose <code>code</code> but not <code>codeName</code> through
BulkWriteException MAY translate the expected code name to a number (see:
<a href="https://github.com/mongodb/mongo/blob/master/src/mongo/base/error_codes.yml">error_codes.yml</a>) and compare with <code>code</code>
instead, but MUST raise an error if the comparison cannot be attempted (e.g. <code>code</code> is also not available, translation
fails).</p>
<p><span id="collection_createChangeStream"></span></p>
<h4 id="createchangestream-2"><a class="header" href="#createchangestream-2">createChangeStream</a></h4>
<p>Creates a collection-level change stream and ensures that the server-side cursor has been created.</p>
<p>This operation proxies the collection's <code>watch</code> method and supports the same arguments and options. Test files SHOULD
NOT use the collection's <code>watch</code> operation directly for reasons discussed in <a href="unified-test-format/unified-test-format.html#entity_changestream">ChangeStream</a>. Test
runners MUST ensure that the server-side cursor is created (i.e. <code>aggregate</code> is executed) as part of this operation and
before the resulting change stream might be saved with <a href="unified-test-format/unified-test-format.html#operation_saveResultAsEntity">operation.saveResultAsEntity</a>.</p>
<p>Test runners MUST NOT iterate the change stream when executing this operation and test files SHOULD NOT specify
<a href="unified-test-format/unified-test-format.html#operation_expectResult">operation.expectResult</a> for this operation.</p>
<p><span id="collection_createFindCursor"></span></p>
<h4 id="createfindcursor"><a class="header" href="#createfindcursor">createFindCursor</a></h4>
<p>This operation proxies the collection's <code>find</code> method and supports the same arguments and options. Test runners MUST
ensure that the server-side cursor is created (i.e. a <code>find</code> command is executed) as part of this operation and before
the resulting cursor might be saved with <a href="unified-test-format/unified-test-format.html#operation_saveResultAsEntity">operation.saveResultAsEntity</a>. Test runners for
drivers that lazily execute the <code>find</code> command on the first iteration of the cursor MUST iterate the resulting cursor
once. The result from this iteration MUST be used as the result for the first iteration operation on the cursor.</p>
<p>Test runners MUST NOT iterate the resulting cursor when executing this operation and test files SHOULD NOT specify
<a href="unified-test-format/unified-test-format.html#operation_expectResult">operation.expectResult</a> for this operation.</p>
<h4 id="createsearchindex"><a class="header" href="#createsearchindex">createSearchIndex</a></h4>
<p>This operations proxies the collection's <code>createSearchIndex</code> helper with the same arguments.</p>
<p>Each <code>createSearchIndex</code> operation receives a
<a href="unified-test-format/../index-management/index-management.html#common-interfaces">SearchIndexModel</a>. If a driver has chosen to implement the
<code>createSearchIndex(name: String, definition: Document)</code> overload of <code>createSearchIndex</code>, then the <code>SearchIndexModel</code>
should be parsed by <code>createSearchIndex</code> unified test runner helper and the correct arguments should be passed into the
driver's helper.</p>
<h4 id="createsearchindexes"><a class="header" href="#createsearchindexes">createSearchIndexes</a></h4>
<p>This operations proxies the collection's <code>createSearchIndexes</code> helper with the same arguments.</p>
<h4 id="dropsearchindex"><a class="header" href="#dropsearchindex">dropSearchIndex</a></h4>
<p>This operation proxies the collection's <code>dropSearchIndex</code> helper with the same arguments.</p>
<h4 id="find-1"><a class="header" href="#find-1">find</a></h4>
<p>When executing a <code>find</code> operation, the test runner MUST fully iterate the result. This will ensure consistent behavior
between drivers that eagerly create a server-side cursor and those that do so lazily when iteration begins.</p>
<h4 id="findoneandreplace-and-findoneandupdate"><a class="header" href="#findoneandreplace-and-findoneandupdate">findOneAndReplace and findOneAndUpdate</a></h4>
<p>The <code>returnDocument</code> option for <code>findOneAndReplace</code> and <code>findOneAndUpdate</code> is documented as an enum with possible values
"Before" and "After". Test files SHOULD express <code>returnDocument</code> as a string and test runners MUST raise an error if its
value does not case-insensitively match either enum value.</p>
<h4 id="insertmany"><a class="header" href="#insertmany">insertMany</a></h4>
<p>The CRUD spec documents <code>insertMany</code> as returning a BulkWriteResult. Because the <code>insertedIds</code> field of BulkWriteResult
is optional for drivers to implement, assertions for that field SHOULD utilize the <a href="unified-test-format/unified-test-format.html#unsetormatches">$$unsetOrMatches</a>
operator.</p>
<h4 id="insertone"><a class="header" href="#insertone">insertOne</a></h4>
<p>The CRUD spec documents <code>insertOne</code> as returning an InsertOneResult; however, because all fields InsertOneResult are
optional drivers are permitted to forgo it entirely and have <code>insertOne</code> return nothing (i.e. void method). Tests
asserting InsertOneResult SHOULD utilize the <a href="unified-test-format/unified-test-format.html#unsetormatches">$$unsetOrMatches</a> operator for <em>both</em> the result object
and any optional fields within, as in the following examples:</p>
<pre><code>- name: insertOne
  object: *collection0
  arguments:
    document: { _id: 2 }
  expectResult:
    $$unsetOrMatches:
      insertedId: { $$unsetOrMatches: 2 }
</code></pre>
<h4 id="listsearchindexes"><a class="header" href="#listsearchindexes">listSearchIndexes</a></h4>
<p>This operation proxies the collection's <code>listSearchIndexes</code> helper and returns the result of the cursor as a list.</p>
<h4 id="updatesearchindex"><a class="header" href="#updatesearchindex">updateSearchIndex</a></h4>
<p>This operation proxies the collection's <code>updateSearchIndex</code> helper with the same arguments.</p>
<h4 id="watch-2"><a class="header" href="#watch-2">watch</a></h4>
<p>This operation SHOULD NOT be used in test files. See <a href="unified-test-format/unified-test-format.html#collection_createChangeStream">collection_createChangeStream</a>.</p>
<h3 id="session-operations"><a class="header" href="#session-operations">Session Operations</a></h3>
<p>These operations and their arguments may be documented in the following specifications:</p>
<ul>
<li><a href="unified-test-format/../transactions-convenient-api/transactions-convenient-api.html">Convenient API for Transactions</a></li>
<li><a href="unified-test-format/../sessions/driver-sessions.html">Driver Sessions</a></li>
</ul>
<p>Session operations that require special handling or are not documented by an existing specification are described below.</p>
<h4 id="withtransaction"><a class="header" href="#withtransaction">withTransaction</a></h4>
<p>The <code>withTransaction</code> operation's <code>callback</code> parameter is a function and not easily expressed in YAML/JSON. For ease of
testing, this parameter is expressed as an array of <a href="unified-test-format/unified-test-format.html#operation">operation</a> objects (analogous to
<a href="unified-test-format/unified-test-format.html#test_operations">test.operations</a>). Test runners MUST evaluate error and result assertions when executing these
operations in the callback.</p>
<p>Test runners MUST allow any errors from the callback operation(s) to propagate to <code>withTransaction</code>, irrespective of
<a href="unified-test-format/unified-test-format.html#operation_ignoreResultAndError">ignoreResultAndError</a> or <a href="unified-test-format/unified-test-format.html#operation_expectError">expectError</a>. For example, if a
callback operation raises an error, it should be possible to assert that error at both the callback operation and
<code>withTransaction</code> level.</p>
<h3 id="bucket-operations"><a class="header" href="#bucket-operations">Bucket Operations</a></h3>
<p>These operations and their arguments may be documented in the following specifications:</p>
<ul>
<li><a href="unified-test-format/../gridfs/gridfs-spec.html">GridFS</a></li>
</ul>
<p>Bucket operations that require special handling or are not documented by an existing specification are described below.</p>
<p><span id="download"></span> <span id="downloadByName"></span></p>
<h4 id="download-and-downloadbyname"><a class="header" href="#download-and-downloadbyname">download and downloadByName</a></h4>
<p>These operations proxy the bucket's <code>openDownloadStream</code> and <code>openDownloadStreamByName</code> methods and support the same
parameters and options, but return a string containing the stream's contents instead of the stream itself. Test runners
MUST fully read the stream to yield the returned string. This is also necessary to ensure that any expected errors are
raised (e.g. missing chunks). Test files SHOULD use <a href="unified-test-format/unified-test-format.html#matcheshexbytes">$$matchesHexBytes</a> in
<a href="unified-test-format/unified-test-format.html#operation_expectResult">expectResult</a> to assert the contents of the returned string.</p>
<h4 id="downloadtostream-and-downloadtostreambyname"><a class="header" href="#downloadtostream-and-downloadtostreambyname">downloadToStream and downloadToStreamByName</a></h4>
<p>These operations SHOULD NOT be used in test files. See
<a href="unified-test-format/unified-test-format.html#io-operations-for-gridfs-streams">IO operations for GridFS streams</a> in <a href="unified-test-format/unified-test-format.html#future-work">Future Work</a>.</p>
<h4 id="opendownloadstream-and-opendownloadstreambyname"><a class="header" href="#opendownloadstream-and-opendownloadstreambyname">openDownloadStream and openDownloadStreamByName</a></h4>
<p>These operations SHOULD NOT be used in test files. See <a href="unified-test-format/unified-test-format.html#download-and-downloadbyname">download and downloadByName</a>.</p>
<p><span id="openUploadStream"></span></p>
<h4 id="openuploadstream-and-openuploadstreamwithid"><a class="header" href="#openuploadstream-and-openuploadstreamwithid">openUploadStream and openUploadStreamWithId</a></h4>
<p>These operations SHOULD NOT be used in test files. See
<a href="unified-test-format/unified-test-format.html#io-operations-for-gridfs-streams">IO operations for GridFS streams</a> in <a href="unified-test-format/unified-test-format.html#future-work">Future Work</a>.</p>
<p><span id="upload-and-uploadWithId"></span></p>
<h4 id="upload-and-uploadwithid"><a class="header" href="#upload-and-uploadwithid">upload and uploadWithId</a></h4>
<p>These operations proxy the bucket's <code>uploadFromStream</code> and <code>uploadFromStreamWithId</code> methods and support the same
parameters and options with one exception: the <code>source</code> parameter is an object specifying hex bytes from which test
runners MUST construct a readable stream for the underlying methods. The structure of <code>source</code> is as follows:</p>
<pre><code>{ $$hexBytes: &lt;string&gt; }
</code></pre>
<p>The string MUST contain an even number of hexadecimal characters (case-insensitive) and MAY be empty. The test runner
MUST raise an error if the structure of <code>source</code> or its string is malformed. The test runner MUST convert the string to
a byte sequence denoting the stream's readable data (if any). For example, "12ab" would denote a stream with two bytes:
"0x12" and "0xab".</p>
<h4 id="uploadfromstream-and-uploadfromstreamwithid"><a class="header" href="#uploadfromstream-and-uploadfromstreamwithid">uploadFromStream and uploadFromStreamWithId</a></h4>
<p>These operations SHOULD NOT be used in test files. See <a href="unified-test-format/unified-test-format.html#upload-and-uploadwithid">upload and uploadWithId</a>.</p>
<h3 id="cursor-operations"><a class="header" href="#cursor-operations">Cursor Operations</a></h3>
<p>There are no defined APIs for change streams and cursors since the mechanisms for iteration may differ between
synchronous and asynchronous drivers. To account for this, this section explicitly defines the supported operations for
the <code>ChangeStream</code>, <code>FindCursor</code>, and <code>CommandCursor</code> entity types.</p>
<p>Test runners MUST ensure that the iteration operations defined in this section will not inadvertently skip the first
document for a cursor. Albeit rare, this could happen if an operation were to blindly invoke <code>next</code> (or equivalent) on a
cursor in a driver where newly created cursors are already positioned at their first element and the cursor had a
non-empty <code>firstBatch</code>. Alternatively, some drivers may use a different iterator method for advancing a cursor to its
first position (e.g. <code>rewind</code> in PHP).</p>
<h4 id="iterateuntildocumentorerror"><a class="header" href="#iterateuntildocumentorerror">iterateUntilDocumentOrError</a></h4>
<p>Iterates the cursor until either a single document is returned or an error is raised. This operation takes no arguments.
If <a href="unified-test-format/unified-test-format.html#operation_expectResult">expectResult</a> is specified, it SHOULD be a single document.</p>
<p>Some specification sections (e.g.
<a href="unified-test-format/../change-streams/tests/README.html#iterating-the-change-stream">Iterating the Change Stream</a>) caution drivers that
implement a blocking mode of iteration (e.g. asynchronous drivers) not to iterate the cursor unnecessarily, as doing so
could cause the test runner to block indefinitely. This should not be a concern for <code>iterateUntilDocumentOrError</code> as
iteration only continues until either a document or error is encountered.</p>
<h4 id="iterateonce"><a class="header" href="#iterateonce">iterateOnce</a></h4>
<p>Performs a single iteration of the cursor. If the cursor's current batch is empty, one <code>getMore</code> MUST be attempted to
get more results. This operation takes no arguments. If <a href="unified-test-format/unified-test-format.html#operation_expectResult">expectResult</a> is specified, it SHOULD
be a single document.</p>
<p>Due to the non-deterministic nature of some cursor types (e.g. change streams on sharded clusters), test files SHOULD
only use this operation to perform command monitoring assertions on the <code>getMore</code> command. Tests that perform assertions
about the result of iteration should use <a href="unified-test-format/unified-test-format.html#iterateuntildocumentorerror">iterateUntilDocumentOrError</a> instead.</p>
<h4 id="close-1"><a class="header" href="#close-1">close</a></h4>
<p>Closes the cursor. Because drivers do not consistently propagate errors from the <code>killCursors</code> command, test runners
MUST suppress all errors when closing the cursor. Test files SHOULD NOT specify <a href="unified-test-format/unified-test-format.html#operation_expectResult">expectResult</a>
or <a href="unified-test-format/unified-test-format.html#operation_expectError">expectError</a> for this operation. To assert whether the <code>killCursors</code> command succeeded or
failed, test files SHOULD use command monitoring assertions with
<a href="unified-test-format/unified-test-format.html#expectedEvent_commandSucceededEvent">commandSucceededEvent</a> and
<a href="unified-test-format/unified-test-format.html#expectedEvent_commandFailedEvent">commandFailedEvent</a> events.</p>
<h3 id="special-test-operations"><a class="header" href="#special-test-operations">Special Test Operations</a></h3>
<p>Certain operations do not correspond to API methods but instead represent special test operations (e.g. assertions).
These operations are distinguished by <a href="unified-test-format/unified-test-format.html#operation_object">operation.object</a> having a value of "testRunner". The
<a href="unified-test-format/unified-test-format.html#operation_name">operation.name</a> field will correspond to an operation defined below.</p>
<p>Special test operations return no result and are always expected to succeed. These operations SHOULD NOT be combined
with <a href="unified-test-format/unified-test-format.html#operation_expectError">expectError</a>, <a href="unified-test-format/unified-test-format.html#operation_expectResult">expectResult</a>, or
<a href="unified-test-format/unified-test-format.html#operation_saveResultAsEntity">saveResultAsEntity</a>.</p>
<h4 id="failpoint"><a class="header" href="#failpoint">failPoint</a></h4>
<p>The <code>failPoint</code> operation instructs the test runner to configure a fail point using a "primary" read preference using
the specified client entity (fail points are not configured using an internal MongoClient).</p>
<p>The following arguments are supported:</p>
<ul>
<li>
<p><code>failPoint</code>: Required document. The <code>configureFailPoint</code> command to be executed.</p>
</li>
<li>
<p><code>client</code>: Required string. See <a href="unified-test-format/unified-test-format.html#commonOptions_client">commonOptions_client</a>.</p>
<p>The client entity SHOULD specify false for <a href="unified-test-format/unified-test-format.html#entity_client_useMultipleMongoses">useMultipleMongoses</a> if this operation
could be executed on a sharded topology (according to <a href="unified-test-format/unified-test-format.html#runOnRequirements">runOnRequirements</a> or
<a href="unified-test-format/unified-test-format.html#test_runOnRequirements">test.runOnRequirements</a>). This is advised because server selection rules for mongos could
lead to unpredictable behavior if different servers were selected for configuring the fail point and executing
subsequent operations.</p>
</li>
</ul>
<p>When executing this operation, the test runner MUST keep a record of the fail point so that it can be disabled after the
test. The test runner MUST also ensure that the <code>configureFailPoint</code> command is excluded from the list of observed
command monitoring events for this client (if applicable).</p>
<p>An example of this operation follows:</p>
<pre><code># Enable the fail point on the server selected with a primary read preference
- name: failPoint
  object: testRunner
  arguments:
    client: *client0
    failPoint:
      configureFailPoint: failCommand
      mode: { times: 1 }
      data:
        failCommands: ["insert"]
        closeConnection: true
</code></pre>
<h4 id="targetedfailpoint"><a class="header" href="#targetedfailpoint">targetedFailPoint</a></h4>
<p>The <code>targetedFailPoint</code> operation instructs the test runner to configure a fail point on a specific mongos.</p>
<p>The following arguments are supported:</p>
<ul>
<li>
<p><code>failPoint</code>: Required document. The <code>configureFailPoint</code> command to be executed.</p>
</li>
<li>
<p><code>session</code>: Required string. See <a href="unified-test-format/unified-test-format.html#commonOptions_session">commonOptions_session</a>.</p>
<p>The client entity associated with this session SHOULD specify true for
<a href="unified-test-format/unified-test-format.html#entity_client_useMultipleMongoses">useMultipleMongoses</a>. This is advised because targeted fail points are intended
to test mongos pinning, which warrants multiple mongoses.</p>
</li>
</ul>
<p>The mongos on which to set the fail point is determined by the <code>session</code> argument (after resolution to a session
entity). Test runners MUST error if the session is not pinned to a mongos server at the time this operation is executed.</p>
<p>If the driver exposes an API to target a specific server for a command, the test runner SHOULD use the client entity
associated with the session to execute the <code>configureFailPoint</code> command. In this case, the test runner MUST also ensure
that this command is excluded from the list of observed command monitoring events for this client (if applicable). If
such an API is not available, but the test runner creates an internal MongoClient for each mongos, the test runner
SHOULD use the internal MongoClient corresponding to the session's pinned server for this operation. Otherwise, test
runners MUST create a new MongoClient that is directly connected to the session's pinned server for this operation. The
new MongoClient instance MUST be closed once the command has finished executing.</p>
<p>A test utilizing <code>targetedFailPoint</code> SHOULD NOT be permitted execute on a load balancer (according to
<a href="unified-test-format/unified-test-format.html#runOnRequirements">runOnRequirements</a> or <a href="unified-test-format/unified-test-format.html#test_runOnRequirements">test.runOnRequirements</a>). This is advised because
the <code>configureFailPoint</code> command does not use the session directly, which means there is no guarantee that the load
balancer will direct the command to the intended mongos.</p>
<p>When executing this operation, the test runner MUST keep a record of both the fail point and pinned mongos server so
that the fail point can be disabled on the same mongos server after the test.</p>
<p>An example of this operation follows:</p>
<pre><code># Enable the fail point on the mongos to which session0 is pinned
- name: targetedFailPoint
  object: testRunner
  arguments:
    session: *session0
    failPoint:
      configureFailPoint: failCommand
      mode: { times: 1 }
      data:
        failCommands: ["commitTransaction"]
        closeConnection: true
</code></pre>
<p>Since mongos pinning only applies when multiple mongoses are used, tests SHOULD NOT use <code>targetedFailPoint</code> unless the
session's MongoClient is configured with <code>useMultipleMongoses: true</code>.</p>
<h4 id="assertsessiontransactionstate"><a class="header" href="#assertsessiontransactionstate">assertSessionTransactionState</a></h4>
<p>The <code>assertSessionTransactionState</code> operation instructs the test runner to assert that the given session has a
particular transaction state.</p>
<p>The following arguments are supported:</p>
<ul>
<li><code>session</code>: Required string. See <a href="unified-test-format/unified-test-format.html#commonOptions_session">commonOptions_session</a>.</li>
<li><code>state</code>: Required string. Expected transaction state for the session. Possible values are as follows: <code>none</code>,
<code>starting</code>, <code>in_progress</code>, <code>committed</code>, and <code>aborted</code>.</li>
</ul>
<p>An example of this operation follows:</p>
<pre><code>- name: assertSessionTransactionState
  object: testRunner
  arguments:
    session: *session0
    state: in_progress
</code></pre>
<h4 id="assertsessionpinned"><a class="header" href="#assertsessionpinned">assertSessionPinned</a></h4>
<p>The <code>assertSessionPinned</code> operation instructs the test runner to assert that the given session is pinned to a mongos
server.</p>
<p>The following arguments are supported:</p>
<ul>
<li><code>session</code>: Required string. See <a href="unified-test-format/unified-test-format.html#commonOptions_session">commonOptions_session</a>.</li>
</ul>
<p>An example of this operation follows:</p>
<pre><code>- name: assertSessionPinned
  object: testRunner
  arguments:
    session: *session0
</code></pre>
<h4 id="assertsessionunpinned"><a class="header" href="#assertsessionunpinned">assertSessionUnpinned</a></h4>
<p>The <code>assertSessionUnpinned</code> operation instructs the test runner to assert that the given session is not pinned to a
mongos server.</p>
<p>The following arguments are supported:</p>
<ul>
<li><code>session</code>: Required string. See <a href="unified-test-format/unified-test-format.html#commonOptions_session">commonOptions_session</a>.</li>
</ul>
<p>An example of this operation follows:</p>
<pre><code>- name: assertSessionUnpinned
  object: testRunner
  arguments:
    session: *session0
</code></pre>
<h4 id="assertdifferentlsidonlasttwocommands"><a class="header" href="#assertdifferentlsidonlasttwocommands">assertDifferentLsidOnLastTwoCommands</a></h4>
<p>The <code>assertDifferentLsidOnLastTwoCommands</code> operation instructs the test runner to assert that the last two
CommandStartedEvents observed on the client have different <code>lsid</code> fields. This assertion is primarily used to test that
dirty server sessions are discarded from the pool.</p>
<p>The following arguments are supported:</p>
<ul>
<li>
<p><code>client</code>: Required string. See <a href="unified-test-format/unified-test-format.html#commonOptions_client">commonOptions_client</a>.</p>
<p>The client entity SHOULD include "commandStartedEvent" in <a href="unified-test-format/unified-test-format.html#entity_client_observeEvents">observeEvents</a>.</p>
</li>
</ul>
<p>The test runner MUST fail this assertion if fewer than two CommandStartedEvents have been observed on the client or if
either command does not include an <code>lsid</code> field.</p>
<p>An example of this operation follows:</p>
<pre><code>- name: assertDifferentLsidOnLastTwoCommands
  object: testRunner
  arguments:
    client: *client0
</code></pre>
<h4 id="assertsamelsidonlasttwocommands"><a class="header" href="#assertsamelsidonlasttwocommands">assertSameLsidOnLastTwoCommands</a></h4>
<p>The <code>assertSameLsidOnLastTwoCommands</code> operation instructs the test runner to assert that the last two
CommandStartedEvents observed on the client have identical <code>lsid</code> fields. This assertion is primarily used to test that
non-dirty server sessions are not discarded from the pool.</p>
<p>The following arguments are supported:</p>
<ul>
<li>
<p><code>client</code>: Required string. See <a href="unified-test-format/unified-test-format.html#commonOptions_client">commonOptions_client</a>.</p>
<p>The client entity SHOULD include "commandStartedEvent" in <a href="unified-test-format/unified-test-format.html#entity_client_observeEvents">observeEvents</a>.</p>
</li>
</ul>
<p>The test runner MUST fail this assertion if fewer than two CommandStartedEvents have been observed on the client or if
either command does not include an <code>lsid</code> field.</p>
<p>An example of this operation follows:</p>
<pre><code>- name: assertSameLsidOnLastTwoCommands
  object: testRunner
  arguments:
    client: *client0
</code></pre>
<h4 id="assertsessiondirty"><a class="header" href="#assertsessiondirty">assertSessionDirty</a></h4>
<p>The <code>assertSessionDirty</code> operation instructs the test runner to assert that the given session is marked dirty.</p>
<p>The following arguments are supported:</p>
<ul>
<li><code>session</code>: Required string. See <a href="unified-test-format/unified-test-format.html#commonOptions_session">commonOptions_session</a>.</li>
</ul>
<p>An example of this operation follows:</p>
<pre><code>- name: assertSessionDirty
  object: testRunner
  arguments:
    session: *session0
</code></pre>
<h4 id="assertsessionnotdirty"><a class="header" href="#assertsessionnotdirty">assertSessionNotDirty</a></h4>
<p>The <code>assertSessionNotDirty</code> operation instructs the test runner to assert that the given session is not marked dirty.</p>
<p>The following arguments are supported:</p>
<ul>
<li><code>session</code>: Required string. See <a href="unified-test-format/unified-test-format.html#commonOptions_session">commonOptions_session</a>.</li>
</ul>
<p>An example of this operation follows:</p>
<pre><code>- name: assertSessionNotDirty
  object: testRunner
  arguments:
    session: *session0
</code></pre>
<h4 id="assertcollectionexists"><a class="header" href="#assertcollectionexists">assertCollectionExists</a></h4>
<p>The <code>assertCollectionExists</code> operation instructs the test runner to assert that the given collection exists in the
database. The test runner MUST use an internal MongoClient for this operation.</p>
<p>The following arguments are supported:</p>
<ul>
<li><code>collectionName</code>: Required string. See <a href="unified-test-format/unified-test-format.html#commonOptions_collectionName">commonOptions_collectionName</a>.</li>
<li><code>databaseName</code>: Required string. See <a href="unified-test-format/unified-test-format.html#commonOptions_databaseName">commonOptions_databaseName</a>.</li>
</ul>
<p>An example of this operation follows:</p>
<pre><code>- name: assertCollectionExists
  object: testRunner
  arguments:
    collectionName: *collection0Name
    databaseName:  *database0Name
</code></pre>
<p>Use a <code>listCollections</code> command to check whether the collection exists. Note that it is currently not possible to run
<code>listCollections</code> from within a transaction.</p>
<h4 id="assertcollectionnotexists"><a class="header" href="#assertcollectionnotexists">assertCollectionNotExists</a></h4>
<p>The <code>assertCollectionNotExists</code> operation instructs the test runner to assert that the given collection does not exist
in the database. The test runner MUST use an internal MongoClient for this operation.</p>
<p>The following arguments are supported:</p>
<ul>
<li><code>collectionName</code>: Required string. See <a href="unified-test-format/unified-test-format.html#commonOptions_collectionName">commonOptions_collectionName</a>.</li>
<li><code>databaseName</code>: Required string. See <a href="unified-test-format/unified-test-format.html#commonOptions_databaseName">commonOptions_databaseName</a>.</li>
</ul>
<p>An example of this operation follows:</p>
<pre><code>- name: assertCollectionNotExists
  object: testRunner
  arguments:
    collectionName: *collection0Name
    databaseName:  *database0Name
</code></pre>
<p>Use a <code>listCollections</code> command to check whether the collection exists. Note that it is currently not possible to run
<code>listCollections</code> from within a transaction.</p>
<h4 id="assertindexexists"><a class="header" href="#assertindexexists">assertIndexExists</a></h4>
<p>The <code>assertIndexExists</code> operation instructs the test runner to assert that an index with the given name exists on the
collection. The test runner MUST use an internal MongoClient for this operation.</p>
<p>The following arguments are supported:</p>
<ul>
<li><code>collectionName</code>: Required string. See <a href="unified-test-format/unified-test-format.html#commonOptions_collectionName">commonOptions_collectionName</a>.</li>
<li><code>databaseName</code>: Required string. See <a href="unified-test-format/unified-test-format.html#commonOptions_databaseName">commonOptions_databaseName</a>.</li>
<li><code>indexName</code>: Required string. Index name.</li>
</ul>
<p>An example of this operation follows:</p>
<pre><code>- name: assertIndexExists
  object: testRunner
  arguments:
    collectionName: *collection0Name
    databaseName:  *database0Name
    indexName: t_1
</code></pre>
<p>Use a <code>listIndexes</code> command to check whether the index exists. Note that it is currently not possible to run
<code>listIndexes</code> from within a transaction.</p>
<h4 id="assertindexnotexists"><a class="header" href="#assertindexnotexists">assertIndexNotExists</a></h4>
<p>The <code>assertIndexNotExists</code> operation instructs the test runner to assert that an index with the given name does not
exist on the collection. The test runner MUST use an internal MongoClient for this operation.</p>
<p>The following arguments are supported:</p>
<ul>
<li><code>collectionName</code>: Required string. See <a href="unified-test-format/unified-test-format.html#commonOptions_collectionName">commonOptions_collectionName</a>.</li>
<li><code>databaseName</code>: Required string. See <a href="unified-test-format/unified-test-format.html#commonOptions_databaseName">commonOptions_databaseName</a>.</li>
<li><code>indexName</code>: Required string. Index name.</li>
</ul>
<p>An example of this operation follows:</p>
<pre><code>- name: assertIndexNotExists
  object: testRunner
  arguments:
    collectionName: *collection0Name
    databaseName:  *database0Name
    indexName: t_1
</code></pre>
<p>Use a <code>listIndexes</code> command to check whether the index exists. Note that it is currently not possible to run
<code>listIndexes</code> from within a transaction.</p>
<p><span id="operation_createEntities"></span></p>
<h4 id="createentities"><a class="header" href="#createentities">createEntities</a></h4>
<p>The <code>createEntities</code> operation instructs the test runner to create the provided entities and store them in the current
test's <a href="unified-test-format/unified-test-format.html#entity-map">Entity Map</a>.</p>
<ul>
<li><code>entities</code>: Required array of one or more <a href="unified-test-format/unified-test-format.html#entity">entity</a> objects. As with the file-level
<a href="unified-test-format/unified-test-format.html#createentities">createEntities</a> directive, test files SHOULD declare entities in dependency order, such that all
referenced entities are defined before any of their dependent entities.</li>
</ul>
<p>An example of this operation follows:</p>
<pre><code>- name: createEntities
  object: testRunner
  arguments:
    entities:
      - client:
          id: &amp;client0 client0
      - database:
          id: &amp;database0 database0
          client: *client0
          databaseName: &amp;database0Name test
</code></pre>
<h4 id="loop"><a class="header" href="#loop">loop</a></h4>
<p>The <code>loop</code> operation executes sub-operations in a loop.</p>
<p>The following arguments are supported:</p>
<ul>
<li>
<p><code>operations</code>: Required array of <a href="unified-test-format/unified-test-format.html#operation">operation</a> objects. List of operations (henceforth referred to as
sub-operations) to run on each loop iteration. Each sub-operation must be a valid operation as described in
<a href="unified-test-format/unified-test-format.html#entity-test-operations">Entity Test Operations</a>.</p>
<p>Sub-operations SHOULD NOT include the <code>loop</code> operation.</p>
<p>If, in the course of executing sub-operations, a sub-operation yields an error or failure, the test runner MUST NOT
execute subsequent sub-operations in the same loop iteration. If <code>storeErrorsAsEntity</code> and/or <code>storeFailuresAsEntity</code>
options are specified, the loop MUST store the error/failure accordingly and continue to the next iteration (i.e. the
error/failure will not interrupt the test). If neither <code>storeErrorsAsEntity</code> nor <code>storeFailuresAsEntity</code> are
specified, the loop MUST terminate and raise the error/failure (i.e. the error/failure will interrupt the test).</p>
</li>
<li>
<p><code>storeErrorsAsEntity</code>: Optional string. If specified, the runner MUST capture errors arising during sub-operation
execution and append a document with error information to the array stored in the specified entity.</p>
<p>If this option is specified, the test runner MUST check the existence and the type of the entity with the specified
name before executing the loop. If the entity does not exist, the test runner MUST create it with the type of BSON
array. If the entity exists and is of type BSON array, the test runner MUST do nothing. If the entity exists and is of
a different type, the test runner MUST raise an error.</p>
<p>If this option is specified and <code>storeFailuresAsEntity</code> is not, failures MUST also be captured and appended to the
array.</p>
<p>Documents appended to the array MUST contain the following fields:</p>
<ul>
<li><code>error</code>: the textual description of the error encountered.</li>
<li><code>time</code>: the number of (floating-point) seconds since the Unix epoch when the error was encountered.</li>
</ul>
</li>
<li>
<p><code>storeFailuresAsEntity</code>: Optional string. If specified, the runner MUST capture failures arising during sub-operation
execution and append a document with failure information to the array stored in the specified entity.</p>
<p>If this option is specified, the test runner MUST check the existence and the type of the entity with the specified
name before executing the loop. If the entity does not exist, the test runner MUST create it with the type of BSON
array. If the entity exists and is of type BSON array, the test runner MUST do nothing. If the entity exists and is of
a different type, the test runner MUST raise an error.</p>
<p>If this option is specified and <code>storeErrorsAsEntity</code> is not, errors MUST also be captured and appended to the array.</p>
<p>Documents appended to the array MUST contain the following fields:</p>
<ul>
<li><code>error</code>: the textual description of the failure encountered.</li>
<li><code>time</code>: the number of (floating-point) seconds since the Unix epoch when the failure was encountered.</li>
</ul>
</li>
<li>
<p><code>storeSuccessesAsEntity</code>: Optional string. If specified, the runner MUST keep track of the number of sub-operations
that completed successfully, and store that number in the specified entity. For example, if the loop contains two
sub-operations, and they complete successfully, each loop execution would increment the number of successes by two.</p>
<p>If the entity of the specified name already exists, the test runner MUST raise an error.</p>
</li>
<li>
<p><code>storeIterationsAsEntity</code>: Optional string. If specified, the runner MUST keep track of the number of iterations of
the loop performed, and store that number in the specified entity. The number of loop iterations is counted
irrespective of whether sub-operations within the iteration succeed or fail.</p>
<p>If the entity of the specified name already exists, the test runner MUST raise an error.</p>
</li>
</ul>
<p>A <em>failure</em> is when the result or outcome of an operation executed by the test runner differs from its expected outcome.
For example, an <code>expectResult</code> assertion failing to match a BSON document or an <code>expectError</code> assertion failing to match
an error message would be considered a failure. An <em>error</em> is any other type of error raised by the test runner. For
example, an unsupported operation or inability to resolve an entity name would be considered an error.</p>
<p>This specification permits the test runner to report some failures as errors and some errors as failures. When the test
runner stores errors and failures as entities it MAY classify conditions as errors and failures in the same way as it
would when used in the driver's test suite. This includes reporting all errors as failures or all failures as errors.</p>
<p>If the test runner does not distinguish errors and failures in its reporting, it MAY report both conditions under either
category, but it MUST report any given condition in at most one category.</p>
<p>The following termination behavior MUST be implemented by the test runner:</p>
<ul>
<li>The test runner MUST provide a way to request termination of loops. This request will be made by the
<a href="https://mongodb-labs.github.io/drivers-atlas-testing/spec-workload-executor.html">Atlas testing workload executor</a> in
response to receiving the termination signal from Astrolabe.</li>
<li>When the termination request is received, the test runner MUST stop looping. If the test runner is looping when the
termination request is received, the current loop iteration MUST complete to its natural conclusion (success or
failure). If the test runner is not looping when the termination request is received, it MUST NOT start any new loop
iterations in either the current test or subsequent tests for the lifetime of the test runner.</li>
<li>The termination request MUST NOT affect non-loop operations, including any operations after the loop. The tests SHOULD
NOT be written in such a way that the success or failure of operations that follow loops depends on how many loop
iterations were performed.</li>
<li>Receiving the termination request MUST NOT by itself be considered an error or a failure by the test runner.</li>
</ul>
<p>The exact mechanism by which the workload executor requests termination of the loop in the test runner, including the
respective API, is left to the driver.</p>
<p>Tests SHOULD NOT include multiple loop operations (nested or sequential).</p>
<p>An example of this operation follows:</p>
<pre><code>- name: loop
  object: testRunner
  arguments:
    storeErrorsAsEntity: errors
    storeFailuresAsEntity: failures
    storeSuccessesAsEntity: successes
    storeIterationsAsEntity: iterations
    operations:
      - name: find
        object: *collection0
        arguments:
          filter: { _id: { $gt: 1 }}
          sort: { _id: 1 }
        expectResult:
          - _id: 2, x: 22
          - _id: 3, x: 33
</code></pre>
<h4 id="assertnumberconnectionscheckedout"><a class="header" href="#assertnumberconnectionscheckedout">assertNumberConnectionsCheckedOut</a></h4>
<p>The <code>assertNumberConnectionsCheckedOut</code> operation instructs the test runner to assert that the given number of
connections are currently checked out for the specified client entity. This operation only applies to drivers that
implement connection pooling and should be skipped for drivers that do not.</p>
<p>The following arguments are supported:</p>
<ul>
<li><code>client</code>: Required string. See <a href="unified-test-format/unified-test-format.html#commonOptions_client">commonOptions_client</a>.</li>
<li><code>connections</code>: Required integer. The number of connections expected to be checked out.</li>
</ul>
<p>An example of this operation follows:</p>
<pre><code>- name: assertNumberConnectionsCheckedOut
  object: testRunner
  arguments:
    client: *client0
    connections: 1
</code></pre>
<h4 id="runonthread"><a class="header" href="#runonthread">runOnThread</a></h4>
<p>The <code>runOnThread</code> operation instructs the test runner to schedule an operation to be run on a given thread. The given
thread MUST begin executing the operation immediately. <code>runOnThread</code> MUST NOT wait for the operation to complete. If any
of the operation's test assertions fail, the entire test case MUST fail as well.</p>
<p>When writing test cases that use <code>runOnThread</code>, it's important to note that certain entities are not concurrency-safe
(e.g. sessions, cursors) and therefore SHOULD NOT be used in operations on multiple different threads entities.</p>
<p>The following arguments are supported:</p>
<ul>
<li><code>thread</code>: Required string. Thread entity on which this operation should be scheduled.</li>
<li><code>operation</code>: Required <a href="unified-test-format/unified-test-format.html#operation">operation</a> object. The operation to schedule on the thread. This object must be a
valid operation as described in <a href="unified-test-format/unified-test-format.html#entity-test-operations">Entity Test Operations</a>.</li>
</ul>
<p>An example of this operation follows:</p>
<pre><code>- name: runOnThread
  object: testRunner
  arguments:
    thread: *thread0
    operation:
      name: insertOne
      object: *collection0
      arguments:
        document: { _id: 2 }
      expectResult:
        $$unsetOrMatches:
          insertedId: { $$unsetOrMatches: 2 }
</code></pre>
<h4 id="waitforthread"><a class="header" href="#waitforthread">waitForThread</a></h4>
<p>The <code>waitForThread</code> operation instructs the test runner to notify the given thread that no more operations are
forthcoming, wait for it to complete its last operation, and assert that it exited without any errors.</p>
<p>If the <code>waitForThread</code> operation is not satisfied after 10 seconds, this operation MUST cause a test failure.</p>
<p>The <code>test.operations</code> list SHOULD contain a <code>waitForThread</code> operation for each thread entity that the test creates.</p>
<p>The following arguments are supported:</p>
<ul>
<li><code>thread</code>: Required string. Thread entity that should be stopped and awaited for completion.</li>
</ul>
<p>An example of this operation follows:</p>
<pre><code>- name: waitForThread
  object: testRunner
  arguments:
    thread: *thread0
</code></pre>
<h4 id="waitforevent"><a class="header" href="#waitforevent">waitForEvent</a></h4>
<p>The <code>waitForEvent</code> operation instructs the test runner to wait until the specified MongoClient has published a specific,
matching event a given number of times. Note that this includes any events published before the <code>waitForEvent</code> operation
started.</p>
<p>If the <code>waitForEvent</code> operation is not satisfied after 10 seconds, this operation MUST cause a test failure.</p>
<p>The following arguments are supported:</p>
<ul>
<li><code>client</code>: Required string. Client entity whose events the runner will be waiting for.</li>
<li><code>event</code>: Required <a href="unified-test-format/unified-test-format.html#expectedevent">expectedEvent</a> object. The event which the test runner is waiting to be observed on
the provided client. The assertions laid out in <a href="unified-test-format/unified-test-format.html#expectedevent">expectedEvent</a> MUST be used to determine if an
observed event matches <code>event</code>. <code>event</code> SHOULD have an event type that was included in the <code>client</code>'s <code>observeEvents</code>
field.</li>
<li><code>count</code>: Required integer. The number of matching events to wait for before resuming execution of subsequent
operations.</li>
</ul>
<p>For example, the following instructs the test runner to wait for at least one poolClearedEvent to be published:</p>
<pre><code>- name: waitForEvent
  object: testRunner
  arguments:
    client: *client0
    event:
      poolClearedEvent: {}
    count: 1
</code></pre>
<h4 id="asserteventcount"><a class="header" href="#asserteventcount">assertEventCount</a></h4>
<p>The <code>assertEventCount</code> operation instructs the test runner to assert the specified MongoClient has published a specific,
matching event a given number of times so far in the test.</p>
<p>The following arguments are supported:</p>
<ul>
<li><code>client</code>: Required string. Client entity whose events the runner will be counting.</li>
<li><code>event</code>: Required <a href="unified-test-format/unified-test-format.html#expectedevent">expectedEvent</a> object. The event which the test runner will be counting on the
provided client. The assertions laid out in <a href="unified-test-format/unified-test-format.html#expectedevent">expectedEvent</a> MUST be used to determine if an observed
event matches <code>event</code>. <code>event</code> SHOULD have an event type that was included in the <code>client</code>'s <code>observeEvents</code> field.</li>
<li><code>count</code>: Required integer. The exact number of matching events that <code>client</code> should have seen so far.</li>
</ul>
<p>For example, the following instructs the test runner to assert that a single PoolClearedEvent was published:</p>
<pre><code>- name: assertEventCount
  object: testRunner
  arguments:
    client: *client0
    event:
      poolClearedEvent: {}
    count: 1
</code></pre>
<h4 id="recordtopologydescription"><a class="header" href="#recordtopologydescription">recordTopologyDescription</a></h4>
<p>The <code>recordTopologyDescription</code> operation instructs the test runner to retrieve the specified MongoClient's current
<a href="unified-test-format/unified-test-format.html#entity_topologydescription">TopologyDescription</a> and store it in the <a href="unified-test-format/unified-test-format.html#entity-map">Entity Map</a>.</p>
<p>The following arguments are supported:</p>
<ul>
<li><code>client</code>: Required string. Client entity whose TopologyDescription will be recorded.</li>
<li><code>id</code>: Required string. The name with which the TopologyDescription will be stored in the <a href="unified-test-format/unified-test-format.html#entity-map">Entity Map</a>.</li>
</ul>
<p>For example:</p>
<pre><code>- name: recordTopologyDescription
  object: testRunner
  arguments:
    client: *client0
    id: &amp;postInsertTopology postInsertTopology
</code></pre>
<h4 id="asserttopologytype"><a class="header" href="#asserttopologytype">assertTopologyType</a></h4>
<p>The <code>assertTopologyType</code> operation instructs the test runner to assert that the given
<a href="unified-test-format/unified-test-format.html#entity_topologydescription">TopologyDescription</a> has a particular TopologyType.</p>
<p>The following arguments are supported:</p>
<ul>
<li><code>topologyDescription</code>: Required string. TopologyDescription entity whose TopologyType will be inspected.</li>
<li><code>topologyType</code>: Required string. Expected TopologyType for the TopologyDescription. See
<a href="unified-test-format/../server-discovery-and-monitoring/server-discovery-and-monitoring.html#topologytype">SDAM: TopologyType</a> for a list of
possible values.</li>
</ul>
<p>For example:</p>
<pre><code>- name: assertTopologyType
  object: testRunner
  arguments:
    topologyDescription: *postInsertTopology
    topologyType: ReplicaSetWithPrimary
</code></pre>
<h4 id="waitforprimarychange"><a class="header" href="#waitforprimarychange">waitForPrimaryChange</a></h4>
<p>The <code>waitForPrimaryChange</code> operation instructs the test runner to wait until the provided MongoClient discovers a
different primary from the one in the provided <a href="unified-test-format/unified-test-format.html#entity_topologydescription">TopologyDescription</a>. If the provided
TopologyDescription does not include a primary, then this operation will wait until the client discovers any primary.</p>
<p>The following arguments are supported:</p>
<ul>
<li>
<p><code>client</code>: Required string. See <a href="unified-test-format/unified-test-format.html#commonOptions_client">commonOptions_client</a>.</p>
<p>The client entity MUST be the same one from which <code>topologyDescription</code> was derived. Test runners do not need to
verify this.</p>
</li>
<li>
<p><code>priorTopologyDescription</code>: Required string. The name of a <a href="unified-test-format/unified-test-format.html#entity_topologydescription">TopologyDescription</a> entity
which will be used to determine if the primary has changed or not.</p>
</li>
<li>
<p><code>timeoutMS</code>: Optional integer. The number of milliseconds to wait for the primary change before timing out and failing
the test. If unspecified, a default timeout of 10 seconds MUST be used.</p>
</li>
</ul>
<p>For example:</p>
<pre><code>- name: waitForPrimaryChange
  object: testRunner
  arguments:
    client: *client0
    priorTopologyDescription: *postInsertTopology
    timeoutMS: 1000
</code></pre>
<h4 id="wait"><a class="header" href="#wait">wait</a></h4>
<p>The <code>wait</code> operation instructs the test runner to sleep for a provided number of milliseconds.</p>
<p>The following arguments are supported:</p>
<ul>
<li><code>ms</code>: Required integer. The number of milliseconds for which the current test runner thread should sleep.</li>
</ul>
<p>For example:</p>
<pre><code>- name: wait
  object: testRunner
  arguments:
    ms: 1000
</code></pre>
<h3 id="special-placeholder-value"><a class="header" href="#special-placeholder-value">Special Placeholder Value</a></h3>
<h4 id="placeholder"><a class="header" href="#placeholder">$$placeholder</a></h4>
<p>Syntax:</p>
<pre><code>{ field: { $$placeholder: 1 } }
</code></pre>
<p>This special key-value pair can be used anywhere the value for a key might be specified in an test file. It is intended
to act as a placeholder value in contexts where the test runner cannot provide a definite value or may be expected to
replace the placeholder with a value that cannot be specified by the test file (e.g. KMS provider credentials). The test
runner MUST raise an error if a placeholder value is used in an unexpected context or a replacement cannot be made.</p>
<p>An example of using this placeholder value follows:</p>
<pre><code>kmsProviders:
  aws:
    accessKeyId: { $$placeholder: 1 }
    privateAccessKey: { $$placeholder: 1 }
</code></pre>
<p>Note: the test runner is not required to validate the type or value of a <code>$$placeholder</code> field.</p>
<h3 id="evaluating-matches"><a class="header" href="#evaluating-matches">Evaluating Matches</a></h3>
<p>Expected values in tests (e.g. <a href="unified-test-format/unified-test-format.html#operation_expectResult">operation.expectResult</a>) are expressed as either relaxed or
canonical <a href="unified-test-format/../extended-json/extended-json.html">Extended JSON</a>.</p>
<p>The algorithm for matching expected and actual values is specified with the following pseudo-code:</p>
<pre><code>function match (expected, actual):
  if expected is a document:
    // handle special operators (e.g. $$type)
    if first and only key of expected starts with "$$":
      execute any assertion(s) for the special operator
      return

    assert that actual is a document

    for every key/value in expected:
      // handle key-based operators (e.g. $$exists, $$unsetOrMatches)
      if value is a document and its first and only key starts with "$$":
        execute any assertion(s) for the special operator
        continue to the next iteration unless actual value must be matched

      assert that actual[key] exists
      assert that actual[key] matches value

    if expected is not the root document:
      assert that actual does not contain additional keys

    return

  if expected is an array:
    assert that actual is an array
    assert that actual and expected have the same number of elements

    for every index/value in expected:
      assert that actual[index] matches value

    return

  // expected is neither a document nor array
  assert that actual and expected are the same type, noting flexible numerics
  assert that actual and expected are equal
</code></pre>
<p>The rules for comparing documents and arrays are discussed in more detail in subsequent sections. When comparing types
<em>other</em> than documents and arrays, test runners MAY adopt any of the following approaches to compare expected and actual
values, as long as they are consistent:</p>
<ul>
<li>Convert both values to relaxed or canonical <a href="unified-test-format/../extended-json/extended-json.html">Extended JSON</a> and compare strings</li>
<li>Convert both values to BSON, and compare bytes</li>
<li>Convert both values to native representations, and compare accordingly</li>
</ul>
<p>When comparing types that contain documents as internal properties (e.g. CodeWScope), the rules in
<a href="unified-test-format/unified-test-format.html#evaluating-matches">Evaluating Matches</a> do not apply and the documents MUST match exactly; however, test runners MUST
permit variation in document key order or otherwise normalize the documents before comparison.</p>
<h4 id="flexible-numeric-comparisons"><a class="header" href="#flexible-numeric-comparisons">Flexible Numeric Comparisons</a></h4>
<p>When comparing numeric types (excluding Decimal128), test runners MUST consider 32-bit, 64-bit, and floating point
numbers to be equal if their values are numerically equivalent. For example, an expected value of <code>1</code> would match an
actual value of <code>1.0</code> (e.g. <code>ok</code> field in a server response) but would not match <code>1.5</code>.</p>
<h4 id="allowing-extra-fields-in-root-level-documents"><a class="header" href="#allowing-extra-fields-in-root-level-documents">Allowing Extra Fields in Root-level Documents</a></h4>
<p>When matching root-level documents, test runners MUST permit the actual document to contain additional fields not
present in the expected document. Examples of root-level documents include, but are not limited to:</p>
<ul>
<li><code>command</code> for <a href="unified-test-format/unified-test-format.html#expectedEvent_commandStartedEvent">CommandStartedEvent</a></li>
<li><code>reply</code> for <a href="unified-test-format/unified-test-format.html#expectedEvent_commandSucceededEvent">CommandSucceededEvent</a></li>
<li><a href="unified-test-format/unified-test-format.html#operation_expectResult">expectResult</a> for <code>findOneAndUpdate</code> <a href="unified-test-format/unified-test-format.html#collection-operations">Collection Operations</a></li>
<li><a href="unified-test-format/unified-test-format.html#operation_expectResult">expectResult</a> for <a href="unified-test-format/unified-test-format.html#iterateuntildocumentorerror">iterateUntilDocumentOrError</a></li>
<li><a href="unified-test-format/unified-test-format.html#expectedError_errorResponse">expectedError_errorResponse</a></li>
<li>each array element in <a href="unified-test-format/unified-test-format.html#operation_expectResult">expectResult</a> for <a href="unified-test-format/unified-test-format.html#find">find</a> or
<a href="unified-test-format/unified-test-format.html#collection_aggregate">collection_aggregate</a> <a href="unified-test-format/unified-test-format.html#collection-operations">Collection Operations</a></li>
</ul>
<p>For example, the following documents match:</p>
<pre><code>expected: { x: 1 }
actual: { x: 1, y: 1 }
</code></pre>
<p>The inverse is not true. For example, the following documents do not match:</p>
<pre><code>expected: { x: 1, y: 1 }
actual: { x: 1 }
</code></pre>
<p>Test runners MUST NOT permit additional fields in nested documents. For example, the following documents do not match:</p>
<pre><code>expected: { x: { y: 1 } }
actual: { x: { y: 1, z: 1 } }
</code></pre>
<p>It may be helpful to think of expected documents as a form of query criteria. The intention behind this rule is that it
is not always feasible or relevant for a test to exhaustively specify all fields in an expected document (e.g. cluster
time in <code>command</code> for <a href="unified-test-format/unified-test-format.html#expectedEvent_commandStartedEvent">CommandStartedEvent</a>).</p>
<p>When the expected value is an array, test runners MUST differentiate between an array of values, which may be documents,
(e.g. <code>distinct</code>) and an array of root-level documents (e.g. <code>find</code>, <code>aggregate</code>). For example, the following array of
documents would not match if returned by <code>distinct</code>, but would match if returned via <code>find</code> (after iterating the
cursor):</p>
<pre><code>expected: [ { x: 1 }, { x: 2 } ]
actual: [ { x: 1, y: 1 }, { x: 2, y: 2 } ]
</code></pre>
<h4 id="document-key-order-variation"><a class="header" href="#document-key-order-variation">Document Key Order Variation</a></h4>
<p>When matching documents, test runners MUST NOT require keys in the expected and actual document to appear in the same
order. For example, the following documents would match:</p>
<pre><code>expected: { x: 1, y: 1 }
actual: { y: 1, x: 1 }
</code></pre>
<h4 id="arrays-must-contain-the-same-number-of-elements"><a class="header" href="#arrays-must-contain-the-same-number-of-elements">Arrays Must Contain the Same Number of Elements</a></h4>
<p>When comparing arrays, expected and actual values MUST contain the same number of elements. For example, the following
arrays corresponding to a <code>distinct</code> operation result would not match:</p>
<pre><code>expected: [ 1, 2, 3 ]
actual: [ 1, 2, 3, 4 ]
</code></pre>
<h4 id="special-operators-for-matching-assertions"><a class="header" href="#special-operators-for-matching-assertions">Special Operators for Matching Assertions</a></h4>
<p>When matching expected and actual values, an equality comparison is not always sufficient. For instance, a test file
cannot anticipate what a session ID will be at runtime, but may still want to analyze the contents of an <code>lsid</code> field in
a command document. To address this need, special operators can be used.</p>
<p>These operators are objects with a single key identifying the operator. Such keys are prefixed with <code>$$</code> to ease in
detecting an operator (test runners need only inspect the first key of each object) and differentiate the object from
MongoDB query operators, which use a single <code>$</code> prefix. The key will map to some value that influences the operator's
behavior (if applicable).</p>
<p>When examining the structure of an expected value during a comparison, test runners MUST check if the value is an object
whose first and only key starts with <code>$$</code> and, if so, defer to the special logic defined in this section.</p>
<h5 id="exists"><a class="header" href="#exists">$$exists</a></h5>
<p>Syntax:</p>
<pre><code>{ field: { $$exists: &lt;boolean&gt; } }
</code></pre>
<p>This operator can be used anywhere the value for a key might be specified in an expected document. If true, the test
runner MUST assert that the key exists in the actual document, irrespective of its value (e.g. a key with a <code>null</code> value
would match). If false, the test runner MUST assert that the key does not exist in the actual document. This operator is
modeled after the <a href="https://www.mongodb.com/docs/manual/reference/operator/query/exists/">$exists</a> query operator.</p>
<p>An example of this operator checking for a field's presence follows:</p>
<pre><code>command:
  getMore: { $$exists: true }
  collection: *collectionName,
  batchSize: 5
</code></pre>
<p>An example of this operator checking for a field's absence follows:</p>
<pre><code>command:
  update: *collectionName
  updates: [ { q: {}, u: { $set: { x: 1 } } } ]
  ordered: true
  writeConcern: { $$exists: false }
</code></pre>
<h5 id="type-1"><a class="header" href="#type-1">$$type</a></h5>
<p>Syntax:</p>
<pre><code>{ $$type: &lt;string&gt; }
{ $$type: [ &lt;string&gt;, &lt;string&gt;, ... ] }
</code></pre>
<p>This operator can be used anywhere a matched value is expected (including <a href="unified-test-format/unified-test-format.html#operation_expectResult">expectResult</a>). The
test runner MUST assert that the actual value exists and matches one of the expected types, which correspond to the
documented string types for the <a href="https://www.mongodb.com/docs/manual/reference/operator/query/type/">$type</a> query
operator.</p>
<p>An example of this operator follows:</p>
<pre><code>command:
  getMore: { $$type: [ "int", "long" ] }
  collection: { $$type: "string" }
</code></pre>
<p>When the actual value is an array, test runners MUST NOT examine types of the array's elements. Only the type of actual
field SHALL be checked. This is admittedly inconsistent with the behavior of the
<a href="https://www.mongodb.com/docs/manual/reference/operator/query/type/">$type</a> query operator, but there is presently no
need for this behavior in tests.</p>
<h5 id="matchesentity"><a class="header" href="#matchesentity">$$matchesEntity</a></h5>
<p>Syntax, where <code>entityName</code> is a string:</p>
<pre><code>{ $$matchesEntity: &lt;entityName&gt; }
</code></pre>
<p>This operator can be used to reference a BSON entity anywhere a matched value is expected (including
<a href="unified-test-format/unified-test-format.html#operation_expectResult">expectResult</a>). If the BSON entity is defined in the current test's <a href="unified-test-format/unified-test-format.html#entity-map">Entity Map</a>,
the test runner MUST fetch that entity and assert that the actual value matches the entity using the standard rules in
<a href="unified-test-format/unified-test-format.html#evaluating-matches">Evaluating Matches</a>; otherwise, the test runner MUST raise an error for an undefined or mistyped
entity. The YAML file SHOULD use an <a href="https://yaml.org/spec/1.2/spec.html#id2786196">alias node</a> for the entity name.</p>
<p>This operator is primarily used to assert identifiers for uploaded GridFS files.</p>
<p>An example of this operator follows:</p>
<pre><code>operations:
  -
    object: *bucket0
    name: upload
    arguments:
      filename: "filename"
      source: { $$hexBytes: "12AB" }
    expectResult: { $$type: "objectId" }
    saveResultAsEntity: &amp;objectid0 "objectid0"
  - object: *filesCollection
    name: find
    arguments:
      sort: { uploadDate: -1 }
      limit: 1
    expectResult:
      - _id: { $$matchesEntity: *objectid0 }
</code></pre>
<h5 id="matcheshexbytes"><a class="header" href="#matcheshexbytes">$$matchesHexBytes</a></h5>
<p>Syntax, where <code>hexBytes</code> is an even number of hexadecimal characters (case-insensitive) and MAY be empty:</p>
<pre><code>{ $$matchesHexBytes: &lt;hexBytes&gt; }
</code></pre>
<p>This operator can be used anywhere a matched value is expected (including <a href="unified-test-format/unified-test-format.html#operation_expectResult">expectResult</a>) and
the actual value is a string. The test runner MUST raise an error if the <code>hexBytes</code> string is malformed. This operator
is primarily used to assert the results of <a href="unified-test-format/unified-test-format.html#download">download</a> and <a href="unified-test-format/unified-test-format.html#downloadByName">downloadByName</a>, which return
stream contents as a string.</p>
<h5 id="unsetormatches"><a class="header" href="#unsetormatches">$$unsetOrMatches</a></h5>
<p>Syntax:</p>
<pre><code>{ $$unsetOrMatches: &lt;anything&gt; }
</code></pre>
<p>This operator can be used anywhere a matched value is expected (including <a href="unified-test-format/unified-test-format.html#operation_expectResult">expectResult</a>),
excluding an array element because
<a href="unified-test-format/unified-test-format.html#arrays-must-contain-the-same-number-of-elements">Arrays Must Contain the Same Number of Elements</a>. The test runner
MUST assert that the actual value either does not exist or matches the expected value. Matching the expected value MUST
use the standard rules in <a href="unified-test-format/unified-test-format.html#evaluating-matches">Evaluating Matches</a>, which means that it may contain special operators.</p>
<p>This operator is primarily used to assert driver-optional fields from the CRUD spec (e.g. <code>insertedId</code> for
InsertOneResult, <code>writeResult</code> for BulkWriteException).</p>
<p>An example of this operator used for a result's field follows:</p>
<pre><code>expectResult:
  insertedId: { $$unsetOrMatches: 2 }
</code></pre>
<p>An example of this operator used for an entire result follows:</p>
<pre><code>expectError:
  expectResult:
    $$unsetOrMatches:
      deletedCount: 0
      insertedCount: 2
      matchedCount: 0
      modifiedCount: 0
      upsertedCount: 0
      upsertedIds: { }
</code></pre>
<h5 id="sessionlsid"><a class="header" href="#sessionlsid">$$sessionLsid</a></h5>
<p>Syntax:</p>
<pre><code>{ $$sessionLsid: &lt;sessionEntityName&gt; }
</code></pre>
<p>This operator can be used anywhere a matched value is expected (including <a href="unified-test-format/unified-test-format.html#operation_expectResult">expectResult</a>). If
the <a href="unified-test-format/unified-test-format.html#entity_session">session entity</a> is defined in the current test's <a href="unified-test-format/unified-test-format.html#entity-map">Entity Map</a>, the test runner MUST
assert that the actual value equals its logical session ID; otherwise, the test runner MUST raise an error for an
undefined or mistyped entity. The YAML file SHOULD use an <a href="https://yaml.org/spec/1.2/spec.html#id2786196">alias node</a>
for a session entity's <code>id</code> field (e.g. <code>session: *session0</code>).</p>
<p>An example of this operator follows:</p>
<pre><code>command:
  ping: 1
  lsid: { $$sessionLsid: *session0 }
</code></pre>
<h5 id="lte"><a class="header" href="#lte">$$lte</a></h5>
<p>Syntax:</p>
<pre><code>{ $$lte: 5 }
</code></pre>
<p>This operator can be used anywhere a matched value is expected (including <a href="unified-test-format/unified-test-format.html#operation_expectResult">expectResult</a>). The
test runner MUST assert that the actual value is less than or equal to the specified value. Test runners MUST also apply
the rules specified in <a href="unified-test-format/unified-test-format.html#flexible-numeric-comparisons">Flexible Numeric Comparisons</a> for this operator. For example, an
expected value of <code>1</code> would match an actual value of <code>1.0</code> and <code>0.0</code> but would not match <code>1.1</code>.</p>
<h5 id="matchasdocument"><a class="header" href="#matchasdocument">$$matchAsDocument</a></h5>
<p>Syntax:</p>
<pre><code>{ $$matchAsDocument: &lt;anything&gt; }
</code></pre>
<p>This operator may be used anywhere a matched value is expected (including <a href="unified-test-format/unified-test-format.html#operation_expectResult">expectResult</a>) and
the actual value is an extended JSON string. The test runner MUST parse the actual value into a BSON document and match
it against the expected value. Matching the expected value MUST use the standard rules in
<a href="unified-test-format/unified-test-format.html#evaluating-matches">Evaluating Matches</a>, which means that it may contain special operators. This operator is primarily
used to assert on extended JSON commands and command replies included in log messages.</p>
<h5 id="matchasroot"><a class="header" href="#matchasroot">$$matchAsRoot</a></h5>
<p>This operator may be used anywhere a matched value is expected (including <a href="unified-test-format/unified-test-format.html#operation_expectResult">expectResult</a>) and
the expected and actual values are documents. The test runner MUST treat the actual value as a root-level document as
described in <a href="unified-test-format/unified-test-format.html#evaluating-matches">Evaluating Matches</a> and match it against the expected value.</p>
<h3 id="test-runner-implementation"><a class="header" href="#test-runner-implementation">Test Runner Implementation</a></h3>
<p>The sections below describe instructions for instantiating the test runner, loading each test file, and executing each
test within a test file. Test runners MUST NOT share state created by processing a test file with the processing of
subsequent test files, and likewise for tests within a test file.</p>
<h4 id="initializing-the-test-runner"><a class="header" href="#initializing-the-test-runner">Initializing the Test Runner</a></h4>
<p>The test runner MUST be configurable with a connection string (or equivalent configuration), which will be used to
initialize any internal MongoClient(s) and any <a href="unified-test-format/unified-test-format.html#entity_client">client entities</a> (in combination with other URI
options). This specification is not prescriptive about how this information is provided. For example, it may be read
from an environment variable or configuration file.</p>
<p>Create a new MongoClient, which will be used for internal operations (e.g. processing <a href="unified-test-format/unified-test-format.html#initialData">initialData</a> and
<a href="unified-test-format/unified-test-format.html#test_outcome">test.outcome</a>). This is referred to elsewhere in the specification as the internal MongoClient. If this
MongoClient would connect multiple mongos nodes and the driver does not provide a way to target operations to specific
servers, the test runner MAY construct internal MongoClients for each mongos.</p>
<p>Determine the server version and topology type using an internal MongoClient. This information will be used to evaluate
any future <a href="unified-test-format/unified-test-format.html#runonrequirement">runOnRequirement</a> checks. Test environments SHOULD NOT use mixed version clusters, so it
is not necessary to check multiple servers.</p>
<p>In addition to the aforementioned connection string, the test runner MUST also be configurable with two other connection
strings (or equivalent configuration) that point to TCP load balancers: one fronting multiple servers and one fronting a
single server. These will be used to initialize client entities when executing tests against a load balanced sharded
cluster. If the topology type is <code>LoadBalanced</code> and Atlas Serverless is not being used, the test runner MUST error if
either of these URIs is not provided. When testing against other topology types or Atlas Serverless, these URIs SHOULD
NOT be provided and MUST be ignored if provided.</p>
<p>The test runner SHOULD terminate any open transactions (see:
<a href="unified-test-format/unified-test-format.html#terminating-open-transactions">Terminating Open Transactions</a>) using the internal MongoClient(s) before executing any
tests.</p>
<h4 id="executing-a-test-file"><a class="header" href="#executing-a-test-file">Executing a Test File</a></h4>
<p>The instructions in this section apply for each test file loaded by the test runner.</p>
<p>Test files, which may be YAML or JSON files, MUST be interpreted using an
<a href="unified-test-format/../extended-json/extended-json.html">Extended JSON</a> parser. The parser MUST accept relaxed and canonical Extended JSON
(per <a href="unified-test-format/../extended-json/extended-json.html#parsers">Extended JSON: Parsers</a>), as test files may use either.</p>
<p>Upon loading a file, the test runner MUST read the <a href="unified-test-format/unified-test-format.html#schemaVersion">schemaVersion</a> field and determine if the test file
can be processed further. Test runners MAY support multiple versions and MUST NOT process incompatible files (as
discussed in <a href="unified-test-format/unified-test-format.html#test-runner-support">Test Runner Support</a>). If a test file is incompatible, test runners MUST raise an
error and MAY do so by reporting a test failure. Test runners MAY make an effort to infer the number of tests (and their
descriptions) from an incompatible file and report a failure for each test.</p>
<p>If <a href="unified-test-format/unified-test-format.html#runOnRequirements">runOnRequirements</a> is specified, the test runner MUST skip the test file unless one or more
<a href="unified-test-format/unified-test-format.html#runonrequirement">runOnRequirement</a> objects are satisfied.</p>
<p>For each element in <a href="unified-test-format/unified-test-format.html#tests">tests</a>, follow the process in <a href="unified-test-format/unified-test-format.html#executing-a-test">Executing a Test</a>.</p>
<h4 id="executing-a-test"><a class="header" href="#executing-a-test">Executing a Test</a></h4>
<p>The instructions in this section apply for each <a href="unified-test-format/unified-test-format.html#test">test</a> occurring in a test file loaded by the test runner. After
processing a test, test runners MUST reset any internal state that resulted from doing so. For example, the
<a href="unified-test-format/unified-test-format.html#entity-map">Entity Map</a> created for one test MUST NOT be shared with another.</p>
<p>If at any point while executing this test an unexpected error is encountered or an assertion fails, the test runner MUST
consider this test to have failed and SHOULD continue with the instructions in this section to ensure that the test
environment is cleaned up (e.g. disable fail points, kill sessions) while also forgoing any additional assertions.</p>
<p>If <a href="unified-test-format/unified-test-format.html#test_skipReason">test.skipReason</a> is specified, the test runner MUST skip this test and MAY use the string value to
log a message.</p>
<p>If <a href="unified-test-format/unified-test-format.html#test_runOnRequirements">test.runOnRequirements</a> is specified, the test runner MUST skip the test unless one or more
<a href="unified-test-format/unified-test-format.html#runonrequirement">runOnRequirement</a> objects are satisfied.</p>
<p>If <a href="unified-test-format/unified-test-format.html#initialData">initialData</a> is specified, for each <a href="unified-test-format/unified-test-format.html#collectiondata">collectionData</a> therein the test runner MUST set
up the collection. All setup operations MUST use the internal MongoClient and a "majority" write concern. The test
runner MUST first drop the collection. If a <code>createOptions</code> document is present, the test runner MUST execute a <code>create</code>
command to create the collection with the specified options. The test runner MUST then insert the specified documents
(if any). If no documents are present and <code>createOptions</code> is not set, the test runner MUST create the collection. If the
topology is sharded, the test runner SHOULD use a single mongos for handling <a href="unified-test-format/unified-test-format.html#initialData">initialData</a> to avoid
possible runtime errors.</p>
<p>If the test might execute a transaction against a sharded deployment, the test runner MUST collect the latest cluster
time from processing <a href="unified-test-format/unified-test-format.html#initialData">initialData</a>. See
<a href="unified-test-format/unified-test-format.html#migrationconflict-errors-on-sharded-clusters">MigrationConflict Errors on Sharded Clusters</a> for more information.</p>
<p>Create a new <a href="unified-test-format/unified-test-format.html#entity-map">Entity Map</a> that will be used for this test. If <a href="unified-test-format/unified-test-format.html#createentities">createEntities</a> is
specified, the test runner MUST create each <a href="unified-test-format/unified-test-format.html#entity">entity</a> accordingly and add it to the map. If the topology is a
sharded cluster, the test runner MUST handle <a href="unified-test-format/unified-test-format.html#entity_client_useMultipleMongoses">useMultipleMongoses</a> accordingly if it
is specified for any client entities. If the topology type is <code>LoadBalanced</code>, client entities MUST be initialized with
the appropriate load balancer connection string as discussed in
<a href="unified-test-format/unified-test-format.html#entity_client_useMultipleMongoses">useMultipleMongoses</a>.</p>
<p>If the test might execute a transaction against a sharded deployment, the test runner MUST advance the cluster time of
any session entities created during the test using the cluster time collected from processing
<a href="unified-test-format/unified-test-format.html#initialData">initialData</a>. See
<a href="unified-test-format/unified-test-format.html#migrationconflict-errors-on-sharded-clusters">MigrationConflict Errors on Sharded Clusters</a> for more information.</p>
<p>If the test might execute a <code>distinct</code> command within a sharded transaction, for each target collection the test runner
SHOULD execute a non-transactional <code>distinct</code> command on each mongos server using an internal MongoClient. See
<a href="unified-test-format/unified-test-format.html#staledbversion-errors-on-sharded-clusters">StaleDbVersion Errors on Sharded Clusters</a> for more information.</p>
<p>If the test might execute a <code>configureFailPoint</code> command, for each target client the test runner MAY specify a reduced
value for <code>heartbeatFrequencyMS</code> (and <code>minHeartbeatFrequencyMS</code> if possible) to speed up SDAM recovery time and server
selection after a failure; however, test runners MUST NOT do so for any client that specifies <code>heartbeatFrequencyMS</code> in
its <code>uriOptions</code>.</p>
<p>For each client entity where <a href="unified-test-format/unified-test-format.html#entity_client_observeEvents">observeEvents</a> has been specified, the test runner MUST
enable all event listeners necessary to collect the specified event types. Test runners MAY leave event listeners
disabled for tests that do not assert events (i.e. tests that omit both <a href="unified-test-format/unified-test-format.html#test_expectEvents">test.expectEvents</a> and
special operations such as <a href="unified-test-format/unified-test-format.html#assertsamelsidonlasttwocommands">assertSameLsidOnLastTwoCommands</a>).</p>
<p>For each client with command monitoring enabled, the test runner MUST ignore events for the following:</p>
<ul>
<li>Any command(s) specified in <a href="unified-test-format/unified-test-format.html#entity_client_ignoreCommandMonitoringEvents">ignoreCommandMonitoringEvents</a>.</li>
<li>Any <code>configureFailPoint</code> commands executed for <a href="unified-test-format/unified-test-format.html#failpoint">failPoint</a> and <a href="unified-test-format/unified-test-format.html#targetedfailpoint">targetedFailPoint</a>
operations.</li>
<li>Any commands containing sensitive information (per the
<a href="unified-test-format/../command-logging-and-monitoring/command-logging-and-monitoring.html#security">Command Logging and Monitoring</a> spec)
unless <a href="unified-test-format/unified-test-format.html#entity_client_observeSensitiveCommands">observeSensitiveCommands</a> is true. Note that drivers will redact
commands and replies for sensitive commands. For <code>hello</code> and legacy hello, which are conditionally sensitive based on
the presence of a <code>speculativeAuthenticate</code> field, the test runner may need to infer that the events are sensitive
based on whether or not the command and reply documents are redacted (i.e. empty documents).</li>
</ul>
<p>For each element in <a href="unified-test-format/unified-test-format.html#test_operations">test.operations</a>, follow the process in
<a href="unified-test-format/unified-test-format.html#executing-an-operation">Executing an Operation</a>. If an unexpected error is encountered or an assertion fails, the test
runner MUST consider this test to have failed.</p>
<p>If any event listeners were enabled on any client entities, the test runner MUST now disable those event listeners.</p>
<p>If any fail points were configured, the test runner MUST now disable those fail points (on the same server) to avoid
spurious failures in subsequent tests. For any fail points configured using <a href="unified-test-format/unified-test-format.html#targetedfailpoint">targetedFailPoint</a>, the
test runner MUST disable the fail point on the same mongos server on which it was originally configured. See
<a href="unified-test-format/unified-test-format.html#disabling-fail-points">Disabling Fail Points</a> for more information.</p>
<p>If <a href="unified-test-format/unified-test-format.html#test_expectEvents">test.expectEvents</a> is specified, for each object therein the test runner MUST assert that the
number and sequence of expected events match the number and sequence of actual events observed on the specified client.
If the list of expected events is empty, the test runner MUST assert that no events were observed on the client. The
process for matching events is described in <a href="unified-test-format/unified-test-format.html#expectedevent">expectedEvent</a>.</p>
<p>If <a href="unified-test-format/unified-test-format.html#test_outcome">test.outcome</a> is specified, for each <a href="unified-test-format/unified-test-format.html#collectiondata">collectionData</a> therein the test runner MUST
assert that the collection contains exactly the expected data. The test runner MUST query each collection using the
internal MongoClient, an ascending sort order on the <code>_id</code> field (i.e. <code>{ _id: 1 }</code>), a "primary" read preference, and a
"local" read concern. When comparing collection data, the rules in <a href="unified-test-format/unified-test-format.html#evaluating-matches">Evaluating Matches</a> do not
apply and the documents MUST match exactly; however, test runners MUST permit variations in document key order or
otherwise normalize the documents before comparison. If the list of documents is empty, the test runner MUST assert that
the collection is empty.</p>
<p>Before clearing the entity map at the end of each test, the test runner MUST allow its entities to be accessed
externally. The exact mechanism for facilitating this access is not prescribed by this specification, but drivers should
be mindful of concurrency if applicable. As an example, the test runner MAY be configured with a callback method, which
will be invoked at the end of each test and provided with the entity map (or an equivalent data structure). As
previously discussed in <a href="unified-test-format/unified-test-format.html#entity-map">Entity Map</a>, test runners MAY restrict access to driver objects if necessary.</p>
<p>Clear the entity map for this test. For each ClientSession in the entity map, the test runner MUST end the session (e.g.
call <a href="unified-test-format/../sessions/driver-sessions.html#endsession">endSession</a>). For each ChangeStream and FindCursor in the entity map,
the test runner MUST close the cursor.</p>
<p>If the test started a transaction (i.e. executed a <code>startTransaction</code> or <code>withTransaction</code> operation), the test runner
MUST terminate any open transactions (see: <a href="unified-test-format/unified-test-format.html#terminating-open-transactions">Terminating Open Transactions</a>).</p>
<p>Proceed to the subsequent test.</p>
<h4 id="executing-an-operation"><a class="header" href="#executing-an-operation">Executing an Operation</a></h4>
<p>The instructions in this section apply for each <a href="unified-test-format/unified-test-format.html#operation">operation</a> occurring in a <a href="unified-test-format/unified-test-format.html#test">test</a> contained within a
test file loaded by the test runner.</p>
<p>If at any point while executing an operation an unexpected error is encountered or an assertion fails, the test runner
MUST consider the parent test to have failed and proceed from <a href="unified-test-format/unified-test-format.html#executing-a-test">Executing a Test</a> accordingly.</p>
<p>If <a href="unified-test-format/unified-test-format.html#operation_object">operation.object</a> is "testRunner", this is a special operation. If
<a href="unified-test-format/unified-test-format.html#operation_name">operation.name</a> is defined in <a href="unified-test-format/unified-test-format.html#special-test-operations">Special Test Operations</a>, the test runner
MUST execute the operation accordingly and, if successful, proceed to the next operation in the test; otherwise, the
test runner MUST raise an error for an undefined operation. The test runner MUST keep a record of any fail points
configured by special operations so that they may be disabled after the current test.</p>
<p>If <a href="unified-test-format/unified-test-format.html#operation_object">operation.object</a> is not "testRunner", this is an entity operation. If
<a href="unified-test-format/unified-test-format.html#operation_object">operation.object</a> is defined in the current test's <a href="unified-test-format/unified-test-format.html#entity-map">Entity Map</a>, the test runner MUST
fetch that entity and note its type; otherwise, the test runner MUST raise an error for an undefined entity. If
<a href="unified-test-format/unified-test-format.html#operation_name">operation.name</a> does not correspond to a known operation for the entity type (per
<a href="unified-test-format/unified-test-format.html#entity-test-operations">Entity Test Operations</a>), the test runner MUST raise an error for an unsupported operation.
Test runners MAY skip tests that include operations that are intentionally unimplemented (e.g. <code>listCollectionNames</code>).</p>
<p>Proceed with preparing the operation's arguments. If <code>session</code> is specified in
<a href="unified-test-format/unified-test-format.html#operation_arguments">operation.arguments</a>, the test runner MUST resolve it to a session entity and MUST raise an error
if the name is undefined or maps to an unexpected type. If a key in <a href="unified-test-format/unified-test-format.html#operation_arguments">operation.arguments</a> does not
correspond to a known parameter/option for the operation, the test runner MUST raise an error for an unsupported
argument.</p>
<p>Before executing the operation, the test runner MUST be prepared to catch a potential error from the operation (e.g.
enter a <code>try</code> block). Proceed with executing the operation and capture its result or error.</p>
<p>Note that some operations require special handling, as discussed in <a href="unified-test-format/unified-test-format.html#entity-test-operations">Entity Test Operations</a>.
For example, model objects may need to be converted to documents (before matching or saving in the entity map) and
returned iterables may need to be fully iterated.</p>
<p>If <a href="unified-test-format/unified-test-format.html#operation_ignoreResultAndError">operation.ignoreResultAndError</a> is true, the test runner MUST NOT make any
assertions regarding the result or error of the operation and MUST proceed to the subsequent operation.</p>
<p>If <a href="unified-test-format/unified-test-format.html#operation_expectError">operation.expectError</a> is specified, the test runner MUST assert that the operation yielded
an error; otherwise, the test runner MUST assert that the operation did not yield an error. If an error was expected,
the test runner MUST evaluate any assertions in <a href="unified-test-format/unified-test-format.html#expectederror">expectedError</a> accordingly.</p>
<p>If <a href="unified-test-format/unified-test-format.html#operation_expectResult">operation.expectResult</a> is specified, the test MUST assert that it matches the actual
result of the operation according to the rules outlined in <a href="unified-test-format/unified-test-format.html#evaluating-matches">Evaluating Matches</a>.</p>
<p>If <a href="unified-test-format/unified-test-format.html#operation_saveResultAsEntity">operation.saveResultAsEntity</a> is specified, the test runner MUST store the result in
the current test's entity map using the specified name. If the operation did not return a result or the result does not
comply with <a href="unified-test-format/unified-test-format.html#supported-entity-types">Supported Entity Types</a> then the test runner MUST raise an error.</p>
<p>After asserting the operation's error and/or result and optionally saving the result, proceed to the subsequent
operation.</p>
<h4 id="special-procedures"><a class="header" href="#special-procedures">Special Procedures</a></h4>
<p>This section describes some procedures that may be referenced from earlier sections.</p>
<h5 id="terminating-open-transactions"><a class="header" href="#terminating-open-transactions">Terminating Open Transactions</a></h5>
<p>Open transactions can cause tests to block indiscriminately. When connected to MongoDB 3.6 or later, test runners SHOULD
terminate all open transactions at the start of a test suite and after each failed test by killing all sessions in the
cluster. Using the internal MongoClient(s), execute the <code>killAllSessions</code> command on either the primary or, if connected
to a sharded cluster, each mongos server.</p>
<p>For example:</p>
<pre><code>db.adminCommand({
  killAllSessions: []
});
</code></pre>
<p>The test runner MAY ignore the following command failures:</p>
<ul>
<li>Interrupted(11601) to work around <a href="https://jira.mongodb.org/browse/SERVER-38335">SERVER-38335</a>.</li>
<li>Unauthorized(13) to work around <a href="https://jira.mongodb.org/browse/SERVER-54216">SERVER-54216</a>.</li>
<li>CommandNotFound(59) if the command is executed on a pre-3.6 server</li>
</ul>
<p>Note that Atlas, by design, does not allow database users to kill sessions belonging to other users. This makes it
impossible to guarantee that an existing transaction will not block test execution. To work around this, test runners
SHOULD either ignore Unauthorized(13) command failures or avoid calling <code>killAllSessions</code> altogether when connected to
Atlas (e.g. by detecting <code>mongodb.net</code> in the hostname or allowing the test runner to be configured externally).</p>
<p>Test runners MUST NOT execute <code>killAllSessions</code> when connected to Atlas Data Lake.</p>
<h5 id="migrationconflict-errors-on-sharded-clusters"><a class="header" href="#migrationconflict-errors-on-sharded-clusters">MigrationConflict Errors on Sharded Clusters</a></h5>
<p>Following <a href="https://jira.mongodb.org/browse/SERVER-82353">SERVER-82353</a>, drivers may encounter MigrationConflict errors
when executing transactions on sharded clusters due to an outdated cluster time. For example:</p>
<pre><code>Transaction fe0b9a7d-4b64-4e38-aad2-4c7dd5ab0c2b - 47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU= -  - :1 was aborted on statement 0 due to: a non-retryable snapshot error :: caused by :: Encountered error from localhost:27217 during a transaction :: caused by :: Database transaction-tests has undergone a catalog change operation at time Timestamp(1708062645, 94) and no longer satisfies the requirements for the current transaction which requires Timestamp(1708062645, 93). Transaction will be aborted.
</code></pre>
<p>To work around this issue, a test runner MUST collect the latest cluster time from processing
<a href="unified-test-format/unified-test-format.html#initialData">initialData</a>, which is executed using the internal MongoClient, and use it to advance the cluster time of
every session entity created during the test, by either <a href="unified-test-format/unified-test-format.html#createentities">createEntities</a> or the
<a href="unified-test-format/unified-test-format.html#operation_createEntities">special test operation</a>). This will ensure that the cluster time is gossipped to any other
mongo hosts that may be used to execute a transaction during the test.</p>
<p>Depending on the test runner implementation, the cluster time may be collected in various ways. For example:</p>
<ul>
<li>Execute a <code>ping</code> command against the same mongos host used for <a href="unified-test-format/unified-test-format.html#initialData">initialData</a> and read the <code>$clusterTime</code>
response field</li>
<li>Execute all operations for <a href="unified-test-format/unified-test-format.html#initialData">initialData</a> using an explicit session and read its cluster time after the
last operation.</li>
</ul>
<p>This logic is only necessary for tests that might execute a transaction against a sharded deployment transaction (i.e.
<a href="unified-test-format/unified-test-format.html#test_operations">test.operations</a> includes <code>startTransaction</code> or <code>withTransaction</code> and the topology is sharded or
load-balanced). To ease the implementation, test runners MAY apply this logic to <em>every</em> test.</p>
<h5 id="staledbversion-errors-on-sharded-clusters"><a class="header" href="#staledbversion-errors-on-sharded-clusters">StaleDbVersion Errors on Sharded Clusters</a></h5>
<p>When a shard receives its first command that contains a <code>databaseVersion</code>, the shard returns a StaleDbVersion error and
mongos retries the operation. In a sharded transaction, mongos does not retry these operations and instead returns the
error to the client. For example:</p>
<pre><code>Command distinct failed: Transaction aa09e296-472a-494f-8334-48d57ab530b6:1 was aborted on statement 0 due to: an error from cluster data placement change :: caused by :: got stale databaseVersion response from shard sh01 at host localhost:27217 :: caused by :: don't know dbVersion.
</code></pre>
<p>To work around this limitation, a test runners MUST execute a non-transactional <code>distinct</code> command on each mongos server
before running any test that might execute <code>distinct</code> within a transaction. To ease the implementation, test runners MAY
execute <code>distinct</code> before <em>every</em> test.</p>
<p>Test runners can remove this workaround once <a href="https://jira.mongodb.org/browse/SERVER-39704">SERVER-39704</a> is resolved,
after which point mongos should retry the operation transparently. The <code>distinct</code> command is the only command allowed in
a sharded transaction that uses the <code>databaseVersion</code> concept so it is the only command affected.</p>
<h3 id="server-fail-points"><a class="header" href="#server-fail-points">Server Fail Points</a></h3>
<p>Many tests utilize the <code>configureFailPoint</code> command to trigger server-side errors such as dropped connections or command
errors. Tests can configure fail points using the special <a href="unified-test-format/unified-test-format.html#failpoint">failPoint</a> or
<a href="unified-test-format/unified-test-format.html#targetedfailpoint">targetedFailPoint</a> operations.</p>
<p>This internal command is not documented in the MongoDB manual (pending
<a href="https://jira.mongodb.org/browse/DOCS-10784">DOCS-10784</a>); however, there is scattered documentation available on the
server wiki (<a href="https://github.com/mongodb/mongo/wiki/The-%22failCommand%22-fail-point">The "failCommand" Fail Point</a>) and
employee blogs (e.g. <a href="https://kchodorow.com/2013/01/15/intro-to-fail-points/">Intro to Fail Points</a>,
<a href="https://emptysqua.re/blog/mongodb-testing-network-errors/">Testing Network Errors With MongoDB</a>). Documentation can
also be gleaned from JIRA tickets (e.g. <a href="https://jira.mongodb.org/browse/SERVER-35004">SERVER-35004</a>,
<a href="https://jira.mongodb.org/browse/SERVER-35083">SERVER-35083</a>). This specification does not aim to provide comprehensive
documentation for all fail points available for driver testing, but some fail points are documented in
<a href="unified-test-format/unified-test-format.html#fail-points-commonly-used-in-tests">Fail Points Commonly Used in Tests</a>.</p>
<h4 id="configuring-fail-points"><a class="header" href="#configuring-fail-points">Configuring Fail Points</a></h4>
<p>The <code>configureFailPoint</code> command is executed on the <code>admin</code> database and has the following structure:</p>
<pre><code>db.adminCommand({
    configureFailPoint: &lt;string&gt;,
    mode: &lt;string|object&gt;,
    data: &lt;object&gt;
});
</code></pre>
<p>The value of <code>configureFailPoint</code> is a string denoting the fail point to be configured (e.g. "failCommand").</p>
<p>The <code>mode</code> option is a generic fail point option and may be assigned a string or object value. The string values
"alwaysOn" and "off" may be used to enable or disable the fail point, respectively. An object may be used to specify
either <code>times</code> or <code>skip</code>, which are mutually exclusive:</p>
<ul>
<li><code>{ times: &lt;integer&gt; }</code> may be used to limit the number of times the fail point may trigger before transitioning to
"off".</li>
<li><code>{ skip: &lt;integer&gt; }</code> may be used to defer the first trigger of a fail point, after which it will transition to
"alwaysOn".</li>
</ul>
<p>The <code>data</code> option is an object that may be used to specify any options that control the particular fail point's
behavior.</p>
<p>In order to use <code>configureFailPoint</code>, the undocumented <code>enableTestCommands</code>
<a href="https://www.mongodb.com/docs/manual/reference/parameters/">server parameter</a> must be enabled by either the
configuration file or command line option (e.g. <code>--setParameter enableTestCommands=1</code>). It cannot be enabled at runtime
via the <a href="https://www.mongodb.com/docs/manual/reference/command/setParameter/">setParameter</a> command). This parameter
should already be enabled for most configuration files in
<a href="https://github.com/10gen/mongo-orchestration">mongo-orchestration</a>.</p>
<h4 id="disabling-fail-points"><a class="header" href="#disabling-fail-points">Disabling Fail Points</a></h4>
<p>A fail point may be disabled like so:</p>
<pre><code>db.adminCommand({
    configureFailPoint: &lt;string&gt;,
    mode: "off"
});
</code></pre>
<h4 id="fail-points-commonly-used-in-tests"><a class="header" href="#fail-points-commonly-used-in-tests">Fail Points Commonly Used in Tests</a></h4>
<h5 id="failcommand"><a class="header" href="#failcommand">failCommand</a></h5>
<p>The <code>failCommand</code> fail point allows the client to force the server to return an error for commands listed in the
<code>data.failCommands</code> field. Additionally, this fail point is documented in server wiki:
<a href="https://github.com/mongodb/mongo/wiki/The-%22failCommand%22-fail-point">The failCommand Fail Point</a>.</p>
<p>The <code>failCommand</code> fail point was introduced in mongod 4.0.0
(<a href="https://jira.mongodb.org/browse/SERVER-34551">SERVER-34551</a>) and mongos 4.1.5
(<a href="https://jira.mongodb.org/browse/SERVER-35518">SERVER-35518</a>); however, the fail point was not usable for testing on
mongos until version 4.1.7 (<a href="https://jira.mongodb.org/browse/SERVER-34943">SERVER-34943</a>).</p>
<p>The <code>failCommand</code> fail point may be configured like so:</p>
<pre><code>db.adminCommand({
    configureFailPoint: "failCommand",
    mode: &lt;string|object&gt;,
    data: {
      failCommands: [&lt;string&gt;, ...],
      closeConnection: &lt;boolean&gt;,
      errorCode: &lt;integer&gt;,
      errorLabels: [&lt;string&gt;, ...],
      writeConcernError: &lt;object&gt;,
      appName: &lt;string&gt;,
      blockConnection: &lt;boolean&gt;,
      blockTimeMS: &lt;integer&gt;,
    }
});
</code></pre>
<p><code>failCommand</code> supports the following <code>data</code> options, which may be combined if desired:</p>
<ul>
<li><code>failCommands</code>: Required array of strings. Lists the command names to fail.</li>
<li><code>closeConnection</code>: Optional boolean, which defaults to <code>false</code>. If <code>true</code>, the command will not be executed, the
connection will be closed, and the client will see a network error.</li>
<li><code>errorCode</code>: Optional integer, which is unset by default. If set, the command will not be executed and the specified
command error code will be returned as a command error.</li>
<li><code>errorLabels</code>: Optional array of strings. If set, this list overrides the server's normal behavior for adding error
labels. An empty array may be used to suppress the server from adding error labels to the response. New in server
4.3.1 (<a href="https://jira.mongodb.org/browse/SERVER-43941">SERVER-43941</a>).</li>
<li><code>appName</code>: Optional string, which is unset by default. If set, the fail point will only apply to connections for
MongoClients created with this <code>appname</code>. New in server 4.4.0-rc2 and backported to 4.2.9
(<a href="https://jira.mongodb.org/browse/SERVER-47195">SERVER-47195</a>).</li>
<li><code>blockConnection</code>: Optional boolean, which defaults to <code>false</code>. If <code>true</code>, the server should block the affected
commands for <code>blockTimeMS</code>. New in server 4.3.4 and backported to 4.2.9
(<a href="https://jira.mongodb.org/browse/SERVER-41070">SERVER-41070</a>).</li>
<li><code>blockTimeMS</code>: Optional integer, which is required when <code>blockConnection</code> is <code>true</code>. The number of milliseconds for
which the affected commands should be blocked. New in server 4.3.4 and backported to 4.2.9
(<a href="https://jira.mongodb.org/browse/SERVER-41070">SERVER-41070</a>).</li>
</ul>
<h5 id="onprimarytransactionalwrite"><a class="header" href="#onprimarytransactionalwrite">onPrimaryTransactionalWrite</a></h5>
<p>The <code>onPrimaryTransactionalWrite</code> fail point allows the client to force a network error before the server would return a
write result to the client. The fail point also allows control whether the server will successfully commit the write via
its <code>failBeforeCommitExceptionCode</code> option. Keep in mind that the fail point only triggers for transaction writes (i.e.
write commands including <code>txnNumber</code> and <code>lsid</code> fields).</p>
<p>The <code>onPrimaryTransactionalWrite</code> fail point was introduced in mongod 3.6.0
(<a href="https://jira.mongodb.org/browse/SERVER-29606">SERVER-29606</a>) to facilitate testing of retryable writes. It is only
supported on mongod and cannot be used with sharded clusters.</p>
<p><code>onPrimaryTransactionalWrite</code> supports the following <code>data</code> options:</p>
<ul>
<li><code>closeConnection</code>: Optional boolean, which defaults to <code>true</code>. If <code>true</code>, the connection on which the write is
executed will be closed before a result can be returned.</li>
<li><code>failBeforeCommitExceptionCode</code>: Optional integer, which is unset by default. If set, the specified exception code
will be thrown and the write will not be committed. If unset, the write will be allowed to commit.</li>
</ul>
<h3 id="determining-if-a-sharded-cluster-uses-replica-sets"><a class="header" href="#determining-if-a-sharded-cluster-uses-replica-sets">Determining if a Sharded Cluster Uses Replica Sets</a></h3>
<p>When connected to a mongos server, the test runner can query the
<a href="https://www.mongodb.com/docs/manual/reference/config-database/#mongodb-data-config.shards">config.shards</a> collection.
Each shard in the cluster is represented by a document in this collection. If the shard is backed by a single server,
the <code>host</code> field will contain a single host. If the shard is backed by a replica set, the <code>host</code> field contain the name
of the replica followed by a forward slash and a comma-delimited list of hosts.</p>
<p>Note: MongoDB 3.6+ requires that all shard servers be replica sets.</p>
<h2 id="design-rationale-29"><a class="header" href="#design-rationale-29">Design Rationale</a></h2>
<p>This specification was primarily derived from the test formats used by the
<a href="unified-test-format/../transactions/transactions.html">Transactions</a> and <a href="unified-test-format/../crud/crud.html">CRUD</a> specs, which have served models or other
specs.</p>
<p>This specification commonly uses "SHOULD" when providing guidance on writing test files. While this may appear
contradictory to the driver mantra preferring "MUST", it is intentional. Some of this guidance addresses style (e.g.
adding comments, using YAML anchors) and cannot be enforced with a JSON schema. Other guidance needs to be purposefully
ignored in order to test the test runner implementation (e.g. defining entities out of order to trigger runtime errors).
The specification does prefer "MUST" in other contexts, such as discussing parts of the test file format that <em>are</em>
enforceable by the JSON schema or the test runner implementation.</p>
<p><span id="rationale_observeSensitiveCommands"></span></p>
<h3 id="why-cant-observesensitivecommands-be-true-when-authentication-is-enabled"><a class="header" href="#why-cant-observesensitivecommands-be-true-when-authentication-is-enabled">Why can't <code>observeSensitiveCommands</code> be true when authentication is enabled?</a></h3>
<p>When running against authentication-enabled clusters, the events observed by a client will always begin with
auth-related commands (e.g. <code>authenticate</code>, <code>saslStart</code>, <code>saslContinue</code>) because the MongoClient will need to
authenticate a connection before issuing the first command in the test specification. Since the exact form of the
authentication command event will depend on whether authentication is enabled, as well as, the auth mechanism in use, it
is not possible to anticipate the command monitoring output and perform the appropriate assertions. Consequently, we
have restricted use of this property to situations where authentication is disabled on the server. This allows tests to
explicitly test sensitive commands via the <code>runCommand</code> helper.</p>
<h2 id="breaking-changes"><a class="header" href="#breaking-changes">Breaking Changes</a></h2>
<p>This section is reserved for future use. Any breaking changes to the test format SHOULD be described here in detail for
historical reference, in addition to any shorter description that may be added to the <a href="unified-test-format/unified-test-format.html#changelog">Changelog</a>.</p>
<h2 id="future-work-18"><a class="header" href="#future-work-18">Future Work</a></h2>
<h3 id="assert-expected-log-messages"><a class="header" href="#assert-expected-log-messages">Assert expected log messages</a></h3>
<p>When drivers support standardized logging, the test format may need to support assertions for messages expected to be
logged while executing operations. Since log messages are strings, this may require an operator to match regex patterns
within strings. Additionally, the test runner may need to support ignoring extra log output, similar to
<code>ignoreExtraEvents</code>.</p>
<h3 id="target-failpoint-by-read-preference"><a class="header" href="#target-failpoint-by-read-preference">Target failPoint by read preference</a></h3>
<p>The <a href="unified-test-format/unified-test-format.html#failpoint">failPoint</a> operation currently uses a "primary" read preference. To date, no spec has needed behavior
to configure a fail point on a non-primary node. If the need does arise, <a href="unified-test-format/unified-test-format.html#failpoint">failPoint</a> can be enhanced to
support a <code>readPreference</code> argument.</p>
<h3 id="io-operations-for-gridfs-streams"><a class="header" href="#io-operations-for-gridfs-streams">IO operations for GridFS streams</a></h3>
<p>Original GridFS spec tests refer to "upload", "download", and "download_by_name" methods, which allow the tests to
abstract stream IO and either upload a byte sequence or assert a downloaded byte sequence. These operations correspond
to the <a href="unified-test-format/unified-test-format.html#download">download</a>, <a href="unified-test-format/unified-test-format.html#downloadByName">downloadByName</a>, <a href="unified-test-format/unified-test-format.html#upload-and-uploadWithId">upload</a>, and
<a href="unified-test-format/unified-test-format.html#upload-and-uploadWithId">uploadWithId</a> <a href="unified-test-format/unified-test-format.html#bucket-operations">Bucket Operations</a>.</p>
<p>In order to support methods such as <code>downloadToStream</code>, <code>openUploadStream</code>, and <code>openUploadStreamWithId</code>, test runners
would need to represent streams as entities and support IO operations to directly read from and write to a stream
entity. This may not be worth the added complexity if the existing operations provide adequate test coverage for GridFS
implementations.</p>
<h3 id="support-client-side-encryption-integration-tests"><a class="header" href="#support-client-side-encryption-integration-tests">Support Client-side Encryption integration tests</a></h3>
<p>Supporting client-side encryption spec tests will require the following changes to the test format:</p>
<ul>
<li><code>json_schema</code> will need to be specified when creating a collection, via either the collection entity definition or
<a href="unified-test-format/unified-test-format.html#initialData">initialData</a>.</li>
<li><code>key_vault_data</code> can be expressed via <a href="unified-test-format/unified-test-format.html#initialData">initialData</a></li>
<li><code>autoEncryptOpts</code> will need to be specified when defining a client entity. Preparation of this field may require
reading AWS credentials from environment variables.</li>
</ul>
<p>The process for executing tests should not require significant changes, but test files will need to express a dependency
on mongocryptd.</p>
<h3 id="incorporate-referenced-entity-operations-into-the-schema-version"><a class="header" href="#incorporate-referenced-entity-operations-into-the-schema-version">Incorporate referenced entity operations into the schema version</a></h3>
<p>The <a href="unified-test-format/unified-test-format.html#schema-version">Schema Version</a> is not impacted by changes to operations defined in other specs and referenced in
<code>Entity Test Operations</code> (e.g. <code>find</code> for CRUD). The <a href="unified-test-format/unified-test-format.html#operation_name">operation.name</a> and
<a href="unified-test-format/unified-test-format.html#operation_arguments">operation.arguments</a> fields are loosely defined in the JSON schema as string and object types,
respectively.</p>
<p>Ideally, all operations (and their arguments) would be enforced by the JSON schema <em>and</em> any changes to operations would
affect the schema version accordingly. For example, a new <code>find</code> option would warrant a minor version bump both for the
CRUD spec and this spec and its schema.</p>
<p>As discussed in <a href="unified-test-format/unified-test-format.html#executing-an-operation">Executing an Operation</a>, test runners MUST raise errors for unsupported
operations and arguments. This is a concession until such time that better processes can be established for versioning
other specs <em>and</em> collating spec changes developed in parallel or during the same release cycle.</p>
<h2 id="changelog-47"><a class="header" href="#changelog-47">Changelog</a></h2>
<ul>
<li>
<p>2024-09-18: Note that <code>failCommand</code> <code>appName</code> option was backported</p>
</li>
<li>
<p>2024-05-08: <strong>Schema version 1.21.</strong></p>
<p>Add <code>writeErrors</code> and <code>writeConcernErrors</code> field to <code>expectedError</code> for the client-level bulk write API.</p>
</li>
<li>
<p>2024-04-15: Note that when <code>directConnection</code> is set to true test runners should only provide a single seed.</p>
</li>
<li>
<p>2024-03-25: <strong>Schema version 1.20.</strong></p>
<p>Add <code>previousDescription</code> and <code>newDescription</code> assertions to <code>topologyDescriptionChangedEvent</code> when checking events
with <code>expectEvents</code></p>
</li>
<li>
<p>2024-03-11: Note that <code>killAllSessions</code> should not be executed on Atlas Data Lake</p>
</li>
<li>
<p>2024-02-27: Document <code>onPrimaryTransactionalWrite</code> fail point, which is used in retryable writes tests.</p>
</li>
<li>
<p>2024-02-23: Require test runners to gossip cluster time from internal MongoClient to each session entity.</p>
</li>
<li>
<p>2024-02-14: Clarify that errors raised from callback operations should always propagate to <code>withTransaction</code>.</p>
</li>
<li>
<p>2024-02-12: Clarify that <code>targetedFailPoint</code> should only be used when <code>useMultipleMongoses</code> is true and not on
load-balanced topologies.</p>
</li>
<li>
<p>2024-02-06: Migrated from reStructuredText to Markdown.</p>
</li>
<li>
<p>2024-01-17: <strong>Schema version 1.19.</strong></p>
<p>Add <code>authMechanism</code> to <code>runOnRequirement</code> and require that <code>uriOptions</code> supports placeholder documents.</p>
</li>
<li>
<p>2024-01-11: <strong>Schema version 1.18.</strong></p>
<p>Allow named KMS providers in <code>kmsProviders</code>. Note location of Client-Side Encryption test credentials.</p>
</li>
<li>
<p>2024-01-03: Document server version requirements for <code>errorLabels</code> and <code>blockConnection</code> options for <code>failCommand</code>
fail point.</p>
</li>
<li>
<p>2023-10-04: <strong>Schema version 1.17.</strong></p>
<p>Add <code>serverHeartbeatStartedEvent</code>, <code>serverHeartbeatSucceededEvent</code>, and <code>serverHeartbeatFailedEvent</code> for asserting on
SDAM server heartbeat events.</p>
</li>
<li>
<p>2023-09-25: Clarify that the UTR is intended to be run against enterprise servers.</p>
</li>
<li>
<p>2022-07-18: <strong>Schema version 1.16.</strong></p>
<p>Add <code>ignoreMessages</code> and <code>ignoreExtraMessages</code> fields to <code>expectedLogMessagesForClient</code> section.</p>
</li>
<li>
<p>2023-06-26: <code>runOnRequirement.csfle</code> should check for crypt_shared and/or mongocryptd.</p>
</li>
<li>
<p>2023-06-13: <strong>Schema version 1.15.</strong></p>
<p>Add <code>databaseName</code> field to <code>CommandFailedEvent</code> and <code>CommandSucceededEvent</code>.</p>
</li>
<li>
<p>2023-05-26: <strong>Schema version 1.14.</strong></p>
<p>Add <code>topologyDescriptionChangedEvent</code>.</p>
</li>
<li>
<p>2023-05-17: Add <code>runCursorCommand</code> and <code>createCommandCursor</code> operations. Added <code>commandCursor</code> entity type which can
be used with existing cursor operations.</p>
</li>
<li>
<p>2023-05-12: Deprecate "sharded-replicaset" topology type. Note that server 3.6+ requires replica sets for shards,
which is also relevant to load balanced topologies.</p>
</li>
<li>
<p>2023-04-13: Remove <code>readConcern</code> and <code>writeConcern</code> options from <code>runCommand</code> operation.</p>
</li>
<li>
<p>2023-02-24: Fix typo in the description of the <code>$$matchAsRoot</code> matching operator.</p>
</li>
<li>
<p>2022-10-17: Add description of a <code>close</code> operation for client entities.</p>
</li>
<li>
<p>2022-10-14: <strong>Schema version 1.13.</strong></p>
<p>Add support for logging assertions via the <code>observeLogMessages</code> field for client entities, along with a new top-level
field <code>expectLogMessages</code> containing <code>expectedLogMessagesForClient</code> objects. Add new special matching operators to
enable command logging assertions, <code>$$matchAsDocument</code> and <code>$$matchAsRoot</code>.</p>
</li>
<li>
<p>2022-10-14: <strong>Schema version 1.12.</strong></p>
<p>Add <code>errorResponse</code> to <code>expectedError</code>.</p>
</li>
<li>
<p>2022-10-05: Remove spec front matter, add "Current Schema Version" field, and reformat changelog. Add comment to
remind editors to note schema version bumps in changelog updates (where applicable).</p>
</li>
<li>
<p>2022-09-02: <strong>Schema version 1.11.</strong></p>
<p>Add <code>interruptInUseConnections</code> field to <code>poolClearedEvent</code></p>
</li>
<li>
<p>2022-07-28: <strong>Schema version 1.10.</strong></p>
<p>Add support for <code>thread</code> entities (<code>runOnThread</code>, <code>waitForThread</code>), TopologyDescription entities
(<code>recordTopologyDescription</code>, <code>waitForPrimaryChange</code>, <code>assertTopologyType</code>), testRunner event assertion operations
(<code>waitForEvent</code>, <code>assertEventCount</code>), expected SDAM events, and the <code>wait</code> operation.</p>
</li>
<li>
<p>2022-07-27: Retroactively note schema version bumps in the changelog and require doing so for future changes.</p>
</li>
<li>
<p>2022-07-11: Update <a href="unified-test-format/unified-test-format.html#future-work">Future Work</a> to reflect that support for ignoring extra observed events was added in
schema version 1.7.</p>
</li>
<li>
<p>2022-06-16: Require server 4.2+ for <code>csfle: true</code>.</p>
</li>
<li>
<p>2022-05-10: Add reference to Client Side Encryption spec under
<a href="unified-test-format/unified-test-format.html#clientencryption-operations">ClientEncryption Operations</a>.</p>
</li>
<li>
<p>2022-04-27: <strong>Schema version 1.9.</strong></p>
<p>Added <code>createOptions</code> field to <code>initialData</code>, introduced a new <code>timeoutMS</code> field in <code>collectionOrDatabaseOptions</code>, and
added an <code>isTimeoutError</code> field to <code>expectedError</code>. Also introduced the <code>createEntities</code> operation.</p>
</li>
<li>
<p>2022-04-27: <strong>Schema version 1.8.</strong></p>
<p>Add <code>runOnRequirement.csfle</code>.</p>
</li>
<li>
<p>2022-04-26: Add <code>clientEncryption</code> entity and <code>$$placeholder</code> syntax.</p>
</li>
<li>
<p>2022-04-22: Revise <code>useMultipleMongoses</code> and "Initializing the Test Runner" for Atlas Serverless URIs using a load
balancer fronting a single proxy.</p>
</li>
<li>
<p>2022-03-01: <strong>Schema version 1.7.</strong></p>
<p>Add <code>ignoreExtraEvents</code> field to <code>expectedEventsForClient</code>.</p>
</li>
<li>
<p>2022-02-24: Rename Versioned API to Stable API</p>
</li>
<li>
<p>2021-08-30: <strong>Schema version 1.6.</strong></p>
<p>Add <code>hasServerConnectionId</code> field to <code>commandStartedEvent</code>, <code>commandSuccededEvent</code> and <code>commandFailedEvent</code>.</p>
</li>
<li>
<p>2021-08-30: Test runners may create an internal MongoClient for each mongos. Better clarify how internal MongoClients
may be used. Clarify that drivers creating an internal MongoClient for each mongos should use those clients for
<code>targetedFailPoint</code> operations.</p>
</li>
<li>
<p>2021-08-23: Allow <code>runOnRequirement</code> conditions to be evaluated in any order.</p>
</li>
<li>
<p>2021-08-09: Updated all existing schema files to require at least one element in <code>test.expectEvents</code> if specified.</p>
</li>
<li>
<p>2021-07-29: Note that events for sensitive commands will have redacted commands and replies when using
<code>observeSensitiveCommands</code>, and how that affects conditionally sensitive commands such as <code>hello</code> and legacy hello.</p>
</li>
<li>
<p>2021-07-01: Note that <code>expectError.expectResult</code> should use <code>$$unsetOrMatches</code> when the result is optional.</p>
</li>
<li>
<p>2021-06-09: <strong>Schema version 1.5.</strong></p>
<p>Added an <code>observeSensitiveCommands</code> property to the <code>client</code> entity type.</p>
</li>
<li>
<p>2021-05-17: Ensure old JSON schema files remain in place</p>
</li>
<li>
<p>2021-04-19: <strong>Schema version 1.4.</strong></p>
<p>Introduce <code>serverless</code> <a href="unified-test-format/unified-test-format.html#runonrequirement">runOnRequirement</a>.</p>
</li>
<li>
<p>2021-04-12: <strong>Schema version 1.3.</strong></p>
<p>Added a <code>FindCursor</code> entity type. Defined a set of cursor operations. Added an <code>auth</code> property to <code>runOnRequirements</code>
and modified the <code>topologies</code> property to accept <code>load-balanced</code>. Added CMAP events to the possible event types for
<code>expectedEvent</code>. Add <code>assertNumberConnectionsCheckedOut</code> operation. Add <code>ignoreResultAndError</code> operation option.</p>
</li>
<li>
<p>2021-04-08: List additional error codes that may be ignored when calling <code>killAllSessions</code> and note that the command
should not be called when connected to Atlas.</p>
</li>
<li>
<p>2021-03-22: Split <code>serverApi</code> into its own section. Note types for <code>loop</code> operation arguments. Clarify how <code>loop</code>
iterations are counted for <code>storeIterationsAsEntity</code>.</p>
</li>
<li>
<p>2021-03-10: Clarify that <code>observedAt</code> field measures time in seconds for <code>storeEventsAsEntities</code>.</p>
</li>
<li>
<p>2021-03-09: Clarify which components of a version string are relevant for comparisons.</p>
</li>
<li>
<p>2021-03-04: Change <code>storeEventsAsEntities</code> from a map to an array of <code>storeEventsAsEntity</code> objects.</p>
</li>
<li>
<p>2021-03-01: <strong>Schema version 1.2.</strong></p>
<p>Added <code>storeEventsAsEntities</code> option for client entities and <code>loop</code> operation, which is needed for Atlas Driver
Testing.</p>
</li>
<li>
<p>2020-12-23: Clarify how JSON schema is renamed for new minor versions.</p>
</li>
<li>
<p>2020-11-06: <strong>Schema version 1.1.</strong></p>
<p>Added <code>serverApi</code> option for client entities, <code>_yamlAnchors</code> property to define values for later use in YAML tests,
and <code>serverParameters</code> property for <code>runOnRequirements</code>.</p>
</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="atlas-data-lake-tests"><a class="header" href="#atlas-data-lake-tests">Atlas Data Lake Tests</a></h1>
<h2 id="introduction-1"><a class="header" href="#introduction-1">Introduction</a></h2>
<p>The YAML and JSON files in this directory are platform-independent tests that drivers can use to assert compatibility
with <a href="https://www.mongodb.com/docs/datalake/">Atlas Data Lake</a>. These tests utilize the
<a href="atlas-data-lake-testing/tests/../../unified-test-format/unified-test-format.html">Unified Test Format</a>.</p>
<p>Several prose tests, which are not easily expressed in YAML, are also presented in this file. Those tests will need to
be manually implemented by each driver.</p>
<h2 id="test-considerations"><a class="header" href="#test-considerations">Test Considerations</a></h2>
<p>Running these integration tests will require a running <code>mongohoused</code> with data available in its <code>test.driverdata</code>
collection. See the
<a href="https://github.com/mongodb-labs/drivers-evergreen-tools/tree/master/.evergreen/atlas_data_lake">ADL directory in drivers-evergreen-tools</a>
and <a href="https://github.com/10gen/mongohouse/blob/master/README.md">10gen/mongohouse README</a> for more information.</p>
<p>The test runner for Atlas Data Lake testing MUST NOT drop the collection and/or database under test. In contrast to most
other tests, which insert their own data fixtures into an empty collection, the data for these tests is specified in the
<code>mongohoused</code> configuration file.</p>
<p>Additionally, the test runner MUST NOT execute <code>killAllSessions</code> (see:
<a href="atlas-data-lake-testing/tests/../../unified-test-format/unified-test-format.html#terminating-open-transactions">Terminating Open Transactions</a>) when
connected to Atlas Data Lake.</p>
<h2 id="prose-tests-1"><a class="header" href="#prose-tests-1">Prose Tests</a></h2>
<p>The following tests MUST be implemented to fully test compatibility with Atlas Data Lake.</p>
<h3 id="1-support-for-killcursors-command"><a class="header" href="#1-support-for-killcursors-command">1. Support for <code>killCursors</code> command</a></h3>
<p>Test that the driver properly constructs and issues a
<a href="https://www.mongodb.com/docs/manual/reference/command/killCursors/">killCursors</a> command to Atlas Data Lake. For this
test, configure an APM listener on a client and execute a query on the <code>test.driverdata</code> collection that will leave a
cursor open on the server (e.g. specify <code>batchSize=2</code> for a query that would match 3+ documents). Drivers MAY iterate
the cursor if necessary to execute the initial <code>find</code> command but MUST NOT iterate further to avoid executing a
<code>getMore</code>.</p>
<p>Observe the CommandSucceededEvent event for the <code>find</code> command and extract the cursor's ID and namespace from the
response document's <code>cursor.id</code> and <code>cursor.ns</code> fields, respectively. Destroy the cursor object and observe a
CommandStartedEvent and CommandSucceededEvent for the <code>killCursors</code> command. Assert that the cursor ID and target
namespace in the outgoing command match the values from the <code>find</code> command's CommandSucceededEvent. When matching the
namespace, note that the <code>killCursors</code> field will contain the collection name and the database may be inferred from
either the <code>$db</code> field or accessed via the CommandStartedEvent directly. Finally, assert that the <code>killCursors</code>
CommandSucceededEvent indicates that the expected cursor was killed in the <code>cursorsKilled</code> field.</p>
<p>Note: this test assumes that drivers only issue a <code>killCursors</code> command internally when destroying a cursor that may
still exist on the server. If a driver constructs and issues <code>killCursors</code> commands in other ways (e.g. public API),
this test MUST be adapted to test all such code paths.</p>
<h3 id="2-connect-without-authentication"><a class="header" href="#2-connect-without-authentication">2. Connect without authentication</a></h3>
<p>Test that the driver can establish a connection with Atlas Data Lake without authentication. For these tests, create a
MongoClient using a valid connection string without auth credentials and execute a ping command.</p>
<h3 id="3-connect-with-authentication"><a class="header" href="#3-connect-with-authentication">3. Connect with authentication</a></h3>
<p>Test that the driver can establish a connection with Atlas Data Lake with authentication. For these tests, create a
MongoClient using a valid connection string with SCRAM-SHA-1 and credentials from the drivers-evergreen-tools ADL
configuration and execute a ping command. Repeat this test using SCRAM-SHA-256.</p>
<h2 id="changelog-48"><a class="header" href="#changelog-48">Changelog</a></h2>
<ul>
<li>
<p>2024-03-08: Convert legacy ADL tests to unified format. Convert test README from reStructuredText to Markdown.</p>
</li>
<li>
<p>2022-10-05: Add spec front matter</p>
</li>
<li>
<p>2020-07-15: Link to CRUD test runner implementation and note that the collection under test must not be dropped before
each test.</p>
</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="performance-benchmarking"><a class="header" href="#performance-benchmarking">Performance Benchmarking</a></h1>
<ul>
<li>Status: Accepted</li>
<li>Minimum Server Version: N/A</li>
</ul>
<h2 id="abstract-45"><a class="header" href="#abstract-45">Abstract</a></h2>
<p>This document describes a standard benchmarking suite for MongoDB drivers.</p>
<h2 id="overview"><a class="header" href="#overview">Overview</a></h2>
<h3 id="name-and-purpose"><a class="header" href="#name-and-purpose">Name and purpose</a></h3>
<p>Driver performance will be measured by the MongoDB Driver Performance Benchmark (AKA "DriverBench"). It will provide
both "horizontal" insights into how individual language driver performance evolves over time and "vertical" insights
into relative performance of different drivers.</p>
<p>We do expect substantial performance differences between language families (e.g. static vs. dynamic or compiled vs.
virtual-machine-based). However we still expect "vertical" comparison within language families to expose outlier
behavior that might be amenable to optimization.</p>
<h3 id="task-hierarchy"><a class="header" href="#task-hierarchy">Task Hierarchy</a></h3>
<p>The benchmark consists of a number of micro-benchmarks tasks arranged into groups of increasing complexity. This allows
us to better isolate areas within drivers that are faster or slower.</p>
<ul>
<li>BSON -- BSON encoding/decoding tasks, to explore BSON codec efficiency</li>
<li>Single-Doc -- single-document insertion and query tasks, to explore basic wire protocol efficiency</li>
<li>Multi-Doc -- multi-document insertion and query tasks, to explore batch-write and cursor chunking efficiency</li>
<li>Parallel -- multi-process/thread ETL tasks, to explore concurrent operation efficiency</li>
</ul>
<h3 id="measurement"><a class="header" href="#measurement">Measurement</a></h3>
<p>In addition to timing data, all micro-benchmark tasks will be measured in terms of "megabytes/second" (MB/s) of
documents processed, with higher scores being better. (In this document, "megabyte" refers to the SI decimal unit, i.e.
1,000,000 bytes.) This makes cross-benchmark comparisons easier.</p>
<p>To avoid various types of measurement skew, tasks will be measured over numerous iterations. Each iteration will have a
"scale" -- the number of similar operations performed -- that will vary by task. The final score for a task will be the
median score of the iterations. Other quantiles will be recorded for diagnostic analysis.</p>
<h3 id="data-sets"><a class="header" href="#data-sets">Data sets</a></h3>
<p>Data sets will vary by micro-benchmark. In some cases, they it will be a synthetically generated document inserted
repeatedly (with different <code>_id</code> fields) to construct an overall corpus of documents. In other cases, data sets will be
synthetic line-delimited JSON files or mock binary files.</p>
<h3 id="composite-scores"><a class="header" href="#composite-scores">Composite scores</a></h3>
<p>Micro-benchmark scores will be combined into a composite for each weight class ("BSONBench", "SingleBench", etc.) and
for read and write operations ("ReadBench" and "WriteBench"). The read and write scores will be combined into an
aggregate composite score ("DriverBench"). The compositing formula in the DriverBench uses simple averages with equal
weighting.</p>
<h3 id="versioning"><a class="header" href="#versioning">Versioning</a></h3>
<p>DriverBench will have vX.Y versioning. Minor updates and clarifications will increment "Y" and should have little impact
on score comparison. Major changes, such as changing score weights, MongoDB version tested against, or hardware used,
will increment "X" to indicate that older version scores are unlikely to be comparable.</p>
<h2 id="benchmark-execution-phases-and-measurement"><a class="header" href="#benchmark-execution-phases-and-measurement">Benchmark execution phases and measurement</a></h2>
<p>All micro-benchmark tasks will be conducted via a number of iterations. Each iteration will be timed and will generally
include a large number of individual driver operations.</p>
<p>We break up the measurement this way to better isolate the benchmark from external volatility. If we consider the
problem of benchmarking an operation over many iterations, such as 100,000 document insertions, we want to avoid two
extreme forms of measurement:</p>
<ul>
<li>measuring a single insertion 100,000 times -- in this case, the timing code is likely to be a greater proportion of
executed code, which could routinely evict the insertion code from CPU caches or mislead a JIT optimizer and throw off
results</li>
<li>measuring 100,000 insertions one time -- in this case, the longer the timer runs, the higher the likelihood that an
external event occurs that affects the time of the run</li>
</ul>
<p>Therefore, we choose a middle ground:</p>
<ul>
<li>measuring the same 1000 insertions over 100 iterations -- each timing run includes enough operations that insertion
code dominates timing code; unusual system events are likely to affect only a fraction of the 100 timing measurements</li>
</ul>
<p>With 100 timings of inserting the same 1000 documents, we build up a statistical distribution of the operation timing,
allowing a more robust estimate of performance than a single measurement. (In practice, the number of iterations could
exceed 100, but 100 is a reasonable minimum goal.)</p>
<p>Because a timing distribution is bounded by zero on one side, taking the mean would allow large positive outlier
measurements to skew the result substantially. Therefore, for the benchmark score, we use the median timing measurement,
which is robust in the face of outliers.</p>
<p>Each benchmark is structured into discrete setup/execute/teardown phases. Phases are as follows, with specific details
given in a subsequent section:</p>
<ul>
<li>setup -- (ONCE PER MICRO-BENCHMARK) something to do once before any benchmarking, e.g. construct a client object, load
test data, insert data into a collection, etc.</li>
<li>before task -- (ONCE PER ITERATION) something to do before every task iteration, e.g. drop a collection, or reload
test data (if the test run modifies it), etc.</li>
<li>do task -- (ONCE PER ITERATION) smallest amount of code necessary to execute the task; e.g. insert 1000 documents one
by one into the database, or retrieve 1000 document of test data from the database, etc.</li>
<li>after task -- (ONCE PER ITERATION) something to do after every task iteration (if necessary)</li>
<li>teardown -- (ONCE PER MICRO-BENCHMARK) something done once after all benchmarking is complete (if necessary); e.g.
drop the test database</li>
</ul>
<p>The wall-clock execution time of each "do task" phase will be recorded. We use wall clock time to model user experience
and as a lowest-common denominator across languages and threading models. Iteration timing should be done with a
high-resolution monotonic timer (or best language approximation).</p>
<p>Unless otherwise specified, the number of iterations to measure per micro-benchmark is variable:</p>
<ul>
<li>iterations should loop for at least 1 minute cumulative execution time</li>
<li>iterations should stop after 100 iterations or 5 minutes cumulative execution time, whichever is shorter</li>
</ul>
<p>This balances measurement stability with a timing cap to ensure all micro-benchmarks can complete in a reasonable time.
Languages with JIT compilers may do warm up iterations for which timings are discarded.</p>
<p>For each micro-benchmark, the 10th, 25th, 50th, 75th, 90th, 95th, 98th and 99th percentiles will be recorded using the
following algorithm:</p>
<ul>
<li>Given a 0-indexed array A of N iteration wall clock times</li>
<li>Sort the array into ascending order (i.e. shortest time first)</li>
<li>Let the index i for percentile p in the range [1,100] be defined as: <code>i = int(N * p / 100) - 1</code></li>
</ul>
<p><em>N.B. This is the <a href="https://en.wikipedia.org/wiki/Percentile#The_Nearest_Rank_method">Nearest Rank</a> algorithm, chosen for
its utter simplicity given that it needs to be implemented identically across multiple languages for every driver.</em></p>
<p>The 50th percentile (i.e. the median) will be used for score composition. Other percentiles will be stored for
visualizations and analysis (e.g. a "candlestick" chart showing benchmark volatility over time).</p>
<p>Each task will have defined for it an associated size in megabytes (MB). The score for micro-benchmark composition will
be the task size in MB divided by the median wall clock time.</p>
<h2 id="micro-benchmark-definitions"><a class="header" href="#micro-benchmark-definitions">Micro-benchmark definitions</a></h2>
<p>Datasets are available in the <code>data</code> directory adjacent to this spec.</p>
<p>Note: The term "LDJSON" means "line-delimited JSON", which should be understood to mean a collection of UTF-8 encoded
JSON documents (without embedded CR or LF characters), separated by a single LF character. (Some Internet definition of
line-delimited JSON use CRLF delimiters, but this benchmark uses only LF.)</p>
<h3 id="bson-micro-benchmarks"><a class="header" href="#bson-micro-benchmarks">BSON micro-benchmarks</a></h3>
<p>Datasets are in the 'extended_bson' tarball.</p>
<p>BSON tests focus on BSON encoding and decoding; they are client-side only and do not involve any transmission of data to
or from the benchmark server. When appropriate, data sets will be stored on disk as
<a href="https://www.mongodb.com/docs/manual/reference/mongodb-extended-json">extended strict JSON</a>. For drivers that don't
support extended JSON, a BSON analogue will be provided as well.</p>
<p>BSON micro-benchmarks include:</p>
<ul>
<li>Flat BSON Encoding and Flat BSON Decoding -- shallow documents with only common BSON field types</li>
<li>Deep BSON Encoding and Deep BSON Decoding -- deeply nested documents with only common BSON field types</li>
<li>Full BSON Encoding and Full BSON Decoding -- shallow documents with all possible BSON field types</li>
</ul>
<h4 id="flat-bson-encoding"><a class="header" href="#flat-bson-encoding">Flat BSON Encoding</a></h4>
<p>Summary: This benchmark tests driver performance encoding documents with top level key/value pairs involving the most
commonly-used BSON types.</p>
<p>Dataset: The dataset, designated FLAT_BSON (ftnt4 Disk file 'flat_bson.json'), will be synthetically generated and
consist of an extended JSON document with a single <code>_id</code> key with an object ID value plus 24 top level keys/value pairs
of the following types: string, Int32, Int64, Double, Boolean. (121 total key/value pairs) Keys will be random ASCII
strings of length 8. String data will be random ASCII strings of length 80.</p>
<p>Dataset size: For score purposes, the dataset size for a task is the size of the single-document source file (7531
bytes) times 10,000 operations, which equals 75,310,000 bytes or 75.31 MB.</p>
<div class="table-wrapper"><table><thead><tr><th>Phase</th><th>Description</th></tr></thead><tbody>
<tr><td>Setup</td><td>Load the FLAT_BSON dataset into memory as a language-appropriate document types. For languages like C without a document type, the raw JSON string for each document should be used instead.</td></tr>
<tr><td>Before task</td><td>n/a</td></tr>
<tr><td>Do task</td><td>Encode the FLAT_BSON document to a BSON byte-string. Repeat this 10,000 times.</td></tr>
<tr><td>After task</td><td>n/a</td></tr>
<tr><td>Teardown</td><td>n/a</td></tr>
</tbody></table>
</div>
<h4 id="flat-bson-decoding"><a class="header" href="#flat-bson-decoding">Flat BSON Decoding</a></h4>
<p>Summary: This benchmark tests driver performance decoding documents with top level key/value pairs involving the most
commonly-used BSON types.</p>
<p>Dataset: The dataset, designated FLAT_BSON, will be synthetically generated and consist of an extended JSON document
with a single <code>_id</code> key with an object ID value plus 24 top level keys/value pairs of each of the following types:
string, Int32, Int64, Double, Boolean. (121 total key/value pairs) Keys will be random ASCII strings of length 8. String
data will be random ASCII strings of length 80.</p>
<p>Dataset size: For score purposes, the dataset size for a task is the size of the single-document source file (7531
bytes) times 10,000 operations, which equals 75,310,000 bytes or 75.31 MB.</p>
<div class="table-wrapper"><table><thead><tr><th>Phase</th><th>Description</th></tr></thead><tbody>
<tr><td>Setup</td><td>Load the FLAT_BSON dataset into memory as a language-appropriate document types. For languages like C without a document type, the raw JSON string for each document should be used instead. Encode it to a BSON byte-string.</td></tr>
<tr><td>Before task</td><td>n/a</td></tr>
<tr><td>Do task</td><td>Decode the BSON byte-string to a language-appropriate document type. Repeat this 10,000 times. For languages like C without a document type, decode to extended JSON instead.</td></tr>
<tr><td>After task</td><td>n/a</td></tr>
<tr><td>Teardown</td><td>n/a</td></tr>
</tbody></table>
</div>
<h4 id="deep-bson-encoding"><a class="header" href="#deep-bson-encoding">Deep BSON Encoding</a></h4>
<p>Summary: This benchmark tests driver performance encoding documents with deeply nested key/value pairs involving
subdocuments, strings, integers, doubles and booleans.</p>
<p>Dataset: The dataset, designated DEEP_BSON (disk file 'deep_bson.json'), will be synthetically generated and consist of
an extended JSON document representing a balanced binary tree of depth 6, with "left" and "right" keys at each level
containing a sub-document until the final level, which will contain a random ASCII string of length 8 (126 total
key/value pairs).</p>
<p>Dataset size: For score purposes, the dataset size for a task is the size of the single-document source file (1964
bytes) times 10,000 operations, which equals 19,640,000 bytes or 19.64 MB.</p>
<div class="table-wrapper"><table><thead><tr><th>Phase</th><th>Description</th></tr></thead><tbody>
<tr><td>Setup</td><td>Load the DEEP_BSON dataset into memory as a language-appropriate document type. For languages like C without a document type, the raw JSON string for each document should be used instead.</td></tr>
<tr><td>Before task</td><td>n/a</td></tr>
<tr><td>Do task</td><td>Encode the DEEP_BSON document to a BSON byte-string. Repeat this 10,000 times.</td></tr>
<tr><td>After task</td><td>n/a</td></tr>
<tr><td>Teardown</td><td>n/a</td></tr>
</tbody></table>
</div>
<h4 id="deep-bson-decoding"><a class="header" href="#deep-bson-decoding">Deep BSON Decoding</a></h4>
<p>Summary: This benchmark tests driver performance decoding documents with deeply nested key/value pairs involving
subdocuments, strings, integers, doubles and booleans.</p>
<p>Dataset: The dataset, designated DEEP_BSON, will be synthetically generated and consist of an extended JSON document
representing a balanced binary tree of depth 6, with "left" and "right" keys at each level containing a sub-document
until the final level, which will contain a random ASCII string of length 8 (126 total key/value pairs).</p>
<p>Dataset size: For score purposes, the dataset size for a task is the size of the single-document source file (1964
bytes) times 10,000 operations, which equals 19,640,000 bytes or 19.64 MB.</p>
<div class="table-wrapper"><table><thead><tr><th>Phase</th><th>Description</th></tr></thead><tbody>
<tr><td>Setup</td><td>Load the DEEP_BSON dataset into memory as a language-appropriate document types. For languages like C without a document type, the raw JSON string for each document should be used instead. Encode it to a BSON byte-string.</td></tr>
<tr><td>Before task</td><td>n/a</td></tr>
<tr><td>Do task</td><td>Decode the BSON byte-string to a language-appropriate document type. Repeat this 10,000 times. For languages like C without a document type, decode to extended JSON instead.</td></tr>
<tr><td>After task</td><td>n/a</td></tr>
<tr><td>Teardown</td><td>n/a</td></tr>
</tbody></table>
</div>
<h4 id="full-bson-encoding"><a class="header" href="#full-bson-encoding">Full BSON Encoding</a></h4>
<p>Summary: This benchmark tests driver performance encoding documents with top level key/value pairs involving the full
range of BSON types.</p>
<p>Dataset: The dataset, designated FULL_BSON (disk file 'full_bson.json'), will be synthetically generated and consist of
an extended JSON document with a single <code>_id</code> key with an object ID value plus 6 each of the following types: string,
double, Int64, Int32, boolean, minkey, maxkey, array, binary data, UTC datetime, regular expression, Javascript code,
Javascript code with context, and timestamp. (91 total keys.) Keys (other than <code>_id</code>) will be random ASCII strings of
length 8. Strings values will be random ASCII strings with length 80.</p>
<p>Dataset size: For score purposes, the dataset size for a task is the size of the single-document source file (5734
bytes) times 10,000 operations, which equals 57,340,000 bytes or 57.34 MB.</p>
<div class="table-wrapper"><table><thead><tr><th>Phase</th><th>Description</th></tr></thead><tbody>
<tr><td>Setup</td><td>Load the FULL_BSON dataset into memory as a language-appropriate document type. For languages like C without a document type, the raw JSON string for each document should be used instead.</td></tr>
<tr><td>Before task</td><td>n/a</td></tr>
<tr><td>Do task</td><td>Encode the FULL_BSON document to a BSON byte-string. Repeat this 10,000 times.</td></tr>
<tr><td>After task</td><td>n/a</td></tr>
<tr><td>Teardown</td><td>n/a</td></tr>
</tbody></table>
</div>
<h4 id="full-bson-decoding"><a class="header" href="#full-bson-decoding">Full BSON Decoding</a></h4>
<p>Summary: This benchmark tests driver performance decoding documents with top level key/value pairs involving the full
range of BSON types.</p>
<p>Dataset: The dataset, designated FULL_BSON, will be synthetically generated and consist of an extended JSON document
with a single <code>_id</code> key with an object ID value plus 6 each of the following types: string, double, Int64, Int32,
boolean, minkey, maxkey, array, binary data, UTC datetime, regular expression, Javascript code, Javascript code with
context, and timestamp. (91 total keys.) Keys (other than <code>_id</code>) will be random ASCII strings of length 8. Strings
values will be random ASCII strings with length 80.</p>
<p>Dataset size: For score purposes, the dataset size for a task is the size of the single-document source file (5734
bytes) times 10,000 operations, which equals 57,340,000 bytes or 57.34 MB.</p>
<div class="table-wrapper"><table><thead><tr><th>Phase</th><th>Description</th></tr></thead><tbody>
<tr><td>Setup</td><td>Load the FULL_BSON dataset into memory as a language-appropriate document types. For languages like C without a document type, the raw JSON string for each document should be used instead. Encode it to a BSON byte-string.</td></tr>
<tr><td>Before task</td><td>n/a</td></tr>
<tr><td>Do task</td><td>Decode the BSON byte-string to a language-appropriate document type. Repeat this 10,000 times. For languages like C without a document type, decode to extended JSON instead.</td></tr>
<tr><td>After task</td><td>n/a</td></tr>
<tr><td>Teardown</td><td>n/a</td></tr>
</tbody></table>
</div>
<h3 id="single-doc-benchmarks"><a class="header" href="#single-doc-benchmarks">Single-Doc Benchmarks</a></h3>
<p>Datasets are in the 'single_and_multi_document' tarball.</p>
<p>Single-doc tests focus on single-document read and write operations. They are designed to give insights into the
efficiency of the driver's implementation of the basic wire protocol.</p>
<p>The data will be stored as strict JSON with no extended types.</p>
<p>Single-doc micro-benchmarks include:</p>
<ul>
<li>Run command</li>
<li>Find one by ID</li>
<li>Small doc insertOne</li>
<li>Large doc insertOne</li>
</ul>
<h4 id="run-command-1"><a class="header" href="#run-command-1">Run command</a></h4>
<p>Summary: This benchmark tests driver performance sending a command to the database and reading a response.</p>
<p>Dataset: n/a</p>
<p>Dataset size: While there is no external dataset, for score calculation purposes use 130,000 bytes (10,000 x the size of
a BSON {hello:true} command).</p>
<p><em>N.B. We use {hello:true} rather than {hello:1} to ensure a consistent command size.</em></p>
<div class="table-wrapper"><table><thead><tr><th>Phase</th><th>Description</th></tr></thead><tbody>
<tr><td>Setup</td><td>Construct a MongoClient object. Construct whatever language-appropriate objects (Database, etc.) would be required to send a command.</td></tr>
<tr><td>Before task</td><td>n/a</td></tr>
<tr><td>Do task</td><td>Run the command {hello:true} 10,000 times, reading (and discarding) the result each time.</td></tr>
<tr><td>After task</td><td>n/a</td></tr>
<tr><td>Teardown</td><td>n/a</td></tr>
</tbody></table>
</div>
<h4 id="find-one-by-id"><a class="header" href="#find-one-by-id">Find one by ID</a></h4>
<p>Summary: This benchmark tests driver performance sending an indexed query to the database and reading a single document
in response.</p>
<p>Dataset: The dataset, designated TWEET (disk file 'tweet.json'), consists of a sample tweet stored as strict JSON.</p>
<p>Dataset size: For score purposes, the dataset size for a task is the size of the single-document source file (1622
bytes) times 10,000 operations, which equals 16,220,000 bytes or 16.22 MB.</p>
<div class="table-wrapper"><table><thead><tr><th>Phase</th><th>Description</th></tr></thead><tbody>
<tr><td>Setup</td><td>Construct a MongoClient object. Drop the 'perftest' database. Load the TWEET document into memory as a language-appropriate document type (or JSON string for C). Construct a Collection object for the 'corpus' collection to use for querying. Insert the document 10,000 times to the 'perftest' database in the 'corpus' collection using sequential <code>_id</code> values. (1 to 10,000)</td></tr>
<tr><td>Before task</td><td>n/a</td></tr>
<tr><td>Do task</td><td>For each of the 10,000 sequential <code>_id</code> numbers, issue a find command for that <code>_id</code> on the 'corpus' collection and retrieve the single-document result.</td></tr>
<tr><td>After task</td><td>n/a</td></tr>
<tr><td>Teardown</td><td>Drop the 'perftest' database.</td></tr>
</tbody></table>
</div>
<h4 id="small-doc-insertone"><a class="header" href="#small-doc-insertone">Small doc insertOne</a></h4>
<p>Summary: This benchmark tests driver performance inserting a single, small document to the database.</p>
<p>Dataset: The dataset, designated SMALL_DOC (disk file 'small_doc.json'), consists of a JSON document with an encoded
length of approximately 250 bytes.</p>
<p>Dataset size: For score purposes, the dataset size for a task is the size of the single-document source file (275 bytes)
times 10,000 operations, which equals 2,750,000 bytes or 2.75 MB.</p>
<div class="table-wrapper"><table><thead><tr><th>Phase</th><th>Description</th></tr></thead><tbody>
<tr><td>Setup</td><td>Construct a MongoClient object. Drop the 'perftest' database. Load the SMALL_DOC dataset into memory as a language-appropriate document type (or JSON string for C).</td></tr>
<tr><td>Before task</td><td>Drop the 'corpus' collection. Create an empty 'corpus' collection with the 'create' command. Construct a Collection object for the 'corpus' collection to use for insertion.</td></tr>
<tr><td>Do task</td><td>Insert the document with the insertOne CRUD method. DO NOT manually add an <code>_id</code> field; leave it to the driver or database. Repeat this 10,000 times.</td></tr>
<tr><td>After task</td><td>n/a</td></tr>
<tr><td>Teardown</td><td>Drop the 'perftest' database.</td></tr>
</tbody></table>
</div>
<h4 id="large-doc-insertone"><a class="header" href="#large-doc-insertone">Large doc insertOne</a></h4>
<p>Summary: This benchmark tests driver performance inserting a single, large document to the database.</p>
<p>Dataset: The dataset, designated LARGE_DOC (disk file 'large_doc.json'), consists of a JSON document with an encoded
length of approximately 2,500,000 bytes.</p>
<p>Dataset size: For score purposes, the dataset size for a task is the size of the single-document source file (2,731,089
bytes) times 10 operations, which equals 27,310,890 bytes or 27.31 MB.</p>
<div class="table-wrapper"><table><thead><tr><th>Phase</th><th>Description</th></tr></thead><tbody>
<tr><td>Setup</td><td>Construct a MongoClient object. Drop the 'perftest' database. Load the LARGE_DOC dataset into memory as a language-appropriate document type (or JSON string for C).</td></tr>
<tr><td>Before task</td><td>Drop the 'corpus' collection. Create an empty 'corpus' collection with the 'create' command. Construct a Collection object for the 'corpus' collection to use for insertion.</td></tr>
<tr><td>Do task</td><td>Insert the document with the insertOne CRUD method. DO NOT manually add an <code>_id</code> field; leave it to the driver or database. Repeat this 10 times.</td></tr>
<tr><td>After task</td><td>n/a</td></tr>
<tr><td>Teardown</td><td>Drop the 'perftest' database.</td></tr>
</tbody></table>
</div>
<h3 id="multi-doc-benchmarks"><a class="header" href="#multi-doc-benchmarks">Multi-Doc Benchmarks</a></h3>
<p>Datasets are in the 'single_and_multi_document' tarball.</p>
<p>Multi-doc benchmarks focus on multiple-document read and write operations. They are designed to give insight into the
efficiency of the driver's implementation of bulk/batch operations such as bulk writes and cursor reads.</p>
<p>Multi-doc micro-benchmarks include:</p>
<ul>
<li>Find many and empty the cursor</li>
<li>Small doc bulk insert</li>
<li>Large doc bulk insert</li>
<li>GridFS upload</li>
<li>GridFS download</li>
</ul>
<h4 id="find-many-and-empty-the-cursor"><a class="header" href="#find-many-and-empty-the-cursor">Find many and empty the cursor</a></h4>
<p>Summary: This benchmark tests driver performance retrieving multiple documents from a query.</p>
<p>Dataset: The dataset, designated TWEET consists of a sample tweet stored as strict JSON.</p>
<p>Dataset size: For score purposes, the dataset size for a task is the size of the single-document source file (1622
bytes) times 10,000 operations, which equals 16,220,000 bytes or 16.22 MB.</p>
<div class="table-wrapper"><table><thead><tr><th>Phase</th><th>Description</th></tr></thead><tbody>
<tr><td>Setup</td><td>Construct a MongoClient object. Drop the 'perftest' database. Load the TWEET dataset into memory as a language-appropriate document type (or JSON string for C). Construct a Collection object for the 'corpus' collection to use for querying. Insert the document 10,000 times to the 'perftest' database in the 'corpus' collection. (Let the driver generate <code>_id</code>s).</td></tr>
<tr><td>Before task</td><td>n/a</td></tr>
<tr><td>Do task</td><td>Issue a find command on the 'corpus' collection with an empty filter expression. Retrieve (and discard) all documents from the cursor.</td></tr>
<tr><td>After task</td><td>n/a</td></tr>
<tr><td>Teardown</td><td>Drop the 'perftest' database.</td></tr>
</tbody></table>
</div>
<h4 id="small-doc-bulk-insert"><a class="header" href="#small-doc-bulk-insert">Small doc bulk insert</a></h4>
<p>Summary: This benchmark tests driver performance inserting multiple, small documents to the database.</p>
<p>Dataset: The dataset, designated SMALL_DOC consists of a JSON document with an encoded length of approximately 250
bytes.</p>
<p>Dataset size: For score purposes, the dataset size for a task is the size of the single-document source file (275 bytes)
times 10,000 operations, which equals 2,750,000 bytes or 2.75 MB.</p>
<div class="table-wrapper"><table><thead><tr><th>Phase</th><th>Description</th></tr></thead><tbody>
<tr><td>Setup</td><td>Construct a MongoClient object. Drop the 'perftest' database. Load the SMALL_DOC dataset into memory as a language-appropriate document type (or JSON string for C).</td></tr>
<tr><td>Before task</td><td>Drop the 'corpus' collection. Create an empty 'corpus' collection with the 'create' command. Construct a Collection object for the 'corpus' collection to use for insertion.</td></tr>
<tr><td>Do task</td><td>Do an ordered 'insert_many' with 10,000 copies of the document. DO NOT manually add an <code>_id</code> field; leave it to the driver or database.</td></tr>
<tr><td>After task</td><td>n/a</td></tr>
<tr><td>Teardown</td><td>Drop the 'perftest' database.</td></tr>
</tbody></table>
</div>
<h4 id="large-doc-bulk-insert"><a class="header" href="#large-doc-bulk-insert">Large doc bulk insert</a></h4>
<p>Summary: This benchmark tests driver performance inserting multiple, large documents to the database.</p>
<p>Dataset: The dataset, designated LARGE_DOC consists of a JSON document with an encoded length of approximately 2,500,000
bytes.</p>
<p>Dataset size: For score purposes, the dataset size for a task is the size of the single-document source file (2,731,089
bytes) times 10 operations, which equals 27,310,890 bytes or 27.31 MB.</p>
<div class="table-wrapper"><table><thead><tr><th>Phase</th><th>Description</th></tr></thead><tbody>
<tr><td>Setup</td><td>Construct a MongoClient object. Drop the 'perftest' database. Load the LARGE_DOC dataset into memory as a language-appropriate document type (or JSON string for C).</td></tr>
<tr><td>Before task</td><td>Drop the 'corpus' collection. Create an empty 'corpus' collection with the 'create' command. Construct a Collection object for the 'corpus' collection to use for insertion.</td></tr>
<tr><td>Do task</td><td>Do an ordered 'insert_many' with 10 copies of the document. DO NOT manually add an <code>_id</code> field; leave it to the driver or database.</td></tr>
<tr><td>After task</td><td>n/a</td></tr>
<tr><td>Teardown</td><td>Drop the 'perftest' database.</td></tr>
</tbody></table>
</div>
<h4 id="gridfs-upload"><a class="header" href="#gridfs-upload">GridFS upload</a></h4>
<p>Summary: This benchmark tests driver performance uploading a GridFS file from memory.</p>
<p>Dataset: The dataset, designated GRIDFS_LARGE (disk file 'gridfs_large.bin'), consists of a single file containing about
50 MB of random data. We use a large file to ensure multiple database round-trips even if chunks are are sent in
batches.</p>
<p>Dataset size: For score purposes, the dataset size for a task is the size of the source file (52,428,800 bytes) times 1
operation or 52.43 MB.</p>
<div class="table-wrapper"><table><thead><tr><th>Phase</th><th>Description</th></tr></thead><tbody>
<tr><td>Setup</td><td>Construct a MongoClient object. rop the 'perftest' database. Load the GRIDFS_LARGE file as a string or other language-appropriate type for binary octet data.</td></tr>
<tr><td>Before task</td><td>Drop the default GridFS bucket. Insert a 1-byte file into the bucket. (This ensures the bucket collections and indices have been created.) Construct a GridFSBucket object to use for uploads.</td></tr>
<tr><td>Do task</td><td>Upload the GRIDFS_LARGE data as a GridFS file. Use whatever upload API is most natural for each language (e.g. open_upload_stream(), write the data to the stream and close the stream).</td></tr>
<tr><td>After task</td><td>n/a</td></tr>
<tr><td>Teardown</td><td>Drop the 'perftest' database.</td></tr>
</tbody></table>
</div>
<h4 id="gridfs-download"><a class="header" href="#gridfs-download">GridFS download</a></h4>
<p>Summary: This benchmark tests driver performance downloading a GridFS file to memory.</p>
<p>Dataset: The dataset, designated GRIDFS_LARGE, consists of a single file containing about 50 MB of random data. We use a
large file to ensure multiple database round-trips even if chunks are are sent in batches.</p>
<p>Dataset size: For score purposes, the dataset size for a task is the size of the source file (52,428,800 bytes) times 1
operation or 52.43 MB.</p>
<div class="table-wrapper"><table><thead><tr><th>Phase</th><th>Description</th></tr></thead><tbody>
<tr><td>Setup</td><td>Construct a MongoClient object. Drop the 'perftest' database. Upload the GRIDFS_LARGE file to the default gridFS bucket with the name "gridfstest". Record the <code>_id</code> of the uploaded file.</td></tr>
<tr><td>Before task</td><td>Construct a GridFSBucket object to use for downloads.</td></tr>
<tr><td>Do task</td><td>Download the "gridfstest" file by its <code>_id</code>. Use whatever download API is most natural for each language (e.g. open_download_stream(), read from the stream into a variable). Discard the downloaded data.</td></tr>
<tr><td>After task</td><td>n/a</td></tr>
<tr><td>Teardown</td><td>Drop the 'perftest' database.</td></tr>
</tbody></table>
</div>
<h3 id="parallel"><a class="header" href="#parallel">Parallel</a></h3>
<p>Datasets are in the 'parallel' tarball.</p>
<p>Parallel tests simulate ETL operations from disk to database or vice-versa. They are designed to be implemented using a
language's preferred approach to concurrency and thus stress how drivers handle concurrency. These intentionally involve
overhead above and beyond the driver itself to simulate -- however loosely -- the sort of "real-world" pressures that a
drivers would be under during concurrent operation.</p>
<p>They are intended for directional indication of which languages perform best for this sort of pseudo-real-world
activity, but are not intended to represent real-world performance claims.</p>
<p>Drivers teams are expected to treat these as a competitive "shoot-out" to surface optimal ETL patterns for each language
(e.g. multi-thread, multi-process, asynchronous I/O, etc.).</p>
<p>Parallel micro-benchmarks include:</p>
<ul>
<li>LDJSON multi-file import</li>
<li>LDJSON multi-file export</li>
<li>GridFS multi-file upload</li>
<li>GridFS multi-file download</li>
</ul>
<h4 id="ldjson-multi-file-import"><a class="header" href="#ldjson-multi-file-import">LDJSON multi-file import</a></h4>
<p>Summary: This benchmark tests driver performance importing documents from a set of LDJSON files.</p>
<p>Dataset: The dataset, designated LDJSON_MULTI (disk directory 'ldjson_multi'), consists of 100 LDJSON files, each
containing 5,000 JSON documents. Each document should be about 1000 bytes.</p>
<p>Dataset size: For score purposes, the dataset size for a task is the total size of all source files: 565,000,000 bytes
or 565 MB.</p>
<div class="table-wrapper"><table><thead><tr><th>Phase</th><th>Description</th></tr></thead><tbody>
<tr><td>Setup</td><td>Construct a MongoClient object. Drop the 'perftest' database.</td></tr>
<tr><td>Before task</td><td>Drop the 'corpus' collection. Create an empty 'corpus' collection with the 'create' command.</td></tr>
<tr><td>Do task</td><td>Do an unordered insert of all 500,000 documents in the dataset into the 'corpus' collection as fast as possible.  Data must be loaded from disk during this phase.  Concurrency is encouraged.</td></tr>
<tr><td>After task</td><td>n/a</td></tr>
<tr><td>Teardown</td><td>Drop the 'perftest' database.</td></tr>
</tbody></table>
</div>
<h4 id="ldjson-multi-file-export"><a class="header" href="#ldjson-multi-file-export">LDJSON multi-file export</a></h4>
<p>Summary: This benchmark tests driver performance exporting documents to a set of LDJSON files.</p>
<p>Dataset: The dataset, designated LDJSON_MULTI, consists of 100 LDJSON files, each containing 5,000 JSON documents. Each
document should be about 1000 bytes.</p>
<p>Dataset size: For score purposes, the dataset size for a task is the total size of all source files: 565,000,000 bytes
or 565 MB.</p>
<div class="table-wrapper"><table><thead><tr><th>Phase</th><th>Description</th></tr></thead><tbody>
<tr><td>Setup</td><td>Construct a MongoClient object. Drop the 'perftest' database. Drop the 'corpus' collection. Do an unordered insert of all 500,000 documents in the dataset into the 'corpus' collection.</td></tr>
<tr><td>Before task</td><td>Construct whatever objects, threads, etc. are required for exporting the dataset.</td></tr>
<tr><td>Do task</td><td>Dump all 500,000 documents in the dataset into 100 LDJSON files of 5,000 documents each as fast as possible. Data must be completely written/flushed to disk during this phase. Concurrency is encouraged. The order and distribution of documents across files does not need to match the original LDJSON_MULTI files.</td></tr>
<tr><td>After task</td><td>n/a</td></tr>
<tr><td>Teardown</td><td>Drop the 'perftest' database.</td></tr>
</tbody></table>
</div>
<h4 id="gridfs-multi-file-upload"><a class="header" href="#gridfs-multi-file-upload">GridFS multi-file upload</a></h4>
<p>Summary: This benchmark tests driver performance uploading files from disk to GridFS.</p>
<p>Dataset: The dataset, designated GRIDFS_MULTI (disk directory 'gridfs_multi'), consists of 50 files, each of 5MB. This
file size corresponds roughly to the output of a (slightly dated) digital camera. Thus the task approximates uploading
50 "photos".</p>
<p>Dataset size: For score purposes, the dataset size for a task is the total size of all source files: 262,144,000 bytes
or 262.144 MB.</p>
<div class="table-wrapper"><table><thead><tr><th>Phase</th><th>Description</th></tr></thead><tbody>
<tr><td>Setup</td><td>Construct a MongoClient object. Drop the 'perftest' database.</td></tr>
<tr><td>Before task</td><td>Drop the default GridFS bucket in the 'perftest' database.  Construct a GridFSBucket object for the default bucket in 'perftest' to use for uploads.    Insert a 1-byte file into the bucket (to initialize indexes).</td></tr>
<tr><td>Do task</td><td>Upload all 50 files in the  GRIDFS_MULTI dataset (reading each from disk). Concurrency is encouraged.</td></tr>
<tr><td>After task</td><td>n/a</td></tr>
<tr><td>Teardown</td><td>Drop the 'perftest' database.</td></tr>
</tbody></table>
</div>
<h4 id="gridfs-multi-file-download"><a class="header" href="#gridfs-multi-file-download">GridFS multi-file download</a></h4>
<p>Summary: This benchmark tests driver performance downloading files from GridFS to disk.</p>
<p>Dataset: The dataset, designated GRIDFS_MULTI, consists of 50 files, each of 5MB. This file size corresponds roughly to
the output of a (slightly dated) digital camera. Thus the task approximates downloading 50 "photos".</p>
<p>Dataset size: For score purposes, the dataset size for a task is the total size of all source files: 262,144,000 bytes
or 262.144 MB.</p>
<div class="table-wrapper"><table><thead><tr><th>Phase</th><th>Description</th></tr></thead><tbody>
<tr><td>Setup</td><td>Construct a MongoClient object. Drop the 'perftest' database. Construct a temporary directory for holding downloads. Drop the default GridFS bucket in the 'perftest' database. Upload the 50 file dataset to the default GridFS bucket in 'perftest'.</td></tr>
<tr><td>Before task</td><td>Delete all files in the temporary folder for downloads. Construct a GridFSBucket object to use for downloads from the default bucket in 'perftest'.</td></tr>
<tr><td>Do task</td><td>Download all 50 files in the GRIDFS_MULTI dataset, saving each to a file in the temporary folder for downloads. Data must be completely written/flushed to disk during this phase. Concurrency is encouraged.</td></tr>
<tr><td>After task</td><td>n/a</td></tr>
<tr><td>Teardown</td><td>Drop the 'perftest' database.</td></tr>
</tbody></table>
</div>
<h2 id="composite-score-calculation"><a class="header" href="#composite-score-calculation">Composite score calculation</a></h2>
<p>Every micro-benchmark has a score equal to the 50th percentile (median) of sampled timings, expressed as Megabytes
(1,000,000 bytes) per second where the micro-benchmark "database size" given in each section above is divided by the
50th percentile of measured wall-clock times.</p>
<p>From these micro-benchmarks, the following composite scores must be calculated:</p>
<div class="table-wrapper"><table><thead><tr><th>Composite Name</th><th>Compositing formula</th></tr></thead><tbody>
<tr><td>BSONBench</td><td>Average of all BSON micro-benchmarks</td></tr>
<tr><td>SingleBench</td><td>Average of all Single-doc micro-benchmarks, except "Run Command"</td></tr>
<tr><td>MultiBench</td><td>Average of all Multi-doc micro-benchmarks</td></tr>
<tr><td>ParallelBench</td><td>Average of all Parallel micro-benchmarks</td></tr>
<tr><td>ReadBench</td><td>Average of "Find one", "Find many and empty cursor", "GridFS download", "LDJSON multi-file export", and "GridFS multi-file download" microbenchmarks</td></tr>
<tr><td>WriteBench</td><td>Average of "Small doc insertOne", "Large doc insertOne", "Small doc bulk insert", "Large doc bulk insert", "GridFS upload", "LDJSON multi-file import", and "GridFS multi-file upload" micro-benchmarks</td></tr>
<tr><td>DriverBench</td><td>Average of ReadBench and WriteBench</td></tr>
</tbody></table>
</div>
<p>At least for this first DriverBench version, scores are combined with simple averages. In addition, the BSONBench scores
do not factor into the overall DriverBench scores, as encoding and decoding are inherent in all other tasks.</p>
<h2 id="benchmark-platform-configuration-and-environments"><a class="header" href="#benchmark-platform-configuration-and-environments">Benchmark platform, configuration and environments</a></h2>
<h3 id="benchmark-client"><a class="header" href="#benchmark-client">Benchmark Client</a></h3>
<p>TBD: spec Amazon instance size; describe in general terms how language clients will be run independently; same AWS zone
as server</p>
<p>All operations must be run with write concern "w:1".</p>
<h3 id="benchmark-server"><a class="header" href="#benchmark-server">Benchmark Server</a></h3>
<p>TBD: spec Amazon instance size; describe configuration (e.g. no auth, journal, pre-alloc sizes?, WT with compression to
minimize disk I/O impact?); same AWS zone as client</p>
<h3 id="score-server"><a class="header" href="#score-server">Score Server</a></h3>
<p>TBD: spec system to hold scores over time</p>
<h3 id="datasets"><a class="header" href="#datasets">Datasets</a></h3>
<p>TBD: generated datasets should be park in S3 or somewhere for retrieval by URL</p>
<h2 id="changelog-49"><a class="header" href="#changelog-49">Changelog</a></h2>
<ul>
<li>
<p>2024-01-22: Migrated from reStructuredText to Markdown.</p>
</li>
<li>
<p>2022-10-05: Remove spec front matter and reformat changelog.</p>
</li>
<li>
<p>2021-04-06: Update run command test to use 'hello' command</p>
</li>
<li>
<p>2016-08-13:</p>
<ul>
<li>Update corpus files to allow much greater compression of data</li>
<li>Updated LDJSON corpus size to reflect revisions to the test data</li>
<li>Published data files on GitHub and updated instructions on how to find datasets</li>
<li>RunCommand and query benchmark can create collection objects during setup rather than before task. (No change on
actual benchmark.)</li>
</ul>
</li>
<li>
<p>2016-01-06:</p>
<ul>
<li>Clarify that 'bulk insert' means 'insert_many'</li>
<li>Clarify that "create a collection" means using the 'create' command</li>
<li>Add omitted "upload files" step to setup for GridFS multi-file download; also clarify that steps should be using the
default bucket in the 'perftest' database</li>
</ul>
</li>
<li>
<p>2015-12-23:</p>
<ul>
<li>Rename benchmark names away from MMA/weight class names</li>
<li>Split BSON encoding and decoding micro-benchmarks</li>
<li>Rename BSON micro-benchmarks to better match dataset names</li>
<li>Move "Run Command" micro-benchmark out of composite</li>
<li>Reduced amount of data held in memory and sent to/from the server to decrease memory pressure and increase number of
iterations in a reasonable time (e.g. file sizes and number of documents in certain datasets changed)</li>
<li>Create empty collections/indexes during the 'before' phase when appropriate</li>
<li>Updated data set sizes to account for changes in the source file structure/size</li>
</ul>
</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="bson-corpus"><a class="header" href="#bson-corpus">BSON Corpus</a></h1>
<ul>
<li>Status: Accepted</li>
<li>Minimum Server Version: N/A</li>
</ul>
<h2 id="abstract-46"><a class="header" href="#abstract-46">Abstract</a></h2>
<p>The official BSON specification does not include test data, so this pseudo-specification describes tests for BSON
encoding and decoding. It also includes tests for MongoDB's "Extended JSON" specification (hereafter abbreviated as
<code>extjson</code>).</p>
<h2 id="meta-46"><a class="header" href="#meta-46">Meta</a></h2>
<p>The key words "MUST", "MUST NOT", "REQUIRED", "SHALL", "SHALL NOT", "SHOULD", "SHOULD NOT", "RECOMMENDED", "MAY", and
"OPTIONAL" in this document are to be interpreted as described in <a href="https://www.ietf.org/rfc/rfc2119.txt">RFC 2119</a>.</p>
<h2 id="motivation-for-change-18"><a class="header" href="#motivation-for-change-18">Motivation for Change</a></h2>
<p>To ensure correct operation, we want drivers to implement identical tests for important features. BSON (and <code>extjson</code>)
are critical for correct operation and data exchange, but historically had no common test corpus. This
pseudo-specification provides such tests.</p>
<h3 id="goals-3"><a class="header" href="#goals-3">Goals</a></h3>
<ul>
<li>Provide machine-readable test data files for BSON and <code>extjson</code> encoding and decoding.</li>
<li>Cover all current and historical BSON types.</li>
<li>Define test data patterns for three cases:
<ul>
<li>conversion/roundtrip,</li>
<li>decode errors, and</li>
<li>parse errors.</li>
</ul>
</li>
</ul>
<h3 id="non-goals-2"><a class="header" href="#non-goals-2">Non-Goals</a></h3>
<ul>
<li>Replace or extend the official BSON spec at <a href="http://bsonspec.org">http://bsonspec.org</a>.</li>
<li>Provide a formal specification for <code>extjson</code>.</li>
</ul>
<h2 id="specification-42"><a class="header" href="#specification-42">Specification</a></h2>
<p>The specification for BSON lives at <a href="http://bsonspec.org">http://bsonspec.org</a>. The <code>extjson</code> format specification is
<a href="bson-corpus/../extended-json/extended-json.html">here</a>.</p>
<h2 id="test-plan-34"><a class="header" href="#test-plan-34">Test Plan</a></h2>
<p>This test plan describes a general approach for BSON testing. Future BSON specifications (such as for new types like
Decimal128) may specialize or alter the approach described below.</p>
<h3 id="description-of-the-bson-corpus"><a class="header" href="#description-of-the-bson-corpus">Description of the BSON Corpus</a></h3>
<p>This BSON test data corpus consists of a JSON file for each BSON type, plus a <code>top.json</code> file for testing the overall,
enclosing document and a <code>multi-type.json</code> file for testing a document with all BSON types. There is also a
<code>multi-type-deprecated.json</code> that includes deprecated keys.</p>
<h4 id="top-level-keys"><a class="header" href="#top-level-keys">Top level keys</a></h4>
<ul>
<li><code>description</code>: human-readable description of what is in the file</li>
<li><code>bson_type</code>: hex string of the first byte of a BSON element (e.g. "0x01" for type "double"); this will be the
synthetic value "0x00" for "whole document" tests like <code>top.json</code>.</li>
<li><code>test_key</code>: (optional) name of a field in a single-BSON-type <code>valid</code> test case that contains the data type being
tested.</li>
<li><code>valid</code> (optional): an array of validity test cases (see below).</li>
<li><code>decodeErrors</code> (optional): an array of decode error cases (see below).</li>
<li><code>parseErrors</code> (optional): an array of type-specific parse error case (see below).</li>
<li><code>deprecated</code> (optional): this field will be present (and true) if the BSON type has been deprecated (i.e. Symbol,
Undefined and DBPointer)</li>
</ul>
<h4 id="validity-test-case-keys"><a class="header" href="#validity-test-case-keys">Validity test case keys</a></h4>
<p>Validity test cases include 'canonical' forms of BSON and Extended JSON that are deemed equivalent and may provide
additional cases or metadata for additional assertions. For each case, keys include:</p>
<ul>
<li><code>description</code>: human-readable test case label.</li>
<li><code>canonical_bson</code>: an (uppercase) big-endian hex representation of a BSON byte string. Be sure to mangle the case as
appropriate in any roundtrip tests.</li>
<li><code>canonical_extjson</code>: a string containing a Canonical Extended JSON document. Because this is itself embedded as a
<em>string</em> inside a JSON document, characters like quote and backslash are escaped.</li>
<li><code>relaxed_extjson</code>: (optional) a string containing a Relaxed Extended JSON document. Because this is itself embedded as
a <em>string</em> inside a JSON document, characters like quote and backslash are escaped.</li>
<li><code>degenerate_bson</code>: (optional) an (uppercase) big-endian hex representation of a BSON byte string that is technically
parseable, but not in compliance with the BSON spec. Be sure to mangle the case as appropriate in any roundtrip tests.</li>
<li><code>degenerate_extjson</code>: (optional) a string containing an invalid form of Canonical Extended JSON that is still
parseable according to type-specific rules. (For example, "1e100" instead of "1E+100".)</li>
<li><code>converted_bson</code>: (optional) an (uppercase) big-endian hex representation of a BSON byte string. It may be present for
deprecated types. It represents a possible conversion of the deprecated type to a non-deprecated type, e.g. symbol to
string.</li>
<li><code>converted_extjson</code>: (optional) a string containing a Canonical Extended JSON document. Because this is itself
embedded as a <em>string</em> inside a JSON document, characters like quote and backslash are escaped. It may be present for
deprecated types and is the Canonical Extended JSON representation of <code>converted_bson</code>.</li>
<li><code>lossy</code> (optional) -- boolean; present (and true) iff <code>canonical_bson</code> can't be represented exactly with extended JSON
(e.g. NaN with a payload).</li>
</ul>
<h4 id="decode-error-case-keys"><a class="header" href="#decode-error-case-keys">Decode error case keys</a></h4>
<p>Decode error cases provide an invalid BSON document or field that should result in an error. For each case, keys
include:</p>
<ul>
<li><code>description</code>: human-readable test case label.</li>
<li><code>bson</code>: an (uppercase) big-endian hex representation of an invalid BSON string that should fail to decode correctly.</li>
</ul>
<h4 id="parse-error-case-keys"><a class="header" href="#parse-error-case-keys">Parse error case keys</a></h4>
<p>Parse error cases are type-specific and represent some input that can not be encoded to the <code>bson_type</code> under test. For
each case, keys include:</p>
<ul>
<li><code>description</code>: human-readable test case label.</li>
<li><code>string</code>: a text or numeric representation of an input that can't be parsed to a valid value of the given type.</li>
</ul>
<h3 id="extended-json-encoding-escaping-and-ordering"><a class="header" href="#extended-json-encoding-escaping-and-ordering">Extended JSON encoding, escaping and ordering</a></h3>
<p>Because the <code>canonical_extjson</code> and other Extended JSON fields are embedded in a JSON document, all their JSON
metacharacters are escaped. Control characters and non-ASCII codepoints are represented with <code>\uXXXX</code>. Note that this
means that the corpus JSON will appear to have double-escaped characters <code>\\uXXXX</code>. This is by design to ensure that the
Extended JSON fields remain printable ASCII without embedded null characters to ensure maximum portability to different
language JSON or extended JSON decoders.</p>
<p>There are legal differences in JSON representation that may complicate testing for particular codecs. The JSON in the
corpus may not resemble the JSON generated by a codec, even though they represent the same data. Some known differences
include:</p>
<ul>
<li>JSON only requires certain characters to be escaped but allows any character to be escaped.</li>
<li>The JSON format is <em>unordered</em> and whitespace (outside of strings) is not significant.</li>
</ul>
<p>Implementations using these tests MUST normalize JSON comparisons however necessary for effective comparison.</p>
<h3 id="language-specific-differences"><a class="header" href="#language-specific-differences">Language-specific differences</a></h3>
<p>Some programming languages may not be able to represent or transmit all types accurately. In such cases, implementations
SHOULD ignore (or modify) any tests which are not supported on that platform.</p>
<h3 id="testing-validity"><a class="header" href="#testing-validity">Testing validity</a></h3>
<p>To test validity of a case in the <code>valid</code> array, we consider up to five possible representations:</p>
<ul>
<li>Canonical BSON (denoted herein as "cB") -- fully valid, spec-compliant BSON</li>
<li>Degenerate BSON (denoted herein as "dB") -- invalid but still parseable BSON (bad array keys, regex options out of
order)</li>
<li>Canonical Extended JSON (denoted herein as "cEJ") -- A string format based on the JSON standard that emphasizes type
preservation at the expense of readability and interoperability.</li>
<li>Degenerate Extended JSON (denoted herin as "dEJ") -- An invalid form of Canonical Extended JSON that is still
parseable. (For example, "1e100" instead of "1E+100".)</li>
<li>Relaxed Extended JSON (denoted herein as "rEJ") -- A string format based on the JSON standard that emphasizes
readability and interoperability at the expense of type preservation.</li>
</ul>
<p>Not all input types will exist for a given test case.</p>
<p>There are two forms of BSON/Extended JSON codecs: ones that have a language-native "intermediate" representation and
ones that do not.</p>
<p>For a codec <em>without</em> an intermediate representation (i.e. one that translates directly from BSON to JSON or back), the
following assertions MUST hold (function names are for clarity of illustration only):</p>
<ul>
<li>for cB input:
<ul>
<li>bson_to_canonical_extended_json(cB) = cEJ</li>
<li>bson_to_relaxed_extended_json(cB) = rEJ (if rEJ exists)</li>
</ul>
</li>
<li>for cEJ input:
<ul>
<li>json_to_bson(cEJ) = cB (unless lossy)</li>
</ul>
</li>
<li>for dB input (if it exists):
<ul>
<li>bson_to_canonical_extended_json(dB) = cEJ</li>
<li>bson_to_relaxed_extended_json(dB) = rEJ (if rEJ exists)</li>
</ul>
</li>
<li>for dEJ input (if it exists):
<ul>
<li>json_to_bson(dEJ) = cB (unless lossy)</li>
</ul>
</li>
<li>for rEJ input (if it exists):
<ul>
<li>bson_to_relaxed_extended_json( json_to_bson(rEJ) ) = rEJ</li>
</ul>
</li>
</ul>
<p>For a codec that has a language-native representation, we want to test both conversion and round-tripping. For these
codecs, the following assertions MUST hold (function names are for clarity of illustration only):</p>
<ul>
<li>for cB input:
<ul>
<li>native_to_bson( bson_to_native(cB) ) = cB</li>
<li>native_to_canonical_extended_json( bson_to_native(cB) ) = cEJ</li>
<li>native_to_relaxed_extended_json( bson_to_native(cB) ) = rEJ (if rEJ exists)</li>
</ul>
</li>
<li>for cEJ input:
<ul>
<li>native_to_canonical_extended_json( json_to_native(cEJ) ) = cEJ</li>
<li>native_to_bson( json_to_native(cEJ) ) = cB (unless lossy)</li>
</ul>
</li>
<li>for dB input (if it exists):
<ul>
<li>native_to_bson( bson_to_native(dB) ) = cB</li>
</ul>
</li>
<li>for dEJ input (if it exists):
<ul>
<li>native_to_canonical_extended_json( json_to_native(dEJ) ) = cEJ</li>
<li>native_to_bson( json_to_native(dEJ) ) = cB (unless lossy)</li>
</ul>
</li>
<li>for rEJ input (if it exists):
<ul>
<li>native_to_relaxed_extended_json( json_to_native(rEJ) ) = rEJ</li>
</ul>
</li>
</ul>
<p>Implementations MAY test assertions in an implementation-specific manner.</p>
<h3 id="testing-decode-errors"><a class="header" href="#testing-decode-errors">Testing decode errors</a></h3>
<p>The <code>decodeErrors</code> cases represent BSON documents that are sufficiently incorrect that they can't be parsed even with
liberal interpretation of the BSON schema (e.g. reading arrays with invalid keys is possible, even though technically
invalid, so they are <em>not</em> <code>decodeErrors</code>).</p>
<p>Drivers SHOULD test that each case results in a decoding error. Implementations MAY test assertions in an
implementation-specific manner.</p>
<h3 id="testing-parsing-errors"><a class="header" href="#testing-parsing-errors">Testing parsing errors</a></h3>
<p>The interpretation of <code>parseErrors</code> is type-specific. The structure of test cases within <code>parseErrors</code> is described in
<a href="bson-corpus/bson-corpus.html#parse-error-case-keys">Parse error case keys</a>.</p>
<p>Drivers SHOULD test that each case results in a parsing error (e.g. parsing Extended JSON, constructing a language
type). Implementations MAY test assertions in an implementation-specific manner.</p>
<h4 id="top-level-document-type-0x00"><a class="header" href="#top-level-document-type-0x00">Top-level Document (type 0x00)</a></h4>
<p>For type "0x00" (i.e. top-level documents), the <code>string</code> field contains input for an Extended JSON parser. Drivers MUST
parse the Extended JSON input using an Extended JSON parser and verify that doing so yields an error. Drivers that parse
Extended JSON into language types instead of directly to BSON MAY need to additionally convert the resulting language
type(s) to BSON to expect an error.</p>
<p>Drivers SHOULD also parse the Extended JSON input using a regular JSON parser (not an Extended JSON one) and verify the
input is parsed successfully. This serves to verify that the <code>parseErrors</code> test cases are testing Extended JSON-specific
error conditions and that they do not have, for example, unintended syntax errors.</p>
<p>Note: due to the generic nature of these tests, they may also be used to test Extended JSON parsing errors for various
BSON types appearing within a document.</p>
<h4 id="binary-type-0x05"><a class="header" href="#binary-type-0x05">Binary (type 0x05)</a></h4>
<p>For type "0x05" (i.e. binary), the rules for handling <code>parseErrors</code> are the same as those for
<a href="bson-corpus/bson-corpus.html#top-level-document-type-0x00">Top-level Document (type 0x00)</a>.</p>
<h4 id="decimal128-type-0x13"><a class="header" href="#decimal128-type-0x13">Decimal128 (type 0x13)</a></h4>
<p>For type "0x13" (i.e. Decimal128), the <code>string</code> field contains input for a Decimal128 parser that converts string input
to a binary Decimal128 value (e.g. Decimal128 constructor). Drivers MUST assert that these strings cannot be
successfully converted to a binary Decimal128 value and that parsing the string produces an error.</p>
<h3 id="deprecated-types"><a class="header" href="#deprecated-types">Deprecated types</a></h3>
<p>The corpus files for deprecated types are provided for informational purposes. Implementations MAY ignore or modify them
to match legacy treatment of deprecated types. The <code>converted_bson</code> and <code>converted_extjson</code> fields MAY be used to test
conversion to a standard type or MAY be ignored.</p>
<h2 id="prose-tests-2"><a class="header" href="#prose-tests-2">Prose Tests</a></h2>
<p>The following tests have not yet been automated, but MUST still be tested.</p>
<h3 id="1-prohibit-null-bytes-in-null-terminated-strings-when-encoding-bson"><a class="header" href="#1-prohibit-null-bytes-in-null-terminated-strings-when-encoding-bson">1. Prohibit null bytes in null-terminated strings when encoding BSON</a></h3>
<p>The BSON spec uses null-terminated strings to represent document field names and regex components (i.e. pattern and
flags/options). Drivers MUST assert that null bytes are prohibited in the following contexts when encoding BSON (i.e.
creating raw BSON bytes or constructing BSON-specific type classes):</p>
<ul>
<li>Field name within a root document</li>
<li>Field name within a sub-document</li>
<li>Pattern for a regular expression</li>
<li>Flags/options for a regular expression</li>
</ul>
<p>Depending on how drivers implement BSON encoding, they MAY expect an error when constructing a type class (e.g. BSON
Document or Regex class) or when encoding a language representation to BSON (e.g. converting a dictionary, which might
allow null bytes in its keys, to raw BSON bytes).</p>
<h2 id="implementation-notes-6"><a class="header" href="#implementation-notes-6">Implementation Notes</a></h2>
<h3 id="a-tool-for-visualizing-bson"><a class="header" href="#a-tool-for-visualizing-bson">A tool for visualizing BSON</a></h3>
<p>The test directory includes a Perl script <code>bsonview</code>, which will decompose and highlight elements of a BSON document. It
may be used like this:</p>
<pre><code class="language-bash">echo "0900000010610005000000" | perl bsonview -x
</code></pre>
<h3 id="notes-for-certain-types"><a class="header" href="#notes-for-certain-types">Notes for certain types</a></h3>
<h4 id="array"><a class="header" href="#array">Array</a></h4>
<p>Arrays can have degenerate BSON if the array indexes are not set as "0", "1", etc.</p>
<h4 id="boolean"><a class="header" href="#boolean">Boolean</a></h4>
<p>The only valid values are 0 and 1. Other non-zero numbers MUST be interpreted as errors rather than "true" values.</p>
<h4 id="binary-2"><a class="header" href="#binary-2">Binary</a></h4>
<p>The Base64 encoded text in the extended JSON representation MUST be padded.</p>
<h4 id="code-1"><a class="header" href="#code-1">Code</a></h4>
<p>There are multiple ways to encode Unicode characters as a JSON document. Individual implementers may need to normalize
provided and generated extended JSON before comparison.</p>
<h4 id="decimal"><a class="header" href="#decimal">Decimal</a></h4>
<p>NaN with payload can't be represented in extended JSON, so such conversions are lossy.</p>
<h4 id="double"><a class="header" href="#double">Double</a></h4>
<p>There is not yet a way to represent Inf, -Inf or NaN in extended JSON. Even if a <code>$numberDouble</code> is added, it is
unlikely to support special values with payloads, so such doubles would be lossy when converted to extended JSON.</p>
<p>String representation of doubles is fairly unportable so it's hard to provide a single string that all
platforms/languages will generate. Testers may need to normalize/modify the test cases.</p>
<h4 id="string"><a class="header" href="#string">String</a></h4>
<p>There are multiple ways to encode Unicode characters as a JSON document. Individual implementers may need to normalize
provided and generated extended JSON before comparison.</p>
<h4 id="dbpointer-1"><a class="header" href="#dbpointer-1">DBPointer</a></h4>
<p>This type is deprecated. The provided converted form (<code>converted_bson</code>) represents them as DBRef documents, but such
conversion is outside the scope of this spec.</p>
<h4 id="symbol"><a class="header" href="#symbol">Symbol</a></h4>
<p>This type is deprecated. The provided converted form converts these to strings, but such conversion is outside the scope
of this spec.</p>
<h4 id="undefined"><a class="header" href="#undefined">Undefined</a></h4>
<p>This type is deprecated. The provided converted form converts these to Null, but such conversion is outside the scope of
this spec.</p>
<h2 id="reference-implementation-24"><a class="header" href="#reference-implementation-24">Reference Implementation</a></h2>
<p>The Java, C# and Perl drivers.</p>
<h2 id="design-rationale-30"><a class="header" href="#design-rationale-30">Design Rationale</a></h2>
<h3 id="use-of-extjson"><a class="header" href="#use-of-extjson">Use of extjson</a></h3>
<p>Testing conversion requires an "input" and an "output". With a BSON string as both input and output, we can only test
that it roundtrips correctly --we can't test that the decoded value visible to the language is correct.</p>
<p>For example, a pathological encoder/decoder could invert Boolean true and false during decoding and encoding. The BSON
would roundtrip but the program would see the wrong values.</p>
<p>Therefore, we need a separate, semantic description of the contents of a BSON string in a machine readable format.
Fortunately, we already have extjson as a means of doing so. The extended JSON strings contained within the tests adhere
to the Extended JSON Specification.</p>
<h3 id="repetition-across-cases"><a class="header" href="#repetition-across-cases">Repetition across cases</a></h3>
<p>Some validity cases may result in duplicate assertions across cases, particularly if the <code>degenerate_bson</code> field is
different in different cases, but the <code>canonical_bson</code> field is the same. This is by design so that each case stands
alone and can be confirmed to be internally consistent via the assertions. This makes for easier and safer test case
development.</p>
<h2 id="changelog-50"><a class="header" href="#changelog-50">Changelog</a></h2>
<ul>
<li>
<p>2024-01-22: Migrated from reStructuredText to Markdown.</p>
</li>
<li>
<p>2023-06-14: Add decimal128 Extended JSON parse tests for clamped zeros with very large exponents.</p>
</li>
<li>
<p>2022-10-05: Remove spec front matter and reformat changelog.</p>
</li>
<li>
<p>2021-09-09: Clarify error expectation rules for <code>parseErrors</code>.</p>
</li>
<li>
<p>2021-09-02: Add spec and prose tests for prohibiting null bytes in null-terminated strings within document field names
and regular expressions. Clarify type-specific rules for <code>parseErrors</code>.</p>
</li>
<li>
<p>2017-05-26: Revised to be consistent with Extended JSON spec 2.0: valid case fields have changed, as have the test
assertions.</p>
</li>
<li>
<p>2017-01-23: Added <code>multi-type.json</code> to test encoding and decoding all BSON types within the same document. Amended all
extended JSON strings to adhere to the Extended JSON Specification. Modified the "Use of extjson" section of this
specification to note that canonical extended JSON is now used.</p>
</li>
<li>
<p>2016-11-14: Removed "invalid flags" BSON Regexp case.</p>
</li>
<li>
<p>2016-10-25: Added a "non-alphabetized flags" case to the BSON Regexp corpus file; decoders must be able to read
non-alphabetized flags, but encoders must emit alphabetized flags. Added an "invalid flags" case to the BSON Regexp
corpus file.</p>
</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="connections-survive-primary-step-down-tests"><a class="header" href="#connections-survive-primary-step-down-tests">Connections Survive Primary Step Down Tests</a></h1>
<p>These tests can be used to verify a driver's compliance with server discovery and monitoring requirements with respect
to handling "not primary" and "node is shutting down" error responses from the server.</p>
<p>These tests apply only to replica set topologies.</p>
<h2 id="server-fail-point"><a class="header" href="#server-fail-point">Server Fail Point</a></h2>
<p>See: <a href="connections-survive-step-down/tests/../../transactions/tests/legacy-test-format.html#server-fail-point">Server Fail Point</a> in the Transactions spec test
suite.</p>
<h3 id="disabling-fail-point-after-test-execution"><a class="header" href="#disabling-fail-point-after-test-execution">Disabling Fail Point after Test Execution</a></h3>
<p>After each test that configures a fail point, drivers should disable the <code>failCommand</code> fail point to avoid spurious
failures in subsequent tests. The fail point may be disabled like so:</p>
<pre><code class="language-javascript">db.runCommand({
    configureFailPoint: "failCommand",
    mode: "off"
});
</code></pre>
<h3 id="consideration-when-using-serverstatus"><a class="header" href="#consideration-when-using-serverstatus">Consideration when using serverStatus</a></h3>
<p>Drivers executing <a href="https://www.mongodb.com/docs/manual/reference/command/serverStatus">serverStatus</a> for connection
assertions MUST take its own connection into account when making their calculations. Those drivers SHOULD execute
<a href="https://www.mongodb.com/docs/manual/reference/command/serverStatus">serverStatus</a> using a separate client not under
test.</p>
<h2 id="tests-3"><a class="header" href="#tests-3">Tests</a></h2>
<h3 id="test-setup"><a class="header" href="#test-setup">Test setup</a></h3>
<p>For each test, make sure the following steps have been completed before running the actual test:</p>
<ul>
<li>Create a <code>MongoClient</code> with <code>retryWrites=false</code></li>
<li>Create a collection object from the <code>MongoClient</code>, using <code>step-down</code> for the database and collection name.</li>
<li>Drop the test collection, using <code>writeConcern</code> "majority".</li>
<li>Execute the "create" command to recreate the collection, using <code>writeConcern</code> "majority".</li>
</ul>
<p>The driver should implement the following tests:</p>
<h3 id="getmore-iteration"><a class="header" href="#getmore-iteration">getMore Iteration</a></h3>
<p>This test requires a replica set with server version 4.2 or higher.</p>
<p>Perform the following operations:</p>
<ul>
<li>Insert 5 documents into a collection with a majority write concern.</li>
<li>Start a find operation on the collection with a batch size of 2, and retrieve the first batch of results.</li>
<li>Send a <code>{replSetFreeze: 0}</code> command to any secondary and verify that the command succeeded. This command will unfreeze
the secondary and ensure that it will be eligible to be elected immediately.</li>
<li>Send a <code>{replSetStepDown: 30, force: true}</code> command to the current primary and verify that the command succeeded.</li>
<li>Retrieve the next batch of results from the cursor obtained in the find operation, and verify that this operation
succeeded.</li>
<li>If the driver implements the <a href="connections-survive-step-down/tests/../../connection-monitoring-and-pooling/connection-monitoring-and-pooling.html">CMAP</a>
specification, verify that no new
<a href="connections-survive-step-down/tests/../../connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#events">PoolClearedEvent</a> has been
published. Otherwise verify that
<a href="https://www.mongodb.com/docs/manual/reference/command/serverStatus/#serverstatus.connections.totalCreated">connections.totalCreated</a>
in <a href="https://www.mongodb.com/docs/manual/reference/command/serverStatus">serverStatus</a> has not changed.</li>
</ul>
<h3 id="not-primary---keep-connection-pool"><a class="header" href="#not-primary---keep-connection-pool">Not Primary - Keep Connection Pool</a></h3>
<p>This test requires a replica set with server version 4.2 or higher.</p>
<ul>
<li>Set the following fail point:
<code>{configureFailPoint: "failCommand", mode: {times: 1}, data: {failCommands: ["insert"], errorCode: 10107}}</code></li>
<li>Execute an insert into the test collection of a <code>{test: 1}</code> document.</li>
<li>Verify that the insert failed with an operation failure with 10107 code.</li>
<li>Execute an insert into the test collection of a <code>{test: 1}</code> document and verify that it succeeds.</li>
<li>If the driver implements the <a href="connections-survive-step-down/tests/../../connection-monitoring-and-pooling/connection-monitoring-and-pooling.html">CMAP</a>
specification, verify that no new
<a href="connections-survive-step-down/tests/../../connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#events">PoolClearedEvent</a> has been
published. Otherwise verify that
<a href="https://www.mongodb.com/docs/manual/reference/command/serverStatus/#serverstatus.connections.totalCreated">connections.totalCreated</a>
in <a href="https://www.mongodb.com/docs/manual/reference/command/serverStatus">serverStatus</a> has not changed.</li>
</ul>
<h3 id="not-primary---reset-connection-pool"><a class="header" href="#not-primary---reset-connection-pool">Not Primary - Reset Connection Pool</a></h3>
<p>This test requires a replica set with server version 4.0.</p>
<ul>
<li>Set the following fail point:
<code>{configureFailPoint: "failCommand", mode: {times: 1}, data: {failCommands: ["insert"], errorCode: 10107}}</code></li>
<li>Execute an insert into the test collection of a <code>{test: 1}</code> document.</li>
<li>Verify that the insert failed with an operation failure with 10107 code.</li>
<li>If the driver implements the <a href="connections-survive-step-down/tests/../../connection-monitoring-and-pooling/connection-monitoring-and-pooling.html">CMAP</a>
specification, verify that a
<a href="connections-survive-step-down/tests/../../connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#events">PoolClearedEvent</a> has been
published</li>
<li>Execute an insert into the test collection of a <code>{test: 1}</code> document and verify that it succeeds.</li>
<li>If the driver does NOT implement the
<a href="connections-survive-step-down/tests/../../connection-monitoring-and-pooling/connection-monitoring-and-pooling.html">CMAP</a> specification, use the
<a href="https://www.mongodb.com/docs/manual/reference/command/serverStatus">serverStatus</a> command to verify
<a href="https://www.mongodb.com/docs/manual/reference/command/serverStatus/#serverstatus.connections.totalCreated">connections.totalCreated</a>
has increased by 1.</li>
</ul>
<h3 id="shutdown-in-progress---reset-connection-pool"><a class="header" href="#shutdown-in-progress---reset-connection-pool">Shutdown in progress - Reset Connection Pool</a></h3>
<p>This test should be run on all server versions &gt;= 4.0.</p>
<p>Perform the following operations on a client configured to NOT retry writes:</p>
<ul>
<li>Set the following fail point:
<code>{configureFailPoint: "failCommand", mode: {times: 1}, data: {failCommands: ["insert"], errorCode: 91}}</code></li>
<li>Execute an insert into the test collection of a <code>{test: 1}</code> document.</li>
<li>Verify that the insert failed with an operation failure with 91 code.</li>
<li>If the driver implements the <a href="connections-survive-step-down/tests/../../connection-monitoring-and-pooling/connection-monitoring-and-pooling.html">CMAP</a>
specification, verify that a
<a href="connections-survive-step-down/tests/../../connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#events">PoolClearedEvent</a> has been
published</li>
<li>Execute an insert into the test collection of a <code>{test: 1}</code> document and verify that it succeeds.</li>
<li>If the driver does NOT implement the
<a href="connections-survive-step-down/tests/../../connection-monitoring-and-pooling/connection-monitoring-and-pooling.html">CMAP</a> specification, use the
<a href="https://www.mongodb.com/docs/manual/reference/command/serverStatus">serverStatus</a> command to verify
<a href="https://www.mongodb.com/docs/manual/reference/command/serverStatus/#serverstatus.connections.totalCreated">connections.totalCreated</a>
has increased by 1.</li>
</ul>
<h3 id="interrupted-at-shutdown---reset-connection-pool"><a class="header" href="#interrupted-at-shutdown---reset-connection-pool">Interrupted at shutdown - Reset Connection Pool</a></h3>
<p>This test should be run on all server versions &gt;= 4.0.</p>
<p>Perform the following operations on a client configured to NOT retry writes:</p>
<ul>
<li>Set the following fail point:
<code>{configureFailPoint: "failCommand", mode: {times: 1}, data: {failCommands: ["insert"], errorCode: 11600}}</code></li>
<li>Execute an insert into the test collection of a <code>{test: 1}</code> document.</li>
<li>Verify that the insert failed with an operation failure with 11600 code.</li>
<li>If the driver implements the <a href="connections-survive-step-down/tests/../../connection-monitoring-and-pooling/connection-monitoring-and-pooling.html">CMAP</a>
specification, verify that a
<a href="connections-survive-step-down/tests/../../connection-monitoring-and-pooling/connection-monitoring-and-pooling.html#events">PoolClearedEvent</a> has been
published</li>
<li>Execute an insert into the test collection of a <code>{test: 1}</code> document and verify that it succeeds.</li>
<li>If the driver does NOT implement the
<a href="connections-survive-step-down/tests/../../connection-monitoring-and-pooling/connection-monitoring-and-pooling.html">CMAP</a> specification, use the
<a href="https://www.mongodb.com/docs/manual/reference/command/serverStatus">serverStatus</a> command to verify
<a href="https://www.mongodb.com/docs/manual/reference/command/serverStatus/#serverstatus.connections.totalCreated">connections.totalCreated</a>
has increased by 1.</li>
</ul>
<h2 id="questions-and-answers-2"><a class="header" href="#questions-and-answers-2">Questions and Answers</a></h2>
<h3 id="do-we-need-to-wait-for-re-election-after-the-first-test"><a class="header" href="#do-we-need-to-wait-for-re-election-after-the-first-test">Do we need to wait for re-election after the first test?</a></h3>
<p>Since test setup requires creation of a collection, a primary must exist, so subsequent tests will block in server
selection until a primary is available again.</p>
<h3 id="why-do-tests-check-for-a-successful-insert-operation-in-addition-to-checking-that-the-pool-was-updated-appropriately"><a class="header" href="#why-do-tests-check-for-a-successful-insert-operation-in-addition-to-checking-that-the-pool-was-updated-appropriately">Why do tests check for a successful insert operation in addition to checking that the pool was updated appropriately?</a></h3>
<p>Ensuring that we can run a successful insert after the primary steps down and without needing to recreate the
<code>MongoClient</code> serves to test the resiliency of drivers in the event of a failover/election. Even though checking for a
successful insert operation does not directly test functionality introduced in this specification, it is a
straightforward way to test driver resiliency against a live replica set undergoing an election. This testing
methodology is in contrast to the one adopted by the SDAM spec tests that rely entirely on mocking with no actual server
communication.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="faas-automated-testing"><a class="header" href="#faas-automated-testing">FaaS Automated Testing</a></h1>
<ul>
<li>Status:</li>
<li>Minimum Server Version: 3.6</li>
</ul>
<hr />
<h2 id="abstract-47"><a class="header" href="#abstract-47">Abstract</a></h2>
<p>This specification is about the ability for drivers to automate tests for "Functions as a Service" from continuous
integration.</p>
<h2 id="meta-47"><a class="header" href="#meta-47">META</a></h2>
<p>The keywords "MUST", "MUST NOT", "REQUIRED", "SHALL", "SHALL NOT", "SHOULD", "SHOULD NOT", "RECOMMENDED", "MAY", and
"OPTIONAL" in this document are to be interpreted as described in <a href="https://www.ietf.org/rfc/rfc2119.txt">RFC 2119</a>.</p>
<h2 id="specification-43"><a class="header" href="#specification-43">Specification</a></h2>
<h3 id="terms-31"><a class="header" href="#terms-31">Terms</a></h3>
<h4 id="faas-2"><a class="header" href="#faas-2">FaaS</a></h4>
<p>"Function as a Service", such as AWS Lambda.</p>
<h3 id="implementing-automated-faas-tests"><a class="header" href="#implementing-automated-faas-tests">Implementing Automated FaaS Tests</a></h3>
<h4 id="aws-lambda"><a class="header" href="#aws-lambda">AWS Lambda</a></h4>
<p>This section describes the required setup of an AWS Lambda function and the steps needed to automate the deployment and
execution of the function in Evergreen.</p>
<h5 id="local-execution"><a class="header" href="#local-execution">Local Execution</a></h5>
<h6 id="prerequisites"><a class="header" href="#prerequisites">Prerequisites</a></h6>
<p>For the initial local setup the following are required:</p>
<ul>
<li>The docker daemon running on the local machine.</li>
<li>The <a href="https://docs.aws.amazon.com/serverless-application-model/latest/developerguide/install-sam-cli.html">AWS SAM CLI</a></li>
</ul>
<p>AWS access MUST be configured, either through <code>$HOME/.aws/credentials</code> or with the following environment variables:</p>
<ul>
<li><code>AWS_ACCESS_KEY_ID</code></li>
<li><code>AWS_SECRET_ACCESS_KEY</code></li>
<li><code>AWS_REGION</code> - Set to us-east-1</li>
<li><code>MONGODB_URI</code> - The local MongoDB instance</li>
</ul>
<h6 id="project-initialization"><a class="header" href="#project-initialization">Project Initialization</a></h6>
<p>Create the new project via SAM and follow the prompts:</p>
<pre><code class="language-bash">sam init
</code></pre>
<p>For the template, select "AWS Quick Start Template".</p>
<pre><code class="language-bash">Which template source would you like to use?
  1 - AWS Quick Start Templates
  2 - Custom Template Location
Choice: 1
</code></pre>
<p>For the quick start template, select "Hello World Example".</p>
<pre><code class="language-bash">Choose an AWS Quick Start application template
  1 - Hello World Example
  2 - Multi-step workflow
  3 - Serverless API
  4 - Scheduled task
  5 - Standalone function
  6 - Data processing
  7 - Infrastructure event management
  8 - Hello World Example With Powertools
  9 - Serverless Connector Hello World Example
  10 - Multi-step workflow with Connectors
  11 - Lambda EFS example
  12 - DynamoDB Example
  13 - Machine Learning
Template: 1
</code></pre>
<p>When prompted for language if the driver language is not Python, select "N".</p>
<pre><code>Use the most popular runtime and package type? (Python and zip) [y/N]: n
</code></pre>
<p>Then select the runtime for your driver:</p>
<pre><code class="language-bash">Which runtime would you like to use?
  1 - aot.dotnet7 (provided.al2)
  2 - dotnet6
  3 - dotnet5.0
  4 - dotnetcore3.1
  5 - go1.x
  6 - go (provided.al2)
  7 - graalvm.java11 (provided.al2)
  8 - graalvm.java17 (provided.al2)
  9 - java11
  10 - java8.al2
  11 - java8
  12 - nodejs18.x
  13 - nodejs16.x
  14 - nodejs14.x
  15 - nodejs12.x
  16 - python3.9
  17 - python3.8
  18 - python3.7
  19 - ruby2.7
  20 - rust (provided.al2)
Runtime: 12
</code></pre>
<p>Select Zip package type:</p>
<pre><code class="language-bash">What package type would you like to use?
  1 - Zip
  2 - Image
Package type: 1
</code></pre>
<p>Then follow the remaining prompts for the driver language to finish setup. Drivers MAY choose to also enable X-Ray
tracing and CloudWatch Application Insights during these next steps.</p>
<p><em>NOTE</em> - If the driver wants to skip prompts in the setup it can provide defaults to the sam init command. Example:</p>
<pre><code class="language-bash">sam init --name my-hello-world-app \
    --app-template "hello-world" \
    --runtime go1.x \
    --package-type Zip
</code></pre>
<h6 id="function-setup"><a class="header" href="#function-setup">Function Setup</a></h6>
<p>In the newly created project directory modify the template.yaml file:</p>
<p>Change default timeout to 30 seconds:</p>
<pre><code class="language-yaml">Globals:
  Function:
    Timeout: 30
</code></pre>
<p>Add a root parameter for the MongoDB connection string:</p>
<pre><code class="language-yaml">Parameters:
  MongoDbUri:
    Type: String
    Description: The MongoDB connection string.
</code></pre>
<p>Replace all instances in the template.yaml of <code>HelloWorld</code> with <code>MongoDB</code> and then modify the root <code>Resources</code> config to
add the MONGODB_URI env variable reference and change the <code>CodeUri</code> to mongodb/ : Then rename the <code>hello-world</code>
directory to <code>mongodb</code>. Do not change the <code>Handler</code> and <code>Runtime</code> properties.</p>
<pre><code class="language-yaml">Resources:
  MongoDBFunction:
    Type: AWS::Serverless::Function
    Properties:
      CodeUri: mongodb/
      Environment:
        Variables:
          MONGODB_URI: !Ref MongoDbUri
</code></pre>
<p>If the generated template contains Resources.Events.CatchAll.Properties.Path then change it to /mongodb and if it also
contains Resources.Handler modify that to mongodb as well.</p>
<pre><code class="language-yaml">Resources:
  Events:
    CatchAll:
      Properties:
        Path: /mongodb
  Handler: mongodb
</code></pre>
<p>If possible, install the current driver under test into the lambda environment, to avoid having to release the driver in
order to test features or catch regressions. See docs on
<a href="https://docs.aws.amazon.com/lambda/latest/dg/configuration-function-zip.html">https://docs.aws.amazon.com/lambda/latest/dg/configuration-function-zip.html</a> for how to create a .zip file deployment
with dependencies.</p>
<p>Start the local MongoDB instance. If using Docker Desktop on MacOS, set
<code>MONGODB_URI=mongodb://host.docker.internal:27017</code> in order for the function to be able to access the host port.</p>
<p>Run the function locally from the same directory where the template.yaml resides:</p>
<pre><code class="language-bash">sam build
sam local invoke --parameter-overrides "MongoDbUri=${MONGODB_URI}"
</code></pre>
<p><em>NOTE</em> "127.0.0.1" in the MONGODB_URI MUST be replaced with "host.docker.internal" to test a local MongoDB deployment.
If "host.docker.internal" does not work (can occur on M1 machines), drivers MAY choose to use a
<a href="https://docs.docker.com/network/bridge/">bridged docker container</a> to test locally.</p>
<h6 id="implementing-the-function"><a class="header" href="#implementing-the-function">Implementing the Function</a></h6>
<p>Drivers MUST setup the function as would be done in their appropriate language. In the function implementation the
driver MUST:</p>
<ul>
<li>Create a MongoClient that points to MONGODB_URI.</li>
<li>Add listeners for the following monitoring events: ServerHeartbeatStarted, ServerHeartbeatFailed, CommandSucceeded,
CommandFailed, ConnectionCreated, ConnectionClosed.</li>
<li>Drivers MUST perform a single insert and then a single delete of the inserted document to force write operations on
the primary node.</li>
<li>Drivers MUST record the durations and counts of the heartbeats, the durations of the commands, as well as keep track
of the number of open connections, and report this information in the function response as JSON.</li>
<li>Drivers MUST assert no ServerHeartbeat events contain the <code>awaited=True</code> flag to confirm that the streaming protocol
is disabled (<a href="https://jira.mongodb.org/browse/DRIVERS-2578">DRIVERS-2578</a>).</li>
</ul>
<h6 id="running-in-continuous-integration"><a class="header" href="#running-in-continuous-integration">Running in Continuous Integration</a></h6>
<p>Running in CI requires Evergreen to be setup to assume the appropriate role in AWS and then execute the script in
drivers-evergreen-tools with the required environment variables. An explanation of the required environment is as
follows:</p>
<div class="table-wrapper"><table><thead><tr><th>Name</th><th>Description</th></tr></thead><tbody>
<tr><td>LAMBDA_AWS_ROLE_ARN</td><td>The role ARN to assume</td></tr>
<tr><td>TEST_LAMBDA_DIRECTORY</td><td>The lambda function directory</td></tr>
<tr><td>DRIVERS_TOOLS</td><td>Location of drivers-evergreen-tools</td></tr>
<tr><td>DRIVERS_ATLAS_PUBLIC_API_KEY</td><td>The Atlas public API key</td></tr>
<tr><td>DRIVERS_ATLAS_PRIVATE_API_KEY</td><td>The Atlas private API key</td></tr>
<tr><td>DRIVERS_ATLAS_LAMBDA_USER</td><td>The Atlas cluster user name</td></tr>
<tr><td>DRIVERS_ATLAS_LAMBDA_PASSWORD</td><td>The Atlas cluster user password</td></tr>
<tr><td>DRIVERS_ATLAS_GROUP_ID</td><td>The driver's Atlas group id</td></tr>
<tr><td>LAMBDA_STACK_NAME</td><td>The driver's Lambda stack name</td></tr>
<tr><td>AWS_REGION</td><td>The function AWS region</td></tr>
<tr><td>AWS_ACCESS_KEY_ID</td><td>Assume role automatically sets this</td></tr>
<tr><td>AWS_SECRET_ACCESS_KEY</td><td>Assume role automatically sets this</td></tr>
<tr><td>AWS_SESSION_TOKEN</td><td>Assume role automatically sets this</td></tr>
</tbody></table>
</div>
<p>Supported Evergreen variants that have the AWS SAM CLI installed:</p>
<ul>
<li>ubuntu2204</li>
<li>ubuntu1804</li>
<li>ubuntu1804-workstation</li>
<li>ubuntu2204-arm64</li>
<li>ubuntu2004-arm64</li>
<li>ubuntu1804-arm64</li>
<li>rhel90</li>
<li>rhel80</li>
<li>rhel84</li>
<li>rhel90-selinux</li>
<li>rhel80-selinux</li>
<li>rhel90-arm64</li>
<li>rhel82-arm64</li>
</ul>
<p>This is an example task group in the Evergreen config that accomplishes this, using subprocess.exec to execute scripts
that call the drivers-evergreen-tools functions inside of it for setup, teardown, and execution:</p>
<pre><code class="language-yaml">tasks:
  - name: "test-aws-lambda-deployed"
    commands:
      - func: "install dependencies"
      - command: ec2.assume_role
        params:
          role_arn: ${LAMBDA_AWS_ROLE_ARN}
          duration_seconds: 3600
      - command: subprocess.exec
        params:
          working_dir: src
          binary: bash
          add_expansions_to_env: true
          args:
            - ${DRIVERS_TOOLS}/.evergreen/aws_lambda/run-deployed-lambda-aws-tests.sh
          env:
            TEST_LAMBDA_DIRECTORY: ${PROJECT_DIRECTORY}/test/lambda
            AWS_REGION: us-east-1
task_groups:
  - name: test_aws_lambda_task_group
    setup_group:
      - func: fetch source
      - command: subprocess.exec
        params:
          working_dir: src
          binary: bash
          add_expansions_to_env: true
          args:
            - ${DRIVERS_TOOLS}/.evergreen/atlas/setup-atlas-cluster.sh
      - command: expansions.update
        params:
          file: src/atlas-expansion.yml
    teardown_group:
      - command: subprocess.exec
        params:
          working_dir: src
          binary: bash
          add_expansions_to_env: true
          args:
            - ${DRIVERS_TOOLS}/.evergreen/atlas/teardown-atlas-cluster.sh
    setup_group_can_fail_task: true
    setup_group_timeout_secs: 1800
    tasks:
      - test-aws-lambda-deployed
</code></pre>
<p>Drivers MUST run the function on a single variant in Evergreen, in order to not potentially hit the Atlas API rate
limit. The variant itself MUST have the SAM CLI installed.</p>
<p>Description of the behaviour of run-deployed-lambda-aws-tests.sh:</p>
<ul>
<li>Builds the Lambda function locally</li>
<li>Deploys the Lambda function to AWS.</li>
<li>Queries for the Lambda function ARN.</li>
<li>Invokes the Lambda function cold and frozen.</li>
<li>Initiates a primary failover of the cluster in Atlas.</li>
<li>Calls the frozen lambda function again.</li>
<li>Deletes the Lambda function.</li>
</ul>
<h2 id="changelog-51"><a class="header" href="#changelog-51">Changelog</a></h2>
<ul>
<li>2024-02-27: Migrated from reStructuredText to Markdown.</li>
<li>2023-08-21: Drivers MUST assert that the streaming protocol is disabled in the Lambda function.</li>
<li>2023-08-17: Fixed URI typo, added host note, increase assume role duration.</li>
<li>2023-06-22: Updated evergreen configuration to use task groups.</li>
<li>2023-04-14: Added list of supported variants, added additional template config.</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="atlas-serverless-tests"><a class="header" href="#atlas-serverless-tests">Atlas Serverless Tests</a></h1>
<ul>
<li>Status: Accepted</li>
<li>Minimum Server Version: N/A</li>
</ul>
<hr />
<h2 id="introduction-2"><a class="header" href="#introduction-2">Introduction</a></h2>
<p>This file describes a subset of existing tests that drivers MUST use to assert compatibility with Atlas Serverless.</p>
<h2 id="serverless-configuration"><a class="header" href="#serverless-configuration">Serverless Configuration</a></h2>
<p>These tests MUST be run against a live Atlas Serverless instance. A new instance MUST be created each time the test
suite is run, and that instance MUST be used for all of the tests required by this specification. Once the tests are
finished, the instance MUST be deleted regardless of the outcome of the tests. The
<a href="https://github.com/mongodb-labs/drivers-evergreen-tools/tree/master/.evergreen/serverless">serverless directory in the drivers-evergreen-tools repository</a>
contains scripts for creating and deleting Atlas Serverless instances, and the <code>config.yml</code> contains an example
Evergreen configuration that uses them to run the tests. It can take up to 15 minutes or so to provision a new Atlas
Serverless instance, so it is recommended to create one manually via the scripts in drivers-evergreen-tools that can be
reused for the initial implementation of the tests before moving to Evergreen patches.</p>
<p>Drivers MUST use the
<a href="https://github.com/mongodb-labs/drivers-evergreen-tools/blob/master/.evergreen/serverless/create-instance.sh">create-instance.sh</a>
script in <code>drivers-evergreen-tools</code> to create a new Atlas Serverless instance for Evergreen tasks. The script writes a
URI for the newly created instance to a YAML expansions file:</p>
<ul>
<li><code>SERVERLESS_URI</code> An SRV connection string to a load balancer fronting a single Atlas Serverless proxy.</li>
</ul>
<p>The <code>expansions.update</code> Evergreen command can be used to read this file and copy the URI into a <code>SERVERLESS_URI</code>
environment variable.</p>
<h2 id="test-runner-configuration"><a class="header" href="#test-runner-configuration">Test Runner Configuration</a></h2>
<p>All tests MUST be run with wire protocol compression and authentication enabled.</p>
<p>In contrast to the <a href="serverless-testing/../load-balancers/tests/README.html">Load Balancer testing</a>, which has separate URIs for load
balancers fronting a single or multiple servers, there is only a single URI for Atlas Serverless testing (i.e.
<code>SERVERLESS_URI</code>).</p>
<p>The TXT record for <code>SERVERLESS_URI</code> already specifies <code>loadBalanced=true</code> so drivers need not add that.</p>
<p><code>SERVERLESS_URI</code> does not include authentication credentials. Drivers MUST specify a username and password (see:
<a href="serverless-testing/index.html#required-variables">Required Variables</a>) when connecting to <code>SERVERLESS_URI</code>.</p>
<p>Drivers MUST use <code>SERVERLESS_URI</code> to configure both internal clients and clients under test (as described in the
<a href="serverless-testing/../unified-test-format/unified-test-format.html">Unified Test Format spec</a>).</p>
<h3 id="required-variables"><a class="header" href="#required-variables">Required Variables</a></h3>
<p>Managing the Atlas Serverless instances and connecting to them requires a few variables to be specified. The variables
marked "private" are confidential and MUST be specified as private Evergreen variables or used only in private Evergreen
projects. If using a public Evergreen project, xtrace MUST be disabled when using these variables to help prevent
accidental leaks.</p>
<ul>
<li><code>${SERVERLESS_DRIVERS_GROUP}</code>: Contains the ID of the Atlas group dedicated to drivers testing of Atlas Serverless.
The backing multi-tenant MongoDB (MTM) MUST have the <code>SINGLE_TARGET_SERVERLESS_DEPLOYMENT</code> feature flag enabled
(<a href="https://jira.mongodb.org/browse/CLOUDP-117288">CLOUDP-117288</a>).</li>
<li><code>${SERVERLESS_API_PUBLIC_KEY}</code>: The public key required to use the Atlas API for managing Atlas Serverless instances.</li>
<li><code>${SERVERLESS_API_PRIVATE_KEY}</code>: (private) The private key required to use the Atlas API for managing Atlas Serverless
instances.</li>
<li><code>${SERVERLESS_ATLAS_USER}</code>: (private) The SCRAM username used to authenticate to any Atlas Serverless instance created
in the drivers testing Atlas group.</li>
<li><code>${SERVERLESS_ATLAS_PASSWORD}</code>: (private) The SCRAM password used to authenticate to any Atlas Serverless instance
created in the drivers testing Atlas group.</li>
</ul>
<h2 id="existing-spec-tests"><a class="header" href="#existing-spec-tests">Existing Spec Tests</a></h2>
<p>Unified spec tests from all specifications MUST be run against Atlas Serverless. Since schema version 1.4, unified tests
can specify Atlas Serverless compatibility in their <code>runOnRequirements</code>.</p>
<p>Any prose and legacy spec tests defined in the following specifications MUST be included in a driver's Atlas Serverless
testing suite:</p>
<ul>
<li>CRUD</li>
<li>Load Balancer</li>
<li>Retryable Reads</li>
<li>Retryable Writes</li>
<li>Sessions</li>
<li>Transactions (excluding convenient API)
<ul>
<li>Note: the killAllSessions command is not supported on Serverless, so the transactions tests may hang if an
individual test leaves a transaction open when it finishes
(<a href="https://jira.mongodb.org/browse/CLOUDP-84298">CLOUDP-84298</a>).</li>
</ul>
</li>
<li>Versioned/Stable API</li>
<li>Client Side Encryption
<ul>
<li>Drivers MUST test with a version of the <code>crypt_shared</code> shared library that matches the MongoDB Server version
running in Serverless. See
<a href="serverless-testing/../client-side-encryption/client-side-encryption.html#enabling-crypt_shared">Using crypt_shared</a>.</li>
</ul>
</li>
</ul>
<p>Note that the legacy JSON/YAML test formats for these specifications were updated to include a new <code>runOnRequirement</code>
specifically for Atlas Serverless testing. To ensure these requirements are enforced properly, the runner MUST be
informed that it is running against an Atlas Serverless instance through some indicator (e.g. an environment variable).</p>
<p>Note that since Atlas Serverless testing uses a load balancer fronting a single Atlas Serverless proxy, the connection
string cannot be modified for <code>useMultipleMongoses</code>. Drivers SHOULD ignore <code>useMultipleMongoses</code> for purposes of Atlas
Serverless testing.</p>
<h2 id="other-tests"><a class="header" href="#other-tests">Other Tests</a></h2>
<p>Any other existing tests for cursor behavior that a driver may have implemented independently of any spec requirements
SHOULD also be included in the driver's Atlas Serverless testing suite. Note that change streams are not supported by
the proxy, so their spec and prose tests MUST be skipped.</p>
<h2 id="changelog-52"><a class="header" href="#changelog-52">Changelog</a></h2>
<ul>
<li>2024-09-02: Migrated from reStructuredText to Markdown.</li>
<li>2022-10-05: Add spec front matter</li>
<li>2022-04-22: Testing uses a load balancer fronting a single proxy.</li>
<li>2021-08-25: Update tests for load balanced serverless instances.</li>
</ul>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->


                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">

            </nav>

        </div>




        <script>
            window.playground_copyable = true;
        </script>


        <script src="elasticlunr.min.js"></script>
        <script src="mark.min.js"></script>
        <script src="searcher.js"></script>

        <script src="clipboard.min.js"></script>
        <script src="highlight.js"></script>
        <script src="book.js"></script>

        <!-- Custom JS scripts -->

        <script>
        window.addEventListener('load', function() {
            window.setTimeout(window.print, 100);
        });
        </script>

    </div>
    </body>
</html>
